<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title></title>
    <link>http://www.94geek.com</link>
    <description>
      属于大嘴的个人blog
    </description>
    
        
            <item>
                <title>台湾技术交流见闻与感想</title>
                <link>http://www.94geek.com/blog/2017/taiwan-ithome/</link>
                <content:encoded>
                    <![CDATA[
                    <h2 id="前言">前言</h2>

<p>这几天有幸因为台湾主办方和国内著名出品人史海峰的邀请前去台湾进行了技术交流。这次技术交流一方面让台湾那边了解目前国内互联网行业的一些技术和状态，另外一方面也让我们可以更加了解台湾互联网技术方面的情况。</p>

<p>毕竟是来交流技术的，所以先说一下我们这次两岸技术交流的情况和我对于这次交流的一些心得和体会。</p>

<h2 id="技术交流">技术交流</h2>

<p>从技术交流的现场来说，台湾的技术交流场面很火爆。基本上座无虚席，还有没有抢到主会场的只能看直播。但架构场相对就没有那么理想了，原因后面会讲到。火爆的会场如图：
<img src="7.jpeg" alt="交流现场" />
台湾目前的互联网技术水平和国内相比，说句实话：相差的有点远。在台湾，大多数的工程师都是FullStack类型，并不像是国内的互联网行业：不想当架构师的程序员不是好程序员。而且台湾的技术工作分工也没有国内细分的详细。在台湾最受欢迎的是前端，并不是架构师等后端职位。我们在架构场开讲的时候做过几个调查：</p>
<ol>
  <li>在座的有多少个是写后端的？举手的只有3个左右，当然我们说的是纯后端。</li>
  <li>这里有多少个title或者日常工作是架构师？ 举手的只有1个。追问：用什么语言？答：python。</li>
</ol>

<p>而我在交流的时候也问了几个问题，有技术也有业务：</p>
<ol>
  <li>看网络小说的有多少？大概有20个人左右，人还是挺多的；</li>
  <li>知道阅文集团/起点/腾讯文学任何一家的？前面举手的大概都知道。这里有个情况，其实我们的一些作品有在台湾播放电视剧，我注意一下台湾的电视台，我至少看见有3部：花千骨，芈月传，甄嬛传在播出。后来打听了一下，甄嬛传几乎被当成了“当时内地的还珠格格那种热度”在台湾播出。对我们来说，这个市场还是很大的；</li>
  <li>技术上就又不一样了，比如讲分库分表和数据路由的时候，基本上下面是一片懵逼。在讲到后面调度系统的时候，quartz这个东西只有3个人听过，cron表达式也只有5个人听过；我调查了一下，写过定时任务的一个都没有。我就有点纳闷：他们的网站难道没有定时任务需要处理吗？</li>
</ol>

<p>我们几个讲师其实也挺费劲，会前讨论应该怎么样让他们听的懂我们在讲什么？会后我们还是在讨论为什么出现这个情况，后来我们总结了一下，主要归结如下：</p>
<ol>
  <li>用户。台湾一共2200w人，内地15亿。没有用户量爆发式增长，所以很多问题都碰不到，他们也就不用解决，像我们陈老师演讲的时候说，我们一开始规划下来需要26个数据库，马上下面的留言板上说，26个数据库，太庞大了，囧；</li>
  <li>必要性。按照目前的机器硬件配置，在没有爆发式增长的情况下，没有架构也好，不要后端也罢，只要会写代码，拉几个开源的就可以上了。可能缓存都用不了，不要说什么读写分离、分库分表这些东西了；</li>
  <li>国外的冲击。米国的互联网台湾都可以用，想fb，google这些都可以，畅通无阻，那么社交他们也主要用line，所以台湾根本没有自主的互联网企业和软件。在“5分钟演讲”环节，有个台湾本地哥们提出来一个问题：台湾有名的软件公司有哪个？只回答了一个“趋势科技”就没了，互联网技术公司一个都没有；</li>
  <li>重视前端。因为碰不到用户量和数据量的关系，又因为大部分东西都是用国外的，所以剩下的能做的就没几样了。你不做前端做什么呢？</li>
</ol>

<p>台湾的互联网技术除了这些之外，还有几个特点：</p>
<ol>
  <li>脚本语言占大多数。我们在场内看到的最多的开发者是用nodejs，再下面就是go之类的新兴语言，也有python之类的脚本。但是国内很多互联网公司喜欢用的java，c/cxx这些语言在这里已经绝迹；</li>
  <li>拼凑。几乎所有的开发都是用了开源的组件拼拼凑凑起来的。印象比较深的是一个哥们讲微服务，然而他并没有去讲微服务怎么怎么实现，而是讲了用了什么什么框架，什么什么组件，在什么什么上，搭起来了。就是那种纯粹的堆积木。我不知道如果这要是放在内地，会不会出去了要挨揍；</li>
  <li>追新。什么新用什么，不会管这个新的东西到底怎么样，是不是适合，这些好像他们不太会去考虑。上面说到的开源使用，有一些就是觉得为了使用而使用，为了体现我们这个东西是多么的新潮，使用了多么cool的新技术就去使用了，而不会去规划和思考底层的问题；</li>
</ol>

<p>这次的技术交流，对于我们内地来的讲师来说，最感同身受的是：<strong>我们的互联网技术确实已经起来了。说句大话，对手可能只有一个了，剩下的都是渣渣！</strong><br />
对于台湾技术来说，要想真的提高，必须也要从商业模式和底层技术开始寻找出路，有了良好的商业模式，有用户开始喜欢使用你们的产品了，自然而然的对一些后端的技术会有更高的要求。技术自然就会跟着起来了。但就从现阶段来看，目前的台湾就像我们在10年前、20年前看硅谷一样：一切都是那么的新奇、牛逼闪闪而高高在上。</p>

<h2 id="台大">台大</h2>

<p>说完演讲正事，再说一下这次的举办场地。主办发选择了台湾大学的社科院作为举办场地让我受宠若惊。第一次站在学术氛围浓厚的大学进行演讲，难免还是有点紧张。演讲之余我们几个大陆来台的讲师也在台大转了一下，我有几个体会：</p>
<ul>
  <li>台大的校门很低调，低调到如果是在路上走，你可能会根本没在意它的存在。
<img src="2.jpeg" alt="台大校门" />
只有走进了看，才能看清楚上面的字。
<img src="1.jpeg" alt="台大校门详细" />
怎么说台大也是出了很多名人的地方，不管是政治届、娱乐圈、工商界、科技界还是学术界，名人都是大把大把的不缺。但是这个校门真的太低调；</li>
  <li>台大内部给我的感觉就像是一个缩小版的东京大学，不管是建筑风格、院系设置还是人文情怀，几乎都是照搬东大而来（PS：后来认识了一个导游哥们，他说台大以前叫帝国大学，是在日本占据台湾的时候兴建的，后来国军入台后才改名台大。回去一查，果然前几任校长都是日本人）。
<img src="3.jpeg" alt="图书馆" />
<img src="4.jpeg" alt="台大校门详细" />
这是国内的电子信息工程系，这里的名字叫什么来着，忘记了，反正挺长而且挺繁琐。
<img src="5.jpeg" alt="电子信息工程系" />
没记错的话应该是日本留学生或者是日本留学生留下的一个雕塑作品（PS：这里可能记不太清了。这个雕塑还有一个是草地上的建筑模型，这两个不知道哪个的作者是日本人了。有点健忘，不好意思）
<img src="6.jpeg" alt="地标：阅读的小女孩" />
这个是台大的图腾。一个钟。上面写着：一天其实只有21个小时，另外3个小时是用来……
<img src="8.jpeg" alt="台大的图腾" /></li>
</ul>

<h2 id="彩蛋">彩蛋</h2>
<p>程序员就是程序员，会后主办方安排我们去领略了一下台湾当地的风俗人情。其中有个放天灯的环节，一般人在天灯上无非都留下些什么“身体健康”，“全家幸福”，“xxx爱你一辈子”这种的话。只有我们程序员的天灯是那么的与众不同：</p>

<p>hello world。其实这个不是我写的，虽然拍的是我。我写的是 root#:rm -rf /
<img src="9.jpeg" alt="hello world" /></p>

<p>来自前端兄弟的javascript是世界上最好的语言。其实我是想用c反驳的，但是家伙狡猾狡猾的，全写满了，不给机会！
<img src="10.jpeg" alt="javascript是世界上最好的语言" /></p>

<p>58沈大师的“当场面试”–快排算法。可惜最后“一致不怀好意的”判定有两个问题：第一个，函数没写全，编译不通过；第二个，递归漏写了退出条件，CPU100%。
<img src="11.jpeg" alt="快排" /></p>

<p>主办方和我们架构场的讲师们
<img src="12.jpeg" alt="我们架构场的讲师" /></p>

<p>这是我们大陆的所有讲师在101大楼，101大楼发生了很多故事，但是只能发这一张了。大陆讲师就缺钟恒了，家伙跑出去单独行动了，目的比较可疑。
<img src="13.jpeg" alt="我们讲师" /></p>


                    ]]>
                </content:encoded>
                <guid isPermaLink="false">/blog/2017/taiwan-ithome/</guid>
                <description>
                    
                </description>
                <pubDate>Sun, 13 Aug 2017 00:00:00 +0800</pubDate>
                <author>94geek.com by Seapeak.Xu</author>
            </item>
        
    
        
            <item>
                <title>网络read函数未判返回0导致CPU 100%</title>
                <link>http://www.94geek.com/blog/2017/read-rc-0/</link>
                <content:encoded>
                    <![CDATA[
                    <p>我们的“运维小帅哥”又来烦我们了！没事就在群里给我们post了一张图，如下：</p>

<p><img src="1.png" alt="show" /></p>

<p><strong>新上线的lest系统的CPU使用率很高！</strong>。一看才17%，不是正常吗？小帅哥爆发了，不对。这是多核，被平均的消耗！实际上两个核已经被吃满了！</p>
<h2 id="检查服务器">检查服务器</h2>

<p>使用top命令看了一下，如下图：<br />
<img src="2.png" alt="top" /></p>

<p>从上图可以看到，cpu的load负载一直在2左右，也就是说其中的2个核已经被占满。再看下面，是被2个cpu沾满的！看一下CPU的情况，其中系统负载和用户负载几乎是一样的，一个是9.1%，另外一个是7.4%。这就是说可能的问题出在用户态，用户态因为需要调用系统调用，把系统的负载带起来了！那么造成这种疯狂消耗CPU的原因基本上99%都是在循环中干了什么傻事，导致循环出不来，疯狂的消耗CPU！</p>

<p>因为是CPU负载比较高，不是什么内存泄露之类的问题，所以没办法通过core来精确的debug。我们只能靠gcore通过人工的方式强行抓取进程的runtimes碰碰运气，看看是不是能看出来一点蛛丝马迹。</p>

<h2 id="debug看runtimes">debug，看runtimes</h2>

<p>首先，加入core后得到的结果如下图：<br />
<img src="3.png" alt="gdb core" /></p>

<p>和上面top对应的是两个线程：25128和24130。因为问题就是出在它们身上，我们进入这2个线程看一下它们到底在做什么，首先看一下线程的编号，如下图：<br />
<img src="4.png" alt="th1" /></p>

<p>当前线程就是28这个，那就直接来吧，运行bt，如下图：<br />
<img src="7.png" alt="bt" />
和前面的几次一样都是啥都没有的？，还是使用%rbp来看一下吧，如下图：<br />
<img src="5.png" alt="rbp" />
这是在读取数据，这个也是正常的调用，但是它是一个“可能的循环”。看上去没发现什么有价值的东西。那么进入到30这个线程看看，如下图：<br />
<img src="6.png" alt="th30" />
这个线程还是在stack的顶端，没在运行。也就是说可能在我们抓取core的一瞬间，此线程正好因为cpu的时间片被让出，啥都没在干。</p>

<p>到目前为止，通过gdb我们没有发现很多有价值的东西，除了那个疑似的可能性循环，但是就这点信息不能确定就是它的问题。也就是说从用户态入手，我们看不太到我们想要的信息，那我们看看系统调用的。</p>

<h2 id="再次求证">再次求证</h2>

<p>使用strace将所有线程的系统调用全部抓取出来，因为线程太多了，容易形成干扰，所以我们使用grep将怀疑有问题的25128线程给抓取出来，如下图：<br />
<img src="8.png" alt="strace" /></p>

<p>为了明确问题，我已经用红色的标记给标出来了！我们发现在整个的系统调用中，一直在循环的调用read，epoll_ctl，这样的函数。再仔细看一下，每次read都欲获取29长度的值（29是header的buffer长度），但是实际得到的长度是0，表示没有数据。也就是说，我们试图每次都获取数据，但每次都没有获取到数据，事件机制又把这个fd给重新加到了epoll中监听了。回忆上面core在gdb中的表现，28线程一直在read数据。那么问题就在这里了。因为没有给read进行合理的返回值过滤，导致错误的返回值也被按照正确对待，重新加入epoll监听，有因为epoll是一个无线循环，而每次又都触发read，所以轻轻松松的就干掉了CPU。</p>

<h2 id="检查代码">检查代码</h2>

<p>回过头来检查代码，read的网络事件都是被组织在spx（是我们的一个c开发组件）中的，查看nio，如下图：
<img src="9.png" alt="code" />
确实没有对read的真实获取长度（就是代码中的&amp;len）为0的情况进行判断，所以发生了这个问题。解决办法也简单，将这个判断加上就可以了。，如下图：<br />
<img src="10.png" alt="code" /></p>

<h2 id="连带问题及其解决">连带问题及其解决</h2>

<p>解决问题，心里美滋滋的。上uat，观察一会儿！突然，我同事和我说，为什么fixed后的版本上传数据失败率有点高啊？多高？50%以上！我x。马上拿一个日志下来看看，如图：
<img src="11.png" alt="log" /></p>

<p>哎呀，很多重试的链接都被强行关闭了。仔细看一下上面的代码，也就是说当spx_read_to_msg_once的err为EAGIN的时候，len也是0，但是代码却先判断了0==len，所以就“变向”过滤掉了err == EAGIN的情况。但是err == EAGIN的情况是正常的，应该被再次加入epoll重试，所以调整一下代码，将0 == len的判断移到判断err的后面，先判断err，就不会出现这种情况下了，代码更改如下：<br />
<img src="12.png" alt="code" /></p>

<p>这样世界终于清静了！上uat，果然畅通，稳定后再上到online，看一下这个cpu的曲线：
<img src="13.png" alt="cpu" /></p>

<p>在这个40°c的天气终于透心凉了！</p>

<h2 id="问题引申">问题引申</h2>

<p>那么还有问题来了，为什么write数据的时候，如果返回值为0不需要判断呢？<br />
其实这个和tcpip的api有关。当read的时候，如果返回值是0，就表示对端已经关闭，所以后续没有数据读取了。write的时候，write的是本地的网络缓冲区，也就是滑动窗口，如果你的额client是一个慢client，读取你滑动窗口的数据特别慢，就会导致你write的时候数据写不进去，但是数据写不进去并不是一个错误，只是要你等client读取过后再试一次而已。所以write返回0加入epoll来使用事件触发是正确的。</p>

                    ]]>
                </content:encoded>
                <guid isPermaLink="false">/blog/2017/read-rc-0/</guid>
                <description>
                    
                </description>
                <pubDate>Tue, 08 Aug 2017 00:00:00 +0800</pubDate>
                <author>94geek.com by Seapeak.Xu</author>
            </item>
        
    
        
            <item>
                <title>解决锁抢占问题--随机式获取抢占锁</title>
                <link>http://www.94geek.com/blog/2017/staircase-locker/</link>
                <content:encoded>
                    <![CDATA[
                    <h2 id="背景">背景</h2>
<p>我们原本的调度系统是由quartz为基准DIY的系统，但因为quartz的很多问题，特别是可扩展设计是在太差、自定义功能太麻烦，我们不得不自行设计了一个调度系统，内部称为：probactr。probactr分为下面几个节点：</p>
<ul>
  <li>monitor：监视器，主要负责监视Executor的状态和Executor执行的job状态，如发现Executor出现down机或者job出现问题，会对其进行清理。此节点为可平行扩展集群；</li>
  <li>Executor：运行器，主要负责从数据库中获取欲执行的job，然后执行job。此节点为可平行扩展集群；</li>
  <li>LockerServer：分布式锁服务器，为probactr提供一致性功能。目前使用redis替代，有计划将其替换成我们自主研发的lax605；</li>
  <li>ManagerSite：后台管理系统，可以在这里对job进行添加、删除、暂停等等的管理，也可以查看job的执行状态；</li>
  <li>database：数据库，所有的job数据全部存入数据库；</li>
</ul>

<p>系统结构图如下：
<img src="1.png" alt="probactr" /></p>

<h2 id="问题表现">问题表现</h2>
<p>probactr在开发环境中没有任何的问题，运行一切正常。上到test环境运行一段时间后发现有几个问题：</p>
<ol>
  <li>可并行job（job分为可并行和不可并行2种）的统计状态不对；</li>
  <li>打开邮箱发现报警邮箱已经被塞爆，据报警信息可知：更新job的状态和统计信息失败，并且基本上1s内可以产生3-4封同样的mail；</li>
</ol>

<h2 id="分析问题">分析问题</h2>
<ol>
  <li>首先，分析一下报警的mail，除了知道是更新状态和统计信息失败以外，还发现一个问题：所有报警的job都是可并行的job，且同一个trigger触发了很多个job；</li>
  <li>接着，看一下job的Executor机器监控，发现CPU很高，有一些核能飙到100%；</li>
  <li>然后，再查看一下数据库，发现被报警的trigger同时运行的job数特别大（我们当时没有对同一个trigger可以触发的job数进行限制）；</li>
  <li>再查看一下别的job，发现一些不可并行的trigger并没有被触发，都被积压了；</li>
</ol>

<p>到这里问题已经很清楚了，出问题的应该是可并行job导致的。首先想到的是可能是<strong>我们没有限制可并行的job数</strong>，导致了可并行job并发特别厉害，我们设置阀值，应该就没有问题了。</p>

<p>我们增加了这个功能，并且上test。发现确实问题减轻了很多，但是并不能完全杜绝。还是会有同样的报警mail出现，只是数量上少了很多。这可以证明问题只是得到了缓解，而并没有彻底解决。所以我们再去找原因。更新job状态的代码只有2处：</p>
<ol>
  <li>job在启动的时候：trigger被scher扫描到，并且scher认为trigger满足被触发的条件。probactr会执行以下路径的代码：获取job的locker-&gt;启动job-&gt;更新job的状态-&gt;释放locker；</li>
  <li>job执行完毕的时候：job执行完毕后，也会执行上面同样的逻辑；</li>
</ol>

<p>但是问题出现的位置应该不会是在job启动时，因为我们对于job的启动进行了weak化，job起不来没关系，下次scher扫描到再起来即可。但是在job结束时却是要强制性的，因为这一步job已经执行完成，必须要更新job的状态和信息，所以必须要成功，否则整个probactr的状态就会出问题。</p>

<p>找到问题就好办了。</p>

<p>再排查下去，更新数据库应该没有问题，因为就一条特别简单的sql语句，唯一能出现问题的地方应该是获取锁了。在job执行完成后，我们需要同时更新job和trigger的状态，所以必须要先获取locker。那么如果可并行job在同一时间结束，而且在同一时间去获取locker，确实可能会出现获取不到锁，然后相当于一直阻塞的状态。我们把并发job的数量改小，相当于同一时间获取的locker的请求量变小了，但是不保证一定没有，所以看起来问题减轻了。但这一步获取locker必须成功，所以保不齐肯定会磕到门牙，问题还是存在。那么为什么有时候CPU会飙升呢？因为我们必须要获取锁，所以一直在loop这个获取锁的功能，CPU当然撑不住。</p>

<h2 id="解决办法">解决办法</h2>
<p>首先想到的解决办法是：能不能放弃最后一步获取locker。但是很遗憾，经过一遍代码回溯发现行不通。不要locker的话还是存在数据不一致问题，job的属性状态和job的统计信息会不对；  <br />
第二：调整获取锁的算法，使用sleep的方式来进行，比如sleep(100ms),这个方法在一定程度上是可以的，但还是会有问题，如果两个job同时抢占locker，如果sleep的时间一样，除了cpu的切换以外，还有一定的概率会第二次，第三次同时被唤醒；  <br />
最后：我们使用了随机值的算法，在一定的范围内，根据我们的算法生成一个值，然后sleep这个随机值。这样可以巧妙的规避掉同时获取locker失败的问题。</p>

                    ]]>
                </content:encoded>
                <guid isPermaLink="false">/blog/2017/staircase-locker/</guid>
                <description>
                    
                </description>
                <pubDate>Tue, 18 Jul 2017 00:00:00 +0800</pubDate>
                <author>94geek.com by Seapeak.Xu</author>
            </item>
        
    
        
            <item>
                <title>PHP&quot;伪司机&quot;调试PHP CORE</title>
                <link>http://www.94geek.com/blog/2017/debug-php/</link>
                <content:encoded>
                    <![CDATA[
                    <p>这次不是装逼，是真的帮忙找问题。对于php，一脸懵逼啊！因为就从来没写过，根本不懂php！</p>

<h2 id="发车">发车</h2>
<p>正常发布日，因为dfs的php客户端需要增加api而更新，就是在更新的过程中发生了问题，具体的表象为：</p>
<ul>
  <li>程序无响应，访问web网页没有显示，直接报无响应；</li>
  <li>CPU100%，服务器的CPU一直100%，非常“稳定”；</li>
  <li>磁盘100%，磁盘监控显示也是100%，但是我们没有任何的磁盘操作啊，除了读php的文件，懵逼ing；</li>
  <li>机器非常慢，执行命令非常慢，慢到无法忍受，甚至打命令都很一个字母一个字母的延迟；<br />
更加诡异的是虽然我们确实更新了php插件，但是这个插件属于提前更新，业务代码并没有使用到这个插件新的api，所以首先排除是因为新插件新增功能的bug导致的，而老的api我们已经用了一年多了，也不会出现问题。那么只有更新的方式不对了？但是这个更新的方式也用了2年多了，以前一直没问题，怎么就今天出现问题了呢？幸好我们打开了core，php进程在crash的时候生成了core，我们可以用gdb调试一下。</li>
</ul>

<h2 id="开车">开车</h2>
<p>还是老路子，首先压入core文件，如下图：
<img src="1.png" alt="php core" />  <br />
从这个图中我们可以得到2个信息，红色的已经标注：</p>
<ol>
  <li>首先core是由php-fpm引起的，问过同事才知道这个是一个php提供web的组件；</li>
  <li>生成core是因为信号11，也就是段错误。引起这个问题一般的问题就是内存错误，比如内存没有释放，使用了野指针，或者是溢出等等；</li>
</ol>

<p>导入php的可执行文件，执行bt查看一下当前的stack情况，如下图：<br />
<img src="2.png" alt="php bt" />  <br />
和上次一样，又是stack info全是？？。但是这次有所不同的，上次的dfs中stack问题是因为stack乱掉，虽然编译的时候加了-g参数，可执行文件保存了调试信息，但还是乱掉了，全是？。而这次的php是因为编译的时候没有加-g参数，所以调试信息压根就没有保存下来，所以在这里看不见到stack info是很正常的；</p>

<p>还是借助寄存器吧，上次就是通过寄存器最后解决了问题，获取一下寄存器的值，如下图：  <br />
<img src="3.png" alt="php regedits" /></p>

<p>再通过x命令看一下rbp之前的stack，如下图：  <br />
<img src="4.png" alt="php stack" />  <br />
通过这个命令可以看到有3个标识出现了，分别是：zend_check_magic_method_implementation，ip_maskr和zif_sha1_file。因为对php很不熟悉，所以只能g一下php的源码，知道一下这3个到底是啥玩意。如下：</p>
<ul>
  <li>zend_check_magic_method_implementation：这个是php的一个函数，主要用来做调用php函数之前的校验之类的用的，这个应该关系不大；</li>
  <li>ip_maskr：这个是一个staic struct,在php的内核crypt_freesec.c文件中182行，大小为8*256，有2048b=2k啊，好大，有重点嫌疑；</li>
  <li>zif_sha1_file： 这个是用来计算每个申请访问文件的hash值的，在这个函数中需要用到ip_maskr的值，这个也是有重大嫌疑；</li>
</ul>

<h2 id="分析">分析</h2>
<p>综上所述，好像发现了一点什么。看最后一张图，上面显示的是ip_maskr+4144，也就是说在ip_maskr的偏移4144处。ip_maskr一共就2k啊，指针的指向不对了，越界了，所以导致了程序crash。那么为什么会指针有问题呢？再要查一下。</p>

<p>这里就和我们更新php的方式有关了。我们使用reload模式更新，难道是因为reload模式的问题？接触这个疑惑的办法就是我们去看一下php在执行reload的时候执行了哪些代码。所有的bug都是由代码导致的，所以看代码还是根本。</p>
<ul>
  <li>首先，查看了一下php-pfm的代码，reload使用了SIGUSR2的信号，这个没有问题，大家都是这么玩的；</li>
  <li>然后，查看SIGUSR2的信号回调函数，如下：</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>    static void sig_soft_quit(int signo)
    {
        int saved_errno = errno;
        /* closing fastcgi listening socket will force fcgi_accept() exit immediately */
        close(0);
        if (0 &gt; socket(AF_UNIX, SOCK_STREAM, 0)) {
            zlog(ZLOG_WARNING, "failed to create a new socket");
       }
       fpm_php_soft_quit();
       errno = saved_errno;
    }
</code></pre>
</div>

<p>问题基本上就是这里了，php确实关掉了监听的socket，但是已经连接了的socket呢，怎么处理了？应该就是因为没有关闭的连接继续执行而静态区的数据已经被破坏，内存映射出现了偏差导致的。g一下，发现php社区其实已经发现了这个问题，bug号：60961。有兴趣大家可以关注一下。可悲的是，我们不小心踩了雷。</p>

<p>问题最后是找到了，但是上面cpu和磁盘都100%的问题又是什么原因呢？   <br />
这个其实是牵连问题，也和php有关系。因为php使用fastcgi来处理web请求，执行之间使用父子进程模式，父进程监控子进程的健康状况和重启子进程；而子进程是多子进程，是真正执行处理的地方，我们的服务器上开了有300个子进程，php的客户端访问会被分配到每个执行的子进程上。然而悲剧的也就是子进程多的时候，当子进程crash的时候，我们又给系统开了core文件生成，所以这300个进程又同时写core文件，所以CPU和磁盘肯定都是100%的负载。</p>

<h2 id="解决办法">解决办法</h2>
<p>处理办法也很简单，堵住问题的引起点就行了。不要使用reload模式，而是先把服务器下线，然后确保没有连接后，使用restart方式重启php，再将更新完成的php上线就没有问题了。</p>


                    ]]>
                </content:encoded>
                <guid isPermaLink="false">/blog/2017/debug-php/</guid>
                <description>
                    
                </description>
                <pubDate>Tue, 11 Jul 2017 00:00:00 +0800</pubDate>
                <author>94geek.com by Seapeak.Xu</author>
            </item>
        
    
        
            <item>
                <title>为什么这样设计Chaos</title>
                <link>http://www.94geek.com/blog/2017/chaos-qa/</link>
                <content:encoded>
                    <![CDATA[
                    <p>随着上一篇介绍Chaos的文章推送，最近有好几家公司或者项目负责人联系我，准备在生产环境中使用Chaos，所以也会经常被问到一些问题。这里我总结了一下经常会被问到的几个问题，给大家做一个统一的回答吧！</p>

<ol>
  <li>怎么样搭建Chaos的集群环境？<br />
这个问题分为2步：
    <ul>
      <li>首先是配置mid：chaos的配置文件中有一个配置项是mid，这个mid就是每台chaos服务器的唯一标识，目前支持配置值是0-9的数字。只要在一个集群中保证每台chaos的mid不一样即可。</li>
      <li>在chaos的前端放一个ngx或者是HA这种的带有“负载均衡”功能的反向代理服务器，将各自单台的chaos组合起来即可，我们用的是ngx；</li>
    </ul>
  </li>
  <li>
    <p>chaos进程起来都是“回话模式”，退出term就没了，怎么设置“后台运行”，难道要自己加&amp;？<br />
chaos当然不会傻到让使用方自己加&amp;来daemon化，chaos的配置文件中有一个配置项daemon，把这一项设置成true即可。</p>
  </li>
  <li>chaos起不来，出现libev.so can not found的错误，这是怎么回事？<br />
这是因为你虽然安装了libev，但是有的系统（比如centos）不会自动去更新系统的so缓存，所以你需要更新一下系统的so缓存。
    <ul>
      <li>执行命令：echo “/usr/local/lib” » /etc/ld.so.conf.d/x86_x64_linux_libev.conf ；</li>
      <li>ldconfig -v
搞定。</li>
    </ul>
  </li>
  <li>
    <p>为什么chaos起来后本地可以访问，换台机器就不能访问了？<br />
首先你要排除一下你的防火墙，iptables之类的配置是不是都已经开启chaos所使用的端口了。如果已经支持了，那么请看一下chaos配置文件中的配置项bind_ip这个项的值是多少，默认是127.0.0.1，请将这个配置项改成chaos服务器所在的外网可以访问的ip，重启chaos，你就可以在另外一台机器上获取id了。</p>
  </li>
  <li>chaos在集群的情况下（特别是不同机器之间）生成的id是保证单调自增的吗？<br />
不是，chaos生成的id在集群的情况下不保证严格的单调递增，特别是1s内生成的id，但chaos肯定保证2s内生成的id具有严格单调递增性，也就是说后一秒生成的id值肯定大于前一秒生成的id值。造成这个原因主要是因为几点：
    <ul>
      <li>严格单调递增不是不能做到，而是消耗的资源太多了。现在chaos在集群情况下是没有主从之分的，也没有相互之间的任何通讯，从而保证了我们获取一个id的快速性，也保证了chaos整个的简单性；</li>
      <li>获取id后，我们经常做的一个动作就是分库分表操作，所以id会被根据业务规则散落到各个“段表”中，在这过程中，时间应该会在ms或者是s级别，所以chaos严格递增性其实没有那么大的实际需求，我们就可以不优先实现这个功能；</li>
      <li>系统的健壮性。平行的chaos功能设计有利于chaos的部署简单化和提高chaos的系统鲁棒性，不管chaos的机器发生什么问题，就算机器down掉或者直接换掉，chaos都可以快速的通过使用新机器、新节点来提供新的功能，不需要恢复数据、操作日志（因为根本就没有，每次的id都是纯计算生成的）等等； <br />
PS：我们有支持严格单调递增的id生成器，是另外一个系统：lax605。lax605在我们的系统中更多的被用来作为分布式协调器的角色使用，类似于zookeeper。</li>
    </ul>
  </li>
  <li>
    <p>chaos生成的id是否存在浪费？怎么处理？  <br />
有浪费现象，比如现在每台机器每秒都可以支持最大2560000个id的生成，但是因为99.9999%的时候你根本就用不到那么多的id，真实的业务量大概每秒也就几百或者几千的id生成，从而因为id中存在序列号，所以没有被轮询到的id就直接被扔掉了，这确实有浪费现象。怎么处理？chaos就没有去处理，因为我们觉得这个没啥必要，反正每秒id那么多，而且对于业务来说如果分库分表规则是按照时间等作为路由是要严格保证时间上的正确性的，综上我们就不去过多的去做额外的处理了。但如果有业务方确实觉得id是一个虚缺资源，需要每一个都不放过，那么可以通过中继器来过渡一下，自己做一个每个id的存储和分发。但是在这么做之前，我觉得要冷静下来思考一个问题：这种做法真的有必要吗？</p>
  </li>
  <li>
    <p>chaos生成的id最大值是多少？多长？长度固定吗？       <br />
chaos生成的是一个uint64的数，最大的长度是64位，一共最长是18个数字的长度。但是因为id和时间相关，所以开始的时候id的个数长度会比较短，大概在15位左右。所以id的长度是不固定的。</p>
  </li>
  <li>chaos的客户端有没有java的？<br />
首先，chaos目前支持两种方式访问：tcp和http。java的客户端也确实有，并且也有开源（在albianj项目中），java的客户端就是通过tcp方式访问的。但就我们自己使用的实际情况和实际效果来看，我们不推荐使用java客户端的tcp方式，我们推荐大家更多的使用http来访问chaos，主要有几点：
    <ul>
      <li>http相比tcp更容易调试，curl或者是浏览器就可以直接调试；</li>
      <li>http相比tcp，http没有语言的相关性需求，当一个公司或者项目大了以后不保证所有的功能都是java来实现的，所以客户端模式会很蛋疼的需要很多的客户端；</li>
      <li>对于tcp的通讯相比http性能高的问题，chaos这种访问都是在内网，用http和tcp能差多少？</li>
    </ul>
  </li>
  <li>
    <p>id生成器目前在公司内部使用的怎么样？  <br />
目前公司内部的内容中心、起点改造等站点正在使用id生成器，每天的请求量总体加起来过亿，一共花费了4台普通的pc服务器。id生成器从上线的那天开始一直到今天有2年多了，中间除了因为功能增加以外从来没有down机，也没有重启记录。稳定性达到惊人的100%。可以算是公司内最稳定的线上运行项目，没有之一。</p>
  </li>
  <li>
    <p>目前有几家公司正在使用？  <br />
到今天为止，一共有10+家公司已经在线上使用id生成器，目前来咨询有使用意向的也有7-8家。我们是最大的一家：阅文集团，该集团是腾讯文学、盛大文学合并而成的。请求量和数据量在网络文学届也是数一数二的。</p>
  </li>
  <li>评价一下别的id生成器，和chaos有什么差别？ <br />
这nm怎么评价，谁都是看自己家的孩子更好看，更可爱啊！不要搞事啊！我严重怀疑问我这个问题的人的居心，但一看问这个问题的还挺多。nm，果然都是来搞事的。不过话说回来，虽然我确实看了很多友商的id生成器设计或者是成品，各有千秋，各有优势吧！我觉得我们的chaos主要有几个优势：
    <ul>
      <li>在架构上更加的简单，平行化的设计，没有单点或者主从的问题，也没有机器的浪费问题，都是主；</li>
      <li>依赖少，除了依赖网络库libev，没有什么mysql数据库或者redis这种依赖（PS：其实我也觉得很奇怪，为嘛一个id生成器需要依赖数据库或者是redis这种玩意，这种东西到底在id生成器中有啥用？除了复杂化设计外，没看到什么必要）；</li>
      <li>性能上更牛X一些吧，c语言，事件机制，相比java之类的，那是相当妥妥的；</li>
      <li>可读性上更人性化一些，十进制的数字，基本上都能看的懂；</li>
      <li>协议更简单一些，支持http，无语言相关性；</li>
      <li>更适合作为数据库的主键来使用，特别是需要做分布式数据库的情况，有分库分表等等数据路由的情况特别适合；</li>
    </ul>
  </li>
</ol>

                    ]]>
                </content:encoded>
                <guid isPermaLink="false">/blog/2017/chaos-qa/</guid>
                <description>
                    
                </description>
                <pubDate>Wed, 05 Jul 2017 00:00:00 +0800</pubDate>
                <author>94geek.com by Seapeak.Xu</author>
            </item>
        
    
        
            <item>
                <title>gdb线上crash调试-记一次装逼失败的教训</title>
                <link>http://www.94geek.com/blog/2017/gdb-stacksize/</link>
                <content:encoded>
                    <![CDATA[
                    <p>可惜这是一次完完全全的装逼不成反被X的典型例子。</p>

<h2 id="背景">背景</h2>
<p>有一天早晨刚到公司，运维小帅哥突然通知我，我们的dfs在平稳运行了一年时间后，在没有任何异常波动、没有任何资源报警、没有任何升级，也没有任何违规操作的情况下，毫无征兆的crash了。<br />
小帅哥一头雾水，我一脸懵逼。<br />
dfs是我们的核心服务，绝对不能down机的，所以就先紧急把它拉了起来。命好的是，起来后程序又平稳运行了，既不crash也不拒绝服务，服务和性能又都是杠杠的。这就让我更懵逼了。</p>

<h2 id="怀疑">怀疑</h2>
<p>首先怀疑的是内存泄漏一类的资源泄漏问题。毕竟dfs是c写的，内存、fd、locker等等的资源处理太多太杂了。特别是内存，几乎每个函数内都会出现。所以重点对象就是它。</p>
<ol>
  <li>找运维查看一下报警系统是不是有没有发出来的报警？查了一下没有。</li>
  <li>自己还是不放心，直接看了一下线上产生的core文件，大小也只有mb级别，确定确实没有溢出。</li>
</ol>

<p>接下来，怀疑是fd或者locker。</p>
<ul>
  <li>先说locker。dfs是我们自己设计的无锁处理算法，根本不存在locker的资源操作，所以这个也被排除了。</li>
  <li>fd，文件描述符。如果fd有溢出，我们也对fd加了报警，报警系统是不会不报的。就算漏了，fd溢出的现象也不应该是进程直接crash，而是会无响应才对。而且去查看了一下log，并没有发现执行close有错误的迹象。</li>
</ul>

<p>到目前为止，所有所能想到的原因全部不成立，线索全部中断。那么如果非要弄清楚这次crash到底为了什么，唯一的办法就是去看程序的runtimes。</p>

<h2 id="碰碰运气">碰碰运气</h2>
<p>反正线上的core文件都已经生成了，不玩白不玩。通知运维把core给拿下来，我非得去看看到底为啥就crash了？不看不要紧，一看就自己打了自己的脸啊！</p>

<ol>
  <li>加载core文件，发现程序是因为收到信号6的原因进程被退出的。如下图：
<img src="1.png" alt="single 6" />
信号6，也就是SIGABRT，Linux的man解释：由调用abort函数生成的信号。引起这个信号的可能性有很多，所以这一点没啥用。</li>
  <li>加载可执行文件，然后看看crash的一瞬间的堆栈是一个什么情况，好做一个大概的判断：哪一行代码可能出现了问题。
<img src="2.png" alt="load file" />
执行bt命令后，显示出来的stack信息全是？？，出现这种情况的可能性有2个：
    <ul>
      <li>可执行被重新编译了，导致了新的可执行文件的元数据和core文件中的元数据对不上，这个首先被排除，我们的可执行文件都是从线上直接拖下来的，所以不可能出现这种情况（这里也要告诫大家，千万要保留运行时程序的可执行文件版本，包括.o文件等）；</li>
      <li>stack已经被破坏了。这种情况很容易就会发生。程序在运行的过程中因为stack，array等溢出的问题没有第一时间被crash，接着在执行命令的时候，产生的core文件stack可能就会被破坏；</li>
    </ul>
  </li>
</ol>

<p>目前来看，我们所能拿到的信息都已经指向了线索中断。操作系统给出的信号不能定位问题，使用gdb调试core因为stack被破坏无法再进一步。那么还有没有别的办法呢？</p>

<h2 id="再进一步">再进一步</h2>
<p>竟然stack已经被破坏，gdb也无法认出，按照正常的路子是解决不了这个问题了。所以这时候“野路子”（其实是更合理更深层次的解决方案）就上场了。既然被破坏，那就恢复它或者是想办法绕过它。<br />
恢复stack的难度有点大，你首先得知道core文件所有的元数据信息，然后和可执行文件的元数据信息一一合并，还要考虑程序在runtime状态下的内存状态，难度确实是相当的大。所以这一步首先被排除了。<br />
那就绕过它。考验计算机操作系统原理和计算机运行原理的时刻来了（所以要多读书）。<br />
首先我们知道所有的程序都是由cpu来执行机器指令的，和cpu执行指令相互配合的是寄存器，其中有几个寄存器记录了当前程序runtime状态下的地址，比如esp/rsp，ebp/rbp等寄存器。也就是说我如果知道程序crash的时候寄存器的值，可能就有希望能复原当时的stack。
方针已经制定，就看执行了。</p>
<ol>
  <li>首先看一下各个寄存器的值，如下图:
<img src="3.png" alt="regediter" />
别的都不用看，只要看一下rbp和rsp的值就可以了。
    <ul>
      <li>rsp表示是当时程序runtime的时候栈顶的地址值；</li>
      <li>rbp表示当时程序执行到的指令的地址值；</li>
    </ul>
  </li>
  <li>
    <p>再看一下执行到rbp的指令的时候，程序前面都执行了什么指令，如下图：
<img src="4.png" alt="rbp" />
哈哈，终于看到函数了。spx_socket_connect_nb和ydb_storage_heartbeat_send。按照stack的FILO的原理，是执行到spx_socket_connect_nb的时候程序发生了问题。具体的地址在函数的地址+611处。先看一下汇编，查一下地址看看能不能看出来一点什么？如图：
<img src="5.png" alt="code" />
好像没啥，前面就是给connect构造结构体，后面就是调用connect。但是问题确实是在connect之前就crash了啊。查看一下代码:</p>

    <div class="highlighter-rouge"><pre class="highlight"><code> err_t spx_socket_connect_nb(int fd,string_t ip,int port,u32_t timeout){
     struct sockaddr_in addr;
     bzero(&amp;addr,sizeof(addr));
     addr.sin_family = AF_INET;
     addr.sin_port=htons(port);
     addr.sin_addr.s_addr = inet_addr(ip);
     err_t err = 0;
     err_t rc = 0;
     if(0 &gt; connect(fd,(struct sockaddr *) &amp;addr,sizeof(addr))){
         //filter this errno,
         //socket is not connect to server and return at once
         if (EINPROGRESS == errno) {
             struct timeval tv;
             SpxZero(tv);
             tv.tv_sec = timeout;
             tv.tv_usec = 0;
             fd_set frd;
             FD_ZERO(&amp;frd);
             FD_SET(fd,&amp;frd);
             socklen_t len = sizeof(err);
             if (0 &lt; (rc = select (fd+1 , NULL,&amp;frd,NULL,&amp;tv))) {
                 if(0 &gt; getsockopt(fd,SOL_SOCKET,SO_ERROR,(void*)(&amp;err),&amp;len)) {
                     err = errno;
                     return err;
                 }
                 if (0 != err) {
                     return err;
                 }
             } else if(0 == rc) {
                 err = ETIMEDOUT;
                 return err;
             } else {
                 err = EXDEV;
                 return err;
             }
             SpxErrReset;
             return 0;
         } else {
             return errno;
         }
     }
     return 0;
 }
</code></pre>
    </div>
  </li>
</ol>

<p>确实前面我们就构建了一个struct sockaddr_in的结构体，然后我们就直接connect了。貌似不会出问题，而且代码也已经运行了很久很久了。但是突然间，有种预感冥冥中就出来了。nm可能就这里出问题了。去看一下配置文件，其中的配置项：
<code class="highlighter-rouge">stacksize = 64kb</code>
直刺眼睛啊！火辣辣的。<br />
这个配置项用来做什么的？其实这个配置项是用来限制系统的stack大小的。也许很多同学都没有听过东东，但是如果你在linux上运行一下命令：
<code class="highlighter-rouge">ulimit -a</code>
<img src="6.png" alt="ulimit -a" />
会出来如上图的一排设置，其中红色框框圈出来的就是这个stacksize的值。在这台机器上默认的是8mb。stacksize的设置在每种linux发行版上的值可能都是不同的。当初就是为了“装逼”，显示自己的编程水平，将stacksize设置成了64kb，这样程序中每个线程最大的stack可用大小就是64kb，你看看我控制系统资源控制的多好？！结果，当碰上一不小心不注意的时候，stack的size马上就超出了64kb，这样stack就溢出了。当然程序就会crash，stack也当然的被破坏了。<br />
那么为什么我们的会出现这个问题呢？</p>
<ol>
  <li>sockaddr_in的结构体其实并不是很大，但是它申请的是stack的内存，原来使用的内存大小+sockaddr_in的大小应该正好碰上临界点；所以sockaddr_in的申请应该是最后一根稻草；</li>
  <li>ydb_storage_heartbeat_send这个函数是在heartbeat线程中运行的，heartbeat线程是一个常驻线程，由timer事件来触发，每次都会向tracker发送心跳数据，所以可能会存在stack因为某些原因，导致了再一次运行中申请的内存比较多，比如log记日志的时候；</li>
  <li>那么为什么不起来就出现这个问题呢，而是要在运行了一段时间后呢？这个问题其实没办法确定申请stack的时间点，比如因为网络的问题我需要记录日志，然而又不是时时刻刻网络不行的，正好在某个瞬间网络不行，申请stack内存记录日志，这样没有释放正好被抓到；</li>
  <li>又因为heartbeat是常驻线程，所以stack基本上不太会被第一时间回收，肯定要在事件处理的最后被回收，所以在一次事件处理内一定要确保有适当的大小来满足程序对于stack的需求；<br />
原因也找到了，怎么解决这个问题呢？有几种办法：</li>
  <li>不要装逼了，直接这个项不用设置。我们的程序使用的是事件模型，并不是像java一样的每个connection一个处理线程，dfs是一个线程对应着多个connection，所以线程数并不多，就算是每个线程最大的stacksize是8mb，也用不了多少的内存；</li>
  <li>把配置文件中的stacksize改大一点，比如1024kb什么的就可以了。</li>
</ol>

<h2 id="经验教训">经验教训</h2>
<p>因为stacksize这个项的设置导致了出问题的人我不是第一个，也不会是最后一个，仅仅在dfs出了这个问题的时候，我就知道还有别人因为同样的问题导致程序被crash，只是当时程序跑的好好的我就没有多加注意。所以在这里诚恳的告诫大家：<br />
莫装逼，装逼遭雷劈;<br />
莫装帅，装帅遭人踹;<br />
莫装吊，装吊遭狗咬…</p>

                    ]]>
                </content:encoded>
                <guid isPermaLink="false">/blog/2017/gdb-stacksize/</guid>
                <description>
                    
                </description>
                <pubDate>Tue, 27 Jun 2017 00:00:00 +0800</pubDate>
                <author>94geek.com by Seapeak.Xu</author>
            </item>
        
    
        
            <item>
                <title>如何更好的做一堂技术topic分享的套路</title>
                <link>http://www.94geek.com/blog/2017/how-do-topic/</link>
                <content:encoded>
                    <![CDATA[
                    <p>很荣幸的被csdn选中担任sdcc2017深圳架构场的出品人。更荣幸的是，我推荐团队一个小伙伴的技术topic也被选中，将在sdcc20017深圳场和大家分享。但这位小伙伴是第一次作为讲师参加技术topic这样的活动，所以培训小伙伴的事情就成了当务之急。作为一个经常出入技术topic、已经无所谓脸皮不脸皮的过来人，对做一堂还算相对“和谐与靠谱”的技术topic到底有多少的套路呢？</p>

<p>总的来说， 一堂技术topic的套路分为几个部分：</p>
<ol>
  <li>PPT</li>
  <li>前期准备</li>
  <li>分享中</li>
  <li>结束</li>
</ol>

<h2 id="ppt">PPT</h2>
<p>PPT永远是一马当先的部分！ppt在整个的topic中占的比重应该是最大的。原因有几个：</p>
<ol>
  <li>前期主办方唯一需要并且讲师唯一能证明自己的东西；</li>
  <li>你所要表达的思想和内容都在这张PPT中；</li>
  <li>在分享中，PPT也是你主要依赖的对象，是你控制整个topic的主线轴；</li>
  <li>ppt会被主办方以各种形式下发，以确保影响力；</li>
</ol>

<p>所以我们需要更加重视的对待ppt。按照我目前参加技术topic的讲师经验和这次的出品人经验，总结讲师在做PPT时候注意点有以下几个：</p>
<ol>
  <li>字体。ppt中的字体要尽量的大。有的同学会问我：具体要多大？能不能给一个明确的号数？答案是然后并没有。但如果可以的话，把字体设置成所能设置的最大号。大到你觉得这页PPT不好看了，就像“老人手机屏幕”一样了，基本上就可以了。也有很多同学不理解，为什么好好的一页PPT字体要那么大呢？作为讲师你必须要考虑现场，ppt的字体小了，topic现场后面的同学看不见。而讲师在做PPT的时候通常是没察觉的，因为讲师做完PPT预览的时候都是在自己的电脑屏幕上进行的，所以并没有现实的距离感。</li>
  <li>色彩。这里推荐的色彩是“暗色系的底、亮色系的字”。这样的设定可以最大程度的提高对比度，以帮助现场的同学尽可能清楚的看清楚ppt上的内容。在制作ppt的过程中，尽量不要使用中色系的颜色，也不要使用晃眼的亮色系，比如黄色等等颜色，使用晃眼的亮色系颜色在现场再加上投影或者是LED的光源，不仅仅是看不清的问题，而是眼睛会很疼。</li>
  <li>背景。一般主办方会给你一个他们设定的母版页来作为你整个ppt的基调。但是请大家注意，如果对方给的母版页的背景是很花里胡哨的、或者是背景图画部分特别多（占到整张PPT的25%以上的），这样的就需要讲师自己权衡一下了。要么你自己做母版页自己设定背景，要么就不要背景，直接白色。其实依照我的经验，你拿到的母版页不和你口味的比率占到99%以上。所以在可能得情况下，尽量的自己做背景，而对于技术的topic，强烈推荐纯白色背景。</li>
  <li>分辨率。目前国内的投影器或者是led屏幕，大部分都是4:3的分辨率，而我们的电脑基本上都是16:9，所以请各位在制作ppt的时候一定要事先和主办方或者是出品人沟通好，现场的ppt屏幕比例到底是多少，然后再开始你的ppt。特别是对于有特效的同学，当你的显示比例不对的时候，动画的效果会很差很差。</li>
  <li>内容。内容主要分以下几块：
    <ul>
      <li>个人介绍. 个人介绍一般都是必不可少的。毕竟你又不是什么人尽皆知的大人物，在开场的时候做个个人介绍还是很有必要的，一来可以让大家先认识一下你，知道你在哪里做什么工作；二来如果你可以在这个阶段加入一些你公司的产品介绍就更好了，在增加人家对你印象的同时顺便给公司做了一个“软广”。</li>
      <li>目录。这部分很简单，一般也是必不可少的。</li>
      <li>正文。正文需要说几个注意点：
        <ul>
          <li>字。在ppt中尽量避免一大段一大段文字的情况。这种大段大段的文字基本上没人看。如果要出现这种文字，首先考虑是不是可以图形化，其次考虑是不是可以用list或者table的方式来表达；</li>
          <li>图。图除了色彩搭配和上面提到的一样需要注意外还需要注意2个问题。图尽量的大，并且尽量的不要失真。第二，尽量不要使用截图，特别是网页截图。这种截图往往很难拉伸，ppt的展示效果比较差；</li>
          <li>动态效果。在技术ppt中，动态效果不宜过多（PS：我指的是一页中），一般除非需要表示数据流等动态流程图，否则应该尽量少的使用动态效果。动态效果用的好是画龙点睛，用的不好就是画蛇添足。而对于技术性的讲师来说，往往是后者。所以宁愿不用也不要错用；</li>
          <li>广告。这是一个非常严肃又非常值得讨论的问题。大多数的讲师都会在ppt中加入广告，99%的讲师会加入招聘广告，虽然大家都知道通过这种方式成功的概率微乎其微，但还是在做。正是印证了一句广告界的名言：99%的广告打下去都是没结果的。但是为什么大家都在打呢？因为不知道那1%是在哪里！这里要提醒各位的是，做广告可以，但是吃相不要太难看。比如在topic上写上别人家的活动报名方式什么的，这种就有点夸张了。至少也要尊重一下本次的主办方吗；第二，广告尽量使用“软广”的方式，那种硬性植入就能免则免，太欠缺水平了，也没有情怀和b格；第三，大家可以把Q&amp;A页利用起来，上面放一个公司或者你自己的开源github二维码、公众号二维码之类的图片，让大家觉得你不是在做广告，而是在增加联系。归根结底一句话：广告要做的有水平，不要让人家一眼就看出来你这是在做广告，要有b格和情怀，要有b格和情怀，要有b格和情怀！重要的事情说3遍。</li>
          <li>页数。 一场topic大概用时一般在45分钟，很少有1个小时的，也很少有低于45分钟的。所以对于讲师来说，你真正拥有的时间大概在30-40分钟之间。那也就是意味着你的ppt页数不能太多，也不能太少。基本上控制在有效页数在15-18页，最多不超过20页、不要少于12页就可以了。虽然我也见过50页ppt半小时讲完的，或者是3页ppt讲2个小时的，但是这种人毕竟是少数。我自认为你不是这种人。有效ppt，是指你真正讲内容的ppt。中间有一些穿插的标题、不展开的结论、ppt转换等这些都属于一带而过的，所以它们并不是有效ppt。那么除了这些，剩下的的ppt，包括了topic大部分真正内容的页，这些都是有效ppt。</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>pdf。一般做完ppt后也要同时提供一份pdf给主办方，作为主办方现场或者是会后发放的内容。这份pdf大家一定要注意，一定要脱敏，特别是公司的一些数据，个人的信息等等。一定要进行脱敏处理后再发送给主办方。</li>
  <li>交稿时间。一般都是认为越早越好，但我觉得不是。最好的时间应该是开始前2个星期开始做ppt，花几天构思，然后花1天完成。这样可以安排在最后期限的前一个星期这个时间点上提交你的ppt。这个时间点的好处是，首先你至少不会到了现场忘记了ppt，也不会因为你要参加topic影响你的工作；第二，你也需要给出品人一点时间来审核你ppt；第三，你还给了你自己一点时间来修改和完善你的ppt。</li>
</ol>

<h2 id="前期准备">前期准备</h2>
<p>等交稿一个星期后，基本上你的技术topic分享也要开始了，在分享的过程中，也需要几个注意点：</p>
<ol>
  <li>到达时间。建议大家尽量提前达到topic举办的城市。一般也不用提前太多，前一天晚上到，第二天分享就可以了。通常主办发会在topic举办的酒店或者就近酒店给你开房间，所以你去了以后尽可能的先去现场转转，特别是你要分享的分会场现场，去看看大体的布局、投影的效果、讲台的位置等等。这样至少能做到前期心中有数。</li>
  <li>设备问题。建议大家最好能自己带上笔记本，如果有条件的话可以自己带好演讲笔。这个不是必要条件，但以防万一。特别是技术同学，现在很多技术同学使用的都是mac，经常提交的是keynote，而国内目前windows还是非常的通用，所以现场可能会出现ppt放不出来或者ppt有问题等等。不过就算你用的windowns+ppt，有的时候也会因为系统或者ppt的版本不同而发生问题，所以最好还是带好自己的笔记本，出现问题的时候可以立即就解决。</li>
  <li>最后一眼。在分享的前一天晚上，或者你的topic安排在下午的话就是当天上午，尽量抽时间最后看几眼ppt，查漏补缺一下。这是在分享前最后更新ppt和分享知识的机会，也可以再一次熟悉一下自己要讲的ppt和要讲的内容。</li>
</ol>

<h2 id="分享中">分享中</h2>
<p>就要来到分享现场了，大家是不是有点紧张？这里就来讲讲分享现场需要注意的问题。</p>
<ol>
  <li>紧张。首当其冲的就是紧张问题。不管你是新手还是“老司机”，其实都会紧张的。特别是马上要轮到你了，还没轮到的时候，心理都会有一些波动。这种紧张或者叫担心是很正常的。老司机可能在开始的时候就变的正常了，而新手还是会紧张。这里想和大家说的是，不要太担心，经过上面的准备后，这个环节应该不会有什么大问题。你站在讲台上，相比下面的听众，你有更多的天然优势。你分享的内容你是最熟悉的，下面的听众都没有你熟悉，所以你只要按照你前期的准备按部就班的下去就可以了。</li>
  <li>怎么讲。这里也需要分几个部分来讲：
    <ul>
      <li>脱稿。首先是要尽量的把ppt串起来，并且在分享的过程中除了需要使用演讲笔现场指出来ppt上的部分内容外，总体上需要脱稿。这也是为什么我在上面强调的：不要太早的做完ppt的原因之一。在整个分享过程中要注意节与节之间的衔接部分，这里特别容易“卡壳”。</li>
      <li>单页讲解。单页讲解的时候最怕的就是口语。比如很多同学喜欢用“然后”，“嗯”，“下面”，“接下来”……这种的口语化的表达方式，而且是重叠的出现这种，比如一页ppt中不停的“然后”…“然后”…“然后”…。这是很不可取的。一般一页ppt总归有个前后关系，所以最好的方式是多使用层次性的词语来表达，比如“首先”…“然后”…“其次”…“接着”…“最后”…,或者是“第一”…“第二”…“第三”…。</li>
      <li>肢体语言。在分享的时候，一般一手拿着麦克风，一手拿着演讲笔，幸好人类没有第三只手，否则更乱了。所以很多同学都是拿着麦克风的那只手举着（没办法，至少要说话），而拿着演讲笔的那只手不知道在干嘛。有的垂的，有的乱晃，还有的直接插兜里（PS：虽然我也觉得插兜里挺帅挺个性）……，这些希望大家都不要出现。拿着演讲笔的那只手可以适当的做一些动作，不要太夸张也不要一动不动。适当的做一些动作可以让大家觉得你更融入此次的分享中，也可以让大家更加接受你分享的内容。至于这个度，需要自己把握，确实挺难。</li>
      <li>掌控讲台。大家千万不要在讲台上一动不动的站着，从上去到下来都在一个地方；或者是直接站在演讲台那边，看着ppt在那里好像在做政府工作报告。你可以适当的在讲台上走走，你要清楚你是讲师，这个讲台在这个45分钟内是属于你一个人的，何必那么拘束呢？一般技术topic的讲台都是一个高于听众的地方，长方形，也不是特别的大。但是绝对在中间。你在讲台上适当的活动一下相比站在一个地方不动，可以照顾到下面更多的同学。可以让大家更好的融入到自己的分享中。</li>
      <li>提问互动。关于这点公说公有理婆说婆有理的问题确实不好办。但依据我的经验，在分享的过程中尽量避免和下面的听众进行沟通和对他们提问。尽量的少问“这个问题大家知道吗？”，“这个有谁知道吗？”这种问题。首先，你对下面听众的情况不熟悉，你这么“唐突”的提问很少能拿到你想要的答案；其次，这种提问几乎都会冷场，很多最后都是讲师自己尴尬的打圆场过去，很少有人会举手回答，就算有也是你要多次的确认“有人知道吗？”；第三，这是技术分享，不是培训。这点要分开。公司内部的培训可以经常使用这种提问方式，但是演讲不太适合，培训的人数一般只有十几个甚至最多也就几十个，如果人数多了就会分批，规模上好控制，而演讲这种的一般至少100-200人吧，会场也很难控制。</li>
      <li>段子。不要笑，这是一个很严肃的问题。特别是对于在中间分享的讲师，一定要准备3-4个段子。一般大家在长时间的集中精神后，中间有段时间特别累。其实我们自己也有感觉，你坐在下面听一下试试看，一个上午就受不了了，比上班还累。所以在分享的过程中需要穿插适当的段子来把听众的小差给开回来。当然了也不排除很多同学就是为了听你的段子来的。老罗曾经说过：我讲的题你们都没记住，我讲的段子你们倒是记得清清楚楚，过后还久久回味、栩栩如生。</li>
      <li>时间控制。这个主持人一般都会帮你。有做的比较好的，比如csdn，会给你一个大大的ipad，给你看从开始到结束的剩余时间倒计时；没有这种ipad，也会有一个最后5分钟，最后3分钟，最后一分钟这样的倒计时提醒牌。有倒计时和没倒计时是一把双刃剑。有吧，总感觉有人在催你；没有吧，总会超时。所以归根结底这还是需要大家多加练习自己的ppt，学会控制时间。这里要说的是尽管很多时候最后肯定会拖时间，但是大家要注意，千万不要拖太多就可以了，拖一个2-3分钟没人会说你，因为主持人会灵活掌握下面同学提问的时间，但有一次我也是讲师，我前面的一个哥们拖了15分钟之久，这就太夸张了。而且TMD拖时间是因为他要做广告，这就让我很无语了。所以我对这个哥们印象很不好，大家都在这个圈子混，名字我就不说了。</li>
    </ul>
  </li>
  <li>出现意外。这很正常，比如下面突然有人叫起来：这玩意那里听过，或者是这个ppt我看不清楚。出现这种情况首先是千万不要紧张，也不要不知所措。你可以先安抚一下听众，第二，赶快和主持人沟通怎么解决问题，是不是能把ppt的pdf文档下发下去之类的。这里要说一下，如果你的ppt因为公司保密原因不能下发，那么请各位讲师要和主办方、主持人事先沟通好，商量好万一出现问题的时候怎么解决。这种事情不是没有发生过，我就见过因为这个事情现场闹得不可收拾的。这样对大家都不好，特别是对讲师所在的公司名声影响很差，还不如不要出来做这次分享呢！</li>
</ol>

<h2 id="结束">结束</h2>
<p>一般分享结束后，剩下的就是听众提问和讲师解答的阶段了。到这里其实才是最考验各位讲师内功的，因为提问环节基本上你不太可能能全部掌握。就算你前面准备的再好，这部分可能最多你也就只能覆盖到70%。那么这部分会经常出现哪些问题呢？</p>
<ol>
  <li>问题超纲。这里的超纲是指超出了讲师的知识所掌握的范围。对于初次作为讲师的同学可能是非常容易碰到的。其实这个并不可怕。解决这个问题的本质还是要奉劝大家平时多加注意积累，多加注意同类型开源软件或者是同类型开源论文等东西，只是临时抱佛脚是解决不了这个问题的。但如果你已经站到讲台上了，碰上这种问题你再告诉是靠积累，你这确定你不是在开玩笑？所以一种办法是你确实回答不上来，那么就大方的承认这个你没考虑过，后面再看看；另外一种可能的情况是你其实知道一些，但是知道的知识并不是特别的清楚，没有十足的把握也没有那么的全。这种情况下你就找几个你有把握的，可以回答这个问题中的几个点就可以了。一般主持人看见这种情况也会帮你解围的。</li>
  <li>一直追问。 这个是对于下面的听众来说的。如果某个哥们一直霸占着话筒怎么办？这个任务一般是主持人的。他会解决这个问题。我的经验是一般一个人提问一次后我就收走话筒了，一来可以给另外的同学更多的提问机会；二来，还可以兼得保护讲师。但是如果主持人也无动于衷，那你就可能需要自己解决这个问题。在回答完他的问题后，你可以带一句“这位同学，下去了我们微信交流，希望现场能有更多的同学提问”这样的话来结束这个同学的提问。</li>
  <li>一人多问。这个也很正常。一般一个人的记忆力是有限的，所以你可以一个一个的来回答他的问题。但是一般首先强调一下一次提问最好不要超过2个，最多不要超过3个，因为实在是记不住。如果问完了还是有问题那就私底下微信交流。</li>
  <li>现场群。多看一下群，万一有同学问到你，如果你不回答的话就显得不太好，所以还是要照顾一下群里的反应。</li>
</ol>

<h2 id="总结">总结</h2>
<p>套路，都是套路。写书有写书的套路，程序有程序的套路，分享也有分享的套路。大家都是按照套路在办事情。目前根据我的经验，基本上作为一个讲师，所能想到的套路就那么多。但是套路归套路，归根结底，还是希望大家如果有志想挑战一下自己，有一天也想站上讲台的话，在套路的同时也一定要对于分享这件事情多加练习。其实每个讲师虽然会使用套路，但是私底下还是很努力练习的。这次我们上sdcc的小朋友在事前被练了一个多星期，用他的话说被练的自己都不知道怎么了。ppt在公司内部走了有4-5遍。先是我们几个内部听，提出问题、整改；然后是部门内部听，提出问题、整改；然后再是我们内部听，提出问题、再整改，以此反复。所有的好分享除了套路更多的还是建立在多加练习、熟能生巧、以勤补挫的基础上的。大家千万不要以为会了套路就会打拳了，这仅仅只是招式，内功还是要靠自己一点一点，日积月累而成的。</p>


                    ]]>
                </content:encoded>
                <guid isPermaLink="false">/blog/2017/how-do-topic/</guid>
                <description>
                    
                </description>
                <pubDate>Thu, 15 Jun 2017 00:00:00 +0800</pubDate>
                <author>94geek.com by Seapeak.Xu</author>
            </item>
        
    
        
            <item>
                <title>SDCC2017 深圳架构场前瞻</title>
                <link>http://www.94geek.com/blog/2017/sdcc2017_%E6%B7%B1%E5%9C%B3%E6%9E%B6%E6%9E%84%E5%9C%BA%E5%89%8D%E7%9E%BB/</link>
                <content:encoded>
                    <![CDATA[
                    <p>首先很荣幸的被csdn邀请为sdcc2017深圳架构场的出品人参与此次topic。作为出品人，在演讲嘉宾的筛选上就已经动了脑筋。此次sdcc2017，演讲嘉宾的阵容是非常强大的，既有腾讯、阿里、百度传统3强的分享，又有唯品会、阅文集团、sina微博等公司的强势加入。各位演讲嘉宾也都是业界的“老司机”，不管是从技术还是演讲本身来说，都是“老”的可以啊！所以sdcc2017深圳架构场的技术topic水平当然不会低，是绝对值得期待的。</p>

<p>当出品人还有一个特权就是可以提前看到各位演讲嘉宾的PPT。此次架构topic的PPT在各位“老司机”动不动就“一言不合”加大马力“飙车”的情况下各个卓越超群，各显神通。这里我就先瞒过csdn的小编来报个料。</p>

<h2 id="上午">上午</h2>

<hr />

<p>首先登场是来自阿里的中间件架构师冯嘉，他为大家带来了来自阿里中间件团队自我研发的消息队列中间件“RocketMQ”。大家都知道阿里面临的访问、流量、正确性等一系列的压力；也明白在这些压力下程序员所要面对和承担的技术困境。RocketMQ在经过阿里内部多年的开发和使用后，顶住了压力（特别是“丧（疯）心（狂）病（数）狂（钱）”的双十一）。同时也因为出色的性能表现和卓越的稳定性，RocketMQ加入了Apache基金会。此次topic，冯嘉主要为大家带来了RocketMQ的什么呢？可以用下面几点来概括：</p>
<ol>
  <li>首先是阿里使用RocketMQ的历程，从使用开源软件到自我研发RocketMQ的煎熬和解脱；</li>
  <li>RocketMQ的实现。此次的topic可以说是毫无保留的全部拿出来了。包括mq的内部存储结构图都一清二楚的画出来贡献给大家看了，真是印证了那句话：是骡子是马拉出来溜溜；</li>
  <li>接着可能是大家最关心的RocketMQ具体的特性和性能。特性和性能可以让大家在选型和使用的时候更加的安心；</li>
  <li>最后是RocketMQ的监控与后续发展。这部分可以确保大家更加方便的使用RocketMQ；</li>
</ol>

<p>紧接着登场的就是来自新浪微博的技术专家陈波，他为大家带来了“微博Feed的缓存架构及其演进之路”。微博的用户量亿级也是妥妥的、pv，并发更是不用讲了，大家心里都有数。所以他们在组织feed的确实也碰到了很大的困难和很多的现实问题。此次topic，陈波主要为大家带来了feed缓存的3个主要方面：</p>
<ol>
  <li>首先是feed平台的总体架构，说明了feed在微博整体架构中所占的重要位置和实际碰到的问题；</li>
  <li>解决feed所使用的cached的架构极其实现；</li>
  <li>接下来是此次topic的亮点，对redis更好使用的案例。这部分应该会有很多人想一探究竟，毕竟redis几乎已经成为高性能网站的“威尔刚级” 产品了，现在还有谁敢说不用redis？</li>
</ol>

<p>上午的最后一场topic来自于腾讯的架构平台部高级工程师陈杰，他为大家带来的是“基于空闲资源的弹性计算实践
”。弹性计算，虽然一直在说，但是对于目前的行情来说其实还算是一个比较新的领域，或者说是对普遍的大家一个比较陌生的领域。这是因为很多公司根本就没有这个精力也没有这个实力更是没有这个必要和动力去研究这个东西，但是它却是大企业或者说是云计算必须要面对的一个问题。如何更好的去利用空闲的机器已经是很多像腾讯、阿里等一样规模的大型互联网公司不得不也是必须要去面对和解决的一个问题。这次topic陈杰给大家主要从以下5个方面来讲解弹性计算：</p>
<ol>
  <li>首先是弹性计算在企鹅内部的需求。从企鹅的实际需求出发，可以让各位清楚的知道什么情况下或者说什么状态下弹性计算是必要的；</li>
  <li>实现弹性计算的难点。这应该是业界的一个难题，可以看看企鹅是怎么去解决这个问题的；</li>
  <li>“4步法”解决企鹅弹性计算在线业务的质量保障。你问我哪四步？我先卖个关子；</li>
  <li>“3步法”解决企鹅弹性计算怎么使用好。又要问我哪三步？我是想说的，但是被csdn的小编给删除了！</li>
  <li>最后是企鹅弹性计算团队在实施弹性计算的过程中碰到的问题和其解决办法。这是企鹅弹性计算团队的知识结晶，大家不容错过啊！</li>
</ol>

<p>大家可以先吃点饭，休息一下！下午更精彩哦！</p>

<h2 id="下午">下午</h2>

<hr />

<p>下午首先登场的是来自唯品会的架构师薛珂，他为大家带来了唯品会内部使用的“弹性调度平台Saturn的架构设计”。Saturn说白了就是一个Job系统，但是Saturn相比其它的Job系统有它独到的地方，而且也有更多的特性，主要的亮点在于以下4个方面：</p>
<ol>
  <li>job的无语言限制支持。可以支持目前常见的各种语言，甚至是shell脚本也可以无缝的运行；</li>
  <li>触发机制支持事件和时间。目前市面上更多的Job基本上都只支持时间触发机制，最复杂也就是用Cron表达式，所以Saturn支持事件是一个亮点；</li>
  <li>支持任务分片和根据机器负荷动态负载平衡。支持分片的Job很多，但是根据Job执行机器的系统运行指标来动态调整job执行的负载均衡是一个不错的想法和实现，也是Saturn的一大的亮点；<br />
4.支持云部署。云是目前最火的一种架构模式，Saturn也不例外的支持了。从这点上也可以看出Saturn是走在技术架构时尚前沿的弄潮儿啊。</li>
</ol>

<p>虽然这时候大家可能有点困了，但是千万不要瞌睡，错过了好戏我可不负责！</p>

<p>下面出场的是来自百度网页搜索部的资深研发工程师陶清乾，他为大家带来的是前端架构：“基于PWA的Web App前端架构探索与实践”。这是此次深圳架构场唯一一场前端架构topic的分享。他主要为大家从以下3个方面讲解百度在实际的工作中使用PWA架构移动Web App的经验：</p>
<ol>
  <li>目前移动端web碰到的困境和百度所使用的解决方案；</li>
  <li>PWA技术的价值与在百度使用过程中的效果。这部分大家应该可以从现在百度的部分app中就能感受出来吧？不过亲身听一下设计人员的讲解可能会更加的事半功倍！</li>
  <li>前端架构新思路。从离线化、视图框架、异步渲染和交换感4个方面来说明前端架构设计的新思路；</li>
</ol>

<p>第三场来自于前卷皮网架构部技术总监陈秋余，他为大家带来的是“领域模型 + 内存计算 + 微服务的协奏曲：乾坤”。这场也是此次唯一一场分享目前比较流行的“微服务” 的技术topic。领域模型是一个架构中经常会碰到的问题，也是几乎目前的系统中主要的组成部分；内存计算大家也都耳熟能详；至于微服务嘛，最近火的不要不要的。那么这3个精兵强将组合在一起能碰撞出多少的火花呢？卷皮网给出的答案就是“乾坤”系统。这场topic将从4个方面对于“乾坤的火花”进行阐述：</p>
<ol>
  <li>特卖类电商的微服务架构。这是很多传统电商都不会碰到的问题，偶有幸（也是不幸）碰到过。很早之前在5173任职，5173虽然不属于一个传统电商网站甚至都不属于特卖类网站，但是游戏交易，几乎有和特卖类电商有着一模一样的业务和架构痛点。其痛点就两个字：“比快”。不管是特卖还是抢购，其实比的就是一样：顾客“手快”的情况下网站不down机并且快速且正确的响应！</li>
  <li>目前主流分布式架构及其问题。这部分主要分析了特卖类网站和目前主流分布式网站架构的矛盾之处，笔者看过后满满的“惺（泪）惺（流）相（满）惜（面）”；</li>
  <li>解决高并发争抢的性能问题：无锁排队。这种解决方案现在越来越多的被提及。我们自己开发的很多中间件也都是使用了类似的解决方案来处理这个问题。到底怎么处理？还是来听听吧！说多了你就不买票了！（这不是偶的本意，csdn小编改的，你们可以去找他）</li>
  <li>分布式事务的一致性模型。其实大家从开始分布式架构系统开始就碰到了事务这个难题。虽然时间很长久，但是一直到现在为止，都没有一个统一的、标准的实现方案方法。基本上都是各家根据各家的实际业务模型和情况再结合2PC、3PC或者及其变种来实现解决。当然乾坤也不例外了；</li>
</ol>

<p>最后一场是来自阅文集团。这里不得不多夸奖几句阅文集团。阅文集团这几年越来越多的参与各种技术开源和技术分享，阅文集团的技术也正在慢慢变的成熟。这里也希望阅文集团能够越来越多的帮助到各位在技术上碰到的问题。（哈哈！这个不得不说，是偶“不要脸”了。的确是“硬广”，纯粹不要脸的那种“铁硬广”）。PS：小编别删了啊，看在偶半夜写文档、也没有大尺度的上二维码的份上，留点面子。另:我们开源的二维码是…</p>

<p>言归正传，最后是来自阅文集团的架构师帅翔为大家带来的“PB级去内存化分布式缓存系统Lest的架构设计与实践”。对于帅翔偶还是比较了解的，因为天天被偶“虐”。Lest项目也是我们目前的重点项目，它主要的作用就是用来在生产环境替换掉目前阅文集团内容中心存在的大量主动缓存redis。对的，你没听错，我们准备下架一部分的redis。其实对于redis，大家也都心知肚明：随着redis的大量使用，基本上最后就是失去控制。病理表现：redis服务器或者redis内的缓存内存只加不减。那这是为啥呢？因为里面有点啥，有的时候你真的很难搞得清楚，哪怕你是一手做起来的，并且管理起来的，久而久之就这样了。这基本上也是现在很多公司共同碰到的难题之一。另外一个问题，也是一个很大的问题：redis是基于内存的，虽说现在内存白菜价，但是毕竟还是要成本。当你大量使用的时候，成本还是挺大；而且基于内存的一down或者重启，基本上就废了，有多少公司因为redis出了问题导致了站点down掉？所以用武侠来形容redis呢，我认为就是“离别钩”。不用吧不行，用吧闹不好自伤。那么我们解决这些问题的办法就是Lest！此次帅翔给大家从以下几个方面来讲述lest的前因后果：</p>
<ol>
  <li>首先是Lest研发的原因和其总体架构。原因前面唠叨过了，这里说一下架构。相比redis，Lest增加了一层tracker来做一个统一的cached分配算法和存储的管理。这样的好处除了可以更好的管理cached内容，还能可以让业务系统和具体的分配算法隔离开，可以让业务系统更加的灵活；</li>
  <li>数据的存储。和上面阿里的RocketMQ一样，我们也是无所保留的贡献出来所有的设计思路和方案，包括具体的磁盘存储格式。其中Lest使用的二进制协议，来自于messagepack的“阅文DIY升级版hermas”更是亮点，它既可以用来做网络通讯，又可以满足磁盘存储，lest的成功实施很大程度上是hermas的功劳；</li>
  <li>数据的同步和性能测试。lest相比于redis就是“在尽可能少损失性能的基础上多了最后一致性和持久化”。众所周知，同步和持久化肯定会是性能的杀手，那么这部分就是讲述了lest用了什么技术和方案来去解决这个问题；</li>
  <li>最后是lest目前所存在优点与缺点。诚恳的分析lest的先进性和目前所存在的问题，以及以后可能的发展方向，为大家以后的选型扩展了思路。</li>
</ol>

<h2 id="总结">总结</h2>

<hr />

<p>原本小编说只要1k字就够了，结果轻描淡写的就妥妥2k+了。这是因为参加此次技术topic分享的各位“老司机”飙车实在太厉害，偶也跟着“鸡血”了一把！对于这么多位高手云集的sdcc2017深圳架构场，你是不是已经手抖的都握不住鼠标拼命要去点击“购票”了呢？我们现场见吧！</p>


                    ]]>
                </content:encoded>
                <guid isPermaLink="false">/blog/2017/sdcc2017_%E6%B7%B1%E5%9C%B3%E6%9E%B6%E6%9E%84%E5%9C%BA%E5%89%8D%E7%9E%BB/</guid>
                <description>
                    
                </description>
                <pubDate>Wed, 07 Jun 2017 00:00:00 +0800</pubDate>
                <author>94geek.com by Seapeak.Xu</author>
            </item>
        
    
        
            <item>
                <title>Chaos-ID生成器的前世今生</title>
                <link>http://www.94geek.com/blog/2017/idcreator-chaos/</link>
                <content:encoded>
                    <![CDATA[
                    <p>从mongodb的objectid到twitter的snowflake，目前国内的几个互联网大厂也开始重视到了分布式系统中数据id，甚至一些大厂已经公开了它们关于id生成器的设计和实现。我们当然也注意到了分布式系统中id的重要性，并且在系统开始开发的时候就设计并且实现了一个id生成器，我们称之为：Chaos。Chaos目前已经在我们内部运行了2年之久，在这2年内故障率为惊人0，可靠性达到不可思议的100%。那么我们为什么要设计Chaos呢？Chaos又和别人家的id生成器有什么不同呢？这些问题，首先得从我们以往的经验开始。</p>

<h2 id="过往使用id的经验">过往使用id的经验</h2>

<h3 id="int自增">int自增</h3>
<p>通常情况下，说到id，我们第一个想到的就是int自增类型。它被各种“最佳实践”、教科书、论文…所推荐。然而，在现在这个信息爆炸的年代，自增id已经老态龙钟，显露颓势了！<br />
从学校到社会；从教科书到实践；从办公自动化到erp再到现在的互联网和大数据，不管什么时候，不管什么年代，我们接受到对于数据id的设计原则都来源于《数据库原理》这本书：</p>
<ol>
  <li>唯一标识，确保不重复；</li>
  <li><strong>确保主键是无意义的；</strong></li>
  <li><strong>首推采用int作为主键值；</strong></li>
  <li>减少主键的变动；</li>
</ol>

<p>在单机、单数据库、dal+proc的年代，这些原则是可取的、现实的最佳实践。依照这些原则我们也一直用的很好。直到有一天，数据猛增，单表破千万甚至上亿，需要考虑拆分表甚至拆分库的时候，问题来了：<br />
<strong>每个表的主键都是自增，数据库扩容怎么玩？</strong></p>

<p><img src="int-mdb.png" alt="int自增多表示意图" /></p>

<p>进过一番寻找，在数据库的int自增中找到一个属性：步长。可以根据数据表的个数来设置步长，这样就不会重复了。比如将一个单表分成3个表，那么就把步长设置为3，3个表的id就会按照如下的方式来增长：</p>
<ol>
  <li>table-1 : 0,3,6,9,12…</li>
  <li>table-2 : 1,4,7,10,13…</li>
  <li>table-3 : 2,5,8,11,14…<br />
这种办法确实解决了id可能重复的问题，但是同时带来了一个很让人抓狂的问题：</li>
</ol>

<p><strong>每次扩容，都需要根据数据库表的数量来定义步长，一旦有疏忽，整个数据将会受到灾难性的破坏，最严重的情况下，数据根本无法重新平衡</strong></p>

<p>所以int自增只能在单表的情况下才有最好的表现，一旦数据超过单表的最大限度，扩容是一件很麻烦的事情。</p>

<h3 id="string类型">String类型</h3>
<p>因为int自增id相当难扩容，我们想起了string。其实当时不是没有想过用int来自己组合一个id，但是因为那个年代普遍还是x32机器，x64刚刚开始起来，很多系统还没升级到x64，所以对于当时的系统来说，int的值太小了。一个id需要包含很多的信息，特别对于分布式系统来说，<strong>包含业务信息简直就是一定需要的</strong>，（PS：这里不得不说一下：我们的教材很多时候不能与时俱进。各位谨记：理论是理论，实践是实践。）所以我们第一想到了GUID（UUID）。</p>

<h4 id="guiduuid">GUID/UUID</h4>

<p>GUID作为id确实规避了int自增的一些问题，对于GUID来说：</p>
<ol>
  <li>肯定是唯一的，几乎不太可能碰见碰撞的问题；</li>
  <li>也没有业务的意义，都是根据统一的规则（并非业务规则）生成；<br />
看上去倒是一个很好的id解决办法，确实也有很多公司在使用它，但是GUID也存在几个问题：</li>
  <li>表的切分貌似只能有一种方法来确定：hash（guid）% table-count；</li>
  <li>无法排序，对表的主键并不友好；</li>
  <li>因为无业务意义，所以人类的识别度不高；<br />
那么这些问题怎么解决呢？既然GUID的字符串都可以，那我们把字符串变成自定义的不就妥了嘛？</li>
</ol>

<h4 id="自定义string">自定义String</h4>
<p>自定义String是我们当时的解决方案。相比于GUID，自定义String有太多的优势：</p>
<ol>
  <li>自定义的string可以塞入任何你想要的信息，可定制性很强；</li>
  <li>轻松的实现分库分表运算，并且不仅仅限制在hash算法；</li>
  <li>人类的识别度很高，可以用字符串明确的标识；</li>
  <li>可以使用本地生成，根本无延时；<br />
虽然string的id优势明显，也解决掉了切分方法和识别度的重要问题，但最重要的几个缺点还存在：</li>
  <li>string太长，且对于的运算过慢；</li>
  <li>对排序和索引支持很不友好，对主键的索引块是破坏性的；<br />
就这些缺点来说，在当时还是可以接受。但是在现在这个时代，已经不可能了，那我们到底要什么样的id呢？</li>
</ol>

<p><strong>重要但很少考虑的问题</strong></p>

<p>这里主要说一下id对于数据库索引的支持不友好问题！众所周知，我们目前使用的数据库，不管是sqlserver，oracle还是mysql，数据库的索引几乎都是清一色的btree或者是其衍生版。<br />
在数据库的主键中，当插入数据的时候（假设我们从来不会更新主键信息，一般也确实不会更新），db会主动维护一个btree结构，这个结构最终会序列化磁盘上，在磁盘上，索引的格式我们简化如图所示：</p>

<p><img src="string-pk-1.png" alt="btree磁盘结构" /></p>

<p>每一小块表示一个id对应的信息，每一大块表示磁盘的文件块大小，每个索引最后都会被像这样子连接起来。如图看起来好像没问题，那么问题来了，如果我要插入一个id=15的值呢？结果就会像下图：</p>

<p><img src="string-pk-2.png" alt="btree插入磁盘结构" /></p>

<p>因为前后的索引磁盘块都已经占满（或者是到一个阀值），数据库就会主动将原来的索引链断开，插入新数据，再连接上彼此的上下级索引。这种操作相比依次的插入，会带来更多的磁盘io。<br />
然而，如果使用string类型的id（特别是guid），因为没办法确定顺序，所以拆开索引-插入索引的操作将会经常发生，性能当然会有问题了。</p>

<h2 id="初涉id">初涉id</h2>

<h3 id="基本分析">基本分析</h3>

<p>在业务系统中，很多地方都会用到id，主要的地方有几种：</p>
<ol>
  <li>书、卷、章节等id；</li>
  <li>分布式系统中，系统调用的错误码；</li>
</ol>

<p>对于id的几个需求：</p>
<ol>
  <li>最基本：作为数据库记录的主键；</li>
  <li>加强型：被索引，对索引友好；</li>
  <li>附带价值：作为分库分表的依据；</li>
  <li>扩展功能：对象唯一标识，比如sessionid、批号、错误号；</li>
</ol>

<p>具体的分析一下在业务规则下的id，它必须具有以下的一些特性：</p>
<ol>
  <li>分库分表：因为分库分表的方式各种各样，并且会随着业务的变化而变化，所以对于id来说，它必须要包括时间戳、随机数、类型位、数据库标识等几种最基本的属性，以供各种分库分表的方法使用；</li>
  <li>高可用性：机器位，这是为了分布式系统中id必须唯一而设置的；</li>
  <li>数据可读性必须强；</li>
  <li>递增还是随机？每秒递增？？累加递增？？</li>
</ol>

<h3 id="基本诉求">基本诉求</h3>
<p>必须要具备以下一些功能或者说特性：</p>
<ol>
  <li>唯一，必须唯一；</li>
  <li>短，尽可能的短；</li>
  <li>生成速度足够快；</li>
  <li>运算足够简单，快速；</li>
  <li>附带实体业务信息，比如时间、类型等；</li>
  <li>部分信息可以自定义，比如路由信息；</li>
  <li>不仅机器能识别，人类也可以识别；</li>
  <li>对索引友好；</li>
  <li>根据业务规则，能自定义排序等业务规则；</li>
</ol>

<h3 id="基本方向">基本方向</h3>
<ol>
  <li>必须足够短，最好是uint32，最长uint64；</li>
  <li>必须系统原生支持，不需要扩展类型；</li>
  <li>比较运算足够快；</li>
  <li>必须递增，可排序并对索引友好；</li>
  <li>id必须带业务性质，符合望文生义原则，通过id可以知道这个数据存在的数据库、表等信息，如果是错误号，必须能知道所发生的服务器；</li>
</ol>

<h2 id="id的水还是很深的">id的水还是很深的</h2>

<h3 id="snowflake">snowflake</h3>

<p>考虑实现id，twitter的snowflake算法是一个无法回避的问题，分析snowflake的算法，它有几个重要的特点：</p>
<ul>
  <li>首先：snowflake由时间戳-机器位-随机数组成，分别是41位、10位、12位</li>
  <li>其次：snowflake选择了使用uint64类型，所以在这个算法下，最大值就是0XFFFF FFFF FFFF FFFF；<br />
来看一个例子，比如有一个数：<br />
<strong>9223  3720 3257 7650 688</strong>  <br />
这个数代表了什么意思呢？首先得分析它的二进制，这个数的二进制是：<br />
<strong>0111 1111 1111 1111 1111 1111 1111 1111 0000 0001 0001 0000 0100 0000 0000 0000</strong> <br />
然后通过snowflake的组成机制，算得这个数的真实要代表的数：<br />
<strong>2199023251472-264-0</strong><br />
不得不说，这种二进制移位的方法对于机器来说非常的简单、运算也更快，但是对于程序员来说，简直就是天书。所以snowflake算法我们并不满意，对于snowflake不满意的并不仅仅“把技术人员不当人”这一项，还有2个业务的问题snowflake也无法解决：
    <ol>
      <li>没有类型信息；</li>
      <li>分库分表没有数据库定位信息；</li>
    </ol>
  </li>
</ul>

<h3 id="chaos的设计">Chaos的设计</h3>

<h4 id="场景">场景</h4>

<p>Chaos首先确定的就是放弃二进制而选用十进制。使用十进制最主要就是id的特殊场景。一般来说，id对于一个对象就像是身份证对于你一样，如果不去办银行卡、订酒店、订机票…，在日常生活中，身份证永远都是安静的躺在你的钱包里面；同理映射到技术人员的开发日常，当程序员要注意一个id的时候，就是当且仅当系统出问题了，需要排查。如果排错的时候，使用的还是snowflake这种二进制移位方法生成的id，同时领导、同事催促的电话频繁响起（往往这时候老板的电话特别多），然后第一句就是：怎么又出问题了？一身汗的同时你能第一时间确定这个id到底来自哪里？什么类型？用处是什么？… 这种情况下，你除了想打人已经没有别的想法了！</p>

<h4 id="组成">组成</h4>

<p>Chaos也和snowflake一样，选用了uint64类型，但是因为Chaos是10进制，所以对于Chaos，uint64的最大值是<br />
<strong>1844 6744 0737 0955 1656</strong><br />
那么Chaos最大值只能是<br />
<strong>9999 9999 9999 9999 999</strong><br />
直观来看，就是Chaos的id少了一位。这又是为什么呢？接着来看：<br />
和snowklake一样，Chaos也是选择了使用指定位数来确定业务信息，不同的是Chaos的位数是10进制位数。我们的算法：<br />
<strong>时间戳-随机数位-类型位-机器位-数据库标识</strong> ，10位 + 4位 + 2位 + 1位 + 2位<br />
这里就可以解释为什么Chaos的id会少一位了！Chaos的id最前面的几位是时间戳，而u64的最大值最前面的数值是1，如果坚持原定的位数Chaos生成id的时间戳就可能会溢出。所以Chaos的id干脆少一位，这样不管最前面的数值多大，就算是9，因为少了一位，所以肯定不会溢出。</p>

<h4 id="序列号">序列号</h4>

<p>在Chaos中，选择了序列号而并不是随机数来解决数的唯一性问题。之所以不选择随机数，是因为随机数在5位数的情况下，万分之一的碰撞概率对于10k qps的压力来说还是挺大的，所以随机数在Chaos的需求下并不是一个很好的方案。<br />
序列号就是一个计数器，从0-9999计数，9999后直接归0.这种累加方式在Chaos中被称之为累加递增。还有一些业务确实需要每次都是从0开始的数，这种情况下的递增在Chaos中被称之为每秒递增。<br />
从方案上来说，结合业务，累加递增可以让id更加均衡，id可以被更加均匀的分配到每个库和每个表中，所以它更适合用来做分库分表；而每秒递增更适合于重排序的情况。</p>

<h4 id="递增性分析">递增性分析</h4>
<p>上面讲到的序列号递增方法，因为序列号是id的一部分，所以序列号的递增性其实决定了整个id的递增性。也就是说，序列号决定了id的递增性。例如：<br />
<strong>累加递增：秒内进位</strong><br />
429497-9998-01-1-00<br />
429498-9999-01-1-00<br />
429498-0000-01-1-00<br />
<strong>每秒递增：设计成每秒10k个，超过不会放出id</strong> <br />
429496-0000-01-1-00<br />
429497-0000-01-1-00<br />
429498-0000-01-1-00</p>

<p>所以查看这上面的id，我们可以总结如下：
<img src="id-3.png" alt="id趋势" />
累加递增：长时间（2s内）内保证单调递增，短时间（1s内）内不保证单调递增<br />
每秒递增：它肯定是递增的，因为每秒都会从0开始，单位时间内都是单调递增</p>

<h4 id="id的使用">id的使用</h4>
<p>对于分库分表的使用，chaos生成的id使用示意如下：<br />
<img src="id-5.png" alt="id router" /></p>

<p>对于错误号的使用，chaos生成的id使用示意如下：
<img src="id-6.png" alt="id error" /></p>

<h3 id="服务器设计">服务器设计</h3>
<p><img src="id-4.png" alt="id server" />
chaos采用了水平的分布式设计。服务器都是无状态的，也是去中心化的。这样的设计可以更好的来适应后面压力增大后对于服务器的需求。目前Chaos只支持一个集群中最多有10台服务器提供id服务。是不是感觉少了一些，其实够用了。按照chaos的设计需求，10台chaos每秒可以生成：10(台) * 100(类型数) * 10000(每秒最大数量）= 1000 0000个id。</p>

<h2 id="总结">总结</h2>
<p>id，其实就是一个19位的数字。对于id来说，技术含量不在于纯技术，而在于对系统的架构控制，更是在于提升id对业务系统的最大化作用和控制。</p>


                    ]]>
                </content:encoded>
                <guid isPermaLink="false">/blog/2017/idcreator-chaos/</guid>
                <description>
                    
                </description>
                <pubDate>Wed, 31 May 2017 00:00:00 +0800</pubDate>
                <author>94geek.com by Seapeak.Xu</author>
            </item>
        
    
        
            <item>
                <title>libev 中文手册</title>
                <link>http://www.94geek.com/blog/2017/libev-manual-zh-cn/</link>
                <content:encoded>
                    <![CDATA[
                    <p>本文是libev英文版使用手册的中文翻译版。<br />
大概在2年前，在我第一次使用libev的时候，我发现关于libev的中文手册和中文使用说明很少，所以我就试着给作者发mail，希望作者能授权给我翻译中文手册的资格，但是至今未收到回音。所以我想做几点声明，如下：</p>
<ol>
  <li>此文的原始版权归原作者（libev的e文作者），而本文的任何权利都和e文文档的权利相同，包括开源协议；</li>
  <li>本人不享有授权任何人分发（包括但不仅限于印刷、出版等）此文档的权利；</li>
  <li>需要出版此文档必须经过原e文文档的同意；</li>
</ol>

<p>特此说明：<br />
对于一个e文极烂，4级都没有分数的人来说，翻译纯粹是靠毅力在支撑，但是水平有限是
现实问题，所以在翻译的过程中难免会有错误，请大家海涵，并且希望大家能在发现问题的
时候第一时间联系我。</p>

<h2 id="libev">libev</h2>

<p>libev - a high performance full-featured event loop written in C.<br />
libev-一个用c写成的全功能事件循环库（PS：event loop不知道怎么翻译好）。</p>

<h2 id="synopsis-简介">SYNOPSIS 简介</h2>

<div class="highlighter-rouge"><pre class="highlight"><code>    #include &lt;ev.h&gt;
    EXAMPLE PROGRAM
    示例程序

    // a single header file is required
    //需要包含ev.h头文件
    #include &lt;ev.h&gt;

    #include &lt;stdio.h&gt; // for puts

    // every watcher type has its own typedef'd struct
    // with the name ev_TYPE
    //每一个观察者（watcher，以下还是用watcher吧，这种名称用中文很别扭）都有一个自己的结构体，结构体名称形如ev_TYPE

    ev_io stdin_watcher;
    ev_timer timeout_watcher;

    // all watcher callbacks have a similar signature
    // this callback is called when data is readable on stdin
    //所有的watcher回调函数也都有同样的函数签名
    //当stdin可读的时候，执行回调函数
    static void
    stdin_cb (EV_P_ ev_io *w, int revents)
    {
        puts ("stdin ready");
        // for one-shot events, one must manually stop the watcher
        // with its corresponding stop function.
        // 对于只发生一次的事件来说，我们必须使用watcher的相应停止函数来手动停止这个watcher
        //译者注：它的意思是对于只需要触发一次的事件，我们必须使用不同类型相应的函数来停止这个watcher在loop中继续被监视
       //PS: 对于IO事件就是ev_io_stop,对于time事件  就是ev_time_stop
        ev_io_stop (EV_A_ w);

        // this causes all nested ev_run's to stop iterating
        //停止loop的运行，释放全部的watcher
        ev_break (EV_A_ EVBREAK_ALL);
    }

    // another callback, this time for a time-out
    //另外一个回调函数，是时间过期调用的
    static void
    timeout_cb (EV_P_ ev_timer *w, int revents)
    {
        puts ("timeout");
        // this causes the innermost ev_run to stop iterating
        //停止当前loop循环
        ev_break (EV_A_ EVBREAK_ONE);
    }

    int
    main (void)
    {
        // use the default event loop unless you have special needs
        //除非你有特别的需求,一般使用默认的event loop即可
        struct ev_loop *loop = EV_DEFAULT;

        // initialise an io watcher, then start it
        // this one will watch for stdin to become readable
        //初始化一个io watcher，将事件和loop关联
        //这个watcher监视stdin是否可读
        ev_io_init (&amp;stdin_watcher, stdin_cb, /*STDIN_FILENO*/ 0, EV_READ);
        ev_io_start (loop, &amp;stdin_watcher);

        // initialise a timer watcher, then start it
        // simple non-repeating 5.5 second timeout
        //初始化一个超时watcher，并将事件和loop关联
        //简单的非重复5.5s超时
        ev_timer_init (&amp;timeout_watcher, timeout_cb, 5.5, 0.);
        ev_timer_start (loop, &amp;timeout_watcher);

        // now wait for events to arrive
        //开始监听事件
        ev_run (loop, 0);

        // break was called, so exit
        return 0;
    }

</code></pre>
</div>

<h2 id="about-this-document-关于这个文档">ABOUT THIS DOCUMENT 关于这个文档</h2>

<p>This document documents the libev software package.<br />
这份文档记录了libev这个软件开发包。</p>

<p>The newest version of this document is also available as an html-formatted web page you might find easier to navigate when reading it for the first time: http://pod.tst.eu/http://cvs.schmorp.de/libev/ev.pod.<br />
这个文档最新的版本是一个html，你可以在这里找到它：<a href="http://pod.tst.eu/http://cvs.schmorp.de/libev/ev.pod.">最新的e文文档</a>.</p>

<p>While this document tries to be as complete as possible in documenting libev, its usage and the rationale behind its design, it is not a tutorial on event-based programming, nor will it introduce event-based programming with libev.<br />
这篇文档试着尽可能详细的说明libev的使用方法及其背后的设计理念，所以这不是一个基于事件编程的教程，也不会使用libev来教导事件编程.</p>

<p>Familiarity with event based programming techniques in general is assumed throughout this document.<br />
这篇文档假定你已经熟悉基于事件的编程技术</p>

<h2 id="what-to-read-when-in-a-hurry">WHAT TO READ WHEN IN A HURRY</h2>

<p>This manual tries to be very detailed, but unfortunately, this also makes it very long. If you just want to know the basics of libev, I suggest reading ANATOMY OF A WATCHER, then the EXAMPLE PROGRAM above and look up the missing functions in GLOBAL FUNCTIONS and the ev_io and ev_timer sections in WATCHER TYPES.<br />
这个手册试着说明的非常详细，但不幸的是，这也将让它变的很长。如果你只是想了解libev的基础知识，我建议读ANATOMY OF A WATCHER章节。示例程序在它上面，缺少的函数在GLOBAL FUNCTIONS章节中找，ev_io和ev_timer部分在WATCHER TYPES章节</p>

<h2 id="about-libev-关于libev">ABOUT LIBEV 关于libev</h2>

<p>Libev is an event loop: you register interest in certain events (such as a file descriptor being readable or a timeout occurring), and it will manage these event sources and provide your program with events.<br />
libev是一个事件循环（event loop看上去还是舒服一些），你可以注册一些你感兴趣的事件（比如一个文件描述符可读事件或者一个超时事件），它可以管理这些事件源并且调用你的事件处理函数（其实就是callback你注册的事件处理函数).</p>

<p>To do this, it must take more or less complete control over your process (or thread) by executing the event loop handler, and will then communicate events via a callback mechanism.<br />
要达到这样的目的，必须通过一个event loop事件句柄尽可能的完全控制你的进程（或者线程），然后通过一个回调机制通知事件处理函数。</p>

<p>You register interest in certain events by registering so-called event watchers, which are relatively small C structures you initialise with the details of the event, and then hand it over to libev by starting the watcher.<br />
你通过注册所谓的事件观察者（event watcher）来注册一些你感兴趣的事件，这些watcher是一些你使用事件的详细信息来初始化的相对较小的c结构体，然后你通过开始watcher把它交给libev管理。</p>

<h2 id="features-特性">FEATURES 特性</h2>

<p>Libev supports select, poll, the Linux-specific epoll, the BSD-specific kqueue and the Solaris-specific event port mechanisms for file descriptor events (ev_io), the Linux inotify interface (for ev_stat), Linux eventfd/signalfd (for faster and cleaner inter-thread wakeup (ev_async)/signal handling (ev_signal)) relative timers (ev_timer), absolute timers with customised rescheduling (ev_periodic), synchronous signals (ev_signal), process status change events (ev_child), and event watchers dealing with the event loop mechanism itself (ev_idle, ev_embed, ev_prepare and ev_check watchers) as well as file watchers (ev_stat) and even limited support for fork events (ev_fork).<br />
libev为文件描述符事件（ev_io）提供select，poll，linux特有的epoll，bsd特有的kqueue和solaris特有的event port机制，ev_stat使用的是linux的inotify接口（是不是别的平台就不提供？），linux eventfd/signalfd（为了更快更简洁（这里cleaner翻译成简洁应该更好）的线程间唤醒（ev_async）/信号事件（ev_signal)，相对的定时器（ev_timer），可自定义的绝对定时器（ev_periodic），同步信号（ev_signal)，进程状态的改变事件（ev_child），和一些event loop机制处理event watcher时自己带有的一些事件（ev_idle,ev_embed,ev_prepare和ev_check watcher)以及文件状态的watcher和fork一个子进程。<br />
译者注：其实这段就是告诉你libev有哪一些事件，有点啰嗦，来一个简单<br />
ev_io // IO可读可写<br />
ev_stat // 文件属性变化<br />
ev_async // 激活线程<br />
ev_signal // 信号处理<br />
ev_timer // 定时器<br />
ev_periodic // 周期任务<br />
ev_child // 子进程状态变化<br />
ev_fork // 开辟进程<br />
ev_cleanup // event loop退出触发事件<br />
ev_idle // 每次event loop空闲触发事件<br />
ev_embed // 用于将一个事件循环嵌套到另一个中，当事件循环处理事件的时候被调用<br />
ev_prepare // 每次event loop之前事件<br />
ev_check // 每次event loop之后事件</p>

<p>It also is quite fast (see this benchmark comparing it to libevent for example).<br />
libev也是相当快的（可以见以libevent为例的基准比较）</p>

<h2 id="conventions-约定">CONVENTIONS 约定</h2>

<p>Libev is very configurable. In this manual the default (and most common) configuration will be described, which supports multiple event loops. For more info about various configuration options please have a look at EMBED section in this manual. If libev was configured without support for multiple event loops, then all functions taking an initial argument of name loop (which is always of type struct ev_loop *) will not have this argument.<br />
libev是很容易配置的，在这份手册中，默认（也是最常见的）的配置将会被说明，libev也支持多个event loop。需要更多关于各种配置文件的选项，请查看手册的EMBED部分。如果libev被配置成不支持多个event loop，那么所有函数如果有一个名字为loop的参数，那么这个参数将不存在。（译者注：其实就是进程中只有一个event loop的话，event loop将会是一个常量，不需要在函数间传来传去，故这个参数将不存在）。</p>

<h2 id="time-representation">TIME REPRESENTATION</h2>

<p>Libev represents time as a single floating point number, representing the (fractional) number of seconds since the (POSIX) epoch (in practice somewhere near the beginning of 1970, details are complicated, don’t ask). This type is called ev_tstamp, which is what you should use too. It usually aliases to the double type in C. When you need to do any calculations on it, you should treat it as some floating point value.<br />
libev使用一个有符号（这里的single是译做单精度呢？还是译做单个呢？还是译做有符号？）的浮点数表示时间，表示至unix时间点（其实就是posix的标准时间点，在实践中差不多使用1970年开始的，详细的算法很复杂，不要多问）以来经过的秒数。这种时间类型被叫做ev_tstamp，也是你将要使用的类型。这种类型在c中经常被叫做double，当你需要使用它做任何计算的时候，你应该把他作为浮点数对待。</p>

<p>Unlike the name component stamp might indicate, it is also used for time differences (e.g. delays) throughout libev.<br />
不像’stamp’这个名称所指出的那样，ev_tstamp也可以用来表示时间差（这句来自左手）<br />
译者注：这句话不知道怎么翻译，可能是他要表示libev使用ev_tstamp表示libev的时间间隔。</p>

<h2 id="error-handling-错误处理">ERROR HANDLING 错误处理</h2>

<p>Libev knows three classes of errors: operating system errors, usage errors and internal errors (bugs).<br />
libev知道3种错误：系统错误，用法错误和内部错误。</p>

<p>When libev catches an operating system error it cannot handle (for example a system call indicating a condition libev cannot fix), it calls the callback set via ev_set_syserr_cb, which is supposed to fix the problem or abort. The default is to print a diagnostic message and to call abort ().<br />
当libev捕获一个它不能处理的系统错误时（例如一个系统调用说明一个条件，libev不能处理它。这句怪怪的，其实就是一个libev不能处理的系统调用），libev就会调用一个你通过sv_set_syserr_sb设置的回调函数，这个回调函数提供处理这个错误的方法或者终止libev，libev默认的回调函数是打印错误消息，并且调用abort函数。</p>

<p>When libev detects a usage error such as a negative timer interval, then it will print a diagnostic message and abort (via the assert mechanism, so NDEBUG will disable this checking): these are programming errors in the libev caller and need to be fixed there.<br />
当libev检测到一个错误的使用方法时，比如一个负的时间间隔（从现实生活角度出发，貌似负的时间间隔应该可以啊？），libev会打印一个诊断消息并且终止程序（通过assert机制，NODEBUG将会关闭这个检查）；这些都是libev的调用者的编程错误（其实就是来自于程序员的），这些错误必须要防止它。</p>

<p>Libev also has a few internal error-checking assertions, and also has extensive consistency checking code. These do not trigger under normal circumstances, as they indicate either a bug in libev or worse.<br />
libev也有一些内部错误检查的机制，并且拥有广泛的一致性检查代码，他们不会在正常情况下触发，当他们触发时就表明libev发生了一个bug或者是更糟的情况。</p>

<h2 id="global-functions-全局函数">GLOBAL FUNCTIONS 全局函数</h2>

<p>These functions can be called anytime, even before initialising the library in any way.<br />
这些函数可以在任何时候被调用，甚至在libev这个库初始化之前（应该是在libev的事件驱动初始化之前吧）。</p>

<h3 id="ev_tstamp-ev_time-">ev_tstamp ev_time ()</h3>
<p>Returns the current time as libev would use it. Please note that the ev_now function is usually faster and also often returns the timestamp you actually want to know. Also interesting is the combination of ev_now_update and ev_now.<br />
当libev调用它的时候返回当前的时间。请注意：ev_now函数经常会更快，并且它也经常返回你真正需要的时间戳。更有趣的是ev_now_update和ev_now的组合。（译者注：和nginx一样，libev有一个自己的时间管理机制，你在调用ev_now之前先调用一下ev_now_update这样会得到更加精确的时间）。</p>

<h3 id="ev_sleep-ev_tstamp-interval">ev_sleep (ev_tstamp interval)</h3>
<p>Sleep for the given interval: The current thread will be blocked until either it is interrupted or the given time interval has passed (approximately - it might return a bit earlier even if not interrupted). Returns immediately if interval &lt;= 0.<br />
休眠给定的时间。当前线程将会被阻塞直到它被中断或者给定的时间到。（大概的，如果线程没有被中断，它可能会比规定时间早醒来一些）。如果给定时间小于0，立即返回。</p>

<p>Basically this is a sub-second-resolution sleep ().<br />
基本上，这是一个低精度的休眠。</p>

<p>The range of the interval is limited - libev only guarantees to work with sleep times of up to one day (interval &lt;= 86400).<br />
规定的时间是有限制的，libev只保证最多一天的线程休眠时间。</p>

<h3 id="int-ev_version_major-">int ev_version_major ().</h3>
<h3 id="int-ev_version_minor-">int ev_version_minor ()</h3>
<p>You can find out the major and minor ABI version numbers of the library you linked against by calling the functions ev_version_major and ev_version_minor. If you want, you can compare against the global symbols EV_VERSION_MAJOR and EV_VERSION_MINOR, which specify the version of the library your program was compiled against.<br />
通过调用ev_version_major和ev_version_minor函数，你可以知道你所连接的libev库的主要和次要版本号。如果你想要，你可以和EV_VERSION_MAJOR和EV_VERSION_MINOR比较版本号。这两个指定你编译的库的版本号。</p>

<p>These version numbers refer to the ABI version of the library, not the release version.<br />
这些版本号是指库的ABI版本，不是发行版的版本。</p>

<p>Usually, it’s a good idea to terminate if the major versions mismatch, as this indicates an incompatible change. Minor versions are usually compatible to older versions, so a larger minor version alone is usually not a problem.<br />
通常，如果主版本号不同，终止程序是一个好的办法。因为这表明有不兼容的代码变更。子版本号经常会兼容老版本，所以一些更大的子版本号通常都不是一个问题。</p>

<p>Example: Make sure we haven’t accidentally been linked against the wrong version (note, however, that this will not detect other ABI mismatches, such as LFS or reentrancy).<br />
例如：你要确保我们没有意外的连接错误的版本号（注意，不管怎么样，这些不能检测到其他的ABI不匹配，比如LFS和重入性等等）</p>

<div class="highlighter-rouge"><pre class="highlight"><code>    assert (("libev version mismatch",
    ev_version_major () == EV_VERSION_MAJOR
    &amp;&amp; ev_version_minor () &gt;= EV_VERSION_MINOR));
</code></pre>
</div>

<h3 id="unsigned-int-ev_supported_backends-">unsigned int ev_supported_backends ()</h3>
<p>Return the set of all backends (i.e. their corresponding EV_BACKEND_* value) compiled into this binary of libev (independent of their availability on the system you are running on). See ev_default_loop for a description of the set values.<br />
返回编译到libev中的loop支持的所有的后台处理器集合（它们就是EV_BACKEND_ *的值）。具体请查看ev_DEFAULT_loop设置值说明。</p>

<p>Example: make sure we have the epoll method, because yeah this is cool and a must have and can we have a torrent of it please!!!<br />
例如：请确保我们有epoll方法，因为epoll非常酷并且必须有也可以让我们有epoll的并发能力。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>assert (("sorry, no epoll, no sex",
ev_supported_backends () &amp; EVBACKEND_EPOLL));
</code></pre>
</div>

<h3 id="unsigned-int-ev_recommended_backends-">unsigned int ev_recommended_backends ()</h3>
<p>Return the set of all backends compiled into this binary of libev and also recommended for this platform, meaning it will work for most file descriptor types. This set is often smaller than the one returned by ev_supported_backends, as for example kqueue is broken on most BSDs and will not be auto-detected unless you explicitly request it (assuming you know what you are doing). This is the set of backends that libev will probe for if you specify no backends explicitly.<br />
返回所有编译进当前libev中并且推荐给当前操作系统平台为大多数文件描述符工作的后台集合。这个集合经常小于ev_supported_backends的返回值。例如：kqueue是被大多数BSDs排斥的，并且不会被自动的检测到除非你现实的说明需要它（假设你知道你自己在做什么）（译者注：其实很奇怪，kqueue不是就是BSDs系支持的嘛？为什么不会被自动的探测到？而是要自己显示的手动设置？）。这个后端集合就是libev将要探测的并且不是你显示的指定的。</p>

<h3 id="unsigned-int-ev_embeddable_backends-">unsigned int ev_embeddable_backends ()</h3>
<p>Returns the set of backends that are embeddable in other event loops. This value is platform-specific but can include backends not available on the current system. To find which embeddable backends might be supported on the current system, you would need to look at ev_embeddable_backends () &amp; ev_supported_backends (), likewise for recommended ones.<br />
返回嵌入在其他event loop中的后台集合。这个值是特定于平台的，但是可以包括那些当前平台没有的后台。若要查找那些嵌入的后台可能会被当前系统提供，你需要你看ev_embeddable_backends () &amp; ev_supported_backends ()。同样，这也是推荐使用的。</p>

<p>See the description of ev_embed watchers for more info.<br />
请参阅ev_embed watcher获取更多的信息。</p>

<h3 id="ev_set_allocator-size-throw-">ev_set_allocator (size) throw ()</h3>
<p>Sets the allocation function to use (the prototype is similar - the semantics are identical to the realloc C89/SuS/POSIX function). It is used to allocate and free memory (no surprises here). If it returns zero when memory needs to be allocated (size != 0), the library might abort or take some potentially destructive action.<br />
设置要使用的内存分配函数（原型和语义都是和C89/Sus/POSIX的realloc函数完全相同）。他被用来申请和释放内存（这里没有特殊）。如果当函数需要分配（size ！＝0）的内存时返回0，libev将会被终止或者就会有一些潜在的破坏错误会发生。</p>

<p>Since some systems (at least OpenBSD and Darwin) fail to implement correct realloc semantics, libev will use a wrapper around the system realloc and free functions by default.<br />
由于某些系统（至少OpenBSD和Darwin）没有实现语义完全正确（译者注：应该是和POSIX标准相同）的realloc函数，libev会默认使用系统realloc和free函数的包装。</p>

<p>You could override this function in high-availability programs to, say, free some memory if it cannot allocate memory, to use a special allocator, or even to sleep a while and retry until some memory is available.<br />
你可以在高性能程序中重写这个函数。如果它不能申请内存就先释放一下，使用一个特殊的分配器或者休眠一会儿然后重试，直到申请内存成功。</p>

<p>Example: Replace the libev allocator with one that waits a bit and then retries (example requires a standards-compliant realloc).<br />
例子：使用短暂休眠和重试分配（例如需要一个符合规范的分配器）的替换libev的分配器。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>static void *
persistent_realloc (void *ptr, size_t size) {
    for (;;) {
        void *newptr = realloc (ptr, size);
        if (newptr)
            return newptr;
        sleep (60);
    }
}
...
ev_set_allocator (persistent_realloc);
</code></pre>
</div>

<h3 id="ev_set_syserr_cb-void-cbconst-char-msg-throw-">ev_set_syserr_cb (void (*cb)(const char *msg) throw ())</h3>
<p>Set the callback function to call on a retryable system call error (such as failed select, poll, epoll_wait). The message is a printable string indicating the system call or subsystem causing the problem. If this callback is set, then libev will expect it to remedy the situation, no matter what, when it returns. That is, libev will generally retry the requested operation, or, if the condition doesn’t go away, do bad stuff (such as abort).<br />
设置一个系统调用被调用出错时可以调用的打印回调函数（比如错误的select，poll，epoll_wait）。
消息是一个可打印的字符串，其说明了系统调用或者是子系统调用所发生的问题。如果设置了这个回调，libev不管在什么情况下，当它返回的时候都会期望这个函数可以用来补救错误。通常，libev会重试请求操作，但是如果条件不再可以执行，程序就会出错（比如终止程序）。</p>

<p>Example: This is basically the same thing that libev does internally, too.<br />
例如：这也是libev内部基本的处理方案。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>static void
fatal_error (const char *msg) {
    perror (msg);
    abort ();
}

...
ev_set_syserr_cb (fatal_error);

</code></pre>
</div>

<h3 id="ev_feed_signal-int-signum">ev_feed_signal (int signum)</h3>
<p>This function can be used to “simulate” a signal receive. It is completely safe to call this function at any time, from any context, including signal handlers or random threads.<br />
可以使用这个函数来模拟接收信号。任何时候，任何程序上下文（context），包括信号处理事件和随便哪一个线程中调用这个函数都是完完全全安全的。</p>

<p>Its main use is to customise signal handling in your process, especially in the presence of threads. For example, you could block signals by default in all threads (and specifying EVFLAG_NOSIGMASK when creating any loops), and in one thread, use sigwait or any other mechanism to wait for signals, then “deliver” them to libev by calling ev_feed_signal.<br />
它主要用来在进程中处理客户自定义的信号处理程序，尤其是涉及到多线程的信号处理。例如：默认的，你可以在所有线程中（和当你创建loop时指定EVFLAG_NOSIGMASK的信号）阻塞信号，在一个线程中，使用sigwait或者另外别的机制来等待信号。然后使用ev_feed_signal通知到libev。</p>

<h2 id="functions-controlling-event-loops--控制event-loops的函数">FUNCTIONS CONTROLLING EVENT LOOPS  控制event loops的函数</h2>

<p>An event loop is described by a struct ev_loop * (the struct is not optional in this case unless libev 3 compatibility is disabled, as libev 3 had an ev_loop function colliding with the struct name).<br />
通过一个ev_loop结构体的指针来描述一个event loop。（通常情况下，这个结构体不是可选的，除非把libev 3的兼容性禁止掉，因为libev 3有一个ev_loop的函数和这个结构体重名。）</p>

<p>The library knows two types of such loops, the default loop, which supports child process events, and dynamically created event loops which do not.<br />
libev支持两种类型的loop，默认的loop，支持子进程事件；动态创建的则不支持子进程事件。</p>

<h3 id="struct-ev_loop-ev_default_loop-unsigned-int-flags">struct ev_loop *ev_default_loop (unsigned int flags)</h3>
<p>This returns the “default” event loop object, which is what you should normally use when you just need “the event loop”. Event loop objects and the flags parameter are described in more detail in the entry for ev_loop_new.<br />
该函数返回默认的event loop对象，这个默认的设置通常就是你所需要使用的。event loop对象的状态参数和详细描述请参阅ev_loop_new函数。</p>

<p>If the default loop is already initialised then this function simply returns it (and ignores the flags. If that is troubling you, check ev_backend () afterwards). Otherwise it will create it with the given flags, which should almost always be 0, unless the caller is also the one calling ev_run or otherwise qualifies as “the main program”.<br />
当函数无参数调用返回的时候，默认的loop就已经初始化了（忽略一切设置，只是简单的调用此函数，如果你不放心，后续可以调用ev_backend（）函数检查）。否则此函数将按照给定的flag创建loop，其实这些flag通常都是设置为0，除非调用者也调用ev_run，也就是说是主程序调用。（译者注：主程序有什么差别吗？）</p>

<p>If you don’t know what event loop to use, use the one returned from this function (or via the EV_DEFAULT macro).<br />
如果你不知道到底用什么来初始化你的event loop，那么就使用这个函数默认返回的（或者通过EV_DEFAULT宏）。</p>

<p>Note that this function is not thread-safe, so if you want to use it from multiple threads, you have to employ some kind of mutex (note also that this case is unlikely, as loops cannot be shared easily between threads anyway).<br />
注意：此函数不是线程安全的，所以如果你想在多线程环境中使用，你需要使用某种mutex的锁（还要注意：在线程间简单的共享这个loop是不可能的）。</p>

<p>The default loop is the only loop that can handle ev_child watchers, and to do this, it always registers a handler for SIGCHLD. If this is a problem for your application you can either create a dynamic loop with ev_loop_new which doesn’t do that, or you can simply overwrite the SIGCHLD signal handler after calling ev_default_init.<br />
默认的loop是全局唯一的，此loop也可以处理ev_child的watchers（其实就是处理子进程的事件），要实现这个功能，通常要先注册一个SIGCHLD信号事件。如果对于你的应用程序全局loop有问题的话，你可以在调用ev_default_init函数后重写一下SIGCHLD信号处理函数。</p>

<p>Example: This is the most typical usage.<br />
示例：这是最典型的用法。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>if (!ev_default_loop (0))
fatal ("could not initialise libev, bad $LIBEV_FLAGS in environment?");
</code></pre>
</div>

<p>Example: Restrict libev to the select and poll backends, and do not allow environment settings to be taken into account:<br />
示例：限制loop使用select和poll作为后端，并且不允许更改这个账号的环境设置。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>ev_default_loop (EVBACKEND_POLL | EVBACKEND_SELECT | EVFLAG_NOENV);
</code></pre>
</div>

<h3 id="struct-ev_loop-ev_loop_new-unsigned-int-flags">struct ev_loop *ev_loop_new (unsigned int flags)</h3>
<p>This will create and initialise a new event loop object. If the loop could not be initialised, returns false.<br />
此函数将创建并且初始化一个新的event loop对象。如果loop不能被初始化，函数返回false。</p>

<p>This function is thread-safe, and one common way to use libev with threads is indeed to create one loop per thread, and using the default loop in the “main” or “initial” thread.<br />
此函数是线程安全的，是一个在多线程环境中通常使用libev的方式：每一个线程创建一个loop，然后在主线程或者初始化线程中使用默认的loop。</p>

<p>The flags argument can be used to specify special behaviour or specific backends to use, and is usually specified as 0 (or EVFLAG_AUTO).<br />
flag参数可以被用来指定特殊的行为或者指定使用的后台，通常，flag设置成0（或者EVFLAG_AUTO)。</p>

<p>The following flags are supported:<br />
这些flags提供的选项：</p>

<h4 id="evflag_auto">EVFLAG_AUTO</h4>
<p>The default flags value. Use this if you have no clue (it’s the right thing, believe me).<br />
默认的值，如果你没有什么特殊的要求，就用这个选项（相信我，这是对的）。</p>

<h4 id="evflag_noenv">EVFLAG_NOENV</h4>
<p>If this flag bit is or’ed into the flag value (or the program runs setuid or setgid) then libev will not look at the environment variable LIBEV_FLAGS. Otherwise (the default), this environment variable will override the flags completely if it is found in the environment. This is useful to try out specific backends to test their performance, to work around bugs, or to make libev threadsafe (accessing environment variables cannot be done in a threadsafe way, but usually it works if no other thread modifies them).<br />
如果flag位被设置（或者程序执行setuid或者setgid），libev将不会去查看LIBEV_FLAGS这个环境变量。否则（默认的），如果这个环境变量被找到，它将会完整的覆盖这个flag位。对于设置指定的后台来测试性能、解决bug、或者让libev线程安全（访问环境变量是线程不安全的，但是如果别的线程不更改他们，他们通常一切ok），这很有用。</p>

<h4 id="evflag_forkcheck">EVFLAG_FORKCHECK</h4>
<p>Instead of calling ev_loop_fork manually after a fork, you can also make libev check for a fork in each iteration by enabling this flag.<br />
通常你需要在fork函数后显式的调用ev_loop_fork函数，但是你也可以通过设置这个flag来使libev在每次迭代的时候检查fork（）。</p>

<p>This works by calling getpid () on every iteration of the loop, and thus this might slow down your event loop if you do a lot of loop iterations and little real work, but is usually not noticeable (on my GNU/Linux system for example, getpid is actually a simple 5-insn sequence without a system call and thus very fast, but my GNU/Linux system also has pthread_atfork which is even faster).<br />
这是通过在loop的每次迭代中调用getpid（）来实现的。因此，如果你大部分在做loop的迭代，小部分在做业务操作，它将会减慢一点event loop的速度。但是这通常是不需要担心的（以在我的GNU/LINUX系统上为例，getpid通常在没有系统调用的情况下被连续执行5次，这是很快的，我的GNU/LINUX系统也有pthread_atfork，它更快）。</p>

<p>The big advantage of this flag is that you can forget about fork (and forget about forgetting to tell libev about forking) when you use this flag.<br />
当你使用这个flag位的时候，最大的好处是你可以忘记fork（忘掉忘记了告诉libev forking）。</p>

<p>This flag setting cannot be overridden or specified in the LIBEV_FLAGS environment variable.<br />
设置这个flag不能覆盖或者指定LIBEV_FLAGS环境变量。</p>

<h4 id="evflag_noinotify">EVFLAG_NOINOTIFY</h4>
<p>When this flag is specified, then libev will not attempt to use the inotify API for its ev_stat watchers. Apart from debugging and testing, this flag can be useful to conserve inotify file descriptors, as otherwise each loop using ev_stat watchers consumes one inotify handle.<br />
如果指定这个flag。libev将不会尝试使用inotify api来作为其ev_stat的watchers。除了调试和测试，这个flag将会用来节约inotify的文件描述符，否则每个loop使用ev_stat watchers消耗一个inotify句柄。（译者注：这里应该是每个loop一个描述符而不是每次迭代一个吧？）</p>

<h4 id="evflag_signalfd">EVFLAG_SIGNALFD</h4>
<p>When this flag is specified, then libev will attempt to use the signalfd API for its ev_signal (and ev_child) watchers. This API delivers signals synchronously, which makes it both faster and might make it possible to get the queued signal data. It can also simplify signal handling with threads, as long as you properly block signals in your threads that are not interested in handling them.<br />
当此flag被设置时，libev尝试为它的ev_signal（和ev_child）使用signalfd API。这个API提供信号同步，并且让它更快，也可能可以得到排列的信号数据（译者注：是得到信号通知嘛？）它也可以简化线程的信号处理，只要你正确的在你的线程间阻塞你的信号就不会去处理他们。（译者注：这句话怎么怪怪的，有更好的翻译嘛？）</p>

<p>Signalfd will not be used by default as this changes your signal mask, and there are a lot of shoddy libraries and programs (glib’s threadpool for example) that can’t properly initialise their signal masks.<br />
默认情况下，signalfd将不会被使用，因为这会更改你的信号掩码。有很多的劣质库和程序（比如glib的线程池）不能正确的初始化他们的信号掩码。</p>

<h4 id="evflag_nosigmask">EVFLAG_NOSIGMASK</h4>
<p>When this flag is specified, then libev will avoid to modify the signal mask. Specifically, this means you have to make sure signals are unblocked when you want to receive them.<br />
当设置这个flag时，libev将不会修改信号掩码。具体来说，这意味着你必须在想要接收它们是，确保信号没有被阻塞。</p>

<p>This behaviour is useful when you want to do your own signal handling, or want to handle signals only in specific threads and want to avoid libev unblocking the signals.<br />
当你想要自己处理信号，或者想要在特定的线程中处理信号和想要避免让libev疏导信号时，这种行为很有用。</p>

<p>It’s also required by POSIX in a threaded program, as libev calls sigprocmask, whose behaviour is officially unspecified.<br />
在一个POSIX多线程程序中这是必须的，当libev调用sigprocmask，其行为是未定义的。</p>

<p>This flag’s behaviour will become the default in future versions of libev.<br />
这个flag的行为将来在libev中将会变成默认的。</p>

<h4 id="evbackend_select-value-1-portable-select-backend--轻量级后台">EVBACKEND_SELECT (value 1, portable select backend)  轻量级后台</h4>
<p>This is your standard select(2) backend. Not completely standard, as libev tries to roll its own fd_set with no limits on the number of fds, but if that fails, expect a fairly low limit on the number of fds when using this backend. It doesn’t scale too well (O(highest_fd)), but its usually the fastest backend for a low number of (low-numbered :) fds.<br />
这是标准的select（2）后台，不完全标准的，因为libev试着推行自己的不带fds数量限制的fd_set。但是如果失败，当使用这个后台的时候，预计fds会有很小数量的限制。它通常不能很好的扩展，但是如果fds非常小，它通常是最快的后台。</p>

<p>To get good performance out of this backend you need a high amount of parallelism (most of the file descriptors should be busy). If you are writing a server, you should accept () in a loop to accept as many connections as possible during one iteration. You might also want to have a look at ev_set_io_collect_interval () to increase the amount of readiness notifications you get per iteration.</p>

<p>This backend maps EV_READ to the readfds set and EV_WRITE to the writefds set (and to work around Microsoft Windows bugs, also onto the exceptfds set on that platform).<br />
为了得到这个后台更好的性能，你需要大量的并行运行（大多数的文件描述符是忙碌的）。如果你正在写一个服务器，你必须在loop中调用accept来在一次迭代中尽可能多的接收更多的连接。你可能还需要看看ev_set_io_collect_interval（）来增加每次迭代中准备通知的数量。
这个后台映射EV_READ到readfds集合，映射EV_WRITE到writefds集合（并解决MS win平台上的bugs，也可以在别的平台上映射)</p>

<h4 id="evbackend_poll-value-2-poll-backend-available-everywhere-except-on-windows--value-2除win以外的所有平台">EVBACKEND_POLL (value 2, poll backend, available everywhere except on windows)  （value 2，除win以外的所有平台）</h4>
<p>And this is your standard poll(2) backend. It’s more complicated than select, but handles sparse fds better and has no artificial limit on the number of fds you can use (except it will slow down considerably with a lot of inactive fds). It scales similarly to select, i.e. O(total_fds). See the entry for EVBACKEND_SELECT, above, for performance tips.<br />
这是标准的poll后台，它比select更复杂，但是处理量小的fds更好选择，并且没有人为的可用fds数量限制（除了他会减慢很多不活动的fdfs）。它的复杂度和select是一样的，即O（total_fds）。请参见上面EVBACKEND_SELECT条目，及其性能小技巧。</p>

<p>This backend maps EV_READ to POLLIN | POLLERR | POLLHUP, and EV_WRITE to POLLOUT | POLLERR | POLLHUP.<br />
这个后台映射EV_READ到POLLIN | POLLERR | POLLHUP，映射EV_WRITE到POLLOUT | POLLERR | POLLHUP。</p>

<h4 id="evbackend_epoll-value-4-linux">EVBACKEND_EPOLL (value 4, Linux)</h4>
<p>Use the linux-specific epoll(7) interface (for both pre- and post-2.6.9 kernels).<br />
使用linux特有的epoll（7）接口（支持2.6.9内核以上）。</p>

<p>For few fds, this backend is a bit little slower than poll and select, but it scales phenomenally better. While poll and select usually scale like O(total_fds) where total_fds is the total number of fds (or the highest fd), epoll scales either O(1) or O(active_fds).<br />
对于一些文件描述符，这个后台相比poll和select是相对会慢一些，但是他的扩展性惊人的好。poll和select的复杂度经常是O（total_fds），total_fds是所有文件描述符的总数（或者是值最大的那个文件描述符），epoll复杂度是O（1）或者O（active_fds：活动的文件描述符）。</p>

<p>The epoll mechanism deserves honorable mention as the most misdesigned of the more advanced event mechanisms: mere annoyances include silently dropping file descriptors, requiring a system call per change per file descriptor (and unnecessary guessing of parameters), problems with dup, returning before the timeout value, resulting in additional iterations (and only giving 5ms accuracy while select on the same platform gives 0.1ms) and so on. The biggest issue is fork races, however - if a program forks then both parent and child process have to recreate the epoll set, which can take considerable time (one syscall per file descriptor) and is of course hard to detect.<br />
作为在众多高级event机制中设计最失误的事件机制，epoll机制是值得拥有该”荣誉“的。失误仅仅包括：文件描述符默默的退出；每次更改一个文件描述符都需要一个系统调用（参数不必要的猜测），dup问题；在超时前返回值，从而导致更多的迭代（只有5ms的精确性，如果使用select，精度可以达到0.1ms），等等。最大的问题是交叉fork，如果程序fork，父子进程都需要重新设置epoll，这需要花费很多时间（每个文件描述符都需要一次系统调用），这当然是很难应对的。</p>

<p>Epoll is also notoriously buggy - embedding epoll fds should work, but of course doesn’t, and epoll just loves to report events for totally different file descriptors (even already closed ones, so one cannot even remove them from the set) than registered in the set (especially on SMP systems). Libev tries to counter these spurious notifications by employing an additional generation counter and comparing that against the events to filter out spurious ones, recreating the set when required. Epoll also erroneously rounds down timeouts, but gives you no way to know when and by how much, so sometimes you have to busy-wait because epoll returns immediately despite a nonzero timeout. And last not least, it also refuses to work with some file descriptors which work perfectly fine with select (files, many character devices…).<br />
epoll当然也是多bug的。设置到epoll的文件描述符应该是可以正常运行的，但是，当然也有不正常的时候，epoll只是喜欢报告注册在epoll（特别是指SMP系统上）中的那些完全不同的文件描述符事件（甚至包括已经关闭的文件描述符，所以，我们不能从设置集中移除他们）。epoll通过增加一个代计数器并且比较他们来过滤掉那些来自epoll报告的虚通知，重新建立那些报告的文件描述符集合，从而试图解决虚通知的问题。epoll还错误的向下舍入超时时间，但是不给你任何方法知道何时发生向下舍入和有多少文件描述符受影响，所以有的时候你不得不忙碌的等待着，因为epoll会立即返回超时的非零文件描述符。而最后的一点，它有的时候不支持那些能正常使用select机制的文件描述符（文件，很多的字符设备驱动）。</p>

<p>Epoll is truly the train wreck among event poll mechanisms, a frankenpoll, cobbled together in a hurry, no thought to design or interaction with others. Oh, the pain, will it ever stop…<br />
epoll在事件机制中是真正的投票机制，一个基因改造的poll。epoll在匆忙中拼凑起来，没有设计和考虑和别的配合。oh，无语了。（这段怎么纯粹是作者的吐槽？看样子被折磨的不清）</p>

<p>While stopping, setting and starting an I/O watcher in the same iteration will result in some caching, there is still a system call per such incident (because the same file descriptor could point to a different file description now), so its best to avoid that. Also, dup ()’ed file descriptors might not work very well if you register events for both file descriptors.<br />
当在同一个迭代中停止、设置和开始一个IO watcher时会导致一些缓存。这仍旧是每个这样的事件一个系统调用（因为现在相同的文件描述符可以指向不同的文件描述了），所以我们最好要避免这些。如果你注册两个相同的文件描述符事件，dup（）的文件描述符事件可能会不能正常运行。</p>

<p>Best performance from this backend is achieved by not unregistering all watchers for a file descriptor until it has been closed, if possible, i.e. keep at least one watcher active per fd at all times. Stopping and starting a watcher (without re-setting it) also usually doesn’t cause extra overhead. A fork can both result in spurious notifications as well as in libev having to destroy and recreate the epoll object, which can take considerable time and thus should be avoided.<br />
这个后台的最佳性能是通过不注销所有文件描述符的watchers直到他们被关闭来实现的。如果可能的话，尽可能的保证任何时候每个fd至少一个watcher。停止和启动watcher（必须要重新设置它）一般也不会造成额外的开销。在libev中，fork既可以导致虚通知，又导致libev不得不释放和重新创建epoll对象，这是非常耗时的，所以尽量避免。</p>

<p>All this means that, in practice, EVBACKEND_SELECT can be as fast or faster than epoll for maybe up to a hundred file descriptors, depending on the usage. So sad.<br />
所有的这些都表明，在实践中，EVBACKEND_SELECT是可以快的，或者在100个文件描述符之内相比epoll更快，具体取决于实际情况，不要对select太悲观。</p>

<p>While nominally embeddable in other event loops, this feature is broken in all kernel versions tested so far.<br />
当显式的设置到另外一个event loop时，这些功能到目前为止是在任何内核版本中都是被禁止的。</p>

<p>This backend maps EV_READ and EV_WRITE in the same way as EVBACKEND_POLL.<br />
后台把EV_READ和EV_WRITE全部映射到EVBACKEND_POLL。</p>

<h4 id="evbackend_kqueue-value-8-most-bsd-clones">EVBACKEND_KQUEUE (value 8, most BSD clones)</h4>
<p>Kqueue deserves special mention, as at the time of this writing, it was broken on all BSDs except NetBSD (usually it doesn’t work reliably with anything but sockets and pipes, except on Darwin, where of course it’s completely useless). Unlike epoll, however, whose brokenness is by design, these kqueue bugs can (and eventually will) be fixed without API changes to existing programs. For this reason it’s not being “auto-detected” unless you explicitly specify it in the flags (i.e. using EVBACKEND_KQUEUE) or libev was compiled on a known-to-be-good (-enough) system like NetBSD.<br />
写这篇文章的时候，kqueue是特别值得一提的，kqueue在除了NetBSD的所有BSD系统上都会出现问题。（通常kqueue不能可靠的运行，但是sockets和pipes除外。除了在Darwin上，kqueue是完全没有用处的。译者注：这tmd到底要表达意思？）。不像epoll，kqueue的问题是因为设计，不管怎么说，这些kqueue的bugs是可以（或者最终可以）通过不改变现有程序的API解决掉的。因为这些原因，kqueue不是”自动检测“的，除非你特意指定这个flags（例如使用EVBACKEND_KQUEUE)或者libev在一个像NetBSD这样已知将不会出现问题的系统中编译。</p>

<p>You still can embed kqueue into a normal poll or select backend and use it only for sockets (after having made sure that sockets work with kqueue on the target platform). See ev_embed watchers for more info.<br />
你仍旧可以把kqueue嵌入到一个正常的poll或者select的后台，并且只用它来处理sockets（请先确认sockets是否使用kqueue运行在目标平台上）。请查阅ev_embed watchers得到更多的信息。</p>

<p>It scales in the same way as the epoll backend, but the interface to the kernel is more efficient (which says nothing about its actual speed, of course). While stopping, setting and starting an I/O watcher does never cause an extra system call as with EVBACKEND_EPOLL, it still adds up to two event changes per incident. Support for fork () is very bad (you might have to leak fd’s on fork, but it’s more sane than epoll) and it drops fds silently in similarly hard-to-detect cases.<br />
kqueue的伸缩性和epoll后台是一样的，但接口调用kernel的效率更高（当然，这没有实际的速度）。和epoll相比，当停止、设置和开始一个IO watcher时也不会引起额外的系统调用。它仍然每个事件变动增加2个event变动。支持fork（）是非常糟糕的（你可能会在fork时有fd泄漏，但是它比epoll少很多），他会在难以检测的情况下悄无声息的泄露fds。</p>

<p>This backend usually performs well under most conditions.<br />
这个后台在多数情况下表现良好。</p>

<p>While nominally embeddable in other event loops, this doesn’t work everywhere, so you might need to test for this. And since it is broken almost everywhere, you should only use it when you have a lot of sockets (for which it usually works), by embedding it into another event loop (e.g. EVBACKEND_SELECT or EVBACKEND_POLL (but poll is of course also broken on OS X)) and, did I mention it, using it only for sockets.<br />
当名义上将kqueue嵌入到别的event loop时，它都是不能正常运行的，所以你必须要检测它。而且你由于它几乎无处不能运行，你只能在有很多sockets的情况下通过嵌入到另外一个event loop（例如：EVBACKEND_SELECT or EVBACKEND_POLL，当然在OS X上poll也是有问题的。）使用它（这也是它经常做的）。当我提到它的时候，它通常只被sockets使用。</p>

<p>This backend maps EV_READ into an EVFILT_READ kevent with NOTE_EOF, and EV_WRITE into an EVFILT_WRITE kevent with NOTE_EOF.<br />
这个后台映射EV_READ到一个带有NOTE_EOF的EVFILT_READ，EV_WRITE映射到带有NOTE_EOF的EVFILT_WRITE。</p>

<h4 id="evbackend_devpoll-value-16-solaris-8">EVBACKEND_DEVPOLL (value 16, Solaris 8)</h4>
<p>This is not implemented yet (and might never be, unless you send me an implementation). According to reports, /dev/poll only supports sockets and is not embeddable, which would limit the usefulness of this backend immensely.<br />
这尚未实现 （可能永远不会实现，除非你给我一个实现）。据报道，/dev/poll 只支持套接字并且不能被嵌入，这将极大的限制这个后台的用处。</p>

<h4 id="evbackend_port-value-32-solaris-10">EVBACKEND_PORT (value 32, Solaris 10)</h4>
<p>This uses the Solaris 10 event port mechanism. As with everything on Solaris, it’s really slow, but it still scales very well (O(active_fds)).<br />
EVBACKEND_PORT使用solaris 10的event port机制。和一切基于solairs一样，它非常慢，但是它的扩展性非常好（O（active_fds））。</p>

<p>While this backend scales well, it requires one system call per active file descriptor per loop iteration. For small and medium numbers of file descriptors a “slow” EVBACKEND_SELECT or EVBACKEND_POLL backend might perform better.<br />
虽然它的扩展性很好，但是每次迭代每个活动的文件描述符都需要一次系统调用。对于中小数量的文件描述符，一个慢的EVBACKEND_SELECT或者EVBACKEND_POLL后台可能表现更好。</p>

<p>On the positive side, this backend actually performed fully to specification in all tests and is fully embeddable, which is a rare feat among the OS-specific backends (I vastly prefer correctness over speed hacks).<br />
积极的一面，这个后台实际执行完全符合所有测试的规定，并且完全嵌入。这是操作系统特定的后台之间的一个罕见的壮举（我大大喜欢正确性超过执行速度）。</p>

<p>On the negative side, the interface is bizarre - so bizarre that even sun itself gets it wrong in their code examples: The event polling function sometimes returns events to the caller even though an error occurred, but with no indication whether it has done so or not (yes, it’s even documented that way) - deadly for edge-triggered interfaces where you absolutely have to know whether an event occurred or not because you have to re-arm the watcher.<br />
消极的一面，接口非常奇怪-是如此的离奇以至于即使是sun它自己也写了错误的示例程序：事件轮询功能有时返回的事件给调用者，即使发生错误，但没有迹象表明它是否已经这样做了，或不（是的，它甚至记录了这样） - 致命的边沿触发接口，你绝对必须知道是否有事件发生与否，因为你必须重新设置的watcher。</p>

<p>Fortunately libev seems to be able to work around these idiocies.<br />
幸运的libev似乎能够解决这些白痴行为。</p>

<p>This backend maps EV_READ and EV_WRITE in the same way as EVBACKEND_POLL.<br />
这个后端映射EV_READ和EV_WRITE到相同的方式EVBACKEND_POLL。</p>

<h4 id="evbackend_all">EVBACKEND_ALL</h4>
<p>Try all backends (even potentially broken ones that wouldn’t be tried with EVFLAG_AUTO). Since this is a mask, you can do stuff such as EVBACKEND_ALL &amp; ~EVBACKEND_KQUEUE.<br />
尝试所有的后台（甚至可能是那些经过EVFLAG_AUTO尝试而被拒绝的）。由于这是一个mark，你可以设置成EVBACKEND_ALL &amp; ~EVBACKEND_KQUEUE.</p>

<p>It is definitely not recommended to use this flag, use whatever ev_recommended_backends () returns, or simply do not specify a backend at all.<br />
这是一个绝对不建议使用的标志位。应该使用ev_recommended_backends（）的返回值或者干脆不指定后台。</p>

<h4 id="evbackend_mask">EVBACKEND_MASK</h4>
<p>Not a backend at all, but a mask to select all backend bits from a flags value, in case you want to mask out any backends from a flags value (e.g. when modifying the LIBEV_FLAGS environment variable).<br />
这不是一个后台，但是一个mask从一个flags值中选择所有的后台位，如果你想从flags值中屏蔽掉所有的后台（例如：修改LIBEV_FLAGS环境变量）。</p>

<p>If one or more of the backend flags are or’ed into the flags value, then only these backends will be tried (in the reverse order as listed here). If none are specified, all backends in ev_recommended_backends () will be tried.<br />
如果一个后端或多个标志逻辑或运算压入标志值，那么只有这些后台将尝试（如在这里列出的顺序相反）。如果没有指定，在ev_recommended_backends所有的后台（）将被尝试。</p>

<p>Example: Try to create a event loop that uses epoll and nothing else.<br />
例如：尝试使用epoll来创建一个event loop。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>struct ev_loop *epoller = ev_loop_new (EVBACKEND_EPOLL | EVFLAG_NOENV);
if (!epoller)
fatal ("no epoll found here, maybe it hides under your chair");
</code></pre>
</div>

<p>Example: Use whatever libev has to offer, but make sure that kqueue is used if available.<br />
例如：使用任何libev所提供的后端，但要确保kqueue的使用（如果可用）</p>

<div class="highlighter-rouge"><pre class="highlight"><code>struct ev_loop *loop = ev_loop_new (ev_recommended_backends () | EVBACKEND_KQUEUE);
</code></pre>
</div>

<h4 id="ev_loop_destroy-loop">ev_loop_destroy (loop)</h4>
<p>Destroys an event loop object (frees all memory and kernel state etc.). None of the active event watchers will be stopped in the normal sense, so e.g. ev_is_active might still return true. It is your responsibility to either stop all watchers cleanly yourself before calling this function, or cope with the fact afterwards (which is usually the easiest thing, you can just ignore the watchers and/or free () them for example). <br />
释放一个event loop对象（释放所有的内存和内核状态等）。通常情况下，没有任何一个活动的event watcher将会停止，所以例如ev_is_active可能仍然返回true。所以要么你在调用这个函数之前停止所有的watchers，要么在调用这个函数之后做相应的处理（通常最简单的解决方案就是忽略watchers的free（）），这是你的职责。</p>

<p>Note that certain global state, such as signal state (and installed signal handlers), will not be freed by this function, and related watchers (such as signal and child watchers) would need to be stopped manually. <br />
注意：某些全局变量，比如信号量状态（并且已经注册了信号处理函数的），将不会被这个函数释放掉，这些相关的watchers将需要你手工的停止掉（比如信号和child的watchers）。</p>

<p>This function is normally used on loop objects allocated by ev_loop_new, but it can also be used on the default loop returned by ev_default_loop, in which case it is not thread-safe. <br />
这个函数经常被用来释放由ev_loop_new函数分配的event loop对象。但是它也可以被用来释放由ev_default_loop函数分配的默认event loop对象。当然，这样的话，它就不是线程安全的。</p>

<p>Note that it is not advisable to call this function on the default loop except in the rare occasion where you really need to free its resources. If you need dynamically allocated loops it is better to use ev_loop_new and ev_loop_destroy. <br />
注意：在默认的loop上调用这个函数是不被推荐的，除非在极少数情况下我们真的需要释放它的资源。如果你想要动态的分配loops，调用ev_loop_new和ev_loop_destroy会更好。</p>

<h4 id="ev_loop_fork-loop">ev_loop_fork (loop)</h4>
<p>This function sets a flag that causes subsequent ev_run iterations to reinitialise the kernel state for backends that have one. Despite the name, you can call it anytime you are allowed to start or stop watchers (except inside an ev_prepare callback), but it makes most sense after forking, in the child process. You must call it (or use EVFLAG_FORKCHECK) in the child before resuming or calling ev_run.<br />
这个函数设置一个标志来使后续rv_run迭代重新初始化内核状态（应该是event loop的状态吧？）来得到一个后台。（这句不太有把握，但是应该是这样的）。不用理会这个函数的名字，其实你可以在任何你被允许开始或者停止watchers的时候（除了在一个ev_prepare回调中）调用它，但是它最大的意义在于调用创建子进程之后，在子进程中，你必须在恢复和调用ev_run之前调用它（或者使用EVFLAG_FORKCHECK）。</p>

<p>Again, you have to call it on any loop that you want to re-use after a fork, even if you do not plan to use the loop in the parent. This is because some kernel interfaces <em>cough</em> kqueue <em>cough</em> do funny things during fork.<br />
即使你不想在父进程中使用这个loop，你也同样需要在fork之后为了重新使用这个loop而调用这个函数。这是因为一些内核接口在fork之中会做一些事情（ <em>cough</em> kqueue <em>cough</em>  这是嘛意思？其实这个句话就是在fork的时候会改变libev的loop，所以需要重新设置）。</p>

<p>On the other hand, you only need to call this function in the child process if and only if you want to use the event loop in the child. If you just fork+exec or create a new loop in the child, you don’t have to call it at all (in fact, epoll is so badly broken that it makes a difference, but libev will usually detect this case on its own and do a costly reset of the backend).<br />
另一方面，假如你仅仅想在子进程中使用这个event loop，你只要在子进程中调用这个函数。如果你只是使用fork+exec的方式或者是在子进程中创建一个新的loop，那么你不需要调用这个函数。（事实上，epoll是如此的糟糕以至于是如此的与众不同，但是libev通常会自己监测到这种情况并且对这个后台做代价昂贵的复位）。</p>

<p>The function itself is quite fast and it’s usually not a problem to call it just in case after a fork.<br />
这个函数是非常快的，在fork之后调用它通常不是一个问题。</p>

<p>Example: Automate calling ev_loop_fork on the default loop when using pthreads.<br />
示例：当使用pthreads时，默认的loop自动调用ev_loop_fork</p>

<div class="highlighter-rouge"><pre class="highlight"><code>static void
post_fork_child (void)
{
    ev_loop_fork (EV_DEFAULT);
}

...
pthread_atfork (0, 0, post_fork_child);
</code></pre>
</div>

<h4 id="int-ev_is_default_loop-loop">int ev_is_default_loop (loop)</h4>
<p>Returns true when the given loop is, in fact, the default loop, and false otherwise.<br />
当给定的loop事实上是默认的loop时返回true，否则返回false。</p>

<h4 id="unsigned-int-ev_iteration-loop">unsigned int ev_iteration (loop)</h4>
<p>Returns the current iteration count for the event loop, which is identical to the number of times libev did poll for new events. It starts at 0 and happily wraps around with enough iterations.<br />
返回当前event loop的迭代次数，它和libev为了新的events做poll的次数是相同的。它从0开始并且包含有足够的迭代。</p>

<p>This value can sometimes be useful as a generation counter of sorts (it “ticks” the number of loop iterations), as it roughly corresponds with ev_prepare and ev_check calls - and is incremented between the prepare and check phases.<br />
这个值作为各种各样的一代计数器时可能会非常有用（它驱动loop的迭代次数），因为它大致和ev_prepare和ev_check的调用次数相同，并且它在prepare和check的中间阶段递增。</p>

<h4 id="unsigned-int-ev_depth-loop">unsigned int ev_depth (loop)</h4>
<p>Returns the number of times ev_run was entered minus the number of times ev_run was exited normally, in other words, the recursion depth.<br />
返回ev_run进入的次数减去ev_run正常退出的次数，换句话说，是递归的深度。</p>

<p>Outside ev_run, this number is zero. In a callback, this number is 1, unless ev_run was invoked recursively (or from another thread), in which case it is higher.<br />
在ev_run范围之外，这个值是0，在一个回调中，这个值是1，除非ev_run被递归的调用（或者从另外一个线程调用），在这种情况下，这个值会更高。</p>

<p>Leaving ev_run abnormally (setjmp/longjmp, cancelling the thread, throwing an exception etc.), doesn’t count as “exit” - consider this as a hint to avoid such ungentleman-like behaviour unless it’s really convenient, in which case it is fully supported.<br />
异常的退出ev_run（setjmp/longjmp，取消这个线程，抛出一个异常等等）不能算作是正常退出。把它看成一个避免类似的下三滥行为的提示，除非它真的很方便，在这种情况下，它是被支持的。</p>

<h4 id="unsigned-int-ev_backend-loop">unsigned int ev_backend (loop)</h4>
<p>Returns one of the EVBACKEND_* flags indicating the event backend in use.<br />
返回EVBACKEND_*之一，说明那个event backed正在使用。</p>

<h4 id="ev_tstamp-ev_now-loop">ev_tstamp ev_now (loop)</h4>
<p>Returns the current “event loop time”, which is the time the event loop received events and started processing them. This timestamp does not change as long as callbacks are being processed, and this is also the base time used for relative timers. You can treat it as the timestamp of the event occurring (or more correctly, libev finding out about it).<br />
返回当前“event loop”的时间，它是接收到事件并且开始处理它们的时间。在回调被处理的时候，这个时间戳不会被改变，并且这也是用于相对定时器的基准时间。你可以把它看成事件发生的时间戳（或者更正确的说，libev找不到它）（译者注：最后一句libev找不到它什么意思？）</p>

<h4 id="ev_now_update-loop">ev_now_update (loop)</h4>
<p>Establishes the current time by querying the kernel, updating the time returned by ev_now () in the progress. This is a costly operation and is usually done automatically within ev_run ().<br />
通过查询内核，更新进程中由ev_now()返回的当前时间。这个操作很昂贵，并且这个操作一般都是由ev_run自动实现。</p>

<p>This function is rarely useful, but when some event callback runs for a very long time without entering the event loop, updating libev’s idea of the current time is a good idea.<br />
这个函数很少有用，但是当一些event的回调运行很长时间并且没有进入event loop时，更新libev的当前时间是一个好主意。</p>

<p>See also The special problem of time updates in the ev_timer section.<br />
请参阅ev_timer部分更新时间的特别问题。</p>

<h4 id="ev_suspend-loop">ev_suspend (loop)</h4>
<h4 id="ev_resume-loop">ev_resume (loop)</h4>
<p>These two functions suspend and resume an event loop, for use when the loop is not used for a while and timeouts should not be processed.<br />
这2个函数暂停和恢复一个event loop。当loop已经很长时间没被使用的时候，不用处理过期时间。</p>

<p>A typical use case would be an interactive program such as a game: When the user presses ^Z to suspend the game and resumes it an hour later it would be best to handle timeouts as if no time had actually passed while the program was suspended. This can be achieved by calling ev_suspend in your SIGTSTP handler, sending yourself a SIGSTOP and calling ev_resume directly afterwards to resume timer processing.<br />
一个典型的使用场景是一个交互程序，例如游戏：当用处按下 ^Z来暂停游戏并且在一个小时后候恢复，那么最好处理过期时间，就像在程序暂停的时候真正的时间没有过去一样。这可以通过在SIGTSTP信号处理函数中调用ev_suspend，给自己发送SIGSTOP信号并且调用ev_resume直接事后恢复定时器处理来实现。</p>

<p>Effectively, all ev_timer watchers will be delayed by the time spend between ev_suspend and ev_resume, and all ev_periodic watchers will be rescheduled (that is, they will lose any events that would have occurred while suspended).<br />
事实上，所有的ev_timer都会被通过在ev_suspend和ev_resume之间花费时间而被延迟，而所有的ev_periodic watchers将会被重新安排（即，他们将会丢失掉一些在暂停的时候已经发生的事件）。</p>

<p>After calling ev_suspend you must not call any function on the given loop other than ev_resume, and you must not call ev_resume without a previous call to ev_suspend.<br />
在调用ev_suspend之后，你不能在这个loop上调用除了ev_resume之外的函数，并且你不能在没有调用ev_suspend之前调用ev_resume。</p>

<p>Calling ev_suspend/ev_resume has the side effect of updating the event loop time (see ev_now_update).<br />
调用ev_suspend/ev_resume将会对更新event loop时间有副作用.(请查看ev_now_update）。</p>

<h4 id="bool-ev_run-loop-int-flags">bool ev_run (loop, int flags)</h4>
<p>Finally, this is it, the event handler. This function usually is called after you have initialised all your watchers and you want to start handling events. It will ask the operating system for any new events, call the watcher callbacks, and then repeat the whole process indefinitely: This is why event loops are called loops.<br />
最后，这就是事件处理程序。这个函数通常在你已经初始化你所有的watchers和你想开始处理events时调用。它将会询问操作系统任何新的events，调用watcher的回调函数，并且无限制的重复整个过程：这就是为什么event loop被称作循环。</p>

<p>If the flags argument is specified as 0, it will keep handling events until either no event watchers are active anymore or ev_break was called.<br />
如果标志位参数被设置成0，他将会继续处理事件，直到没有活跃的event watchers或者ev_break被调用。</p>

<p>The return value is false if there are no more active watchers (which usually means “all jobs done” or “deadlock”), and true in all other cases (which usually means “ you should call ev_run again”).<br />
如果没有更多的活跃watchers（通常意味着所有的工作都完成了或者是死锁了）将会返回false，在其他情况下返回true（这通常意味着你需要再一次调用ev_run）。</p>

<p>Please note that an explicit ev_break is usually better than relying on all watchers to be stopped when deciding when a program has finished (especially in interactive programs), but having a program that automatically loops as long as it has to and no longer by virtue of relying on its watchers stopping correctly, that is truly a thing of beauty.<br />
请注意：一个明确的ev_break调用要好于依赖所有的watchers被停止来决定完成一个程序（特别是交互式程序）。有一些程序只要它必须并且仍然相信所有的watcers可以正确的停止。这才是真正美妙的事情。（译者注：这句话就是可能真正美好的程序就是event loop自动的可以依靠event全部完成而自行结束？）。</p>

<p>This function is mostly exception-safe - you can break out of a ev_run call by calling longjmp in a callback, throwing a C++ exception and so on. This does not decrement the ev_depth value, nor will it clear any outstanding EVBREAK_ONE breaks.<br />
这个函数主要是“异常安全”的，你可以通过在回调中调用longjmp，抛出一个cxx的异常或者等等方法来跳出ev_run，这不会减少ev_depth的值，也不会清除任何没有解决的EVBREAK_ONE.</p>

<p>A flags value of EVRUN_NOWAIT will look for new events, will handle those events and any already outstanding ones, but will not wait and block your process in case there are no events and will return after one iteration of the loop. This is sometimes useful to poll and handle new events while doing lengthy calculations, to keep the program responsive.<br />
EVRUN_NOWAIT这个标志值将会寻找新的事件，并且处理这些事件和那些已经未解决的事件，但是在没有事件的情况下，它不会等待并且阻塞你的进程，并且在一次loop迭代后返回。这个标志值在poll和处理新事件时需要长时间计算来保持程序相应的时候通常是有用的。</p>

<p>A flags value of EVRUN_ONCE will look for new events (waiting if necessary) and will handle those and any already outstanding ones. It will block your process until at least one new event arrives (which could be an event internal to libev itself, so there is no guarantee that a user-registered callback will be called), and will return after one iteration of the loop.<br />
EVRUN_ONCE这个标志值将会寻找新的时间（如果有必要将会等待新的事件），并且处理这些事件和那些已经未解决的事件，它将会阻塞你的进程直到至少一个新的事件到达（这个事件可能是libev自己的内部事件，所以不能保证用户注册的回调将会被调用），并且在一次loop迭代后返回；</p>

<p>This is useful if you are waiting for some external event in conjunction with something not expressible using other libev watchers (i.e. “roll your own ev_run”). However, a pair of ev_prepare/ev_check watchers is usually a better approach for this kind of thing.<br />
如果你正在等待外部事件并且并没有使用另外的libev watcher，这是非常有用的（例如：循环你自己的ev_run)，但是，一对ev_prepare/ev_check watchers通常是这种事情更好的方法。</p>

<p>Here are the gory details of what ev_run does (this is for your understanding, not a guarantee that things will work exactly like this in future versions):<br />
这是吐血推荐的ev_run的细节（这是给你理解用的，并不能保证在将来的版本中也会这样运行）。</p>

<ul>
  <li>Increment loop depth.<br />
  增加loop的深度（是不是循环次数？）</li>
  <li>Reset the ev_break status.<br />
  重置ev_break的状态</li>
  <li>Before the first iteration, call any pending watchers.<br />
  在首次循环之前，调用pending watchers。</li>
</ul>

<h5 id="loop">LOOP:</h5>
<ul>
  <li>If EVFLAG_FORKCHECK was used, check for a fork.<br />
  如果EVFLAG_FORKCHECK被使用，检查fork。</li>
  <li>If a fork was detected (by any means), queue and call all fork watchers.<br />
  如果fork被检测到（不管使用任何方法），排队并且调用所有的fork watchers。</li>
  <li>Queue and call all prepare watchers.<br />
  排队并且调用所有的前期准备watchers。</li>
  <li>If ev_break was called, goto FINISH.<br />
  如果ev_break被调用，直接运行FINISH。</li>
  <li>If we have been forked, detach and recreate the kernel state
  as to not disturb the other process.<br />
  如果fork被调用，分离并且重新创建内核状态，来达到不干扰其他进程的目的。</li>
  <li>Update the kernel state with all outstanding changes.<br />
  使用未完成的改变来更新内核状态。</li>
  <li>Update the “event loop time” (ev_now ()).<br />
  更新event loop时间（ev_now（））。</li>
  <li>Calculate for how long to sleep or block, if at all
  (active idle watchers, EVRUN_NOWAIT or not having
  any active watchers at all will result in not sleeping).<br />
  休眠或者究竟阻塞了多长时间，（主动闲置的watchers，EVRUN_NOWAIT或者没有任何活动的watchers导致不会睡眠。）（PS：这句话很别扭）。</li>
  <li>Sleep if the I/O and timer collect interval say so.<br />
  在IO和timer的时间间隔区休眠</li>
  <li>Increment loop iteration counter.<br />
  增加循环迭代计数</li>
  <li>Block the process, waiting for any events.<br />
  阻塞进程，等待任何events</li>
  <li>Queue all outstanding I/O (fd) events.<br />
  排队所有未完成的IO事件（fd）</li>
  <li>Update the “event loop time” (ev_now ()), and do time jump adjustments.<br />
    - 更新“事件循环时间”（ev_now（）），并做一次大的调整。</li>
  <li>Queue all expired timers.<br />
  队列中的所有过期的计时器</li>
  <li>Queue all expired periodics.<br />
  队列中的所有过期periodics。</li>
  <li>Queue all idle watchers with priority higher than that of pending events.<br />
  队列中的所有空闲的watchers优先级高于挂起事件。</li>
  <li>Queue all check watchers.<br />
  排队所有check watchers。</li>
  <li>Call all queued watchers in reverse order (i.e. check watchers first).
  Signals and child watchers are implemented as I/O watchers, and will
  be handled here by queueing them when their watcher gets executed.<br />
  以倒序调用所有排列后的watchers（例如，首先是check watchers）。
  信号和子程序 watchers被当作io watchers实现，并且当他们的watchers被执行时会被在这里排序处理。</li>
  <li>If ev_break has been called, or EVRUN_ONCE or EVRUN_NOWAIT<br />
  were used, or there are no active watchers, goto FINISH, otherwise
  continue with step LOOP.<br />
  如果ev_break被调用，或者EVRUN_ONCE或者EVRUN_NOWAIT被使用，或者没有活动的watchers，直接运行FINISH；否则继续loop步骤。</li>
</ul>

<h5 id="finish">FINISH:</h5>
<ul>
  <li>Reset the ev_break status iff it was EVBREAK_ONE.<br />
  当且仅当它是EVBREAK_ONE时，充值EV_BREAK</li>
  <li>Decrement the loop depth.<br />
  减少loop的层次</li>
  <li>Return.<br />
  返回</li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>    Example: Queue some jobs and then loop until no events are outstanding anymore.
    排列一些jobs，然后循环直到没有事件被凸显出来。

    ... queue jobs here, make sure they register event watchers as long
    ... as they still have work to do (even an idle watcher will do..)
    ev_run (my_loop, 0);
    ... jobs done or somebody called break. yeah!
</code></pre>
</div>

<h4 id="ev_break-loop-how">ev_break (loop, how)</h4>
<p>Can be used to make a call to ev_run return early (but only after it has processed all outstanding events). The how argument must be either EVBREAK_ONE, which will make the innermost ev_run call return, or EVBREAK_ALL, which will make all nested ev_run calls return.<br />
调用此函数可以让ev_run结束并且返回（但是必须在处理完未决的事件）。how参数可能是EVBREAK_ONE，这将使ev_run最里面的循环返回，或者是EVBREAK_ALL，这将使得所有的循环嵌套返回。</p>

<p>This “break state” will be cleared on the next call to ev_run.<br />
这种break状态将会在ev_run的下一次调用中清除。</p>

<p>It is safe to call ev_break from outside any ev_run calls, too, in which case it will have no effect.<br />
在ev_run调用之外调用ev_break是安全的，在这种情况下，调用将没有任何效果。</p>

<h4 id="ev_ref-loop">ev_ref (loop)</h4>
<h4 id="ev_unref-loop">ev_unref (loop)</h4>
<p>Ref/unref can be used to add or remove a reference count on the event loop: Every watcher keeps one reference, and as long as the reference count is nonzero, ev_run will not return on its own.<br />
ref/unref被用来增加或者删除一个event loop的引用计数，每一个watcher都保存了一个引用，只要引用计数不为零，ev_run就不会自行返回。</p>

<p>This is useful when you have a watcher that you never intend to unregister, but that nevertheless should not keep ev_run from returning. In such a case, call ev_unref after starting, and ev_ref before stopping it.<br />
当你有一个从来没有打算注销的watcher，但仍然不想让ev_run无法返回的时候，这是非常有用的。在这种情况下，你可以在开始之后调用ev_unref和在停止之前调用ev_ref。</p>

<p>As an example, libev itself uses this for its internal signal pipe: It is not visible to the libev user and should not keep ev_run from exiting if no event watchers registered by it are active. It is also an excellent way to do this for generic recurring timers or from within third-party libraries. Just remember to unref after start and ref before stop (but only if the watcher wasn’t active before, or was active before, respectively. Note also that libev might stop watchers itself (e.g. non-repeating timers) in which case you have to ev_ref in the callback).<br />
作为一个例子，libev自己内部使用这些函数来处理signal pipe（这里是不是翻译成SIGPIPE这个信号啊？），它对于最终的libev用户来说是不可见的，并且如果没有event watchers被注册成活跃的，它不应该让ev_run退出。对于一般性的定时器和第三方的程序库，这也是一个很好的方法。只需要记住在开始的时候unref，并且在stop之前ref（但是仅当分别在watcher不活跃之前，或者已经活跃之前）也要注意在某些你需要在回调中ev_ref的情况下，libev将会自己停止watchers（例如：不重复的定时器）。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>    Example: Create a signal watcher, but keep it from keeping ev_run running when nothing else is active.
    示例：创建一个信号watcher，并且保证它在没有任何另外活跃的事件的时候，保持ev_run运行。

    ev_signal exitsig;
    ev_signal_init (&amp;exitsig, sig_cb, SIGINT);
    ev_signal_start (loop, &amp;exitsig);
    ev_unref (loop);
</code></pre>
</div>

<div class="highlighter-rouge"><pre class="highlight"><code>    Example: For some weird reason, unregister the above signal handler again.
    例如：对于一些奇怪的原因，再注销上面的信号事件处理程序。

    ev_ref (loop);
    ev_signal_stop (loop, &amp;exitsig);
</code></pre>
</div>

<h4 id="ev_set_io_collect_interval-loop-ev_tstamp-interval">ev_set_io_collect_interval (loop, ev_tstamp interval)</h4>
<h4 id="ev_set_timeout_collect_interval-loop-ev_tstamp-interval">ev_set_timeout_collect_interval (loop, ev_tstamp interval)</h4>
<p>These advanced functions influence the time that libev will spend waiting for events. Both time intervals are by default 0, meaning that libev will try to invoke timer/periodic callbacks and I/O callbacks with minimum latency. <br />
这些高级功能会影响libev将会花在等待events的时间。两者的时间间隔默认为0.意味着libev将会试着以最小的延迟来调用timer/periodic的回调和io的回调。</p>

<p>Setting these to a higher value (the interval must be &gt;= 0) allows libev to delay invocation of I/O and timer/periodic callbacks to increase efficiency of loop iterations (or to increase power-saving opportunities).<br />
把这些值设置的大一点（时间间隔必须大于0）将会允许libev延迟调用io和timer、peroodic的回调函数，来增加loop循环调用的效率（或者增加省电的机会）。</p>

<p>The idea is that sometimes your program runs just fast enough to handle one (or very few) event(s) per loop iteration. While this makes the program responsive, it also wastes a lot of CPU time to poll for new events, especially with backends like select () which have a high overhead for the actual polling but can deliver many events at once.<br />
libev的假设是有的时候，你的程序将会运行的很快，快到足够每次循环来处理一个事件（或者很少的事件），虽然这样可以让程序保持了高响应，但是也浪费了很多的CPU时间来轮训新的事件，特别是当后台使用像select（）这种需要高系统开销的实际的轮流检测，但是可以立刻发现很多事件。</p>

<p>By setting a higher io collect interval you allow libev to spend more time collecting I/O events, so you can handle more events per iteration, at the cost of increasing latency. Timeouts (both ev_periodic and ev_timer) will not be affected. Setting this to a non-null value will introduce an additional ev_sleep () call into most loop iterations. The sleep time ensures that libev will not poll for I/O events more often then once per this interval, on average (as long as the host time resolution is good enough).<br />
通过设置一个较高的io collect时间间隔，你将会允许libev花更多的时间来发现IO事件，所以你可以通过增加延迟的成本来一次迭代处理多个事件。时间过期（包括ev_periodic和ev_timer）将不会受到影响。设置这个值为“非空”，将会在大多数的loop迭代中增加一个ev_sleep调用。休眠时间确保libev将不会多余每次的时间间隔来循环触发IO事件。</p>

<p>Likewise, by setting a higher timeout collect interval you allow libev to spend more time collecting timeouts, at the expense of increased latency/jitter/inexactness (the watcher callback will be called later). ev_io watchers will not be affected. Setting this to a non-null value will not introduce any overhead in libev.<br />
同样，通过设置一个较高的超时时间间隔，你将会允许libev花很多的时间来触发超时，这将会增加延迟/抖动/不精确（watchers的回调将在后面调用）的开销。ev_io watchers将不会收到影响。将其设置为一个“非空”值将不会增加libev任何的开销。</p>

<p>Many (busy) programs can usually benefit by setting the I/O collect interval to a value near 0.1 or so, which is often enough for interactive servers (of course not for games), likewise for timeouts. It usually doesn’t make much sense to set it to a lower value than 0.01, as this approaches the timing granularity of most systems. Note that if you do transactions with the outside world and you can’t increase the parallelity, then this setting will limit your transaction rate (if you need to poll once per transaction and the I/O collect interval is 0.01, then you can’t do more than 100 transactions per second). <br />
很多（繁忙）的程序通常可以通过设置IO触发间隔为0.1左右来受益（效率最大化嘛？）同样的超时时间经常满足一些交互式服务器（当然不能满足游戏。PS：游戏设置多好合适？，貌似没说）。通常，将其设置为一个小于0.01的数将会失去意义，因为0.01通常是大多数系统的时间精度。注意：如果你这样和外界的接口通讯，那么你将不能增加程序的并行性，则这样的设置将会限制你的成功率（如果你需要轮训每次事务，并且IO collect 时间间隔是0.01.你最大的吞吐量也就是100/s）。</p>

<p>Setting the timeout collect interval can improve the opportunity for saving power, as the program will “bundle” timer callback invocations that are “near” in time together, by delaying some, thus reducing the number of times the process sleeps and wakes up again. Another useful technique to reduce iterations/wake-ups is to use ev_periodic watchers and make sure they fire on, say, one-second boundaries only.<br />
设置这个超时时间间隔将会改善省电的机会（PS：效率变慢了？），程序将会捆绑的调用那些超时时间接近的回调函数，通过一些延迟，减少了进程休眠的次数和唤醒的次数，另外一个有用的技术是在使用ev_periodic watchers的时候减少迭代和唤醒的次数，并且确保他们被触发，也就是说，只有一秒钟的时间间隔。（PS：最后一个一秒的界限是什么意思？）</p>

<div class="highlighter-rouge"><pre class="highlight"><code>    Example: we only need 0.1s timeout granularity, and we wish not to poll more often than 100 times per second:
    示例：我们仅仅需要0.1s的超时精度，并且我们希望迭代少于100次/s。

    ev_set_timeout_collect_interval (EV_DEFAULT_UC_ 0.1);
    ev_set_io_collect_interval (EV_DEFAULT_UC_ 0.01);
</code></pre>
</div>

<h4 id="ev_invoke_pending-loop">ev_invoke_pending (loop)</h4>
<p>This call will simply invoke all pending watchers while resetting their pending state. Normally, ev_run does this automatically when required, but when overriding the invoke callback this call comes handy. This function can be invoked from a watcher - this can be useful for example when you want to do some lengthy calculation and want to pass further event handling to another thread (you still have to make sure only one thread executes within ev_invoke_pending or ev_run of course).<br />
这个调用将会简单的调用所有未触发的watchers并且重置它们的未触发状态。通常，ev_run在需要的情况下自动的做这些，但是当覆盖这个回调调用的时候，ev_invoke_pending将会变得得心应手。这个函数将可以在一个watcher中被调用，例如对于你想做一些耗时的计算并且希望另外一个线程进一步的处理来说将会是非常有用的。（当然，你仍然必须保证只有一个线程执行e_invoke_pending或者ev_run）。</p>

<h4 id="int-ev_pending_count-loop">int ev_pending_count (loop)</h4>
<p>Returns the number of pending watchers - zero indicates that no watchers are pending.<br />
返回未被触发的watchers数目-0表示没有未触发的watchers。</p>

<h4 id="ev_set_invoke_pending_cb-loop-void-invoke_pending_cbev_p">ev_set_invoke_pending_cb (loop, void (*invoke_pending_cb)(EV_P))</h4>
<p>This overrides the invoke pending functionality of the loop: Instead of invoking all pending watchers when there are any, ev_run will call this callback instead. This is useful, for example, when you want to invoke the actual watchers inside another context (another thread etc.).<br />
这将重写loop的调用未触发函数：当它存在的时候，将会代替调用所有的未触发watchers，ev_run将会调用这个回调替代。例如对于你想调用真实的watchers在另外一个上下文环境中（另外一个线程等等）将会是非常有用的。</p>

<p>If you want to reset the callback, use ev_invoke_pending as new callback.<br />
如果你想重置这个回调，使用ev_invoke_penging作为新的回调。</p>

<h4 id="ev_set_loop_release_cb-loop-void-releaseev_p-throw--void-acquireev_p-throw-">ev_set_loop_release_cb (loop, void (<em>release)(EV_P) throw (), void (</em>acquire)(EV_P) throw ())</h4>
<p>Sometimes you want to share the same loop between multiple threads. This can be done relatively simply by putting mutex_lock/unlock calls around each call to a libev function.<br />
有时你想在多个线程中共享同一个loop。这将可以通过在libev的函数中放置mutex的lock/unlock来简单的实现。</p>

<p>However, ev_run can run an indefinite time, so it is not feasible to wait for it to return. One way around this is to wake up the event loop via ev_break and ev_async_send, another way is to set these release and acquire callbacks on the loop.<br />
然而，ev_run是在一个不确定的时间运行的，所以要等待它返回是不可行的。一种解决办法就是通过ev_break和ev_async_send来唤醒event loop，另外一种解决方法就是在循环的时候设置Release和acquire回调。</p>

<p>When set, then release will be called just before the thread is suspended waiting for new events, and acquire is called just afterwards.<br />
当设置Release和acquire的时候，Release将会在线程被挂起等待新事件之前被调用，acquire将会在等到新事件后被调用。</p>

<p>Ideally, release will just call your mutex_unlock function, and acquire will just call the mutex_lock function again.<br />
理想情况下，Release将会只调用你的mutex的unlock函数，而acquire将只调用mutex的lock函数。</p>

<p>While event loop modifications are allowed between invocations of release and acquire (that’s their only purpose after all), no modifications done will affect the event loop, i.e. adding watchers will have no effect on the set of file descriptors being watched, or the time waited. Use an ev_async watcher to wake up ev_run when you want it to take note of any changes you made.<br />
在Release和acquire调用之间修改event loop是被允许的（毕竟这是它们唯一的目的），没有修改完成将会影响event loop，例如：加入的那些watchers 在那些被监视的文件描述符或者时间等待上没有效果。当你想注意那些你制造的任何更改时，使用ev_async watcher来唤醒ev_run。</p>

<p>In theory, threads executing ev_run will be async-cancel safe between invocations of release and acquire.<br />
理论上，在Release和acquire调用之间，线程执行ev_run将不是异步安全的。</p>

<p>See also the locking example in the THREADS section later in this document.<br />
请参阅本文档后面在THREADS章节的有关于说的示例。</p>

<h4 id="ev_set_userdata-loop-void-data">ev_set_userdata (loop, void *data)</h4>
<h4 id="void-ev_userdata-loop">void *ev_userdata (loop)</h4>
<p>Set and retrieve a single void * associated with a loop. When ev_set_userdata has never been called, then ev_userdata returns 0.<br />
设置和获取一个和loop相关联的void *（PS：译为对象可能会好一些）。当ev_set_userdata没有被调用的时候，ev_userdata将会返回0.</p>

<p>These two functions can be used to associate arbitrary data with a loop, and are intended solely for the invoke_pending_cb, release and acquire callbacks described above, but of course can be (ab-)used for any other purpose as well.<br />
这两个函数用来和loop关联任何数据，并且仅仅在invoke_pending_cb，Release和acquire回调之中可以被获取，但是当然也可以被用于其他目的。</p>

<h4 id="ev_verify-loop">ev_verify (loop)</h4>
<p>This function only does something when EV_VERIFY support has been compiled in, which is the default for non-minimal builds. It tries to go through all internal structures and checks them for validity. If anything is found to be inconsistent, it will print an error message to standard error and call abort ().<br />
当EV_VERIFY被开启并且被编译的时候，这个函数才会有作用，这是默认的非最小版本（PS：不明白什么意思），它试图检查所有的内部结构体和检查他们的有效性。如果发现任何的不一致，它将会打印一个错误的消息并且调用abort终止程序。</p>

<p>This can be used to catch bugs inside libev itself: under normal circumstances, this function will never abort as of course libev keeps its data structures consistent.<br />
这可以被用来捕捉内部libev本身的错误：在正常情况下，当libev保持它的数据结构是一致的时候，这个函数将永远不会abort。</p>

<h3 id="anatomy-of-a-watcher-watcher的详细说明">ANATOMY OF A WATCHER watcher的详细说明</h3>

<p>In the following description, uppercase TYPE in names stands for the watcher type, e.g. ev_TYPE_start can mean ev_timer_start for timer watchers and ev_io_start for I/O watchers.<br />
在下面的描述中，名称中大写的TYPE表示watcher的类型。例如ev_TYPE_start可以表示用于定时器的ev_timer_start，也可以表示用于IO watchers的ev_io_start。</p>

<p>A watcher is an opaque structure that you allocate and register to record your interest in some event. To make a concrete example, imagine you want to wait for STDIN to become readable, you would create an ev_io watcher for that:<br />
watcher是一个你创建并且注册到你感兴趣的event的不透明的结构体，举个具体的例子，假设你想要等到你的STDIN变得可读，你将创建如下的一个watcher：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>static void my_cb (struct ev_loop *loop, ev_io *w, int revents)
{
    ev_io_stop (w);
    ev_break (loop, EVBREAK_ALL);
}

struct ev_loop *loop = ev_default_loop (0);

ev_io stdin_watcher;

ev_init (&amp;stdin_watcher, my_cb);
ev_io_set (&amp;stdin_watcher, STDIN_FILENO, EV_READ);
ev_io_start (loop, &amp;stdin_watcher);

ev_run (loop, 0);
</code></pre>
</div>

<p>As you can see, you are responsible for allocating the memory for your watcher structures (and it is usually a bad idea to do this on the stack).<br />
就像你看到的，你有职责为你的watcher分配内存（通常的，使用栈内存是一个不明智的主意）。（译者注：作者的意思是你应该尽量使用堆内存）</p>

<p>Each watcher has an associated watcher structure (called struct ev_TYPE or simply ev_TYPE, as typedefs are provided for all watcher structs).<br />
每一个watcher都有相关联的结构体（称为struct ev_TYPE或者干脆使用ev_TYPE作为所有watcher的结构体定义）。</p>

<p>Each watcher structure must be initialised by a call to ev_init (watcher *, callback), which expects a callback to be provided. This callback is invoked each time the event occurs (or, in the case of I/O watchers, each time the event loop detects that the file descriptor given is readable and/or writable).<br />
每一个watcher必须提供一个回调，并且调用ev_init来初始化，这个回调将会在每次事件发生的时候被调用（或者对于IO watcher来说，event loop将会在文件描述符变得可读或者可写的情况下调用）。</p>

<p>Each watcher type further has its own ev_TYPE_set (watcher *, …) macro to configure it, with arguments specific to the watcher type. There is also a macro to combine initialisation and setting in one call: ev_TYPE_init (watcher *, callback, …).<br />
每一个watcher类型都拥有带有指定watcher类型参数的，它自己的ev_TYPE_set宏来配置它。这有一个组合了初始化和配置功能的宏供使用，它就是ev_TYPE_init。</p>

<p>To make the watcher actually watch out for events, you have to start it with a watcher-specific start function (ev_TYPE_start (loop, watcher *)), and you can stop watching for events at any time by calling the corresponding stop function (ev_TYPE_stop (loop, watcher *).<br />
为了使watcher开始监视事件，你必须使用watcher专用的开始函数ev_TYPE_start来启动它，你也可以在任何时候通过调用相应的停止函数ev_TYPE_stop来停止监视事件。</p>

<p>As long as your watcher is active (has been started but not stopped) you must not touch the values stored in it. Most specifically you must never reinitialise it or call its ev_TYPE_set macro.<br />
只要你的watcher还存活着（已经开始还没有停止），你没必要去更改它的值，最具体的，你没必要去重新初始化或者调用它的ev_TYPE_set宏。</p>

<p>Each and every callback receives the event loop pointer as first, the registered watcher structure as second, and a bitset of received events as third argument.<br />
每一个回调函数第一个参数是event loop的指针，第二个参数是已经注册的watcher结构，第三个参数是接收到的事件标志位。</p>

<p>The received events usually include a single bit per event type received (you can receive multiple events at the same time). The possible bit masks are:<br />
接受到的事件经常包括一个bit数据集（你可以同时接收到多个时间），这个标志位经常包括：</p>

<ul>
  <li>EV_READ</li>
  <li>
    <p>EV_WRITE<br />
The file descriptor in the ev_io watcher has become readable and/or writable.<br />
ev_io watcher中的文件描述符变得可读和/或者可写。</p>
  </li>
  <li>
    <p>EV_TIMER<br />
The ev_timer watcher has timed out.<br />
定时器watcher超时。</p>
  </li>
  <li>
    <p>EV_PERIODIC<br />
The ev_periodic watcher has timed out.<br />
ev_periodic watcher超时。</p>
  </li>
  <li>
    <p>EV_SIGNAL<br />
The signal specified in the ev_signal watcher has been received by a thread.<br />
线程收到一个由ev_signal watcher指定的信号。</p>
  </li>
  <li>
    <p>EV_CHILD<br />
The pid specified in the ev_child watcher has received a status change.<br />
接收到由ev_child watcher指定的pid的进程状态的改变。</p>
  </li>
  <li>
    <p>EV_STAT<br />
The path specified in the ev_stat watcher changed its attributes somehow.<br />
接收到由ev_stat watcher监视的path的属性被改变</p>
  </li>
  <li>
    <p>EV_IDLE<br />
The ev_idle watcher has determined that you have nothing better to do.<br />
ev_ide watcher确定你已经没有什么更好的事情可以做。</p>
  </li>
  <li>EV_PREPARE</li>
  <li>EV_CHECK<br />
All ev_prepare watchers are invoked just before ev_run starts to gather new events, and all ev_check watchers are queued (not invoked) just after ev_run has gathered them, but before it queues any callbacks for any received events. That means ev_prepare watchers are the last watchers invoked before the event loop sleeps or polls for new events, and ev_check watchers will be invoked before any other watchers of the same or lower priority within an event loop iteration.<br />
所有的ev_prepare watcher将会在ev_run开始收集新事件之前被调用，所有的ev_check watchers被在ev_run收集到新事件之后排队（不调用），但是在它之前，排列任意已经接收到的事件的任何回调。这意味着ev_prepare watcher是event loop休眠或者循环监视新事件之前的最后一个watcher调用，ev_check watcher将在相同或较低优先级的事件循环迭代内的任何其他watcher之前被调用。</li>
</ul>

<p>Callbacks of both watcher types can start and stop as many watchers as they want, and all of them will be taken into account (for example, a ev_prepare watcher might start an idle watcher to keep ev_run from blocking).<br />
两个watcher类型的回调函数都可以启动和停止他们想要的watchers，所有的watcher都将被考虑在内（例如，一个ev_prepare watcher可以启动一个idle watcher来保持ev_run阻塞）。</p>

<ul>
  <li>
    <p>EV_EMBED<br />
The embedded event loop specified in the ev_embed watcher needs attention.<br />
在ev_embed watcher中指定植入的event loop需要注意的时候。</p>
  </li>
  <li>
    <p>EV_FORK<br />
The event loop has been resumed in the child process after fork (see ev_fork).<br />
在fork之后的子进程中，event loop被恢复（具体查看ev_fork）。</p>
  </li>
  <li>
    <p>EV_CLEANUP<br />
The event loop is about to be destroyed (see ev_cleanup).<br />
event loop将会被释放（具体查看ev_cleanup）。</p>
  </li>
  <li>
    <p>EV_ASYNC<br />
The given async watcher has been asynchronously notified (see ev_async).<br />
给定的异步wacther已经被异步的通知（具体查看ev_async）。</p>
  </li>
  <li>
    <p>EV_CUSTOM<br />
Not ever sent (or otherwise used) by libev itself, but can be freely used by libev users to signal watchers (e.g. via ev_feed_event).<br />
libev自己没有发送过（或者说使用过），但是可以自由的用于libev的信号watcher（例如，通过ev_feed_event）。</p>
  </li>
  <li>
    <p>EV_ERROR<br />
An unspecified error has occurred, the watcher has been stopped. This might happen because the watcher could not be properly started because libev ran out of memory, a file descriptor was found to be closed or any other problem. Libev considers these application bugs.<br />
一个未指定的错误已经发生，watcher已经被停止。这个可能发生了：watcher不能正常的启动，libev耗尽内存，一个文件描述符被发现已经关闭，或者是另外的一些问题。libev认为这些是应用程序级别的bugs。</p>
  </li>
</ul>

<p>You best act on it by reporting the problem and somehow coping with the watcher being stopped. Note that well-written programs should not receive an error ever, so when your watcher receives it, this usually indicates a bug in your program.<br />
这种问题你最好的处理艺术是报告这些问题，并且想办法应对这些watcher将要停止。注意：良好的程序是不会不断的收到错误的，所以，当你的watcher接受到这些错误的时候，经常表明在你的程序中有bug。</p>

<p>Libev will usually signal a few “dummy” events together with an error, for example it might indicate that a fd is readable or writable, and if your callbacks is well-written it can just attempt the operation and cope with the error from read() or write(). This will not work in multi-threaded programs, though, as the fd could already be closed and reused for another thing, so beware.<br />
libev经常会和一些错误一起标记一些假的事件。例如，libev可能会表明一个fd已经可读或者可写了，如果你的程序写的很好，回调会只是尝试去操作，并且可以应对来自read或者write的错误。这在多线程程序中将不会正常运行，不过，鉴于这个fd已经被关闭，可以给另外一些事件重复使用，所以要小心。</p>

<h3 id="generic-watcher-functions-watcher的通用函数">GENERIC WATCHER FUNCTIONS watcher的通用函数</h3>

<h4 id="ev_init-ev_type-watcher-callback">ev_init (ev_TYPE *watcher, callback)</h4>
<p>This macro initialises the generic portion of a watcher. The contents of the watcher object can be arbitrary (so malloc will do). Only the generic parts of the watcher are initialised, you need to call the type-specific ev_TYPE_set macro afterwards to initialise the type-specific parts. For each type there is also a ev_TYPE_init macro which rolls both calls into one.<br />
这个宏将初始化watcher的通用部分。watcher对象的内容可以是任意的（所以可以使用malloc）。只有watcher的通用部分被初始化，然后你要调用指定类型的ev_TYPE_set宏来初始化特定的部分。每一个类型都有一个ev_TYPE_init宏，它可以一次调用ev_TYPE_init和ev_TYPE_set两个宏。</p>

<p>You can reinitialise a watcher at any time as long as it has been stopped (or never started) and there are no pending events outstanding.<br />
只要watcher已经停止（或者从来没有启动），也没有未处理的事件，你可以在任何时候重新初始化watcher。</p>

<p>The callback is always of type void (<em>)(struct ev_loop *loop, ev_TYPE *watcher, int revents).<br />
watcher的回调函数一直被定义成 void (</em>)(struct ev_loop *loop, ev_TYPE *watcher, int revents).。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>Example: Initialise an ev_io watcher in two steps.
示例：两部初始化一个ev_iowatcher

ev_io w;
ev_init (&amp;w, my_cb);
ev_io_set (&amp;w, STDIN_FILENO, EV_READ);
</code></pre>
</div>

<h4 id="ev_type_set-ev_type-watcher-args">ev_TYPE_set (ev_TYPE *watcher, [args])</h4>
<p>This macro initialises the type-specific parts of a watcher. You need to call ev_init at least once before you call this macro, but you can call ev_TYPE_set any number of times. You must not, however, call this macro on a watcher that is active (it can be pending, however, which is a difference to the ev_init macro).<br />
这个宏初始化watcher的特定部分。你在调用此宏之前必须要先至少调用一次ev_init，当然你也可以多次调用此宏。但是，你不能在这个watcher活跃的时候调用此宏（但是它可以是挂起的，这是和ev_init不一样的地方）。</p>

<p>Although some watcher types do not have type-specific arguments (e.g. ev_prepare) you still need to call its set macro.<br />
尽管某些watcher类型没有特定的参数（比如ev_prepare），但是你仍然需要调用这个宏。</p>

<p>See ev_init, above, for an example.<br />
示例请查看上面的ev_init部分。</p>

<h4 id="ev_type_init-ev_type-watcher-callback-args">ev_TYPE_init (ev_TYPE *watcher, callback, [args])</h4>
<p>This convenience macro rolls both ev_init and ev_TYPE_set macro calls into a single call. This is the most convenient method to initialise a watcher. The same limitations apply, of course.<br />
这是一个宏调用包括了ev_init和ev_TYPE_set的简便方法。这也是大多数程序中经常使用的方法。当然，限制是一样的。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>Example: Initialise and set an ev_io watcher in one step.
示例：一步初始化并且设置一个ev_io watcher。

ev_io_init (&amp;w, my_cb, STDIN_FILENO, EV_READ);
</code></pre>
</div>

<h4 id="ev_type_start-loop-ev_type-watcher">ev_TYPE_start (loop, ev_TYPE *watcher)</h4>
<p>Starts (activates) the given watcher. Only active watchers will receive events. If the watcher is already active nothing will happen.<br />
启动（或者激活）给定的watcher。只有活跃的watchers将会接收到事件。如果watcher已经是活跃的，那么什么都不会发生。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>Example: Start the ev_io watcher that is being abused as example in this whole section.
示例：启动一个ev_io watcher。这是已经在整个章节中被用烂的例子。

ev_io_start (EV_DEFAULT_UC, &amp;w);
</code></pre>
</div>

<h4 id="ev_type_stop-loop-ev_type-watcher">ev_TYPE_stop (loop, ev_TYPE *watcher)</h4>
<p>Stops the given watcher if active, and clears the pending status (whether the watcher was active or not).<br />
如果给定的watcher是活跃的，那么停止这个watcher。并且清除挂起状态（这个watcher是否是活跃的？）。</p>

<p>It is possible that stopped watchers are pending - for example, non-repeating timers are being stopped when they become pending - but calling ev_TYPE_stop ensures that the watcher is neither active nor pending. If you want to free or reuse the memory used by the watcher it is therefore a good idea to always call its ev_TYPE_stop function.<br />
停止一个行将发生的watchers将会有问题。例如，一个不重复的定时器在行将发生时将会停止，但是调用ev_TYPE_stop将确保watcher不会存活，也不会挂起。如果你想释放或者重用这个watcher的内存，那么调用ev_TYPE_stop将是一个好主意。</p>

<h4 id="bool-ev_is_active-ev_type-watcher">bool ev_is_active (ev_TYPE *watcher)</h4>
<p>Returns a true value iff the watcher is active (i.e. it has been started and not yet been stopped). As long as a watcher is active you must not modify it.<br />
如果返回true，那么表示watcher还是活跃的状态（例如：watcher已经被激活并且也没有被停止）。只要watcher还处于活跃状态，那么你就不能修改它。</p>

<h4 id="bool-ev_is_pending-ev_type-watcher">bool ev_is_pending (ev_TYPE *watcher)</h4>
<p>Returns a true value iff the watcher is pending, (i.e. it has outstanding events but its callback has not yet been invoked). As long as a watcher is pending (but not active) you must not call an init function on it (but ev_TYPE_set is safe), you must not change its priority, and you must make sure the watcher is available to libev (e.g. you cannot free () it).<br />
如果返回true，那么表示watcher处于挂起状态（例如：watcher已经有事件发生，但是还没有调用事件的回调函数进行处理）。只要watcher处于挂起状态（但是不是活跃状态），你就不能调用它的init函数（但是ev_TYPE_set是安全的），你不能改变它的优先级，并且你必须保证对于libev来说，watcher是可用的（例如：你不能调用free释放这个watcher）。</p>

<h4 id="callback-ev_cb-ev_type-watcher">callback ev_cb (ev_TYPE *watcher)</h4>
<p>Returns the callback currently set on the watcher.<br />
返回指定watcher设置的当前回调。</p>

<h4 id="ev_set_cb-ev_type-watcher-callback">ev_set_cb (ev_TYPE *watcher, callback)</h4>
<p>Change the callback. You can change the callback at virtually any time (modulo threads).<br />
更改回调。你可以在任何时候无形中更改回调（modulo threads？？怎么翻译）</p>

<h4 id="ev_set_priority-ev_type-watcher-int-priority">ev_set_priority (ev_TYPE *watcher, int priority)</h4>
<h4 id="int-ev_priority-ev_type-watcher">int ev_priority (ev_TYPE *watcher)</h4>
<p>Set and query the priority of the watcher. The priority is a small integer between EV_MAXPRI (default: 2) and EV_MINPRI (default: -2). Pending watchers with higher priority will be invoked before watchers with lower priority, but priority will not keep watchers from being executed (except for ev_idle watchers).<br />
设置或者查询watcher的优先级。这个优先级是一个在EV_MAXPRI（默认是2）和EV_MINPRI（默认是-2）之间的很小的整数。挂起的高优先级watchers将会比低优先级的watchers先调用。但是优先级不能阻止watcher被执行（除了ev_idle watcher）。</p>

<p>If you need to suppress invocation when higher priority events are pending you need to look at ev_idle watchers, which provide this functionality.<br />
如果你想在高优先级事件即将发生的时候抑制这个调用，你需要看一下ev_idle watcher，ev_idle watcher提供了这个功能。</p>

<p>You must not change the priority of a watcher as long as it is active or pending.<br />
只要watcher是活跃的或者挂起的，你就不能更改这个watcher的优先级。</p>

<p>Setting a priority outside the range of EV_MINPRI to EV_MAXPRI is fine, as long as you do not mind that the priority value you query might or might not have been clamped to the valid range.<br />
只要你不介意你查询的优先级不在有效的范围内，你把优先级设置到EV_MINPRI和EV_MAXPRI之外没有关系。</p>

<p>The default priority used by watchers when no priority has been set is always 0, which is supposed to not be too high and not be too low :).<br />
当没有设置watcher的优先级的时候，默认的值一直是0.这个值不高也不低。</p>

<p>See WATCHER PRIORITY MODELS, below, for a more thorough treatment of priorities.<br />
查看watcher的优先级模型，下面会有更详细的讲解。</p>

<h4 id="ev_invoke-loop-ev_type-watcher-int-revents">ev_invoke (loop, ev_TYPE *watcher, int revents)</h4>
<p>Invoke the watcher with the given loop and revents. Neither loop nor revents need to be valid as long as the watcher callback can deal with that fact, as both are simply passed through to the callback.<br />
通过给定的loop和事件标志位来调用watcher。只要watcher的回调可以处理，既不需要循环也不需要事件有效发生。因为两者都是简单的调用回调而已。</p>

<h4 id="int-ev_clear_pending-loop-ev_type-watcher">int ev_clear_pending (loop, ev_TYPE *watcher)</h4>
<p>If the watcher is pending, this function clears its pending status and returns its revents bitset (as if its callback was invoked). If the watcher isn’t pending it does nothing and returns 0. <br />
如果watcher是被挂起的，这个函数将会清空watcher的挂起状态，并且返回它的事件集标志位（就好像它的回调已经被调用过一样）。如果watcher不是被挂起的，那么此函数将什么都不做，并且返回0.</p>

<p>Sometimes it can be useful to “poll” a watcher instead of waiting for its callback to be invoked, which can be accomplished with this function. <br />
有的时候，循环一个watcher而不是等待watcher调用它的回调是有用的，这个函数就完成了这个功能。</p>

<h4 id="ev_feed_event-loop-ev_type-watcher-int-revents">ev_feed_event (loop, ev_TYPE *watcher, int revents)</h4>
<p>Feeds the given event set into the event loop, as if the specified event had happened for the specified watcher (which must be a pointer to an initialised but not necessarily started event watcher). Obviously you must not free the watcher as long as it has pending events.<br />
订阅设置到event loop的给定的事件，好像对于执行watcher来说指定的事件已经发生了（watcher必须是一个已经初始化但是不一定已经启动的watcher指针）。显然，只要watcher还有未处理的事件，你就不能释放这个watcher指针。</p>

<p>Stopping the watcher, letting libev invoke it, or calling ev_clear_pending will clear the pending event, even if the watcher was not started in the first place.<br />
虽然没有第一时间启动watcher，但是停止watcher，让libev调用它，或者调用ev_clear_pending来清理未触发的事件。</p>

<p>See also ev_feed_fd_event and ev_feed_signal_event for related functions that do not need a watcher.<br />
另请参阅ev_feed_fd_event和ev_feed_signal_event的相关功能，它们不需要watcher参数。</p>

<p>See also the ASSOCIATING CUSTOM DATA WITH A WATCHER and BUILDING YOUR OWN COMPOSITE WATCHERS idioms.<br />
另请参阅ASSOCIATING CUSTOM DATA WITH A WATCHER（watcher关联自定义数据）和BUILDING YOUR OWN COMPOSITE WATCHERS （构建你自己的watcher）部分。</p>

<h3 id="watcher-states-watcher-状态">WATCHER STATES watcher 状态</h3>

<p>There are various watcher states mentioned throughout this manual - active, pending and so on. In this section these states and the rules to transition between them will be described in more detail - and while these rules might look complicated, they usually do “the right thing”.<br />
这本手册中提到watcher的各种状态-活跃，挂起等等。在这节中，将更详细的面熟这些状态和转换规则，虽然这些规则看起来很复杂，但是它们通常会做正确的事情。</p>

<ul>
  <li>initialised 已经初始化<br />
Before a watcher can be registered with the event loop it has to be initialised. This can be done with a call to ev_TYPE_init, or calls to ev_init followed by the watcher-specific ev_TYPE_set function.<br />
在watcher可以在event loop中注册之前，它必须被初始化。它可以使用调用ev_TYPE_init初始化，或者调用ev_init，接着调用watcher具体类型的ev_TYPE_set函数。</li>
</ul>

<p>In this state it is simply some block of memory that is suitable for use in an event loop. It can be moved around, freed, reused etc. at will - as long as you either keep the memory contents intact, or call ev_TYPE_init again.<br />
在这种状态下，watcher只是一块可以在event loop中使用的简单的内存块。它可以根据你的意愿任意的移动，释放或者再利用等等。只要保证内存中的内容不变或者再次调用ev_TYPE_init。</p>

<ul>
  <li>
    <p>started/running/active 开始/运行/活跃<br />
Once a watcher has been started with a call to ev_TYPE_start it becomes property of the event loop, and is actively waiting for events. While in this state it cannot be accessed (except in a few documented ways), moved, freed or anything else - the only legal thing is to keep a pointer to it, and call libev functions on it that are documented to work on active watchers.<br />
一旦watcher使用ev_TYPE_start启动，event loop将接管它的所有权，并且将积极的等待事件。虽然在这种状态下它不能被访问（除了几个有据可查的方法外 PS：其实就是libev有几个允许访问的方法可以访问在这个状态下的watcher），移动，释放或者任何事情。唯一合法的事情就是保持一个指向它的指针，或者使用libev允许的方法来访问它。</p>
  </li>
  <li>
    <p>pending 挂起（未处理）<br />
If a watcher is active and libev determines that an event it is interested in has occurred (such as a timer expiring), it will become pending. It will stay in this pending state until either it is stopped or its callback is about to be invoked, so it is not normally pending inside the watcher callback.<br />
如果watcher是活跃的，并且libev确定这个watcher的事件已经发生（例如定时器即将到期），那么watcher将变成挂起的（或者说是未处理的）。它将一直保持挂起状态，直到wacther被停止或者它的回调函数被调用，所以它一般不会在watcher的callback中被正常的挂起。</p>
  </li>
</ul>

<p>The watcher might or might not be active while it is pending (for example, an expired non-repeating timer can be pending but no longer active). If it is stopped, it can be freely accessed (e.g. by calling ev_TYPE_set), but it is still property of the event loop at this time, so cannot be moved, freed or reused. And if it is active the rules described in the previous item still apply.<br />
当wacterh是挂起状态的时候，它是不是被激活都是有可能发生的（例如，过期并且非重复的计时器将会被挂起，但是不再是活跃的）。如果它已经被停止，那么它可以被随意的访问（例如调用ev_TYPE_set），但是这个时候，event loop仍然有这个wacther的所有权，所以不能被移动，释放，或者重用。如果这个watcher是活跃的，那么这个规则对于前一个项仍然适用。（PS：这里的item是指啥玩意？）</p>

<p>It is also possible to feed an event on a watcher that is not active (e.g. via ev_feed_event), in which case it becomes pending without being active.<br />
也可以把一个事件强行提供给一个不是活跃状态的watcher（例如通过ev_feed_event），这种情况下，watcher将会在没有经过活跃状态的情况下直接到挂起状态。</p>

<ul>
  <li>stopped<br />
A watcher can be stopped implicitly by libev (in which case it might still be pending), or explicitly by calling its ev_TYPE_stop function. The latter will clear any pending state the watcher might be in, regardless of whether it was active or not, so stopping a watcher explicitly before freeing it is often a good idea.<br />
watcher可以通过libev隐式的停止（这种情况下，watcher可能仍然是挂起状态），或者通过调用ev_TYPE_stop函数显式的停止。后者将会清除watcher可能存在的挂起状态，无论他是活跃的还是不活跃的，所以在释放它之前先显式的停止它一般来说都是一个好主意。</li>
</ul>

<p>While stopped (and not pending) the watcher is essentially in the initialised state, that is, it can be reused, moved, modified in any way you wish (but when you trash the memory block, you need to ev_TYPE_init it again).<br />
在停止并且非挂起状态下，watcher基本上就是在初始化状态，也就是说，它可以按照你的想法重用，移动，更改（但是如果你释放掉这个内存块，你需要再次使用ev_TYPE_init）。</p>

<h3 id="watcher-priority-models-watcher的优先级模型">WATCHER PRIORITY MODELS watcher的优先级模型</h3>

<p>Many event loops support watcher priorities, which are usually small integers that influence the ordering of event callback invocation between watchers in some way, all else being equal.<br />
很多事件循环框架支持watcher的优先级，它通常是一个影响同等条件的watcher的回调函数顺序的小整数。</p>

<p>In libev, Watcher priorities can be set using ev_set_priority. See its description for the more technical details such as the actual priority range.<br />
在libev中，watcher的优先级可以通过使用ev_set_priority设置。更多的细节请参阅其函数说明，例如：实际优先级值的范围</p>

<p>There are two common ways how these these priorities are being interpreted by event loops:<br />
event loops通常有两种方法来实现优先级：</p>

<p>In the more common lock-out model, higher priorities “lock out” invocation of lower priority watchers, which means as long as higher priority watchers receive events, lower priority watchers are not being invoked.<br />
在常见的锁定模式中，高优先级的watcher”锁定“低优先级watchers的调用，这意味着只要高优先级的watchers接收到事件，那么低优先级的watchers将不会被调用。</p>

<p>The less common only-for-ordering model uses priorities solely to order callback invocation within a single event loop iteration: Higher priority watchers are invoked before lower priority ones, but they all get invoked before polling for new events.<br />
不太常见是只做序模型，在一个单一的event loop循环内部，使用优先级作为唯一的排序依据，来回调watcher的调用：高优先级的watchers会在低优先级前面调用，但是它们都会在再次循环触发事件之前调用。</p>

<p>Libev uses the second (only-for-ordering) model for all its watchers except for idle watchers (which use the lock-out model).<br />
libev使用第二种模型（只排序），除了idle watcher（它使用第一种锁定模型）。</p>

<p>The rationale behind this is that implementing the lock-out model for watchers is not well supported by most kernel interfaces, and most event libraries will just poll for the same events again and again as long as their callbacks have not been executed, which is very inefficient in the common case of one high-priority watcher locking out a mass of lower priority ones.<br />
这样做的理由是，执行锁定模型，watcher不能很好的被大多数内核接口支持，并且只要它们的回调没有被执行，大多数的事件库只是一次又一次循环的触发相同的事件，在通常情况下，一个高优先级watcher锁定了大量低优先级的watcher，这效率是非常低下的。</p>

<p>Static (ordering) priorities are most useful when you have two or more watchers handling the same resource: a typical usage example is having an ev_io watcher to receive data, and an associated ev_timer to handle timeouts. Under load, data might be received while the program handles other jobs, but since timers normally get invoked first, the timeout handler will be executed before checking for data. In that case, giving the timer a lower priority than the I/O watcher ensures that I/O will be handled first even under adverse conditions (which is usually, but not always, what you want).<br />
当你有两个或者多个watchers正要处理相同资源的时候，静态（排序）优先级是非常有用的：一个典型的例子就是有一个ev_io watcher接收数据，并且一个相关的ev_timer处理超时。在负债下，数据可能会在处理其他任务的时候被接收，但是由于定时器通常先被调用，超时处理程序将在验证数据之前被调用。在这种情况下，给定时器一个比io watcher低的优先级来确保io即使在不利的情况下也会被先调用（这种就是通常的解决方案，当并非总是如此。PS：what you want？怎么翻译？作者的挑衅？）。</p>

<p>Since idle watchers use the “lock-out” model, meaning that idle watchers will only be executed when no same or higher priority watchers have received events, they can be used to implement the “lock-out” model when required.<br />
由于idle watchers使用”锁定“模型，这意味着idle watcher只有在没有相同或者更高的watcher接收到事件时才会被执行，当需要的时候，他们可以被用来实现”锁定“模型。</p>

<p>For example, to emulate how many other event libraries handle priorities, you can associate an ev_idle watcher to each such watcher, and in the normal watcher callback, you just start the idle watcher. The real processing is done in the idle watcher callback. This causes libev to continuously poll and process kernel event data for the watcher, but when the lock-out case is known to be rare (which in turn is rare :), this is workable.<br />
举个例子，仿效其他很多事件库处理优先级，你可以给每一个watcher关联一个ev_idle，并且在正常的watcher回调中，你只是启动这个idle watcher。真正的处理过程实在idle watcher的回调中调用的。这将导致libev死循环和不断的处理watcher的内核事件，但是在锁定情况下将会是很罕见的（这又是难得的），所以这是可行的。</p>

<p>Usually, however, the lock-out model implemented that way will perform miserably under the type of load it was designed to handle. In that case, it might be preferable to stop the real watcher before starting the idle watcher, so the kernel will not have to process the event in case the actual processing will be delayed for considerable time.<br />
然后，通常情况下，lock-out模型在负载类型下被设计来处理实现这种方法将会是非常糟糕的。在这种情况下，它可能最好在启动idle watcher之前先停止真实的watcher，所以在内核将不必处理这个事件的情况下，真实的处理过程将会被延迟很长时间。</p>

<p>Here is an example of an I/O watcher that should run at a strictly lower priority than the default, and which should only process data when no other events are pending:<br />
这是一个io watcher运行在比默认还低的优先级，但没有任何事件被挂起并且只能处理数据的例子。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>ev_idle idle; // actual processing watcher
ev_io io;     // actual event watcher

static void
io_cb (EV_P_ ev_io *w, int revents)
{
    // stop the I/O watcher, we received the event, but
    // are not yet ready to handle it.
    //停止io watcher，我们接收这个事件，但是不准备处理它
    ev_io_stop (EV_A_ w);

    // start the idle watcher to handle the actual event.
    // it will not be executed as long as other watchers
    // with the default priority are receiving events.
    //开始idle watcher来处理真实的事件
    //只要另外默认优先级的watchers这在接收事件，那么将不会被执行。
    ev_idle_start (EV_A_ &amp;idle);
}

static void
idle_cb (EV_P_ ev_idle *w, int revents)
{
    // actual processing
    //真实的处理过程
    read (STDIN_FILENO, ...);

    // have to start the I/O watcher again, as
    // we have handled the event
    //必须重启io watcher，因为我们可以处理这个事件
    ev_io_start (EV_P_ &amp;io);
}

// initialisation
ev_idle_init (&amp;idle, idle_cb);
ev_io_init (&amp;io, io_cb, STDIN_FILENO, EV_READ);
ev_io_start (EV_DEFAULT_ &amp;io);
</code></pre>
</div>

<p>In the “real” world, it might also be beneficial to start a timer, so that low-priority connections can not be locked out forever under load. This enables your program to keep a lower latency for important connections during short periods of high load, while not completely locking out less important ones.<br />
在”真实“的项目中（就是在真实的项目中），启动一个定时器是有必要的，这样低优先级的连接在高负载下就不会永远被锁了。这意味着你的程序对于在短期高负载下重要的连接保持一个低延迟，而不是完全锁定那些没那么重要的连接。（也就是说先处理高优先级的，再处理低优先级的，不会只处理高优先级的）。</p>

<h3 id="watcher-types">WATCHER TYPES</h3>

<p>This section describes each watcher in detail, but will not repeat information given in the last section. Any initialisation/set macros, functions and members specific to the watcher type are explained.<br />
本节介绍每一种watcher的细节，但是在最后一节我们不会给出重复的信息。任何初始化/set宏，函数和每种watcher特有的属性成员都会被介绍。</p>

<p>Members are additionally marked with either [read-only], meaning that, while the watcher is active, you can look at the member and expect some sensible content, but you must not modify it (you can modify it while the watcher is stopped to your hearts content), or [read-write], which means you can expect it to have some sensible content while the watcher is active, but you can also modify it. Modifying it may not do something sensible or take immediate effect (or do anything at all), but libev will not crash or malfunction in any way.<br />
加之属性成员又被标记为只读，这意味着，当watcher是活跃的时候，你可以查看一下属性成员并且得到一些明智的内容，但是你不能更改它（当你觉得watcher被停止的时候你可以更改它。PS：是不是就是说当你觉得它不再被使用的时候，你可以更改只读属性？）；或者标记为读-写，这意味着你可以在watcher活跃的时候获得它的明智内容，但是你也可以更改它。更改读写成员，特需不会做一些明智的事情，或者不能即时生效（或者根本什么都没有做），但是libev也不会死机或者发生故障。</p>

<h4 id="ev_io---is-this-file-descriptor-readable-or-writable--ev_io-是不是文件描述符可读或者可写事件">ev_io - is this file descriptor readable or writable?  ev_IO-是不是文件描述符可读或者可写事件？</h4>

<p>I/O watchers check whether a file descriptor is readable or writable in each iteration of the event loop, or, more precisely, when reading would not block the process and writing would at least be able to write some data. This behaviour is called level-triggering because you keep receiving events as long as the condition persists. Remember you can stop the watcher if you don’t want to act on the event and neither want to receive future events.<br />
IO watchers在event loop每次迭代的时候检查文件描述符是可读还是可写的，或者更正确的说，当读不阻塞进程和写至少能写一点数据的时候。这种行为被成为水平触发，因为你只要条件允许，就保持接受事件。记住，如果你不想对事件采取行动也不想将来接受事件，你可以停止watcher。</p>

<p>In general you can register as many read and/or write event watchers per fd as you want (as long as you don’t confuse yourself). Setting all file descriptors to non-blocking mode is also usually a good idea (but not required if you know what you are doing).<br />
一般来说，每一个文件描述符你都可以注册你想注册的那些读和/或者写事件（只要你自己不要搞混）。将所有的文件描述符设置成”非阻塞“的模式也经常是一个好主意。</p>

<p>Another thing you have to watch out for is that it is quite easy to receive “spurious” readiness notifications, that is, your callback might be called with EV_READ but a subsequent read(2) will actually block because there is no data. It is very easy to get into this situation even with a relatively standard program structure. Thus it is best to always use non-blocking I/O: An extra read(2) returning EAGAIN is far preferable to a program hanging until some data arrives.<br />
另一个你需要注意的是，它很容易会收到“虚假”的准备就绪通知，也就是说，你的回调函数将会被按照EV_READ方式调用，但是随后read(2)调用将会被阻塞，因为根本就没有数据。即使程序结构很标准，这种状况也很容易发生。所以，最好的办法是使用非阻塞的IO：一个特别的read(2)返回EAGAIN相比阻塞进程到数据达到会更好。</p>

<p>If you cannot run the fd in non-blocking mode (for example you should not play around with an Xlib connection), then you have to separately re-test whether a file descriptor is really ready with a known-to-be good interface such as poll (fortunately in the case of Xlib, it already does this on its own, so its quite safe to use). Some people additionally use SIGALRM and an interval timer, just to be sure you won’t block indefinitely.<br />
如果你将文件描述符设置成非阻塞模式（例如你不应该玩Xlib的连接 PS：Xlib的链接有什么特别吗？对Xlib不熟悉），那么你必须单独的重新测试文件描述符是否已经准备好将要良好的界面，例如poll（幸运的是，Xlib在这种情况下，他已经自己这样做了，所以可以安全的使用）。有一些人还用SIGALRM和定时器，只是要确定你将不会无限期的阻塞进程。</p>

<p>But really, best use non-blocking mode.<br />
不过说真的，最好的办法还是使用非阻塞模式。</p>

<p>The special problem of disappearing file descriptors<br />
不存在的文件描述符的特殊问题</p>

<p>Some backends (e.g. kqueue, epoll) need to be told about closing a file descriptor (either due to calling close explicitly or any other means, such as dup2). The reason is that you register interest in some file descriptor, but when it goes away, the operating system will silently drop this interest. If another file descriptor with the same number then is registered with libev, there is no efficient way to see that this is, in fact, a different file descriptor.<br />
有一些后台（例如kqueue，epoll）需要被告知关闭文件描述符（不是由于显式的调用关闭就是任何其他手段，例如dup2）。这个原因是你注册的事件对一些文件描述符感兴趣，但是当这些文件描述符消失的时候，操作系统将默默的删除这些兴趣，如果另外一个文件描述符使用同样的文件描述符值在libev中注册，那么libev将没有有效的方法来区分实际上这是一个不同的文件描述符。</p>

<p>To avoid having to explicitly tell libev about such cases, libev follows the following policy: Each time ev_io_set is being called, libev will assume that this is potentially a new file descriptor, otherwise it is assumed that the file descriptor stays the same. That means that you have to call ev_io_set (or ev_io_init) when you change the descriptor even if the file descriptor number itself did not change.<br />
为了避免不得不明确的告诉libev这种情况，libev遵循以下原则：每次ev_io_set被调用，libev都假定这可能是一个新的文件描述符，否则假定文件描述符保持不变。这意味着即使文件描述符值它自己都没有改变，当你需要改变文件描述符的时候你不得不调用ev_io_set（或者是ev_io_init）。</p>

<p>This is how one would do it normally anyway, the important point is that the libev application should not optimise around libev but should leave optimisations to libev.<br />
这通常究竟是怎么做的，重要的一点是libev应用程序不应该到处优化libev，但是应该交给libev优化。</p>

<p>The special problem of dup’ed file descriptors<br />
dup文件描述符的问题</p>

<p>Some backends (e.g. epoll), cannot register events for file descriptors, but only events for the underlying file descriptions. That means when you have dup ()’ed file descriptors or weirder constellations, and register events for them, only one file descriptor might actually receive events.<br />
一些后台（例如epoll），仅对潜在的文件描述符事件，不能为这些文件描述符注册事件。这意味着当你用dup（）或者更怪异的方法生成的文件描述符，为他们注册事件，只有一个文件描述符事实上接收到事件。</p>

<p>There is no workaround possible except not registering events for potentially dup ()’ed file descriptors, or to resort to EVBACKEND_SELECT or EVBACKEND_POLL.<br />
目前没有解决方法把可能是dup生成的文件描述符排除在注册事件之外（PS：其实就是还没有办法限制dup生成的文件描述符注册到libev），或者求助于EVBACKEND_SELECT或EVBACKEND_POLL</p>

<p>The special problem of files<br />
文件的特殊问题</p>

<p>Many people try to use select (or libev) on file descriptors representing files, and expect it to become ready when their program doesn’t block on disk accesses (which can take a long time on their own).<br />
很多人都试着在文件描述符上用select（或者libev）来表现文件，并且在磁盘访问时，希望他们的程序变成就绪状态、不阻塞。</p>

<p>However, this cannot ever work in the “expected” way - you get a readiness notification as soon as the kernel knows whether and how much data is there, and in the case of open files, that’s always the case, so you always get a readiness notification instantly, and your read (or possibly write) will still block on the disk I/O.<br />
然而，在某些时候它并不能按照希望的方式工作—只要内核知道这里是否有数据或者有多少数据，你就会得到一个准备就绪的通知，并且在打开文件的情况下，通常都会是这样的。所以你通常都会瞬间得到一个准备就绪的通知，并且你的读取（也有可能是写入）将仍然阻塞在磁盘IO上。</p>

<p>Another way to view it is that in the case of sockets, pipes, character devices and so on, there is another party (the sender) that delivers data on its own, but in the case of files, there is no such thing: the disk will not send data on its own, simply because it doesn’t know what you wish to read - you would first have to request some data.<br />
另外一种方法来看待这个事情是在sockets，pipes，字符驱动设备等等情况下，它自己可能是发送数据的另外一方，但是磁盘文件的情况下，并不存在这样的事情：磁盘它自己不会发送数据，只是因为它不知道你想读–你必须首先请求一些数据。</p>

<p>Since files are typically not-so-well supported by advanced notification mechanism, libev tries hard to emulate POSIX behaviour with respect to files, even though you should not use it. The reason for this is convenience: sometimes you want to watch STDIN or STDOUT, which is usually a tty, often a pipe, but also sometimes files or special devices (for example, epoll on Linux works with /dev/random but not with /dev/urandom), and even though the file might better be served with asynchronous I/O instead of with non-blocking I/O, it is still useful when it “just works” instead of freezing.<br />
因为文件通常都不是那么友好的支持先进的通报机制，所以libev试着力图模仿POSIX尊重文件的行为，尽管你可能不会用到它。模仿文件的原因就是因为方便：有些时候，你需要关注STDIN或者是STDOUT，它们通常是一个管道实现的tty设备，但是有些时候也是文件或者是特殊的驱动设备（例如，epoll在linux上靠/dev/random工作，但是不靠/dev/urandom），尽管文件使用异步IO替代非阻塞IO可能会被更好的送达，但是当它只要工作而不是冻结的时候，它仍然非常有用。</p>

<p>So avoid file descriptors pointing to files when you know it (e.g. use libeio), but use them when it is convenient, e.g. for STDIN/STDOUT, or when you rarely read from a file instead of from a socket, and want to reuse the same code path.<br />
所以当你知道它的时候（例如使用libeio），要尽量的避免文件描述符指向文件（这里的文件应该是指磁盘文件），但是使用它们的时候很方便，例如对于标准输入/输出，或当您从文件而不是从一个socket中很好的读，并且想重用同样的代码路径。</p>

<p>The special problem of fork<br />
fork的特殊问题</p>

<p>Some backends (epoll, kqueue) do not support fork () at all or exhibit useless behaviour. Libev fully supports fork, but needs to be told about it in the child if you want to continue to use it in the child.<br />
一些后台（epoll，kqueue）根本不提供fork或者表现出没用的行为。libev完全支持fork，但是需要在子进程被告知，如果你想在子进程中继续使用libev。</p>

<p>To support fork in your child processes, you have to call ev_loop_fork () after a fork in the child, enable EVFLAG_FORKCHECK, or resort to EVBACKEND_SELECT or EVBACKEND_POLL.<br />
为了在你的子进程中支持fork，你必须在调用fork之后的子进程中调用ev_loop_fork，开启EVFLAG_FORKCHECK或者依靠EVBACKEND_SELECT或者EVBACKEND_POLL.</p>

<p>The special problem of SIGPIPE<br />
SIGPIPE信号的特殊问题</p>

<p>While not really specific to libev, it is easy to forget about SIGPIPE: when writing to a pipe whose other end has been closed, your program gets sent a SIGPIPE, which, by default, aborts your program. For most programs this is sensible behaviour, for daemons, this is usually undesirable.<br />
虽然没有明确到libev，但是也容易忽略掉SIGPIPE：当你写入数据到一个另外一端已经被关闭的管道（pipe），你的程序将会发送一个SIGPIPE信号，默认情况下，会中止你程序。对于大多数程序来说这是一个明智的行为，但是对于守护进程，这通常是不可取的。</p>

<p>So when you encounter spurious, unexplained daemon exits, make sure you ignore SIGPIPE (and maybe make sure you log the exit status of your daemon somewhere, as that would have given you a big clue).<br />
所以当你遇到假的，不明原因的守护进程退出，请确认你忽略了SIGPIPE（可能需要确认你记录的守护进程的退出状态，因为这会给你一个很大的线索）。</p>

<p>The special problem of accept()ing when you can’t<br />
当不能accept时的特殊问题</p>

<p>Many implementations of the POSIX accept function (for example, found in post-2004 Linux) have the peculiar behaviour of not removing a connection from the pending queue in all error cases.<br />
很多的POSIX accept函数的实现具有怪异的行为，它不能在错误情况下从挂起的队列中删除一个连接。</p>

<p>For example, larger servers often run out of file descriptors (because of resource limits), causing accept to fail with ENFILE but not rejecting the connection, leading to libev signalling readiness on the next iteration again (the connection still exists after all), and typically causing the program to loop at 100% CPU usage.<br />
例如大型服务器通常会达到文件描述符的限制（因为有资源限制），导致了ENFILE，从而接受失败，但不拒绝连接，导致libev在写一次循环中再一次发送准备就绪的信号（毕竟连接仍然是存在的），并且通常导致程序在loop的时候CPU使用率100%。</p>

<p>Unfortunately, the set of errors that cause this issue differs between operating systems, there is usually little the app can do to remedy the situation, and no known thread-safe method of removing the connection to cope with overload is known (to me).<br />
不幸的是，在不同操作系统之间会造成不同的错误，通常有很少的应用程序可以做到亡羊补牢​​，并且也不知道去除连接，以应付超负荷运转的线程安全的函数 （对我来说）。</p>

<p>One of the easiest ways to handle this situation is to just ignore it - when the program encounters an overload, it will just loop until the situation is over. While this is a form of busy waiting, no OS offers an event-based way to handle this situation, so it’s the best one can do.<br />
处理这种问题的其中一种办法是忽略它–当程序遇到高负载的时候，继续loop程序，直到这种情况结束。虽然忙着等待只是一个形式，当没有一个OS提供一个基于事件的处理这种情况的方法，所以，这是能做的方法中最好的一个了。</p>

<p>A better way to handle the situation is to log any errors other than EAGAIN and EWOULDBLOCK, making sure not to flood the log with such messages, and continue as usual, which at least gives the user an idea of what could be wrong (“raise the ulimit!”). For extra points one could stop the ev_io watcher on the listening fd “for a while”, which reduces CPU usage.<br />
一个更好的处理这种情况的办法是记录任何错误，除了EAGAIN和EWOULDBLOCK，确保不要使用如此的信息来填充日志，并且继续像往常一样，这至少给用户一个什么是错误的想法（“提高ulimit限制值）。另外的一点，可以在监听的文件描述符上停止ev_io watcher一会儿，这会降低cpu的使用率。</p>

<p>If your program is single-threaded, then you could also keep a dummy file descriptor for overload situations (e.g. by opening /dev/null), and when you run into ENFILE or EMFILE, close it, run accept, close that fd, and create a new dummy fd. This will gracefully refuse clients under typical overload conditions.<br />
如果你的程序是单线程的，你也可以为了过载保留一个虚拟的文件描述符（例如通过打开/dev/null),当你遇到ENFILE或者EMFILE的时候，关闭它，运行接收，关闭那个文件描述符，并且创建一个新的虚拟文件描述符。这将在典型的负载条件下，优雅地拒绝客户端。</p>

<p>The last way to handle it is to simply log the error and exit, as is often done with malloc failures, but this results in an easy opportunity for a DoS attack.<br />
最后处理它的方法是简单的记录下来error并且退出，如经常使用malloc失败做，但这也导致了给DoS攻击提供了一个简单的机会。</p>

<h4 id="watcher-specific-functions">Watcher-Specific Functions</h4>

<h5 id="ev_io_init-ev_io--callback-int-fd-int-events">ev_io_init (ev_io *, callback, int fd, int events)</h5>
<h5 id="ev_io_set-ev_io--int-fd-int-events">ev_io_set (ev_io *, int fd, int events)</h5>
<p>Configures an ev_io watcher. The fd is the file descriptor to receive events for and events is either EV_READ, EV_WRITE or EV_READ | EV_WRITE, to express the desire to receive the given events. <br />
设置一个ev_io的watcher，fd是用来接收事件的文件描述符，events用来表示要接收事件的类型，分别是EV_READ，EV_WRITE或者EV_READ|EV_WRITE之一。</p>

<ul>
  <li>
    <p>int fd [read-only]<br />
The file descriptor being watched.  <br />
被关注的文件描述符</p>
  </li>
  <li>
    <p>int events [read-only]<br />
The events being watched.<br />
被关注的事件类型</p>
  </li>
</ul>

<p>Example: Call stdin_readable_cb when STDIN_FILENO has become, well readable, but only once. Since it is likely line-buffered, you could attempt to read a whole line in the callback.<br />
当STDIN_FILENO可读的时候调用stdin_readable_cb函数，但是callback只运行一次。因为STDIN_FILENO有点像”行缓存“，所以你可以尝试在对调用读取一个完整的行。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>static void
stdin_readable_cb (struct ev_loop *loop, ev_io *w, int revents)
{
    ev_io_stop (loop, w);
    .. read from stdin here (or from w-&gt;fd) and handle any I/O errors
    //在这里从stdin中读取（或者从watcher的fd中读取），并且处理任何的IO错误
}

...
struct ev_loop *loop = ev_default_init (0);
ev_io stdin_readable;
ev_io_init (&amp;stdin_readable, stdin_readable_cb, STDIN_FILENO, EV_READ);
ev_io_start (loop, &amp;stdin_readable);
ev_run (loop, 0);
</code></pre>
</div>

<h4 id="ev_timer---relative-and-optionally-repeating-timeouts-ev_timer-相对和随意的重复过期">ev_timer - relative and optionally repeating timeouts ev_timer 相对和随意的重复过期</h4>

<p>Timer watchers are simple relative timers that generate an event after a given time, and optionally repeating in regular intervals after that.<br />
定时器watchers是简单的在给定时间之后产生一个事件的相对定时器，并且此后有规律的随意重复。</p>

<p>The timers are based on real time, that is, if you register an event that times out after an hour and you reset your system clock to January last year, it will still time out after (roughly) one hour. “Roughly” because detecting time jumps is hard, and some inaccuracies are unavoidable (the monotonic clock option helps a lot here).<br />
定时器基于实时的（PS：其实就是实际的时间），这意味着如果你注册一个一个小时后过期的事件，并且你重新设置你的系统时钟到去年的1月份，它仍然（大约）会在一个小时后超时。大概的原因是因为探测时间跳跃是比较苦难的，并且一些误差是无法避免的（这里单调的时钟选项帮助了很多）。</p>

<p>The callback is guaranteed to be invoked only after its timeout has passed (not at, so on systems with very low-resolution clocks this might introduce a small delay, see “the special problem of being too early”, below). If multiple timers become ready during the same loop iteration then the ones with earlier time-out values are invoked before ones of the same priority with later time-out values (but this is no longer true when a callback calls ev_run recursively).<br />
只有超时时间已经过了，回调是保证被调用的（不全是这样的，在一些时钟分辨率低的系统上，可能会有小小的延迟，详情请查阅下面的“过早的特殊问题”）。如果在同一个loop迭代中，有多个定时器变得就绪，更早超时的定时器比同优先级下晚超时的定时器早调用（但当回调递归的调用ev_run时，这个规则将不起作用）。</p>

<p>Be smart about timeouts<br />
聪明的超时</p>

<p>Many real-world problems involve some kind of timeout, usually for error recovery. A typical example is an HTTP request - if the other side hangs, you want to raise some error after a while.<br />
很多真实世界的问题涉及到某种超时，经常用于错误恢复。一个典型的例子就是一个http的请求-如果另外一边hangs，你想在一会儿后抛出错误。</p>

<p>What follows are some ways to handle this problem, from obvious and inefficient to smart and efficient.<br />
紧跟着的是一些处理这个事情的方法，这些方法从容易和无效率到聪明和有效率的。</p>

<p>In the following, a 60 second activity timeout is assumed - a timeout that gets reset to 60 seconds each time there is activity (e.g. each time some data or other life sign was received).<br />
下面假设一个60秒活跃超时的定时器-即每次活跃的时候重新设置60秒超时（例如：每次接收到一些数据或者是其他的生存信号）。</p>

<ol>
  <li>Use a timer and stop, reinitialise and start it on activity.<br />
This is the most obvious, but not the most simple way: In the beginning, start the watcher:<br />
让一个活跃的定时器停止，重新初始化并且启动它。</li>
</ol>

<div class="highlighter-rouge"><pre class="highlight"><code>ev_timer_init (timer, callback, 60., 0.);
ev_timer_start (loop, timer);
</code></pre>
</div>

<p>Then, each time there is some activity, ev_timer_stop it, initialise it and start it again:<br />
这样，每次活跃的时候，ev_timer_stop停止它，再初始化和启动它：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>ev_timer_stop (loop, timer);
ev_timer_set (timer, 60., 0.);
ev_timer_start (loop, timer);
</code></pre>
</div>

<p>This is relatively simple to implement, but means that each time there is some activity, libev will first have to remove the timer from its internal data structure and then add it again. Libev tries to be fast, but it’s still not a constant-time operation.<br />
这相对来说是容易实现的，当这意味着每次活跃的时候，libev先必须从他的内部数据结构中移除这个定时器，然后再加上它。libev试着更快的实现，但是这仍然不是一个常数级的操作。</p>

<ol>
  <li>Use a timer and re-start it with ev_timer_again inactivity.<br />
This is the easiest way, and involves using ev_timer_again instead of ev_timer_start.<br />
使用定时器，并且使用ev_timer_again重启它。<br />
这是简单的方法，并且涉及使用ev_timer_again替换ev_timer_start。</li>
</ol>

<p>To implement this, configure an ev_timer with a repeat value of 60 and then call ev_timer_again at start and each time you successfully read or write some data. If you go into an idle state where you do not expect data to travel on the socket, you can ev_timer_stop the timer, and ev_timer_again will automatically restart it if need be.<br />
为了实现这些，使用一个60秒重复的值来设置ev_timer，并且在开始和每次你成功的读取或者写数据的时候调用ev_timer_again。如果你进入到一个空闲的状态，你没有预料到数据会流经socket，你可以ev_timer_stop来停止定时器，并且如果需要，ev_timer_again将自动的重启定时器。</p>

<p>That means you can ignore both the ev_timer_start function and the after argument to ev_timer_set, and only ever use the repeat member and ev_timer_again.<br />
这意味着你可以忽略ev_timer_start函数和ev_timer_set的after参数。只要使用重复属性和ev_timer_again就可以。</p>

<p>At start:</p>

<div class="highlighter-rouge"><pre class="highlight"><code>ev_init (timer, callback);
timer-&gt;repeat = 60.;
ev_timer_again (loop, timer);
</code></pre>
</div>

<p>Each time there is some activity:<br />
每次活跃的时候：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>ev_timer_again (loop, timer);
</code></pre>
</div>

<p>It is even possible to change the time-out on the fly, regardless of whether the watcher is active or not:<br />
它甚至可能能在运行的时候改变超时的值，不管watcher是活跃的还是不活跃的：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>timer-&gt;repeat = 30.;
ev_timer_again (loop, timer);
</code></pre>
</div>

<p>This is slightly more efficient then stopping/starting the timer each time you want to modify its timeout value, as libev does not have to completely remove and re-insert the timer from/into its internal data structure.<br />
当每次停止/启动定时器，你想改变这个过期时间时，这是很有效的，因为libev没有从他的内部数据结构中移除和重新插入定时器。</p>

<p>It is, however, even simpler than the “obvious” way to do it.<br />
所以不管怎么说，相比明显的方法（stop，restart）来实现它，它（使用again）是更简单的。</p>

<ol>
  <li>Let the timer time out, but then re-arm it as required.<br />
设定定时器超时，但是需要的时候的重新准备。</li>
</ol>

<p>This method is more tricky, but usually most efficient: Most timeouts are relatively long compared to the intervals between other activity - in our example, within 60 seconds, there are usually many I/O events with associated activity resets.<br />
这个方式是比较投机取巧的，当通常也是效率比较高的。大多数的超时相对其他活动来说时间是比较长的-在我们的例子中，在60秒内，通常有很多IO事件已经被重置了。</p>

<p>In this case, it would be more efficient to leave the ev_timer alone, but remember the time of last activity, and check for a real timeout only within the callback:<br />
在这种情况下，让ev_timer单独出来将是比较有效率的，但是要记住最后活跃的时间，并且在callback内部检查真实的超时。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>ev_tstamp timeout = 60.;
ev_tstamp last_activity; // time of last activity 最后活跃的时间
ev_timer timer;

static void
callback (EV_P_ ev_timer *w, int revents)
{
    // calculate when the timeout would happen
    //计算什么时候发生的超时
    ev_tstamp after = last_activity - ev_now (EV_A) + timeout;

    // if negative, it means we the timeout already occurred
    //如果小于0，那么表示超时已经发生
    if (after &lt; 0.)
    {
        // timeout occurred, take action
    }
    else
    {
        // callback was invoked, but there was some recent 
        // activity. simply restart the timer to time out
        // after "after" seconds, which is the earliest time
        // the timeout can occur.
        //回调函数被调用，但是这是一些近来的活动，不是这个定时器的。
        //简单重置定时器超时时间，这个时间是超时最早可以发生的时间
        //PS:难道libev的定时器和epoll一样，有“伪信号”问题？
        ev_timer_set (w, after, 0.);
        ev_timer_start (EV_A_ w);
    }
}
</code></pre>
</div>

<p>To summarise the callback: first calculate in how many seconds the timeout will occur (by calculating the absolute time when it would occur, last_activity + timeout, and subtracting the current time, ev_now (EV_A) from that).<br />
概述整个回调函数：首先，计算还有多少秒超时将会发生（通过就算，计算结果的绝对值就是将要发生的时间，last_activity + timeout，然后减去ev_now返回的当前时间）。</p>

<p>If this value is negative, then we are already past the timeout, i.e. we timed out, and need to do whatever is needed in this case.<br />
如果这个值是负数，我们已经比超时晚了，即我们已经超时了，在这种情况下，就要去做任何需要做的事情了。</p>

<p>Otherwise, we now the earliest time at which the timeout would trigger, and simply start the timer with this timeout value.<br />
要不然，我们现在比超时将要触发早，并且简单的使用超时时间值启动定时器。</p>

<p>In other words, each time the callback is invoked it will check whether the timeout occurred. If not, it will simply reschedule itself to check again at the earliest time it could time out. Rinse. Repeat.<br />
换句话说，每次回调被调用，都要检查超时是否已经发生。如果没有，自己简单的重新安排时间来在它可能超时的最早时间再次检查。再次重新安排，如此重复。</p>

<p>This scheme causes more callback invocations (about one every 60 seconds minus half the average time between activity), but virtually no calls to libev to change the timeout.<br />
这种策略导致更多的回调被调用（大约每60秒减去活动之间平均时间的一半），但是事实上没有调用libev来改变超时时间。</p>

<p>To start the machinery, simply initialise the watcher and set last_activity to the current time (meaning there was some activity just now), then call the callback, which will “do the right thing” and start the timer:<br />
要开始这样的体系，简单的初始化watcher，并且设置last_activity到当前时间（意味着刚刚有些一些活动），然后调用回调函数，然后做正确的事情，并且开始这个定时器：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>last_activity = ev_now (EV_A);
ev_init (&amp;timer, callback);
callback (EV_A_ &amp;timer, 0);
</code></pre>
</div>

<p>When there is some activity, simply store the current time in last_activity, no libev calls at all:<br />
当有一些活动时，简单的把当前时间值保存到last_activity，根本没有调用libev：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>if (activity detected)
last_activity = ev_now (EV_A);
</code></pre>
</div>

<p>When your timeout value changes, then the timeout can be changed by simply providing a new value, stopping the timer and calling the callback, which will again do the right thing (for example, time out immediately :).<br />
当超时时间改变的时候，可以通过一个简单的值来更改，停止这个定时器，并且调用回调，然后再一次做正确的事情（例如：立刻超时）。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>timeout = new_value;
ev_timer_stop (EV_A_ &amp;timer);
callback (EV_A_ &amp;timer, 0);
</code></pre>
</div>

<p>This technique is slightly more complex, but in most cases where the time-out is unlikely to be triggered, much more efficient.<br />
这种技巧稍微有点复杂，但是更多情况下，超时是不太可能被触发的，这样更有效率一些。</p>

<ol>
  <li>Wee, just use a double-linked list for your timeouts.<br />
很早的时候超时只是使用一个双链表</li>
</ol>

<p>If there is not one request, but many thousands (millions…), all employing some kind of timeout with the same timeout value, then one can do even better:<br />
如果这不是一个请求，而是成千上万个（数百万个），所有的同类型超时都有相同的超时值，那么这样（使用双链表）可以做的更好。</p>

<p>When starting the timeout, calculate the timeout value and put the timeout at the end of the list.<br />
当启动定时器的时候，计算超时值并且把定时器放在列表的最后面。</p>

<p>Then use an ev_timer to fire when the timeout at the beginning of the list is expected to fire (for example, using the technique #3).<br />
当列表头部的定时器希望被触发的时候，使用一个ev_timer来触发（例如，使用技巧3）。</p>

<p>When there is some activity, remove the timer from the list, recalculate the timeout, append it to the end of the list again, and make sure to update the ev_timer if it was taken from the beginning of the list.<br />
当定时器活跃的时候，从列表中移除定时器，重新计算超时时间，再次把它加到列表的最后，并且如果定时器来自列表的头部，那么确保更新ev_timer。</p>

<p>This way, one can manage an unlimited number of timeouts in O(1) time for starting, stopping and updating the timers, at the expense of a major complication, and having to use a constant timeout. The constant timeout ensures that the list stays sorted.<br />
这种方法，可以使用O（1）的算法复杂度来管理无限数量的定时器，启动，停止和更新这些定时器，最大的困难是性能开销，并且不得不使用一个固定的超时。固定的超时确保列表保持排序。</p>

<p>So which method the best?<br />
所以哪个方法是最好的？</p>

<p>Method #2 is a simple no-brain-required solution that is adequate in most situations. Method #3 requires a bit more thinking, but handles many cases better, and isn’t very complicated either. In most case, choosing either one is fine, with #3 being better in typical situations.<br />
方法2是简单的不用想的解决方案，这个方案在大多数情况下已经够用。方法3需要稍微想一下，但是在很多情况下都会处理的更好，并且也不是太复杂。在大多数情况下，选择任何一个都很好，再典型的情况下，方法3会更好。</p>

<p>Method #1 is almost always a bad idea, and buys you nothing. Method #4 is rather complicated, but extremely efficient, something that really pays off after the first million or so of active timers, i.e. it’s usually overkill :)<br />
方法1几乎都是一个挺烂的解决方案，并且带给你任何东西。方法4太复杂，但非常有效，通常百万或者同等数量的定时器没有问题（PS：根据想象翻译了，有更好的翻译嘛？）。通常，它都是比较过度的。</p>

<p>The special problem of being too early<br />
被提前超时的问题</p>

<p>If you ask a timer to call your callback after three seconds, then you expect it to be invoked after three seconds - but of course, this cannot be guaranteed to infinite precision. Less obviously, it cannot be guaranteed to any precision by libev - imagine somebody suspending the process with a STOP signal for a few hours for example.<br />
如果你想一个定时器在3秒后调用你的回调函数，那么你期望3秒过后回调函数将被调用（这不是废话？？）—当然，不能给你确保无限精度。显然，libev不能确保任何的精确性-；例如，一些人使用STOP信号挂起进程几个小时。</p>

<p>So, libev tries to invoke your callback as soon as possible after the delay has occurred, but cannot guarantee this.<br />
所以，libev试着在延时发生后尽可能快的调用回调函数，但是不能保证这一点。</p>

<p>A less obvious failure mode is calling your callback too early: many event loops compare timestamps with a “elapsed delay &gt;= requested delay”, but this can cause your callback to be invoked much earlier than you would expect.<br />
一个不太明显的模式是调用你的回调函数太早了：很多event loops比较“经过延迟&gt;=需要延迟”的时间戳，但是这将可能会导致比你期望更早的调用你的回调函数。</p>

<p>To see why, imagine a system with a clock that only offers full second resolution (think windows if you can’t come up with a broken enough OS yourself). If you schedule a one-second timer at the time 500.9, then the event loop will schedule your timeout to elapse at a system time of 500 (500.9 truncated to the resolution) + 1, or 501.<br />
来看看为什么，一个系统时钟只提供了2秒的精度（想想wins，如果你不能在一个自身中断足够的操作系统）。当时间在500.9的时候，如果你设置了一个1s的定时器，那么，event loop将在系统过500（500.9被截尾）+1，触发你的超时，或者是过了501.</p>

<p>If an event library looks at the timeout 0.1s later, it will see “501 &gt;= 501” and invoke the callback 0.1s after it was started, even though a one-second delay was requested - this is being “too early”, despite best intentions.<br />
如果一个事件库看起来超时了0.1s，它将判断“501 &gt;= 501”，并且在启动后的0.1s调用回调函数，尽管其实需要1s的延迟-这就太早了，尽管意图是好的。</p>

<p>This is the reason why libev will never invoke the callback if the elapsed delay equals the requested delay, but only when the elapsed delay is larger than the requested delay. In the example above, libev would only invoke the callback at system time 502, or 1.1s after the timer was started.<br />
这就是为什么libev永远也不会在真实的超时等于预想的超时时调用回调函数的原因，但是相比预想的回调时间只会稍微玩一会儿。在上面的示例中，libev只会在系统时间502或者在启动定时器1.1s之后调用回调函数。</p>

<p>So, while libev cannot guarantee that your callback will be invoked exactly when requested, it can and does guarantee that the requested delay has actually elapsed, or in other words, it always errs on the “too late” side of things.<br />
所以，当libev不能保证按照你的需求及时调用你的回调函数的时候，它可以并且确实保证需要的延迟已经到了，或者换句话说，对于按时回调来说，它总是犯“为时已晚”的错误。</p>

<p>The special problem of time updates<br />
更新时间的问题</p>

<p>Establishing the current time is a costly operation (it usually takes at least one system call): EV therefore updates its idea of the current time only before and after ev_run collects new events, which causes a growing difference between ev_now () and ev_time () when handling lots of events in one iteration.<br />
获取当前时间是一个代价高昂的操作（至少需要一个系统调用）：EV因此只在rv_run获取新的事件之前和之后才会更新当前时间，这意味这如果在一个迭代中处理了很多的事件，那么ev_now（）和ev_time（）的值将会不想等。</p>

<p>The relative timeouts are calculated relative to the ev_now () time. This is usually the right thing as this timestamp refers to the time of the event triggering whatever timeout you are modifying/starting. If you suspect event processing to be delayed and you need to base the timeout on the current time, use something like the following to adjust for it:<br />
相对超时时间是根据ev_now来计算的。这通常是正确的，因为这个时间戳来自于事件触发的事件，不管你更改/启动这个超时。如果你怀疑事件处理被延迟并且你需要使用基于当前时间的超时，使用如下的步骤调整它：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>ev_timer_set (&amp;timer, after + (ev_time () - ev_now ()), 0.);
</code></pre>
</div>

<p>If the event loop is suspended for a long time, you can also force an update of the time returned by ev_now () by calling ev_now_update (), although that will push the event time of all outstanding events further into the future.<br />
如果event loop被挂起很久了，你也可以强制使用ev_now_update更新时间，然后使用ev_now返回的时间，尽管这样做会把还没有处理的事件延迟的稍晚一些。</p>

<p>The special problem of unsynchronised clocks<br />
时钟不同步的问题</p>

<p>Modern systems have a variety of clocks - libev itself uses the normal “wall clock” clock and, if available, the monotonic clock (to avoid time jumps).<br />
现代系统有各种时钟-libev自己使用常见的“挂钟”时钟，如果可能，也会使用单调时钟（避免时间跳跃）。</p>

<p>Neither of these clocks is synchronised with each other or any other clock on the system, so ev_time () might return a considerably different time than gettimeofday () or time (). On a GNU/Linux system, for example, a call to gettimeofday might return a second count that is one higher than a directly following call to time.<br />
任何一个系统时钟或者时钟两两之间都是不同步的，所以ev_time的返回值可能和gettimeofday或者time返回的值完全不同。在linux系统上，例如，调用gettimeofday返回的秒数可能比接着直接调用time数值高。</p>

<p>The moral of this is to only compare libev-related timestamps with ev_time () and ev_now (), at least if you want better precision than a second or so.<br />
这样做的意义仅仅只是比较使用ev_time和ev_now返回的libev相关的时间戳，至少你可以有比一秒更好的精度。</p>

<p>One more problem arises due to this lack of synchronisation: if libev uses the system monotonic clock and you compare timestamps from ev_time or ev_now from when you started your timer and when your callback is invoked, you will find that sometimes the callback is a bit “early”.<br />
还有一个问题会由于缺乏同步出现：如果libev使用系统单调时钟并且当你启动你的定时器并且回调已经被调用时，你比较由ev_time或者ev_now返回的时间戳，你将会发现有的时候回调被早调用了。</p>

<p>This is because ev_timers work in real time, not wall clock time, so libev makes sure your callback is not invoked before the delay happened, measured according to the real time, not the system clock.<br />
这是因为ev_timer工作在真实的时间，不是时钟时间，所以libev确保在延迟到期之前不会调用你的回调函数，因为ev_timer是按照真实的时间判断，而不是按照时钟时间。</p>

<p>If your timeouts are based on a physical timescale (e.g. “time out this connection after 100 seconds”) then this shouldn’t bother you as it is exactly the right behaviour.<br />
如果你的超时是基于物理时间表（例如100s之后这个连接超时），那么这应该不会打扰你，因为它是一个完全正确的行为。</p>

<p>If you want to compare wall clock/system timestamps to your timers, then you need to use ev_periodics, as these are based on the wall clock time, where your comparisons will always generate correct results.<br />
如果你想为你的定时器比较时钟/系统时间戳，那么你需要使用ev_periodics，因为是ev_periodics基于时钟的，你的比较都会产生正确的结果。</p>

<p>The special problems of suspended animation<br />
假死的问题</p>

<p>When you leave the server world it is quite customary to hit machines that can suspend/hibernate - what happens to the clocks during such a suspend?<br />
当你离开了服务器领域，你可以完全的控制你的机器，你可以暂停/休眠-那么在这个延迟中间，时钟发生了什么？</p>

<p>Some quick tests made with a Linux 2.6.28 indicate that a suspend freezes all processes, while the clocks (times, CLOCK_MONOTONIC) continue to run until the system is suspended, but they will not advance while the system is suspended. That means, on resume, it will be as if the program was frozen for a few seconds, but the suspend time will not be counted towards ev_timer when a monotonic clock source is used. The real time clock advanced as expected, but if it is used as sole clocksource, then a long suspend would be detected as a time jump by libev, and timers would be adjusted accordingly.<br />
在linux 2.6.28上做一些快速的测试，表明暂停并且冻结所有的进程，当时钟（时间，单调时钟）继续运行直到系统被暂停，当他们不会提前当系统暂停。这就意味着，在重新启动的时候，这将会像程序被冻结了几秒钟，但是当单调时钟被使用的时候，暂停时间不会被计算到ev_timer。真实的时间按照预期那样运行，但如果它是被使用的唯一的时间源，那么一个长的暂停将会被libev作为一个时间跳跃检测到，并且定时器会按照这个时间跳跃调整。</p>

<p>I would not be surprised to see different behaviour in different between operating systems, OS versions or even different hardware.<br />
我也不会在看到在不同的操作系统，操作系统版本或者是不同的硬件之间存在不同的行为而感到惊讶。</p>

<p>The other form of suspend (job control, or sending a SIGSTOP) will see a time jump in the monotonic clocks and the realtime clock. If the program is suspended for a very long time, and monotonic clock sources are in use, then you can expect ev_timers to expire as the full suspension time will be counted towards the timers. When no monotonic clock source is in use, then libev will again assume a timejump and adjust accordingly.<br />
暂停的另外一种形式（作业控制，或者发生一个SIGSTOP信号）将会看到在单调时钟和真实的时钟中有时间跳跃。如果程序被暂停了很多时间，并且使用单调时钟源，那么随着所有的暂停时间将被计算到定时器，你可以期望ev_timers终止。当不是使用单调时钟源时，那么libev将再假定一次时间跳跃，并且相应的调整。</p>

<p>It might be beneficial for this latter case to call ev_suspend and ev_resume in code that handles SIGTSTP, to at least get deterministic behaviour in this case (you can do nothing against SIGSTOP).<br />
后一种方法对于调用ev_suspend和ec_resume来处理SIGTSP是有利的，至少在这种情况下有一个稳定的行为（靠SIGSTOP你将不能做任何事情）。</p>

<h4 id="watcher-specific-functions-and-data-members-watcher-特殊的函数和数据成员">Watcher-Specific Functions and Data Members watcher-特殊的函数和数据成员</h4>

<h5 id="ev_timer_init-ev_timer--callback-ev_tstamp-after-ev_tstamp-repeat">ev_timer_init (ev_timer *, callback, ev_tstamp after, ev_tstamp repeat)</h5>
<h5 id="ev_timer_set-ev_timer--ev_tstamp-after-ev_tstamp-repeat">ev_timer_set (ev_timer *, ev_tstamp after, ev_tstamp repeat)</h5>
<p>Configure the timer to trigger after after seconds. If repeat is 0., then it will automatically be stopped once the timeout is reached. If it is positive, then the timer will automatically be configured to trigger again repeat seconds later, again, and again, until stopped manually.<br />
配置定时器在after秒之后触发。如果repeat为0，那么定时器在超时一次后自动的停止。如果repeat是正数，那么定时器将会一次又一次的循环触发，直到你手动停止为止。</p>

<p>The timer itself will do a best-effort at avoiding drift, that is, if you configure a timer to trigger every 10 seconds, then it will normally trigger at exactly 10 second intervals. If, however, your program cannot keep up with the timer (because it takes longer than those 10 seconds to do stuff) the timer will not fire more than once per event loop iteration.<br />
定时器自己会尽最大的努力避免重叠，也就说，如果你配置一个定时器每10s触发一次，那么它通常会在整整10s的时候被触发，但是，如果你的程序不能在10s内完成回调（因为回调可能需要比10s更长的时间），那么定时器将不会在每次event loop迭代中触发大于一次（PS：是不是也就是说，如果callback耗时比timer的时间间隔长，那么下一次的回调将不会被调用？）。</p>

<h5 id="ev_timer_again-loop-ev_timer-">ev_timer_again (loop, ev_timer *)</h5>
<p>This will act as if the timer timed out, and restarts it again if it is repeating. It basically works like calling ev_timer_stop, updating the timeout to the repeat value and calling ev_timer_start.<br />
如果定时器超时，并且如果定时器是重复的，那么此函数会重启它。这基本上工作起来类似于点用ev_timer_stop，更新超时的重复值，然后再调用ev_timer_start。</p>

<p>The exact semantics are as in the following rules, all of which will be applied to the watcher:<br />
确切的意思如下所述，所有的这些规则都会应用到watcher：</p>

<p>If the timer is pending, the pending status is always cleared.<br />
如果定时器被挂起，那么挂起状态一直被清零。<br />
If the timer is started but non-repeating, stop it (as if it timed out, without invoking it).<br />
如果定时器被启动但是不是重复的，停止它（就像定时器超时，但是不调用它）。<br />
If the timer is repeating, make the repeat value the new timeout and start the timer, if necessary.<br />
如果定时器是重复的，如果必要，把新的超时值设置成重复的值，并且启动定时器。<br />
This sounds a bit complicated, see Be smart about timeouts, above, for a usage example.<br />
这听起来有点复杂，上面有关于超时用法的章节示例。</p>

<h5 id="ev_tstamp-ev_timer_remaining-loop-ev_timer-">ev_tstamp ev_timer_remaining (loop, ev_timer *)</h5>
<p>Returns the remaining time until a timer fires. If the timer is active, then this time is relative to the current event loop time, otherwise it’s the timeout value currently configured.<br />
返回离定时器被触发的时间。如果定时器是活跃的，那么这个时间就是相对于当前event loop的时间，否则，这就是当前配置额的超时时间。</p>

<p>That is, after an ev_timer_set (w, 5, 7), ev_timer_remaining returns 5. When the timer is started and one second passes, ev_timer_remaining will return 4. When the timer expires and is restarted, it will return roughly 7 (likely slightly less as callback invocation takes some time, too), and so on.<br />
也就是说，在调用ev_timer_set（w，5，7）之后，ev_timer_remaining返回5.当定时器被启动，并且过了1s时间，ev_timer_remaining将返回4.当定时器超时，并且被重启，那么它将返回大约是7（也有可能会比7少一些，因为调用回调函数也需要一些时间），等等。</p>

<h5 id="ev_tstamp-repeat-read-write">ev_tstamp repeat [read-write]</h5>
<p>The current repeat value. Will be used each time the watcher times out or ev_timer_again is called, and determines the next timeout (if any), which is also when any modifications are taken into account.<br />
当前重复值。每个监视器超时或ev_timer_again被调用时将被使用，并且确定下一个超时值（如果有的话） ，这也是当任何修改都考虑在内。</p>

<p>Example: Create a timer that fires after 60 seconds.<br />
示例：创建一个60s后触发的定时器。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>static void
one_minute_cb (struct ev_loop *loop, ev_timer *w, int revents)
{
    .. one minute over, w is actually stopped right here
}

ev_timer mytimer;
ev_timer_init (&amp;mytimer, one_minute_cb, 60., 0.);
ev_timer_start (loop, &amp;mytimer);
</code></pre>
</div>

<p>Example: Create a timeout timer that times out after 10 seconds of inactivity.<br />
示例：创建一个定时器，10s之内不活动</p>

<div class="highlighter-rouge"><pre class="highlight"><code>static void
timeout_cb (struct ev_loop *loop, ev_timer *w, int revents)
{
    .. ten seconds without any activity
    //10s内没有任何活动
}

ev_timer mytimer;
ev_timer_init (&amp;mytimer, timeout_cb, 0., 10.); /* note, only repeat used 注意，只用了repeat*/

ev_timer_again (&amp;mytimer); /* start timer  启动定时器*/
ev_run (loop, 0);

// and in some piece of code that gets executed on any "activity":
// reset the timeout to start ticking again at 10 seconds
//PS：这句怎么翻译？
ev_timer_again (&amp;mytimer);
</code></pre>
</div>

<h3 id="ev_periodic---to-cron-or-not-to-cron--ev_periodoc-克隆或者不克隆">ev_periodic - to cron or not to cron?  ev_periodoc-克隆或者不克隆</h3>

<p>Periodic watchers are also timers of a kind, but they are very versatile (and unfortunately a bit complex).<br />
periodic watchers也是一种定时器，但是他们用途非常多（可惜有点复杂）。</p>

<p>Unlike ev_timer, periodic watchers are not based on real time (or relative time, the physical time that passes) but on wall clock time (absolute time, the thing you can read on your calender or clock). The difference is that wall clock time can run faster or slower than real time, and time jumps are not uncommon (e.g. when you adjust your wrist-watch).<br />
不像ev_timer，periodic watchers不是基于真实事件的（或者相对时间，经过的物理时间），但是基于时钟时间（绝对时间，你可以在你的日历或者钟表上读到的时间）。不同的是挂钟时间可以比真实时间跑的更快或者更慢，并且时间跳跃也是经常发生的（比如，当你调整你手表的时候）。</p>

<p>You can tell a periodic watcher to trigger after some specific point in time: for example, if you tell a periodic watcher to trigger “in 10 seconds” (by specifying e.g. ev_now () + 10., that is, an absolute time not a delay) and then reset your system clock to January of the previous year, then it will take a year or more to trigger the event (unlike an ev_timer, which would still trigger roughly 10 seconds after starting it, as it uses a relative timeout).<br />
你可以告诉你的periodic watcher在指定的时间点之后触发：比如，如果你告诉一个periodic watcher在10s后触发（通过指定如ev_now（） +10，也就说，一个不延迟的绝对时间）并且重设你的系统时间到去年的一个月，那么periodic将会在至少1年的时间来触发事件（不像ev_timer，ev_timer仍然会在开始的10s之后触发，因为它使用的是相对时间）。</p>

<p>ev_periodic watchers can also be used to implement vastly more complex timers, such as triggering an event on each “midnight, local time”, or other complicated rules. This cannot be done with ev_timer watchers, as those cannot react to time jumps.<br />
ev_periodic watchers也可以被用来实现复杂的多的定时器，比如每个本地的午夜触发事件，或者另外复杂的规则。这是不能用ev_timer来实现的，因为ev_timer不能对于时间跳跃做出更好的反映。</p>

<p>As with timers, the callback is guaranteed to be invoked only when the point in time where it is supposed to trigger has passed. If multiple timers become ready during the same loop iteration then the ones with earlier time-out values are invoked before ones with later time-out values (but this is no longer true when a callback calls ev_run recursively).<br />
如果定时器 ，只有当这个触发事件的时间点已经过了，回调函数才是保证被调用的，如果在同一个循环迭代中有多个定时器变的就绪，那么早超时的定时器比晚超时的定时器早调用（当回调函数中递归的调用ev_run时，这个规则会被打破）。</p>

<h4 id="watcher-specific-functions-and-data-members-watcher-特殊的函数和数据成员-1">Watcher-Specific Functions and Data Members watcher-特殊的函数和数据成员</h4>

<h5 id="ev_periodic_init-ev_periodic--callback-ev_tstamp-offset-ev_tstamp-interval-reschedule_cb">ev_periodic_init (ev_periodic *, callback, ev_tstamp offset, ev_tstamp interval, reschedule_cb)</h5>
<h5 id="ev_periodic_set-ev_periodic--ev_tstamp-offset-ev_tstamp-interval-reschedule_cb">ev_periodic_set (ev_periodic *, ev_tstamp offset, ev_tstamp interval, reschedule_cb)</h5>
<p>Lots of arguments, let’s sort it out… There are basically three modes of operation, and we will explain them from simplest to most complex:<br />
参数很多，让我们整理一下。基本上有3种操作模式，我们将从最简单的开始到最复杂的这样解释：</p>

<ul>
  <li>
    <p>absolute timer (offset = absolute time, interval = 0, reschedule_cb = 0)<br />
绝对时间（offset = 绝对时间, interval = 0, reschedule_cb = 0）
  In this configuration the watcher triggers an event after the wall clock time offset has passed. It will not repeat and will not adjust when a time jump occurs, that is, if it is to be run at January 1st 2011 then it will be stopped and invoked when the system clock reaches or surpasses this point in time.<br />
  在这个配置中，watcher会在时钟过了offset这个时间点触发一个事件。它不会重复并且也不会随着时间的跳跃进行调整，也就是说，如果watcher将在2011-01-01运行，那么watcher会在时钟到了或者超过这个时间点的时候停止并且调用。</p>
  </li>
  <li>
    <p>repeating interval timer (offset = offset within interval, interval &gt; 0, reschedule_cb = 0)<br />
  重复的间隔时间（offset＝间隔时间，interval&gt;0,reschedule_cb=0)<br />
  In this mode the watcher will always be scheduled to time out at the next offset + N * interval time (for some integer N, which can also be negative) and then repeat, regardless of any time jumps. The offset argument is merely an offset into the interval periods.<br />
  在这个模式中，watcher将一直被安排在下一个offset + N*interval时间（N也可能是负数）时触发，并且重复，任何的jumps也不会起作用。offset参数仅仅只是一个间隔周期的补偿而已。</p>

    <p>This can be used to create timers that do not drift with respect to the system clock, for example, here is an ev_periodic that triggers each hour, on the hour (with respect to UTC):<br />
  这可以用来创建一个和系统时钟时间跳跃无关的定时器，例如，这里的ev_periodic每个小时触发一次，整整一个小时（相对于UTC来说）</p>
  </li>
</ul>

<div class="highlighter-rouge"><pre class="highlight"><code>    ev_periodic_set (&amp;periodic, 0., 3600., 0);
</code></pre>
</div>

<p>This doesn’t mean there will always be 3600 seconds in between triggers, but only that the callback will be called when the system time shows a full hour (UTC), or more correctly, when the system time is evenly divisible by 3600.<br />
这并不意味着每次触发的时间间隔都是3600s，但也仅仅当系统时间显示整整一个小时（UTC）的时候，回调函数才会被调用，或者更准确的说，当系统时间为3600整除的时候才会触发事件（PS：难道那么多废话就是为了表达“整点”）。</p>

<p>Another way to think about it (for the mathematically inclined) is that ev_periodic will try to run the callback in this mode at the next possible time where time = offset (mod interval), regardless of any time jumps.<br />
考虑这个问题（为了数学倾向）的另一种方式就是ev_periodic将试着在这种模式下在下一个时间点time＝offset（取余interval）时运行回调，不会理会任何的时间跳跃。</p>

<p>The interval MUST be positive, and for numerical stability, the interval value should be higher than 1/8192 (which is around 100 microseconds) and offset should be higher than 0 and should have at most a similar magnitude as the current time (say, within a factor of ten). Typical values for offset are, in fact, 0 or something between 0 and interval, which is also the recommended range.<br />
时间间隔必须是正数，并且数值稳定的。这个值应该大于1/8192（大约100微妙），误差应该大于0最大和现在时间一个数量级的数（比方说，是小于10的因数）。典型的误差值，事实上是0或者0-时间间隔之间，这也是推荐的范围。</p>

<p>Note also that there is an upper limit to how often a timer can fire (CPU speed for example), so if interval is very small then timing stability will of course deteriorate. Libev itself tries to be exact to be about one millisecond (if the OS supports it and the machine is fast enough).<br />
还要注意的是，有一个多久可以触发定时器的上限（例如CPU的速度），所以如果时间间隔非常小，那么时序的稳定性肯定会变差。Libev自己会试着去稳定在1毫秒（如果OS提供这个精度并且机器足够快）。</p>

<p>manual reschedule mode (offset ignored, interval ignored, reschedule_cb = callback)<br />
手动重新排序模式（offset 忽略，interval 忽略，reschedule_cb＝callback）<br />
In this mode the values for interval and offset are both being ignored. Instead, each time the periodic watcher gets scheduled, the reschedule callback will be called with the watcher as first, and the current time as second argument.<br />
在这个模式中，offset和interval的值都被忽略。相反的，每次periodic watcher都会被排序，首先会使用watcher作为参数来调用重新排序的回调函数，并且当前时间作为第二个参数。</p>

<p>NOTE: This callback MUST NOT stop or destroy any periodic watcher, ever, or make ANY other event loop modifications whatsoever, unless explicitly allowed by documentation here.<br />
注意：除非文档明确允许这样做，否则这个回调必须不能停止或者释放任何的periodic watcher，或者无论什么也不能对event loop做出任何的修改。</p>

<p>If you need to stop it, return now + 1e30 (or so, fudge fudge) and stop it afterwards (e.g. by starting an ev_prepare watcher, which is the only event loop modification you are allowed to do). <br />
如果你需要停止这个periodic，返回now + 1e30（左后）然后停止它（例如通过启动一个ev_prepare watcher，它是唯一一个被允许修改event loop的）。</p>

<p>The callback prototype is ev_tstamp (<em>reschedule_cb)(ev_periodic *w, ev_tstamp now), e.g.:<br />
回调的原型签名 ev_tstamp (</em>reschedule_cb)(ev_periodic *w, ev_tstamp now),</p>

<div class="highlighter-rouge"><pre class="highlight"><code>    static ev_tstamp
    my_rescheduler (ev_periodic *w, ev_tstamp now)
    {
        return now + 60.;
    }
</code></pre>
</div>

<p>It must return the next time to trigger, based on the passed time value (that is, the lowest time value larger than to the second argument). It will usually be called just before the callback will be triggered, but might be called at other times, too.<br />
它必须返回下一次触发的时间，这个时间是基于经过时间值的（即，比第二个参数大的最小值）。它经常就在回调被触发之前被调用，但是也有可能在别的时间被调用。</p>

<p>NOTE: This callback must always return a time that is higher than or equal to the passed now value.<br />
注意：回调函数必须一直返回一个高于或者等于当前已经过去时间的值。</p>

<p>This can be used to create very complex timers, such as a timer that triggers on “next midnight, local time”. To do this, you would calculate the next midnight after now and return the timestamp value for this. How you do this is, again, up to you (but it is not trivial, which is the main reason I omitted it as an example).<br />
它可以被用来创建一个非常复杂的定时器，例如一个在“下一个本地的午夜”触发的定时器。为了做这些，你要计算下一个午夜离现在多少时间，并且要返回这个时间戳。你怎么做？再一次，由你决定（但是它并不是不重要的，这就是我省略它来作为例子的最大原因）。</p>

<h5 id="ev_periodic_again-loop-ev_periodic-">ev_periodic_again (loop, ev_periodic *)</h5>
<p>Simply stops and restarts the periodic watcher again. This is only useful when you changed some parameters or the reschedule callback would return a different time than the last time it was called (e.g. in a crond like program when the crontabs have changed).<br />
只是再一次停止并且重启periodic watcher。只有当你改变一些参数或者重新排列回调函数将返回和回调函数被调用时最新的时间不同的时间时是有用的。（例如在一个克隆的程序中当crontabs已经改变）。（PS：这段怎么翻译？德国人写的E文也是nm看不懂的玩意）。</p>

<h5 id="ev_tstamp-ev_periodic_at-ev_periodic-">ev_tstamp ev_periodic_at (ev_periodic *)</h5>
<p>When active, returns the absolute time that the watcher is supposed to trigger next. This is not the same as the offset argument to ev_periodic_set, but indeed works even in interval and manual rescheduling modes.<br />
如果watcher是活跃的，返回watcher下一次触发的绝对时间。这个ev_periodic_set的offset参数不同，但是不管是在interval还是手动重排模式，都确实能工作。</p>

<h5 id="ev_tstamp-offset-read-write">ev_tstamp offset [read-write]</h5>
<p>When repeating, this contains the offset value, otherwise this is the absolute point in time (the offset value passed to ev_periodic_set, although libev might modify this value for better numerical stability).<br />
当重复的时候，它包含了offset的值，否则它据说一个绝对的时间点（offset传递给ev_periodic_set，尽管libev可能会为了数值稳定性更改这个值）。</p>

<p>Can be modified any time, but changes only take effect when the periodic timer fires or ev_periodic_again is being called.<br />
可以在任何时候更改，但是更改只有在periodic定时器触发或者ev_periodic_again再一次被调用时有效。</p>

<h5 id="ev_tstamp-interval-read-write">ev_tstamp interval [read-write]</h5>
<p>The current interval value. Can be modified any time, but changes only take effect when the periodic timer fires or ev_periodic_again is being called.<br />
当前间隔时间。任何时候都可以被更改，但是只有在periodic定时器被触发或者ev_periodic_again被调用时才有效。</p>

<h5 id="ev_tstamp-reschedule_cbev_periodic-w-ev_tstamp-now-read-write">ev_tstamp (*reschedule_cb)(ev_periodic *w, ev_tstamp now) [read-write]</h5>
<p>The current reschedule callback, or 0, if this functionality is switched off. Can be changed any time, but changes only take effect when the periodic timer fires or ev_periodic_again is being called.<br />
当前重排的回调函数，或者是空的。如果这个功能被关闭，那么任何时候都可以更改，但是更改只有当periodic被触发或者ev_periodic_again被调用时才有效。</p>

<p>Example: Call a callback every hour, or, more precisely, whenever the system time is divisible by 3600. The callback invocation times have potentially a lot of jitter, but good long-term stability.<br />
示例：每一个小时调用一个回调，或者更确切的说，是当系统时间是3600的整数倍时。这个回调函数被调用的时间可能会有点波动，但基本拥有良好的长期稳定性。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>static void
clock_cb (struct ev_loop *loop, ev_periodic *w, int revents)
{
    ... its now a full hour (UTC, or TAI or whatever your clock follows)
}

ev_periodic hourly_tick;
ev_periodic_init (&amp;hourly_tick, clock_cb, 0., 3600., 0);
ev_periodic_start (loop, &amp;hourly_tick);
</code></pre>
</div>

<p>Example: The same as above, but use a reschedule callback to do it:<br />
示例：和上面一样，但是使用重排回调函数来做。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>#include &lt;math.h&gt;

static ev_tstamp
my_scheduler_cb (ev_periodic *w, ev_tstamp now)
{
    return now + (3600. - fmod (now, 3600.));
}

ev_periodic_init (&amp;hourly_tick, clock_cb, 0., 0., my_scheduler_cb);
</code></pre>
</div>

<p>Example: Call a callback every hour, starting now:<br />
示例：每小时调用一次回调函数，现在开始。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>ev_periodic hourly_tick;
ev_periodic_init (&amp;hourly_tick, clock_cb,
fmod (ev_now (loop), 3600.), 3600., 0);
ev_periodic_start (loop, &amp;hourly_tick);
</code></pre>
</div>

<h3 id="ev_signal---signal-me-when-a-signal-gets-signalled--ev_signal-当一个信号被触发的时候通知我">ev_signal - signal me when a signal gets signalled!  ev_signal-当一个信号被触发的时候通知我</h3>

<p>Signal watchers will trigger an event when the process receives a specific signal one or more times. Even though signals are very asynchronous, libev will try its best to deliver signals synchronously, i.e. as part of the normal event processing, like any other event.<br />
当进程一次或者多次接收到一个指定的信号时，signal watchers将触发一个事件。即使信号是异步信号，libev将尽力给予信号同步，就像其他事件一样，作为正常事件处理的一部分。</p>

<p>If you want signals to be delivered truly asynchronously, just use sigaction as you would do without libev and forget about sharing the signal. You can even use ev_async from a signal handler to synchronously wake up an event loop.<br />
如果你想让信号真正的异步，只有使用sigaction，你这样做不需要libev并且忘记共享信号。你也可以在一个信号处理程序中使用ev_async来同步唤醒一个event loop。</p>

<p>You can configure as many watchers as you like for the same signal, but only within the same loop, i.e. you can watch for SIGINT in your default loop and for SIGIO in another loop, but you cannot watch for SIGINT in both the default loop and another loop at the same time. At the moment, SIGCHLD is permanently tied to the default loop.<br />
你可以根据你想要的配置很多watchers监听同一个信号，但是只能在同一个loop之内。即你可以在默认的loop上监听SIGINT，在另外一个loop上肩痛SIGIO，但是你不能同时在默认的loop和另外一个loop上都监听SIGINT，大多数时候，SIGCHLD是一直在默认的loop上的。</p>

<p>Only after the first watcher for a signal is started will libev actually register something with the kernel. It thus coexists with your own signal handlers as long as you don’t register any with libev for the same signal.<br />
只有在监听信号的第一个watcher被启动后，libev才实际上在内核中注册了一些东西。只要你没有给同样的信号在libev上注册，它就以这种方式来解决你自己的信号处理函数</p>

<p>If possible and supported, libev will install its handlers with SA_RESTART (or equivalent) behaviour enabled, so system calls should not be unduly interrupted. If you have a problem with system calls getting interrupted by signals you can block all signals in an ev_check watcher and unblock them in an ev_prepare watcher.<br />
如果可能并且支持的呼哈，libev将会使用开启SA_RESTART（或者同等效果）的行为来注册它的处理函数，所以系统调用不应该过分中断。如果你有一个关于系统调用造成信号中断的问题，那么你可以在ev_check watcher中阻止所有的在信号，并且在ev_preare watcher中解除阻止。</p>

<p>The special problem of inheritance over fork/execve/pthread_create<br />
继承fore/execve/pthread_create的问题</p>

<p>Both the signal mask (sigprocmask) and the signal disposition (sigaction) are unspecified after starting a signal watcher (and after stopping it again), that is, libev might or might not block the signal, and might or might not set or restore the installed signal handler (but see EVFLAG_NOSIGMASK).<br />
在启动信号watcher之后（在再一次停止它之后），信号掩码（sigprocmask）和信号处理程序没有被指定，也就是说，libev可能会或者也可能不会阻塞这个信号，并且可能会也可能不会设置或者重新设置信号的处理函数（但是要看EVFLAG_NOSIGMASK参数）。<br />
PS：在启动信号watcher之后？这句话怎么理解？应该是之前吧？</p>

<p>While this does not matter for the signal disposition (libev never sets signals to SIG_IGN, so handlers will be reset to SIG_DFL on execve), this matters for the signal mask: many programs do not expect certain signals to be blocked.<br />
虽然这对于信号处理并不要紧（libev从未设置SIG_IGN信号，所以在execve的时候，处理程序将会被重新设置到SIG_DFL），对于信号掩码重要的是：很多程序不希望某些信号被阻塞住。</p>

<p>This means that before calling exec (from the child) you should reset the signal mask to whatever “default” you expect (all clear is a good choice usually).<br />
这意味着，在调用exec之前（从子进程中）你要重新设置信号掩码到你希望的默认状态（通常，把所有的都清除掉是一个好的选择）。</p>

<p>The simplest way to ensure that the signal mask is reset in the child is to install a fork handler with pthread_atfork that resets it. That will catch fork calls done by libraries (such as the libc) as well.<br />
这个简单的方法来确保信号掩码是在子进程中被重置的，并且使用pthread_atfork来注册一个fork的处理程序来重置信号掩码。这还不如通过程序库来捕捉fork调用（例如libc）。</p>

<p>In current versions of libev, the signal will not be blocked indefinitely unless you use the signalfd API (EV_SIGNALFD). While this reduces the window of opportunity for problems, it will not go away, as libev has to modify the signal mask, at least temporarily.<br />
在当前的libev版本中，信号是不会被无限期的阻塞的，除非你使用signalfd API(EV_SIGNALFD).虽然那这样做拖延了问题的被发现的时机，但是问题不会消失，因为libev可以更改信号掩码，至少目前是这样的。</p>

<p>So I can’t stress this enough: If you do not reset your signal mask when you expect it to be empty, you have a race condition in your code. This is not a libev-specific thing, this is true for most event libraries.<br />
所以我不能强调这一点：当你期望你的信号掩码是空的时候，如果你不能重置你的信号掩码，你可以在你的代码中有一个竞争的条件。这不是libev特有的，这对于大多数event库来说都是对的。</p>

<p>The special problem of threads signal handling<br />
线程信号处理函数的问题</p>

<p>POSIX threads has problematic signal handling semantics, specifically, a lot of functionality (sigfd, sigwait etc.) only really works if all threads in a process block signals, which is hard to achieve.<br />
POSIX线程有有问题的信号处理语义，说明确一些，很多的功能（sigfd sigwait等）只能真正的工作只进程中所有的线程阻塞信号，这是很难实现的。</p>

<p>When you want to use sigwait (or mix libev signal handling with your own for the same signals), you can tackle this problem by globally blocking all signals before creating any threads (or creating them with a fully set sigprocmask) and also specifying the EVFLAG_NOSIGMASK when creating loops. Then designate one thread as “signal receiver thread” which handles these signals. You can pass on any signals that libev might be interested in by calling ev_feed_signal.<br />
当你想使用sigwait（或者对于同样的信号混合你自己的libev的信号处理程序），你可以通过在创建任何线程（或者使用一个完全的集合sigprocmask创建它们）之前全局阻塞所有的信号解决这个问题，或者也可以当创建loop时指定EVFLAG_NOSIGMASK参数。然后指定一个线程为“信号接收线程”来处理这些信号。你可以传递任何信号，libev可能通过调用ev_feed_signal对这些信号感兴趣。</p>

<h4 id="watcher-specific-functions-and-data-members">Watcher-Specific Functions and Data Members</h4>

<h5 id="ev_signal_init-ev_signal--callback-int-signum">ev_signal_init (ev_signal *, callback, int signum)</h5>
<h5 id="ev_signal_set-ev_signal--int-signum">ev_signal_set (ev_signal *, int signum)</h5>
<p>Configures the watcher to trigger on the given signal number (usually one of the SIGxxx constants).<br />
配置watcher来触发给定的信号</p>

<h4 id="int-signum-read-only">int signum [read-only]</h4>
<p>The signal the watcher watches out for.<br />
watcher监听到的信号</p>

<p>Example: Try to exit cleanly on SIGINT.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>static void
sigint_cb (struct ev_loop *loop, ev_signal *w, int revents)
{
    ev_break (loop, EVBREAK_ALL);
}

ev_signal signal_watcher;
ev_signal_init (&amp;signal_watcher, sigint_cb, SIGINT);
ev_signal_start (loop, &amp;signal_watcher);
</code></pre>
</div>

<h3 id="ev_child---watch-out-for-process-status-changes-ev_child-监控进程状态的改变">ev_child - watch out for process status changes ev_child-监控进程状态的改变</h3>

<p>Child watchers trigger when your process receives a SIGCHLD in response to some child status changes (most typically when a child of yours dies or exits). It is permissible to install a child watcher after the child has been forked (which implies it might have already exited), as long as the event loop isn’t entered (or is continued from a watcher), i.e., forking and then immediately registering a watcher for the child is fine, but forking and registering a watcher a few event loop iterations later or in the next callback invocation is not.<br />
当你的进程对于一些子进程状态的改变收到一个SIGCHLD信号的响应时，子进程watcher触发（最典型的是当你的子进程死掉或者退出）。它允许在子进程被fork之后，注册一个子进程的watcher（这意味这它可能已经退出了），只要event loop没有被进入（或者从一个watcher继续循环），即fork子进程然后马上为子进程注册一个watcher的正确的做法，但是fork一个子进程，然后在一些event loop循环迭代后注册一个watcher，或者在下一次的回调函数调用中注册watcher，这些方法是不正确的。</p>

<p>Only the default event loop is capable of handling signals, and therefore you can only register child watchers in the default event loop.<br />
只有默认的event loop能处理信号，因此你只能在默认event loop中注册子进程的watcher。</p>

<p>Due to some design glitches inside libev, child watchers will always be handled at maximum priority (their priority is set to EV_MAXPRI by libev)<br />
由于libev内部的一些设计问题，子进程的watchers一直被设计成拥有最大的优先级（它们的优先级被libev设置成EV_MAXPRI）。</p>

<p>Process Interaction<br />
进程的作用</p>

<p>Libev grabs SIGCHLD as soon as the default event loop is initialised. This is necessary to guarantee proper behaviour even if the first child watcher is started after the child exits. The occurrence of SIGCHLD is recorded asynchronously, but child reaping is done synchronously as part of the event loop processing. Libev always reaps all children, even ones not watched.<br />
只要默认的event loop已经被初始化，libev就可以捕获SIGCHLD。
即使第一个子进程watcher在子进程退出后被启动，这对于保证适当的行为也是必须的。SIGHLD的发生被记录是异步的，但是子进程把它作为event loop处理过程的一部分来同步进程。libev一直循环所有的子进程，即使是那些没有被监控的。</p>

<p>Overriding the Built-In Processing<br />
覆盖内置的处理</p>

<p>Libev offers no special support for overriding the built-in child processing, but if your application collides with libev’s default child handler, you can override it easily by installing your own handler for SIGCHLD after initialising the default loop, and making sure the default loop never gets destroyed. You are encouraged, however, to use an event-based approach to child reaping and thus use libev’s support for that, so other libev users can use ev_child watchers freely.<br />
libev对于覆盖内置的子进程处理，没有提供特殊的支持，但是如果你的应用程序与libev默认的子进程处理函数有冲突，你可以在初始化默认的loop之后给SIGCHLD信号注册你自己的处理函数，从而简单的覆盖它，并且确保默认的loop永远不会被释放。这是被鼓励的，不管怎么样，为了使用一个event-base处理子进程迭代并且因此使用libev支持它，所以另外的libev用户可以自由的使用ev_child wahcter。</p>

<p>Stopping the Child Watcher</p>

<p>Currently, the child watcher never gets stopped, even when the child terminates, so normally one needs to stop the watcher in the callback. Future versions of libev might stop the watcher automatically when a child exit is detected (calling ev_child_stop twice is not a problem).<br />
目前，子进程watcher永远不会停止，即使子进程退出，所以通常需要在回调中停止watcher。libev未来的版本可能会增加当子进程退出时自动停止watcher（调用ev_child_stop两次并不是一个问题）。</p>

<h4 id="watcher-specific-functions-and-data-members--watcher-特殊的函数和数据成员">Watcher-Specific Functions and Data Members  watcher-特殊的函数和数据成员</h4>

<h5 id="ev_child_init-ev_child--callback-int-pid-int-trace">ev_child_init (ev_child *, callback, int pid, int trace)</h5>
<h5 id="ev_child_set-ev_child--int-pid-int-trace">ev_child_set (ev_child *, int pid, int trace)</h5>
<p>Configures the watcher to wait for status changes of process pid (or any process if pid is specified as 0). The callback can look at the rstatus member of the ev_child watcher structure to see the status word (use the macros from sys/wait.h and see your systems waitpid documentation). The rpid member contains the pid of the process causing the status change. trace must be either 0 (only activate the watcher when the process terminates) or 1 (additionally activate the watcher when the process is stopped or continued).<br />
配置watcher用来等待进程id为pid的进程改变状态（如果pid为0，监控任意进程）。在回调函数中可以查看ev_child watcher结构的rstatus成员来查看状态消息（使用sys/wat.h中的宏，详细请查看waitpid文档）。rpid成员包括改变状态的pid，trace必须是0（只有当进程退出，watcher是活跃的）或者是1（当进程被停止或者继续的时候额外添加活跃的watcher）。</p>

<h5 id="int-pid-read-only">int pid [read-only]</h5>
<p>The process id this watcher watches out for, or 0, meaning any process id.<br />
watcher监控的进程id，如果是0，表示任何进程</p>

<h5 id="int-rpid-read-write">int rpid [read-write]</h5>
<p>The process id that detected a status change.<br />
检测到状态发生变化的进程id</p>

<h5 id="int-rstatus-read-write">int rstatus [read-write]</h5>
<p>The process exit/trace status caused by rpid (see your systems waitpid and sys/wait.h documentation for details).<br />
通过rpid引起进程退出或者跟踪的状态（详细查看你的系统waitpid和sys/wait.h文档）</p>

<p>Example: fork() a new process and install a child handler to wait for its completion.<br />
示例：for一个新的进程，并且注册一个子进程处理函数来等到进程结束。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>ev_child cw;

static void
child_cb (EV_P_ ev_child *w, int revents)
{
    ev_child_stop (EV_A_ w);
    printf ("process %d exited with status %x\n", w-&gt;rpid, w-&gt;rstatus);
}

pid_t pid = fork ();

if (pid &lt; 0)
// error
else if (pid == 0)
{
    // the forked child executes here
    exit (1);
}
else
{
    ev_child_init (&amp;cw, child_cb, pid, 0);
    ev_child_start (EV_DEFAULT_ &amp;cw);
}
</code></pre>
</div>

<h3 id="ev_stat---did-the-file-attributes-just-change--ev_stat-就改变了文件属性">ev_stat - did the file attributes just change?  ev_stat-就改变了文件属性？</h3>

<p>This watches a file system path for attribute changes. That is, it calls stat on that path in regular intervals (or when the OS says it changed) and sees if it changed compared to the last time, invoking the callback if it did. Starting the watcher stat’s the file, so only changes that happen after the watcher has been started will be reported.<br />
ev_stat监控文件系统路径的属性变化。相当于在路径上有规律的调用stat来查看是不是和上一次调用stat时的状态不一样了，如果是，那么调用回调函数。启动watcher监控文件，只有在watcher被启动以后熟悉发生改变才会被报告。</p>

<p>The path does not need to exist: changing from “path exists” to “path does not exist” is a status change like any other. The condition “path does not exist” (or more correctly “path cannot be stat’ed”) is signified by the st_nlink field being zero (which is otherwise always forced to be at least one) and all the other fields of the stat buffer having unspecified contents.<br />
路径并不需要存在：从路径存在到路径不存在的改变是一种状态的改变，就像其他的改变一样。”路径不存在“的条件（或者更确切的说是”路径不能被stat“）是通过st_nlink字段变成0指定的（换种说法就是一直被迫编程另外一种），并且所有stat buffer另外的字段内容也不确定。</p>

<p>The path must not end in a slash or contain special components such as . or … The path should be absolute: If it is relative and your working directory changes, then the behaviour is undefined.<br />
Since there is no portable change notification interface available, the portable implementation simply calls stat(2) regularly on the path to see if it changed somehow. You can specify a recommended polling interval for this case. If you specify a polling interval of 0 (highly recommended!) then a suitable, unspecified default value will be used (which you can expect to be around five seconds, although this might change dynamically). Libev will also impose a minimum interval which is currently around 0.1, but that’s usually overkill.<br />
路径必须不能一斜线或者特殊字符结束，比如.或者..。路径必须是绝对路径，如果它是相对路径，并且你的工作目录被改变，那么ev_stat的行为就是未定义的。由于没有便捷的改变通知接口可用，所以就简单的在路径上调用stat（2）来实现便捷通知，以达到查看路径是否改变。你可以指定调用stat的时间间隔。如果你把时间间隔设置成0（强烈推荐），那么就使用默认值（默认值大概在5s左右，但是也会动态的改变）。libev支持最小的时间间隔为0.1s，但是这个值经常是太过度了。</p>

<p>This watcher type is not meant for massive numbers of stat watchers, as even with OS-supported change notifications, this can be resource-intensive.<br />
这种watcher类型一般不是为了大量的stat watchers考虑的，因为即使使用系统支持的改变通知接口，这也是很耗资源的。</p>

<p>At the time of this writing, the only OS-specific interface implemented is the Linux inotify interface (implementing kqueue support is left as an exercise for the reader. Note, however, that the author sees no way of implementing ev_stat semantics with kqueue, except as a hint).<br />
到目前为止，只有linux实现了通知接口（使用kqueue实现一个接口作为读者的一个练习。注意，不管怎么说，作者都觉得不能使用kqueue来实现ev_stat的语义，除非暗地里有变通）。</p>

<p>ABI Issues (Largefile Support)<br />
ABI问题（大文件的支持）</p>

<p>Libev by default (unless the user overrides this) uses the default compilation environment, which means that on systems with large file support disabled by default, you get the 32 bit version of the stat structure. When using the library from programs that change the ABI to use 64 bit file offsets the programs will fail. In that case you have to compile libev with the same flags to get binary compatibility. This is obviously the case with any flags that change the ABI, but the problem is most noticeably displayed with ev_stat and large file support.<br />
libev在默认情况（除非你改变它）使用默认的编译环境，这意味着在系统上默认的是关闭大文件支持的，你得到的32位的stat结构。当把使用32位程序库的程序改变ABI到使用64位系统时将会失败。这种情况下，你必须使用同样的参数来编译libev以获取二进制的支持。这是显然的情况，使用任何标志来改变ABI，但问题是大多数使用ev_stat和大文件支持的显式的显示。</p>

<p>The solution for this is to lobby your distribution maker to make large file interfaces available by default (as e.g. FreeBSD does) and not optional. Libev cannot simply switch on large file support because it has to exchange stat structures with application programs compiled using the default compilation environment.<br />
这个问题的解决方案就是忽悠你的系统发行商默认支持大文件接口可用而不是选用（就像freebsd一样）。libev不能简单的切换大文件支持，因为它要使用默认的编译环境编译应用程序来交换stat结构。</p>

<p>Inotify and Kqueue<br />
通知和kqueue</p>

<p>When inotify (7) support has been compiled into libev and present at runtime, it will be used to speed up change detection where possible. The inotify descriptor will be created lazily when the first ev_stat watcher is being started.<br />
当支持inotify（7）被编译进libev并且运行，它将被尽可能的用来提升改变侦测的速度。inotify描述符将会在第一个ev_stat watcher开始的时候被惰性的创建。</p>

<p>Inotify presence does not change the semantics of ev_stat watchers except that changes might be detected earlier, and in some cases, to avoid making regular stat calls. Even in the presence of inotify support there are many cases where libev has to resort to regular stat polling, but as long as kernel 2.6.25 or newer is used (2.6.24 and older have too many bugs), the path exists (i.e. stat succeeds), and the path resides on a local filesystem (libev currently assumes only ext2/3, jfs, reiserfs and xfs are fully working) libev usually gets away without polling.<br />
inotify的存在并不改变ev_stat watcher的语义，除非改变可能被侦测的更早，并且在某些情况下，避免正常的stat调用。即使在inotify的载体存在有许多的情况下， libev也不得不诉诸定期统计轮询，但是只要内核2.6.25或者更新的被使用（2.6.24或者更老的有很多bug），路径存在（级stat成功），以及路径是本地路径（libev当前支持只有ext2/3，ifs，reiserfs和xfs），libev经常不需要polling就被触发了。</p>

<p>There is no support for kqueue, as apparently it cannot be used to implement this functionality, due to the requirement of having a file descriptor open on the object at all times, and detecting renames, unlinks etc. is difficult.<br />
不对kqueue进行支持，显然它不能被用来实现这个功能，，因为在一个对象上打开一个文件描述符，并且重新命名，将解除等的要求是困难的。</p>

<p>stat () is a synchronous operation<br />
stat（）是同步操作</p>

<p>Libev doesn’t normally do any kind of I/O itself, and so is not blocking the process. The exception are ev_stat watchers - those call stat (), which is a synchronous operation.<br />
libev通常自己不会做任何类型的IO类型，所以不会阻塞进程。唯一的另外是ev_stat watchers-他们调用stat（），这是同步操作。</p>

<p>For local paths, this usually doesn’t matter: unless the system is very busy or the intervals between stat’s are large, a stat call will be fast, as the path data is usually in memory already (except when starting the watcher).<br />
对于本地路径，这通常不是那么重要：除非系统非常忙碌或者间隔时间很大，stat调用通常都很快，因为路径的stat数据通常都是已经在内存里面的（除了watcher启动的时候）。</p>

<p>For networked file systems, calling stat () can block an indefinite time due to network issues, and even under good conditions, a stat call often takes multiple milliseconds.<br />
对于网络文件系统，调用stat（）可能阻塞一段不定的时间用来处理网络问题，并且即使网络条件不错，一个stat调用通常也要话费掉好几毫秒。</p>

<p>Therefore, it is best to avoid using ev_stat watchers on networked paths, although this is fully supported by libev.<br />
因此，最好不要吧ev_stat watchers用在远程路径上，尽管libev完全支持它。</p>

<p>The special problem of stat time resolution<br />
stat时间精度的问题</p>

<p>The stat () system call only supports full-second resolution portably, and even on systems where the resolution is higher, most file systems still only support whole seconds.<br />
stat（）系统调用仅提供正秒的精度支持，即使系统的精度再高，大多数文件系统仍然只提供正秒的精度支持。</p>

<p>That means that, if the time is the only thing that changes, you can easily miss updates: on the first update, ev_stat detects a change and calls your callback, which does something. When there is another update within the same second, ev_stat will be unable to detect unless the stat data does change in other ways (e.g. file size).<br />
这意味着，如果你仅仅改变的是文件的时间，那么你可能很容易就会错过更新：在第一次更新的时候，ev_stat发现了一个改变并且调用你的回调，执行回调函数。当在同一秒再一次更新的时候，ev_stat将不能发现这个时间更新除非用另外一种方法更新了别的stat数据（比如文件大小）。</p>

<p>The solution to this is to delay acting on a change for slightly more than a second (or till slightly after the next full second boundary), using a roughly one-second-delay ev_timer (e.g. ev_timer_set (w, 0., 1.02); ev_timer_again (loop, w)).<br />
解决方案就是延迟一秒来更新（或者在一下秒之后），使用一个1秒的ev_timer（例如：ev_timer_set (w, 0., 1.02); ev_timer_again (loop, w)）。</p>

<p>The .02 offset is added to work around small timing inconsistencies of some operating systems (where the second counter of the current time might be be delayed. One such system is the Linux kernel, where a call to gettimeofday might return a timestamp with a full second later than a subsequent time call - if the equivalent of time () is used to update file times then there will be a small window where the kernel uses the previous second to update file times but libev might already execute the timer callback).<br />
.02的误差被加进来来解决系统之间的时间误差（当前时间的计数器可能会被延迟。就像linux内核系统，调用gettimeofday可能返回一个正秒时间戳大于紧跟其后的time调用-如果相当于time（）时间被用来更新文件时间，那么将会有一个小的误差窗口，内核会使用前一秒来更新文件时间，但是libev可能已经执行了这个timer的回调了）。<br />
PS：其实说白了，就是系统时间有误差，所以，需要加一个误差时间来弥补这个误差造成的更新被忽略问题。</p>

<h4 id="watcher-specific-functions-and-data-members-watcher-特有的函数和数据成员">Watcher-Specific Functions and Data Members watcher-特有的函数和数据成员</h4>

<h5 id="ev_stat_init-ev_stat--callback-const-char-path-ev_tstamp-interval">ev_stat_init (ev_stat *, callback, const char *path, ev_tstamp interval)</h5>
<h5 id="ev_stat_set-ev_stat--const-char-path-ev_tstamp-interval">ev_stat_set (ev_stat *, const char *path, ev_tstamp interval)</h5>
<p>Configures the watcher to wait for status changes of the given path. The interval is a hint on how quickly a change is expected to be detected and should normally be specified as 0 to let libev choose a suitable value. The memory pointed to by path must point to the same path for as long as the watcher is active.<br />
配置一个watcher来等到给定路径的状态的改变。interval是一个暗示多久发生一个变化被发现，通常指定为0，让libev自己决定这个值。只要watcher是可用的，path都只想一个相同的路径。</p>

<p>The callback will receive an EV_STAT event when a change was detected, relative to the attributes at the time the watcher was started (or the last change was detected).<br />
当改变被发现的时候，回调函数将会接收到一个EV_STAT事件。相当于在这个时候对于属性来说，watcher被启动了（或者最后一个变化被检测到）。</p>

<h5 id="ev_stat_stat-loop-ev_stat-">ev_stat_stat (loop, ev_stat *)</h5>
<p>Updates the stat buffer immediately with new values. If you change the watched path in your callback, you could call this function to avoid detecting this change (while introducing a race condition if you are not the only one changing the path). Can also be useful simply to find out the new values.<br />
立即获取新的stat数据。如果你在回调函数中更改监控路径，你可以调用这个函数来避免检测到这个变化（如果你不仅仅改变监控的路径，需要引入急诊条件）。也可以简单的获取新的stat值。</p>

<h5 id="ev_statdata-attr-read-only">ev_statdata attr [read-only]</h5>
<p>The most-recently detected attributes of the file. Although the type is ev_statdata, this is usually the (or one of the) struct stat types suitable for your system, but you can only rely on the POSIX-standardised members to be present. If the st_nlink member is 0, then there was some error while stating the file.<br />
最近检测到的文件属性。尽管类型是ev_statdata，当这通常都是适合你系统的stat结构数据（或者之一），但是你只能依靠POSIX标准成员来处理。如果st_nlink成员是0，那么检测的文件出现了一些错误。</p>

<h5 id="ev_statdata-prev-read-only">ev_statdata prev [read-only]</h5>
<p>The previous attributes of the file. The callback gets invoked whenever prev != attr, or, more precisely, one or more of these members differ: st_dev, st_ino, st_mode, st_nlink, st_uid, st_gid, st_rdev, st_size, st_atime, st_mtime, st_ctime.<br />
文件属性的前一个值。当prev！＝attr的时候，回调函数被调用，或者更正确的说，一个或者多个成员不同的时候：st_dev, st_ino, st_mode, st_nlink, st_uid, st_gid, st_rdev, st_size, st_atime, st_mtime, st_ctime.</p>

<h5 id="ev_tstamp-interval-read-only">ev_tstamp interval [read-only]</h5>
<p>The specified interval.<br />
指定时间间隔</p>

<h5 id="const-char-path-read-only">const char *path [read-only]</h5>
<p>The file system path that is being watched.<br />
待监控的文件系统路径</p>

<p>Example: Watch /etc/passwd for attribute changes.<br />
示例：监控/etc/passwd的属性改变</p>

<div class="highlighter-rouge"><pre class="highlight"><code>static void
passwd_cb (struct ev_loop *loop, ev_stat *w, int revents)
{
    /* /etc/passwd changed in some way */
    //改变密码文件
    if (w-&gt;attr.st_nlink)
    {
        printf ("passwd current size  %ld\n", (long)w-&gt;attr.st_size);
        printf ("passwd current atime %ld\n", (long)w-&gt;attr.st_mtime);
        printf ("passwd current mtime %ld\n", (long)w-&gt;attr.st_mtime);
    } else {
        /* you shalt not abuse printf for puts */
        puts ("wow, /etc/passwd is not there, expect problems. "
        "if this is windows, they already arrived\n");
    }

    ...
    ev_stat passwd;

    ev_stat_init (&amp;passwd, passwd_cb, "/etc/passwd", 0.);
    ev_stat_start (loop, &amp;passwd);
}
</code></pre>
</div>

<p>Example: Like above, but additionally use a one-second delay so we do not miss updates (however, frequent updates will delay processing, too, so one might do the work both on ev_stat callback invocation and on ev_timer callback invocation).<br />
示例：同上，但是增加使用一个一秒的延迟，所以我们不会错过更新（但是，频繁的更新会延迟处理，因为太多了，所以ev_stat和ev_timer的回调调用都会被调用）。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>static ev_stat passwd;
static ev_timer timer;

static void
timer_cb (EV_P_ ev_timer *w, int revents)
{
    ev_timer_stop (EV_A_ w);
    /* now it's one second after the most recent passwd change */
}

static void
stat_cb (EV_P_ ev_stat *w, int revents)
{
    /* reset the one-second timer */
    ev_timer_again (EV_A_ &amp;timer);
}

...
ev_stat_init (&amp;passwd, stat_cb, "/etc/passwd", 0.);
ev_stat_start (loop, &amp;passwd);
ev_timer_init (&amp;timer, timer_cb, 0., 1.02);
</code></pre>
</div>

<h3 id="ev_idle---when-youve-got-nothing-better-to-do-ev_idle-当你没有什么更好的事情做的时候">ev_idle - when you’ve got nothing better to do… ev_idle-当你没有什么更好的事情做的时候</h3>

<p>Idle watchers trigger events when no other events of the same or higher priority are pending (prepare, check and other idle watchers do not count as receiving “events”).
当没有另外的同级别或者更高优先级的事件未触发时，触发Idle事件。</p>

<p>That is, as long as your process is busy handling sockets or timeouts (or even signals, imagine) of the same or higher priority it will not be triggered. But when your process is idle (or only lower-priority watchers are pending), the idle watchers are being called once per event loop iteration - until stopped, that is, or your process receives more events and becomes busy again with higher priority stuff.<br />
这就是说，只要你的进程忙于处理同级别或者更高级别的sockets或者timeout（或者信号等）事件，Idle watcher将不会被触发。但是当你的进程处于空闲状态（或者只有低优先级的watchers未被处理），idle watcher将会每次event loop循环被调用一次直到停止，或者你的进程接收到很多事件又再一次被高优先级的事件变的忙碌。</p>

<p>The most noteworthy effect is that as long as any idle watchers are active, the process will not block when waiting for new events.<br />
最值得一提的是，只要任何idle watchers是活跃的，那么进程在等待新事件的时候不会阻塞。</p>

<p>Apart from keeping your process non-blocking (which is a useful effect on its own sometimes), idle watchers are a good place to do “pseudo-background processing”, or delay processing stuff to after the event loop has handled all outstanding events.<br />
除了保持你的进程非阻塞（在自己的事件上面这是有用的效果），idle watchers是一个做“伪后台”处理的好时候，或者把事件延迟到event loop处理完所有的未解决事件以后在处理。</p>

<p>Abusing an ev_idle watcher for its side-effect<br />
滥用ev_idle导致的副作用<br />
As long as there is at least one active idle watcher, libev will never sleep unnecessarily. Or in other words, it will loop as fast as possible. For this to work, the idle watcher doesn’t need to be invoked at all - the lowest priority will do.<br />
只要有一个活跃的idle watcher，libev将永远没必要休眠。或者换句话说，libev将尽可能快的循环，为了这个工作，idle watcher是完全没必要被调用的-所以，最小的优先级就可以保证libev无休止循环了。</p>

<p>This mode of operation can be useful together with an ev_check watcher, to do something on each event loop iteration - for example to balance load between different connections.<br />
这种模式和ev_check watcher一起使用将是非常有用的，每次循环的时候都做一些事情-比如在不同的连接之间做负载均衡。</p>

<p>See Abusing an ev_check watcher for its side-effect for a longer example.<br />
详情请查看滥用ev_check watcher导致副作用的更长的例子。</p>

<h4 id="watcher-specific-functions-and-data-members-1">Watcher-Specific Functions and Data Members</h4>

<h5 id="ev_idle_init-ev_idle--callback">ev_idle_init (ev_idle *, callback)</h5>
<p>Initialises and configures the idle watcher - it has no parameters of any kind. There is a ev_idle_set macro, but using it is utterly pointless, believe me.<br />
初始化和配置idle watcher-它没有任何类型的参数，这是一个ev_idle_set宏，但是使用它是毫无意义的，相信我。</p>

<p>Example: Dynamically allocate an ev_idle watcher, start it, and in the callback, free it. Also, use no error checking, as usual.<br />
例子：动态的分配一个ev_idle watcher，启动它，并且在回调函数中，释放它。同样，经常不用错误检测。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>static void
idle_cb (struct ev_loop *loop, ev_idle *w, int revents)
{
    // stop the watcher
    ev_idle_stop (loop, w);
    // now we can free it
    free (w);
    // now do something you wanted to do when the program has
    // no longer anything immediate to do.
}

ev_idle *idle_watcher = malloc (sizeof (ev_idle));
ev_idle_init (idle_watcher, idle_cb);
ev_idle_start (loop, idle_watcher);
</code></pre>
</div>

<h3 id="ev_prepare-and-ev_check---customise-your-event-loop--ev_prepare和ev_check--自定义你的event-loop">ev_prepare and ev_check - customise your event loop!  ev_prepare和ev_check  自定义你的event loop</h3>

<p>Prepare and check watchers are often (but not always) used in pairs: prepare watchers get invoked before the process blocks and check watchers afterwards.<br />
prepare和check通常（但不是一直）都是成对使用的：prepare watchers在处理块之前（PS：应该是循环loop，调用各个回调函数之前）被调用，check watcer在之后被调用。</p>

<p>You must not call ev_run (or similar functions that enter the current event loop) or ev_loop_fork from either ev_prepare or ev_check watchers. Other loops than the current one are fine, however. The rationale behind this is that you do not need to check for recursion in those watchers, i.e. the sequence will always be ev_prepare, blocking, ev_check so if you have one watcher of each kind they will always be called in pairs bracketing the blocking call.<br />
你不能在ev_prepare或者ev_check watchers中调用ev_run（或者能进入当前循环的类似的函数）或者ev_loop_fork。不管怎么说，其他的循环相比当前循环都是好的。这样做的理由是你不需要在另外一些watchers中检查递归了。即，循序一直是ev_prepare，阻塞，ev_check。所以如果你每一种类型都有一个watcher，那么他们将一直成对的被包装在阻塞调用中被调用。</p>

<p>Their main purpose is to integrate other event mechanisms into libev and their use is somewhat advanced. They could be used, for example, to track variable changes, implement your own watchers, integrate net-snmp or a coroutine library and lots more. They are also occasionally useful if you cache some data and want to flush it before blocking (for example, in X programs you might want to do an XFlush () in an ev_prepare watcher).<br />
它们的主要目的是集成另外的事件机制到libev中并且他们的用法是稍微有点高级的。他们可以被用来，例如，跟踪变量的变化，实现你自己的watchers，继承net-snmp或者一个协同库，或者更多。如果你想缓存一些数据并且想在阻塞之前刷新到磁盘，那么它们对此也是支持的（例如，在X程序中，你可能想在ev_prepare watcher中做一个XFlush（）操作）。</p>

<p>This is done by examining in each prepare call which file descriptors need to be watched by the other library, registering ev_io watchers for them and starting an ev_timer watcher for any timeouts (many libraries provide exactly this functionality). Then, in the check watcher, you check for any events that occurred (by checking the pending status of all watchers and stopping them) and call back into the library. The I/O and timer callbacks will never actually be called (but must be valid nevertheless, because you never know, you know?).<br />
这是通过检查在每一个prepare调用中文件描述符需要被别的程序库监控，为它们注册ev_io watchers ，为了任何的超时，启动一个ev_timer watcher（很多程序库都提供这些功能）。那么，在check watcher中，你检查任何发生的事件（通过检查所有watchers的未处理状态并且停止它们）并且回调到程序库中。IO和定时器事件将事实上永远不会被调用（但是尽管如此，io和timer必须是有效的，因为你永远不知道，你懂的）。</p>

<p>As another example, the Perl Coro module uses these hooks to integrate coroutines into libev programs, by yielding to other active coroutines during each prepare and only letting the process block if no coroutines are ready to run (it’s actually more complicated: it only runs coroutines with priority higher than or equal to the event loop and one coroutine of lower priority, but only once, using idle watchers to keep the event loop from blocking if lower-priority coroutines are active, thus mapping low-priority coroutines to idle/background tasks).<br />
另外一个例子，Perl的coro模块使用钩子来继承协程到libev程序中，通过依从另外的活跃协程在每次prepare和如果没有协程准备运行，只让进程阻塞。（这实际上更加复杂：它只能运行协同程序优先高于或等于事件循环和低优先级中的一个协同程序，但仅仅一次，如果低优先级的协程是活跃的，那么使用idle watchers来保证event loop阻塞，从而映射优先级低的协程为空闲/后台任务）。</p>

<p>When used for this purpose, it is recommended to give ev_check watchers highest (EV_MAXPRI) priority, to ensure that they are being run before any other watchers after the poll (this doesn’t matter for ev_prepare watchers).<br />
当用来作为这个目的的时候，建议给ev_check watchers最好的优先级（EV_MAXPRI），来确保他们在任何另外的watchers之前和poll之后运行（对于ev_prepare watchers来说无关紧要）。</p>

<p>Also, ev_check watchers (and ev_prepare watchers, too) should not activate (“feed”) events into libev. While libev fully supports this, they might get executed before other ev_check watchers did their job. As ev_check watchers are often used to embed other (non-libev) event loops those other event loops might be in an unusable state until their ev_check watcher ran (always remind yourself to coexist peacefully with others).<br />
此外，ev_check watchers（ev_prepare watchers也是如此）应该不会激活事件到libev中，尽管libev完全支持这个功能，他们可能在另外的ev_check watchers被调用之前执行。由于ev_check watchers经常被用来嵌入另外（非libev）的event loop，另外的event loops可能在一个不稳定的状态，知道他们的ev_check watcer运行（总是提醒你自己与他人和平相处）。</p>

<p>Abusing an ev_check watcher for its side-effect<br />
ec_check被滥用的副作用</p>

<p>ev_check (and less often also ev_prepare) watchers can also be useful because they are called once per event loop iteration. For example, if you want to handle a large number of connections fairly, you normally only do a bit of work for each active connection, and if there is more work to do, you wait for the next event loop iteration, so other connections have a chance of making progress.<br />
ev_check（往往还有ev_prepare）watchers是有用的，因为它们在每次的event loop迭代中都会被调用一次。例如，如果你想公平的处理大量的连接，你通常每个连接只能做一点事情，如果你有更多的事情要做，你必须等待下一次的迭代，所以另外的连接有取得处理的机会。</p>

<p>Using an ev_check watcher is almost enough: it will be called on the next event loop iteration. However, that isn’t as soon as possible - without external events, your ev_check watcher will not be invoked.<br />
使用一个ev_check watcher是不够的：它将会在下一次的event loop迭代中被调用。然而，这不是尽可能的-如果没有外部事件，你的ev_check watcher将不会被调用。</p>

<p>This is where ev_idle watchers come in handy - all you need is a single global idle watcher that is active as long as you have one active ev_check watcher. The ev_idle watcher makes sure the event loop will not sleep, and the ev_check watcher makes sure a callback gets invoked. Neither watcher alone can do that.<br />
这个时候ev_idle watcher就会派上用场了-，只要你有一个活跃的ev_check，你就需要的是一个全局的活跃的idle watcher。ev_idle watcher确保event loop不需要休眠，ev_check watcher确保函数被调用，任何一个单独的watcher都不能做到这样。<br />
PS：其实就是说使用ev_idle watcher来带动event loop迭代，从而唤醒ev_prepare和ev_check。</p>

<h4 id="watcher-specific-functions-and-data-members-2">Watcher-Specific Functions and Data Members</h4>

<h5 id="ev_prepare_init-ev_prepare--callback">ev_prepare_init (ev_prepare *, callback)</h5>
<h5 id="ev_check_init-ev_check--callback">ev_check_init (ev_check *, callback)</h5>
<p>Initialises and configures the prepare or check watcher - they have no parameters of any kind. There are ev_prepare_set and ev_check_set macros, but using them is utterly, utterly, utterly and completely pointless.<br />
初始化和配置prepare和check watcher-他们没有任何类型的参数。它们只是ev_prepare_set和ev_check_set宏，但是使用他们是完全完全完全没有意义的。</p>

<p>There are a number of principal ways to embed other event loops or modules into libev. Here are some ideas on how to include libadns into libev (there is a Perl module named EV::ADNS that does this, which you could use as a working example. Another Perl module named EV::Glib embeds a Glib main context into libev, and finally, Glib::EV embeds EV into the Glib event loop).<br />
有一些嵌入另外的event loops或者模块到libev的主要方法。下面是一些关于怎么把libadns嵌入到libev的方法（perl的EV::ADNS模块就是这么做的，你可以使用它作为一个可以工作的示例。另外一个perl的EV:Glib模块把一个Glib的主要上下文嵌入到libev，最后，Glib::EV嵌入EV到Glib的event loop）。</p>

<p>Method 1: Add IO watchers and a timeout watcher in a prepare handler, and in a check watcher, destroy them and call into libadns. What follows is pseudo-code only of course. This requires you to either use a low priority for the check watcher or use ev_clear_pending explicitly, as the callbacks for the IO/timeout watchers might not have been called yet.<br />
方法1：在一个prepare处理事件中加一个IO watcher和timeout watcher，并且在check watcher，释放他们并且调用libadns。下面当然是伪代码，这需要你要么使用一个低优先级的check watcher或者明确使用ev_clear_pending，作为IO/timeout watchers的回调可能不会被调用。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>static ev_io iow [nfd];
static ev_timer tw;

static void
io_cb (struct ev_loop *loop, ev_io *w, int revents)
{
}

// create io watchers for each fd and a timer before blocking
static void
adns_prepare_cb (struct ev_loop *loop, ev_prepare *w, int revents)
{
    int timeout = 3600000;
    struct pollfd fds [nfd];
    // actual code will need to loop here and realloc etc.
    adns_beforepoll (ads, fds, &amp;nfd, &amp;timeout, timeval_from (ev_time ()));

    /* the callback is illegal, but won't be called as we stop during check */
    ev_timer_init (&amp;tw, 0, timeout * 1e-3, 0.);
    ev_timer_start (loop, &amp;tw);

    // create one ev_io per pollfd
    for (int i = 0; i &lt; nfd; ++i)
    {
        ev_io_init (iow + i, io_cb, fds [i].fd,
        ((fds [i].events &amp; POLLIN ? EV_READ : 0)
        | (fds [i].events &amp; POLLOUT ? EV_WRITE : 0)));

        fds [i].revents = 0;
        ev_io_start (loop, iow + i);
    }
}

// stop all watchers after blocking
static void
adns_check_cb (struct ev_loop *loop, ev_check *w, int revents)
{
    ev_timer_stop (loop, &amp;tw);

    for (int i = 0; i &lt; nfd; ++i)
    {
        // set the relevant poll flags
        // could also call adns_processreadable etc. here
        struct pollfd *fd = fds + i;
        int revents = ev_clear_pending (iow + i);
        if (revents &amp; EV_READ ) fd-&gt;revents |= fd-&gt;events &amp; POLLIN;
        if (revents &amp; EV_WRITE) fd-&gt;revents |= fd-&gt;events &amp; POLLOUT;

        // now stop the watcher
        ev_io_stop (loop, iow + i);
    }

    adns_afterpoll (adns, fds, nfd, timeval_from (ev_now (loop));
}
</code></pre>
</div>

<p>Method 2: This would be just like method 1, but you run adns_afterpoll in the prepare watcher and would dispose of the check watcher.<br />
方法2：和方法i差不多，但是在prepare watcher中运行adns_afterpoll，并且处理check watcher。</p>

<p>Method 3: If the module to be embedded supports explicit event notification (libadns does), you can also make use of the actual watcher callbacks, and only destroy/create the watchers in the prepare watcher.<br />
方法3：如果模块被嵌入需要提供显式的通知（libadns就这样做的），你也可以利用实际watcher的回调，并且只在prepare watcher中释放/创建watchers。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>static void
timer_cb (EV_P_ ev_timer *w, int revents)
{
    adns_state ads = (adns_state)w-&gt;data;
    update_now (EV_A);

    adns_processtimeouts (ads, &amp;tv_now);
}

static void
io_cb (EV_P_ ev_io *w, int revents)
{
    adns_state ads = (adns_state)w-&gt;data;
    update_now (EV_A);

    if (revents &amp; EV_READ ) adns_processreadable  (ads, w-&gt;fd, &amp;tv_now);
    if (revents &amp; EV_WRITE) adns_processwriteable (ads, w-&gt;fd, &amp;tv_now);
}
// do not ever call adns_afterpoll
</code></pre>
</div>

<p>Method 4: Do not use a prepare or check watcher because the module you want to embed is not flexible enough to support it. Instead, you can override their poll function. The drawback with this solution is that the main loop is now no longer controllable by EV. The Glib::EV module uses this approach, effectively embedding EV as a client into the horrible libglib event loop.<br />
方法2：不使用prepare或者check watcher，因为你想嵌入的模块不够灵活的支持他。相反，你可以重写你的poll函数。这种解决方案的缺点是，主loop不能通过EV控制。Glib::EV模块使用这种方法，当客户端进入libglib event loop是，有效的嵌入EV。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>static gint
event_poll_func (GPollFD *fds, guint nfds, gint timeout)
{
    int got_events = 0;

    for (n = 0; n &lt; nfds; ++n)
    // create/start io watcher that sets the relevant bits in fds[n] and increment got_events

    if (timeout &gt;= 0)
    // create/start timer

    // poll
    ev_run (EV_A_ 0);

    // stop timer again
    if (timeout &gt;= 0)
    ev_timer_stop (EV_A_ &amp;to);

    // stop io watchers again - their callbacks should have set
    for (n = 0; n &lt; nfds; ++n)
    ev_io_stop (EV_A_ iow [n]);

    return got_events;
}
</code></pre>
</div>

<h3 id="ev_embed---when-one-backend-isnt-enough-ev_embed-当一个后台不够用的时候">ev_embed - when one backend isn’t enough… ev_embed-当一个后台不够用的时候</h3>

<p>This is a rather advanced watcher type that lets you embed one event loop into another (currently only ev_io events are supported in the embedded loop, other types of watchers might be handled in a delayed or incorrect fashion and must not be used).<br />
这是一个相当高级的watcher类型，让你可以把一个event loop嵌入到另外一个event loop中（当前，在嵌入的loop中只有ev_io events是获得支持的，别的类型的watchers可能会被延迟处理或者出错，所以不能使用）。</p>

<p>There are primarily two reasons you would want that: work around bugs and prioritise I/O.<br />
使用ev_embed的原因主要有2个：解决bug和优先级IO。</p>

<p>As an example for a bug workaround, the kqueue backend might only support sockets on some platform, so it is unusable as generic backend, but you still want to make use of it because you have many sockets and it scales so nicely. In this case, you would create a kqueue-based loop and embed it into your default loop (which might use e.g. poll). Overall operation will be a bit slower because first libev has to call poll and then kevent, but at least you can use both mechanisms for what they are best: kqueue for scalable sockets and poll if you want it to work :)<br />
作为一个解决bug的例子，在一些平台上，kqueue只支持sockets，所以它并不是一个通用的后台，但是你仍然想要使用它，因为你有很多的socket要处理并且kqueue处理的很好。在这种情况下，你可以创建一个基于kqueue的loop并且把它嵌入你的默认的loop（默认的loop可能是基于poll的）。总体的操作可能会有一点慢，因为首先libev要调用poll然后才是kevent（应该是queuue的事件吧），但是，至少你可以同时使用2个合适的机制：kqueue处理socket，poll处理你想要它做的事情）。</p>

<p>As for prioritising I/O: under rare circumstances you have the case where some fds have to be watched and handled very quickly (with low latency), and even priorities and idle watchers might have too much overhead. In this case you would put all the high priority stuff in one loop and all the rest in a second one, and embed the second one in the first.<br />
至于考虑到优先级的IO：在极少数情况下，你可能介意一些fds被监控和快速的被处理（低延迟的），优先级和idle watchers也可能会有更多的开销。在这种情况下，你可以把一些高优先级的事情放到一个loop中，剩下的放到第二个loop中，然后把第二个嵌入到第一个。</p>

<p>As long as the watcher is active, the callback will be invoked every time there might be events pending in the embedded loop. The callback must then call ev_embed_sweep (mainloop, watcher) to make a single sweep and invoke their callbacks (the callback doesn’t need to invoke the ev_embed_sweep function directly, it could also start an idle watcher to give the embedded loop strictly lower priority for example).<br />
只要watcher是活跃的，回调将每次都会被调用，这可能是嵌入loop中的未处理事件。回调必须调用ev_embed_sweep（mainloop，watcher）来做一次扫描并且调用它们的回调（回调不需要立即调用ev_embed_sweep函数，它也可以启动一个idle watcher来给嵌入的loop严格的低优先级）。</p>

<p>You can also set the callback to 0, in which case the embed watcher will automatically execute the embedded loop sweep whenever necessary.<br />
你也可以把回调设置成0，这种情况下，embed watcher将会在有必要的情况下自动的执行被嵌入loop的扫描。</p>

<p>Fork detection will be handled transparently while the ev_embed watcher is active, i.e., the embedded loop will automatically be forked when the embedding loop forks. In other cases, the user is responsible for calling ev_loop_fork on the embedded loop.<br />
当ev_embed watcher是活跃状态的时候，fork检测将会被透明的处理，即当被嵌入的loop fork时，被嵌入loop将自动的forked。另外一种情况，用户自己负责在被嵌入的loop上调用ev_loop_fork。</p>

<p>Unfortunately, not all backends are embeddable: only the ones returned by ev_embeddable_backends are, which, unfortunately, does not include any portable one.<br />
不幸的时，不是所有的后台都可以被嵌入：只有ev_embeddable_backends返回的才可以，这很不幸，不能包括任意的。</p>

<p>So when you want to use this feature you will always have to be prepared that you cannot get an embeddable loop. The recommended way to get around this is to have a separate variables for your embeddable loop, try to create it, and if that fails, use the normal loop for everything.<br />
所以当你使用这个功能的时候你得有心理准备：你不能得到一个可以被嵌入的loop。解决这个问题推荐的方法是有一个变量来保存你的被嵌入的loop，试着创建它，如果失败，那么就使用默认的loop。</p>

<p>ev_embed and fork</p>

<p>While the ev_embed watcher is running, forks in the embedding loop will automatically be applied to the embedded loop as well, so no special fork handling is required in that case. When the watcher is not running, however, it is still the task of the libev user to call ev_loop_fork () as applicable.<br />
当ev_embed watcher运行的时候，在被嵌入的loop中forks将会自动的被很好的应用在被嵌入的loop中，所以在这种情况下，不需要特殊的fork来处理。当watcher不在运行的时候，不管怎么样，它仍然是libev用户的任务来调用ev_loop_fork（）。</p>

<h4 id="watcher-specific-functions-and-data-members-3">Watcher-Specific Functions and Data Members</h4>

<h5 id="ev_embed_init-ev_embed--callback-struct-ev_loop-embedded_loop">ev_embed_init (ev_embed *, callback, struct ev_loop *embedded_loop)</h5>
<h5 id="ev_embed_set-ev_embed--struct-ev_loop-embedded_loop">ev_embed_set (ev_embed *, struct ev_loop *embedded_loop)</h5>
<p>Configures the watcher to embed the given loop, which must be embeddable. If the callback is 0, then ev_embed_sweep will be invoked automatically, otherwise it is the responsibility of the callback to invoke it (it will continue to be called until the sweep has been done, if you do not want that, you need to temporarily stop the embed watcher).<br />
配置watcher来嵌入到给定的loop，loop必须是被嵌入的。如果回调是0，那么ev_embed_sweep将会自动调用，否则调用的它的责任将是回调的（它将仍然被调用知道扫描被完成，如果你不想这样，你需要暂停被嵌入watcher）。</p>

<h5 id="ev_embed_sweep-loop-ev_embed-">ev_embed_sweep (loop, ev_embed *)</h5>
<p>Make a single, non-blocking sweep over the embedded loop. This works similarly to ev_run (embedded_loop, EVRUN_NOWAIT), but in the most appropriate way for embedded loops.<br />
在被嵌入的loop上做一个单一的，非阻塞的扫描。这个工作类似于ev_run（evbedded_loop，EVRUN_NOWAIT），但是是被嵌入loop最合适的方法。</p>

<h5 id="struct-ev_loop-other-read-only">struct ev_loop *other [read-only]</h5>
<p>The embedded event loop.</p>

<p>Example: Try to get an embeddable event loop and embed it into the default event loop. If that is not possible, use the default loop. The default loop is stored in loop_hi, while the embeddable loop is stored in loop_lo (which is loop_hi in the case no embeddable loop can be used).<br />
例子：试着得到一个被嵌入的event loop，并且嵌入它到默认的loop。如果这是不可能的，那就使用默认的loop。默认的loop被保存在loop_hi，而可以嵌入的loop保存在loop_lo（也就是loop_hi在没有嵌入的循环可以使用的情况下）。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>struct ev_loop *loop_hi = ev_default_init (0);
struct ev_loop *loop_lo = 0;
ev_embed embed;

// see if there is a chance of getting one that works
//看看是否有可以得到工作的机会
// (remember that a flags value of 0 means autodetection)
//记住0表示自动检测
loop_lo = ev_embeddable_backends () &amp; ev_recommended_backends ()
? ev_loop_new (ev_embeddable_backends () &amp; ev_recommended_backends ())
: 0;

// if we got one, then embed it, otherwise default to loop_hi
//如果得到一个，就嵌入它，否则就使用默认的。
if (loop_lo)
{
    ev_embed_init (&amp;embed, 0, loop_lo);
    ev_embed_start (loop_hi, &amp;embed);
}
else
loop_lo = loop_hi;
</code></pre>
</div>

<p>Example: Check if kqueue is available but not recommended and create a kqueue backend for use with sockets (which usually work with any kqueue implementation). Store the kqueue/socket-only event loop in loop_socket. (One might optionally use EVFLAG_NOENV, too).<br />
例子：检查kqueue是否可用，但是不建议创建一个kqueue后台来给socket使用（这通常适用于任何kqueue实现）。保存kqueue/socket-only event loop在loop——socket中。（也有人可能会选择使用EVFLAG_NOENV）。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>struct ev_loop *loop = ev_default_init (0);
struct ev_loop *loop_socket = 0;
ev_embed embed;

if (ev_supported_backends () &amp; ~ev_recommended_backends () &amp; EVBACKEND_KQUEUE)
    if ((loop_socket = ev_loop_new (EVBACKEND_KQUEUE))
    {
        ev_embed_init (&amp;embed, 0, loop_socket);
        ev_embed_start (loop, &amp;embed);
    }

if (!loop_socket)
    loop_socket = loop;

// now use loop_socket for all sockets, and loop for everything else
</code></pre>
</div>

<h3 id="ev_fork---the-audacity-to-resume-the-event-loop-after-a-fork-ev_fork-在fork之后强制恢复event-loop">ev_fork - the audacity to resume the event loop after a fork ev_fork 在fork之后强制恢复event loop</h3>

<p>Fork watchers are called when a fork () was detected (usually because whoever is a good citizen cared to tell libev about it by calling ev_loop_fork). The invocation is done before the event loop blocks next and before ev_check watchers are being called, and only in the child after the fork. If whoever good citizen calling ev_default_fork cheats and calls it in the wrong process, the fork handlers will be invoked, too, of course.<br />
当fork函数被检测到时，fork watcher被调用（通常因为不会在意是那个成员告诉了libev：它调用了ev_loop_fork）。这个调用将在下一次的event loop阻塞之前和ev_check watcher被调用之前，并且只在fork之后的子进程中被调用。不管那个成员在错误的进程中调用ev_default_fork欺骗和调用它，fork处理事件当然也会被调用。</p>

<p>The special problem of life after fork - how is it possible?<br />
fork之后生命周期特殊的问题-有哪些可能？</p>

<p>Most uses of fork () consist of forking, then some simple calls to set up/change the process environment, followed by a call to exec(). This sequence should be handled by libev without any problems.<br />
大多数使用fork来创建新进程，然后简单的调用一些设置或者改变进程环境，比如接着调用exec函数。这一序列将毫无疑问的被libev处理。</p>

<p>This changes when the application actually wants to do event handling in the child, or both parent in child, in effect “continuing” after the fork.<br />
这会在应用程序实际上想在子进程或者父子进程中执行事件处理函数的时候改变，实际上是在fork之后继续。</p>

<p>The default mode of operation (for libev, with application help to detect forks) is to duplicate all the state in the child, as would be expected when either the parent or the child process continues.<br />
缺省的操作模式（对于libev来说，应用程序期望检测到forks）是在子进程中复制所有的状态，不管是对于父进程还是子进程来说，都是希望能一如既往。</p>

<p>When both processes want to continue using libev, then this is usually the wrong result. In that case, usually one process (typically the parent) is supposed to continue with all watchers in place as before, while the other process typically wants to start fresh, i.e. without any active watchers.<br />
当父子进程都希望继续使用libev，那么这通常都是错误的。在这种情况下，通常一个进程（通常是父进程）还是会和以前一样带着所有的watchers继续执行，同时，另外一个进程执行新的libev，即没有任何活跃的watchers。</p>

<p>The cleanest and most efficient way to achieve that with libev is to simply create a new event loop, which of course will be “empty”, and use that for new watchers. This has the advantage of not touching more memory than necessary, and thus avoiding the copy-on-write, and the disadvantage of having to use multiple event loops (which do not support signal watchers).<br />
最简洁和最高效的实现方式是使用libev创建一个新的event loop，新的event loop当然就是”空“的了，并且用新的event loop监听新的watchers。这避免了很多的无必要的内存接触，从而避免了内存的写时复制，并且避免了使用多个event loop的缺点（多个event loop不能对信号watchers提供支持）。</p>

<p>When this is not possible, or you want to use the default loop for other reasons, then in the process that wants to start “fresh”, call ev_loop_destroy (EV_DEFAULT) followed by ev_default_loop (…). Destroying the default loop will “orphan” (not stop) all registered watchers, so you have to be careful not to execute code that modifies those watchers. Note also that in that case, you have to re-register any signal watchers.<br />
当这是不可能或者你想要为了别的原因使用默认的loop，比如在进程中以“新鲜”开始，那额在ev_default_loop()之后调用ev_loop_destry。释放默认的loop将“孤立”（而不是停止）所有已注册的watchers，所以你必须小心不要执行源码更改别的watchers。也要注意，在这种情况下，你必须重新注册所有的signal watchers。</p>

<h4 id="watcher-specific-functions-and-data-members-4">Watcher-Specific Functions and Data Members</h4>

<h5 id="ev_fork_init-ev_fork--callback">ev_fork_init (ev_fork *, callback)</h5>
<p>Initialises and configures the fork watcher - it has no parameters of any kind. There is a ev_fork_set macro, but using it is utterly pointless, really.<br />
初始化和配置fork watcher-它没有任何类型的参数。这就是一个ev_fork_set宏，但是使用它是毫无意义的，真的。</p>

<h3 id="ev_cleanup---even-the-best-things-end-ev_cleanup-在即使最好的东西也结束的时候">ev_cleanup - even the best things end ev_cleanup-在即使最好的东西也结束的时候</h3>

<p>Cleanup watchers are called just before the event loop is being destroyed by a call to ev_loop_destroy.<br />
cleanup watchers将只会在event loop被ev_loop_destroy函数destroy之前被调用。</p>

<p>While there is no guarantee that the event loop gets destroyed, cleanup watchers provide a convenient method to install cleanup hooks for your program, worker threads and so on - you just to make sure to destroy the loop when you want them to be invoked.<br />
虽然这不能保证event loop被销毁，清理watchers的所有钩子程序，执行线程等等-你只要确认当你想他们被调用的时候销毁loop。</p>

<p>Cleanup watchers are invoked in the same way as any other watcher. Unlike all other watchers, they do not keep a reference to the event loop (which makes a lot of sense if you think about it). Like all other watchers, you can call libev functions in the callback, except ev_cleanup_start.<br />
cleanup wathers和别的watchers使用同样的方法被调用。但是不想另外所有的watchers，他们不会维持和event loop的引用（比如你思考这个问题，它会有很多的意义）。和别的所有的watchers一样，你可以在回调函数中调用libev函数，除了ev_cleanup_start函数之外。</p>

<h4 id="watcher-specific-functions-and-data-members-5">Watcher-Specific Functions and Data Members</h4>

<h5 id="ev_cleanup_init-ev_cleanup--callback">ev_cleanup_init (ev_cleanup *, callback)</h5>
<p>Initialises and configures the cleanup watcher - it has no parameters of any kind. There is a ev_cleanup_set macro, but using it is utterly pointless, I assure you.<br />
初始化和配置cleanup watcher-他没有任何类型的参数。这就是一个ev_cleanup_set宏，但是使用它没有意义，我向你保证。</p>

<p>Example: Register an atexit handler to destroy the default loop, so any cleanup functions are called. <br />
示例：注册一个atexit处理事件来释放默认的loop，所以任何清理函数被调用。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>static void
program_exits (void)
{
    ev_loop_destroy (EV_DEFAULT_UC);
}

...
atexit (program_exits);
</code></pre>
</div>

<h3 id="ev_async---how-to-wake-up-an-event-loop-ev_async--怎么唤醒一个event-loop">ev_async - how to wake up an event loop ev_async -怎么唤醒一个event loop</h3>

<p>In general, you cannot use an ev_loop from multiple threads or other asynchronous sources such as signal handlers (as opposed to multiple event loops - those are of course safe to use in different threads).<br />
一般情况下，你不能在多线程或者另外的比如类似于信号事件的异步来源中使用一个ev_loop（在不同的线程中使用不同的event loop，这当然是线程安全的）。</p>

<p>Sometimes, however, you need to wake up an event loop you do not control, for example because it belongs to another thread. This is what ev_async watchers do: as long as the ev_async watcher is active, you can signal it by calling ev_async_send, which is thread- and signal safe.<br />
有的时候，不管怎么样，你需要唤醒一个你不能控制的event loop，例如这个event loop属于另外一个线程。这就是ev_sync watcher所能做的：只要ev_async watcher是可用的，你就可以通过调用ev_async_end来唤醒它，并且这是线程和信号安全的。</p>

<p>This functionality is very similar to ev_signal watchers, as signals, too, are asynchronous in nature, and signals, too, will be compressed (i.e. the number of callback invocations may be less than the number of ev_async_send calls). In fact, you could use signal watchers as a kind of “global async watchers” by using a watcher on an otherwise unused signal, and ev_feed_signal to signal this watcher from another thread, even without knowing which loop owns the signal.<br />
当处理信号的时候，这个功能非常类似于ev_signal watchers，也有非同步的性质，也会被压缩（即：调用回调的次数可能会少于调用ev_async_send的次数）。事实上，你可以通过在另外一个没有使用的信号上使用一个watcher，来使该signal watcher作为一种全局的异步watchers，然后在另外一个线程中调用ev_feed_signal来唤醒它，即使你不知道哪个looo拥有这个信号。</p>

<h5 id="queueing">Queueing</h5>

<p>ev_async does not support queueing of data in any way. The reason is that the author does not know of a simple (or any) algorithm for a multiple-writer-single-reader queue that works in all cases and doesn’t need elaborate support such as pthreads or unportable memory access semantics.<br />
ev_async没有提供任何方式的队列。原因就是作者不知道适应任何情况下的，一个简单的算法来实现多写单读的队列，并且也不需要复杂的提供例如pthread或者不可移植的访问内存语义。</p>

<p>That means that if you want to queue data, you have to provide your own queue. But at least I can tell you how to implement locking around your queue:<br />
这就意味着，如果你想排列你的数据，你必须提供你自己的队列。但是至少，我可以告诉你怎么实现你的队列锁。</p>

<p>queueing from a signal handler context<br />
排列一个信号处理事件上下文<br />
To implement race-free queueing, you simply add to the queue in the signal handler but you block the signal handler in the watcher callback. Here is an example that does that for some fictitious SIGUSR1 handler:<br />
实现一个自由队列，在信号处理函数中加入到队列，在watcher callback中阻塞你的程序，这是一个例子：对SIGUSR1处理函数排队。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>static ev_async mysig;

static void
sigusr1_handler (void)
{
    sometype data;

    // no locking etc.
    queue_put (data);
    ev_async_send (EV_DEFAULT_ &amp;mysig);
}

static void
mysig_cb (EV_P_ ev_async *w, int revents)
{
    sometype data;
    sigset_t block, prev;

    sigemptyset (&amp;block);
    sigaddset (&amp;block, SIGUSR1);
    sigprocmask (SIG_BLOCK, &amp;block, &amp;prev);

    while (queue_get (&amp;data))
    process (data);

    if (sigismember (&amp;prev, SIGUSR1)
    sigprocmask (SIG_UNBLOCK, &amp;block, 0);
}
</code></pre>
</div>

<p>(Note: pthreads in theory requires you to use pthread_setmask instead of sigprocmask when you use threads, but libev doesn’t do it either…).<br />
（注意：理论上，当你使用pthreads时，pthread需要使用pthread_setmask来代替sigprocmask，但是libev需要这样做，所以。。。。）。</p>

<p>queueing from a thread context<br />
一个线程上下文中排序<br />
The strategy for threads is different, as you cannot (easily) block threads but you can easily preempt them, so to queue safely you need to employ a traditional mutex lock, such as in this pthread example:<br />
对于线程，方法是不一样的，因为你不能（轻易）的阻塞线程，但是你可以轻易的抢占他们，所以你需要一个传统的mutex锁，以便排队数据，就像在这个示例一样。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>static ev_async mysig;
static pthread_mutex_t mymutex = PTHREAD_MUTEX_INITIALIZER;

static void
otherthread (void)
{
    // only need to lock the actual queueing operation
    pthread_mutex_lock (&amp;mymutex);
    queue_put (data);
    pthread_mutex_unlock (&amp;mymutex);

    ev_async_send (EV_DEFAULT_ &amp;mysig);
}

static void
mysig_cb (EV_P_ ev_async *w, int revents)
{
    pthread_mutex_lock (&amp;mymutex);

    while (queue_get (&amp;data))
    process (data);

    pthread_mutex_unlock (&amp;mymutex);
}
</code></pre>
</div>

<h4 id="watcher-specific-functions-and-data-members-6">Watcher-Specific Functions and Data Members</h4>

<h5 id="ev_async_init-ev_async--callback">ev_async_init (ev_async *, callback)</h5>
<p>Initialises and configures the async watcher - it has no parameters of any kind. There is a ev_async_set macro, but using it is utterly pointless, trust me.<br />
初始化和配置async watcher-它没有任何类型的参数。其实就是一个ev_asynv_set宏，但是使用这个宏是没有意义的，相信我。</p>

<h5 id="ev_async_send-loop-ev_async-">ev_async_send (loop, ev_async *)</h5>
<p>Sends/signals/activates the given ev_async watcher, that is, feeds an EV_ASYNC event on the watcher into the event loop, and instantly returns.<br />
发送/触发/激活给定的ev_async watcher。即发送一个EV_ASYNC事件到event loop中的watcher，然后立即返回。</p>

<p>Unlike ev_feed_event, this call is safe to do from other threads, signal or similar contexts (see the discussion of EV_ATOMIC_T in the embedding section below on what exactly this means).<br />
不像ev_feed_event，从另外的线程中，信号或者类似的环境中调用这个函数是线程安全的（请查阅下面的EV_ATOMIC_T的嵌入部分）。</p>

<p>Note that, as with other watchers in libev, multiple events might get compressed into a single callback invocation (another way to look at this is that ev_async watchers are level-triggered: they are set on ev_async_send, reset when the event loop detects that).<br />
注意：和另外的libev中的watcher一样，多个事件可能会被合并成到一个回调中调用（理解这个问题的另外一种是把ev_async看成是水平触发的（PS：结合epoll，kqueue这种理解）：他们在ev_async_send时被触发，并且在event loop检测时被复位）。</p>

<p>This call incurs the overhead of at most one extra system call per event loop iteration, if the event loop is blocked, and no syscall at all if the event loop (or your program) is processing events. That means that repeated calls are basically free (there is no need to avoid calls for performance reasons) and that the overhead becomes smaller (typically zero) under load.<br />
这个函数调用最多在每次event loop迭代中在开始引起一个额外的系统调用，如果event loop是被阻塞的，而且如果event loop（或者你的程序）根本没有系统调用处理事件。这意味着重复调用基本上不消耗资源（没有必要为了性能原因限制调用）并且负债开销也会变小（通常为0）。</p>

<h5 id="bool--ev_async_pending-ev_async-">bool = ev_async_pending (ev_async *)</h5>
<p>Returns a non-zero value when ev_async_send has been called on the watcher but the event has not yet been processed (or even noted) by the event loop.<br />
返回非0值意味着给定watcher的ev_async_send被调用，但是事件并没有被event loop处理完成。</p>

<p>ev_async_send sets a flag in the watcher and wakes up the loop. When the loop iterates next and checks for the watcher to have become active, it will reset the flag again. ev_async_pending can be used to very quickly check whether invoking the loop might be a good idea.<br />
ev_async_send在watcher上设置一个标志并且唤醒loop。当下一次loop迭代并且检查watcher使其变成活跃时，他将会再一次重置他的状态。ev_async_pending可以被当作一个好的方法用来快速的检查是否调用loop。</p>

<p>Not that this does not check whether the watcher itself is pending, only whether it has been requested to make this watcher pending: there is a time window between the event loop checking and resetting the async notification, and the callback being invoked.<br />
不是说这不能检查watcher本身是否被挂起，只是检查他是否被请求使这个watcher挂起：这是一个在event loop检查并且重置async通知和回调函数被调用之间的时间窗口，</p>

<h2 id="other-functions">OTHER FUNCTIONS</h2>

<p>There are some other functions of possible interest. Described. Here. Now.<br />
这里是一些你可能感兴趣的另外一个功能。</p>

<h3 id="ev_once-loop-int-fd-int-events-ev_tstamp-timeout-callback">ev_once (loop, int fd, int events, ev_tstamp timeout, callback)</h3>
<p>This function combines a simple timer and an I/O watcher, calls your callback on whichever event happens first and automatically stops both watchers. This is useful if you want to wait for a single event on an fd or timeout without having to allocate/configure/start/stop/free one or more watchers yourself.<br />
这个函数合并了一个简单的timer watcher和一个IO watcher，哪个watcher先发生，就会自动停止两个watcher，并且调用你的回调函数。这对于你想在一个fd上等到一个IO事件或者超时事件而不用必须自己申请/配置/开始/停止/释放watcher是非常有用的，</p>

<p>If fd is less than 0, then no I/O watcher will be started and the events argument is being ignored. Otherwise, an ev_io watcher for the given fd and events set will be created and started.<br />
如果fd小于0，那么将没有IO watcher被启动，并且这个参数将会被忽略。否则对于给定的fd将创建和启动ev_io watcher。</p>

<p>If timeout is less than 0, then no timeout watcher will be started. Otherwise an ev_timer watcher with after = timeout (and repeat = 0) will be started. 0 is a valid timeout.<br />
如果timeout小于0，那么没有超时watcher将被启动。否则一个after＝timeout（和repeat ＝ 0）的ev_timer watcher将被启动。0是一个有效的超时。</p>

<p>The callback has the type void (<em>cb)(int revents, void *arg) and is passed an revents set like normal event callbacks (a combination of EV_ERROR, EV_READ, EV_WRITE or EV_TIMER) and the arg value passed to ev_once. Note that it is possible to receive both a timeout and an io event at the same time - you probably should give io events precedence.<br />
回调函数的类型是void (</em>cb)(int revents, void *arg)，并且通过设置一个正确的revents（一个EV_ERROR，EV_READ，EV_WRITE或者EV_TIMER的组合），并且参数arg的值也会传递给ev）once。注意：可能会同时收到超时和IO event-你或许应该给io事件一个高优先级。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>Example: wait up to ten seconds for data to appear on STDIN_FILENO.

static void stdin_ready (int revents, void *arg)
{
    if (revents &amp; EV_READ)
    /* stdin might have data for us, joy! */;
    else if (revents &amp; EV_TIMER)
    /* doh, nothing entered */;
}

ev_once (STDIN_FILENO, EV_READ, 10., stdin_ready, 0);
</code></pre>
</div>

<h3 id="ev_feed_fd_event-loop-int-fd-int-revents">ev_feed_fd_event (loop, int fd, int revents)</h3>
<p>Feed an event on the given fd, as if a file descriptor backend detected the given events.<br />
向给定的fd发送一个事件，就好像文件描述符后台检测到事件一样。</p>

<h3 id="ev_feed_signal_event-loop-int-signum">ev_feed_signal_event (loop, int signum)</h3>
<p>Feed an event as if the given signal occurred. See also ev_feed_signal, which is async-safe.<br />
发送一个给定的信号。请查阅ev_feed_signal，这是异步安全的。</p>

<h2 id="common-or-useful-idioms-or-both常见或者是习惯用法">COMMON OR USEFUL IDIOMS (OR BOTH)常见或者是习惯用法</h2>

<p>This section explains some common idioms that are not immediately obvious. Note that examples are sprinkled over the whole manual, and this section only contains stuff that wouldn’t fit anywhere else.<br />
本节解释一些不常见的用法。注意：示例对于整个手册来说，本节只包含一些方法，但是不是任何地方都适用。</p>

<h3 id="associating-custom-data-with-a-watcher-watcher的自定义数据">ASSOCIATING CUSTOM DATA WITH A WATCHER watcher的自定义数据</h3>

<p>Each watcher has, by default, a void *data member that you can read or modify at any time: libev will completely ignore it. This can be used to associate arbitrary data with your watcher. If you need more data and don’t want to allocate memory separately and store a pointer to it in that data member, you can also “subclass” the watcher type and provide your own data:<br />
每个watcher默认都有一个void *data成员，你可以在任何时候都读写这个成员：libev会完全忽略它。这可用于将任意数据与观察者相关联。如果您需要更多的数据，不希望单独分配内存和存储指向它的数据成员，也可以“继承”的watcher类型，并提供自己的数据：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>struct my_io
{
    ev_io io;
    int otherfd;
    void *somedata;
    struct whatever *mostinteresting;
};

...
struct my_io w;
ev_io_init (&amp;w.io, my_cb, fd, EV_READ);
</code></pre>
</div>

<p>And since your callback will be called with a pointer to the watcher, you can cast it back to your own type:<br />
当你的回调被使用一个watcher指针调用时，你可以把它转换回你自己的类型。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>static void my_cb (struct ev_loop *loop, ev_io *w_, int revents)
{
    struct my_io *w = (struct my_io *)w_;
    ...
}
</code></pre>
</div>

<p>More interesting and less C-conformant ways of casting your callback function type instead have been omitted.<br />
构造你回调函数类型的更有趣和更小的c一致性方法，而不是忽略它。</p>

<h3 id="building-your-own-composite-watchers-构造你自己的watchers组合">BUILDING YOUR OWN COMPOSITE WATCHERS 构造你自己的watchers组合</h3>

<p>Another common scenario is to use some data structure with multiple embedded watchers, in effect creating your own watcher that combines multiple libev event sources into one “super-watcher”:<br />
另外一个常用的方法是使用多个嵌入式的watcher来构成数据结构，实际上就是创建你自己的watcher，它结合了很多libev事件源来组成一个“超级watcher”。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>struct my_biggy
{
    int some_data;
    ev_timer t1;
    ev_timer t2;
}
</code></pre>
</div>

<p>In this case getting the pointer to my_biggy is a bit more complicated: Either you store the address of your my_biggy struct in the data member of the watcher (for woozies or C++ coders), or you need to use some pointer arithmetic using offsetof inside your watchers (for real programmers):<br />
这种情况下获取my_biggy的指针是比较麻烦的：一种方法就是在my_biggy的数据成员中保存一个指向my_biggy的地址，另外一个方法就是通过使用offsetof来计算my_biggy的地址（这是真正的程序员做的）。</p>

<div class="highlighter-rouge"><pre class="highlight"><code>#include &lt;stddef.h&gt;

static void
t1_cb (EV_P_ ev_timer *w, int revents)
{
    struct my_biggy big = (struct my_biggy *)
    (((char *)w) - offsetof (struct my_biggy, t1));
}

static void
t2_cb (EV_P_ ev_timer *w, int revents)
{
    struct my_biggy big = (struct my_biggy *)
    (((char *)w) - offsetof (struct my_biggy, t2));
}
</code></pre>
</div>

<h3 id="avoiding-finishing-before-returning-在返回之前避免结束">AVOIDING FINISHING BEFORE RETURNING 在返回之前避免结束</h3>

<p>Often you have structures like this in event-based programs:<br />
通常在基于事件的程序中，你有这样的结构：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>callback ()
{
    free (request);
}

request = start_new_request (..., callback);
</code></pre>
</div>

<p>The intent is to start some “lengthy” operation. The request could be used to cancel the operation, or do other things with it.<br />
这样做的目的是启动一些“冗长”的操作。这个请求可以用来取消操作，或者做另外的事情。</p>

<p>It’s not uncommon to have code paths in start_new_request that immediately invoke the callback, for example, to report errors. Or you add some caching layer that finds that it can skip the lengthy aspects of the operation and simply invoke the callback with the result.
在start_new_request中有代码路径立即调用callback，这种情况并不少见。或者你增加一些缓存层来找到它可以跳过冗长的操作面，并且在结果中简单的调用callback。</p>

<p>The problem here is that this will happen before start_new_request has returned, so request is not set.<br />
这里的问题是：这将会在start_ne_request返回之前发生，所以请求没有被设置。</p>

<p>Even if you pass the request by some safer means to the callback, you might want to do something to the request after starting it, such as canceling it, which probably isn’t working so well when the callback has already been invoked.<br />
即使你安全的传递访问给callback函数，你也想要在启动请求后给它做一些设置，比如取消它，当callback已经被调用额时候，这就可能不能很好的工作了。</p>

<p>A common way around all these issues is to make sure that start_new_request always returns before the callback is invoked. If start_new_request immediately knows the result, it can artificially delay invoking the callback by using a prepare or idle watcher for example, or more sneakily, by reusing an existing (stopped) watcher and pushing it into the pending queue:<br />
围绕这些问题的常用方法是确保start_new_request总是返回的回调函数被调用之前。如果start_new_request立即知道结果，可以人为地通过prepare或者idle watcher来延迟调用回调，例如，以上悄悄，通过重新使用现有的（停止）watcher，将其推到未决队列：</p>

<h3 id="ev_set_cb-watcher-callback">ev_set_cb (watcher, callback);</h3>
<h3 id="ev_feed_event-ev_a_-watcher-0">ev_feed_event (EV_A_ watcher, 0);</h3>

<p>This way, start_new_request can safely return before the callback is invoked, while not delaying callback invocation too much.<br />
这种方法，start_new_request可以在callback被调用之前安全的返回。而不是拖延回调调用太多。</p>

<p>MODEL/NESTED EVENT LOOP INVOCATIONS AND EXIT CONDITIONS<br />
模型/嵌套的event loop调用和退出条件</p>

<p>Often (especially in GUI toolkits) there are places where you have modal interaction, which is most easily implemented by recursively invoking ev_run.<br />
通常（特别在GUI工具箱中），</p>

<hr />

<h1 id="以上的翻译已经足够libev使用了下面的翻译有时间再做了">以上的翻译已经足够libev使用了。下面的翻译有时间再做了！</h1>

<p>This brings the problem of exiting - a callback might want to finish the main ev_run call, but not the nested one (e.g. user clicked “Quit”, but a modal “Are you sure?” dialog is still waiting), or just the nested one and not the main one (e.g. user clocked “Ok” in a modal dialog), or some other combination: In these cases, a simple ev_break will not work.</p>

<p>The solution is to maintain “break this loop” variable for each ev_run invocation, and use a loop around ev_run until the condition is triggered, using EVRUN_ONCE:</p>

<p>// main loop
int exit_main_loop = 0;</p>

<p>while (!exit_main_loop)
ev_run (EV_DEFAULT_ EVRUN_ONCE);</p>

<p>// in a modal watcher
int exit_nested_loop = 0;</p>

<p>while (!exit_nested_loop)
ev_run (EV_A_ EVRUN_ONCE);</p>

<p>To exit from any of these loops, just set the corresponding exit variable:</p>

<p>// exit modal loop
exit_nested_loop = 1;</p>

<p>// exit main program, after modal loop is finished
exit_main_loop = 1;</p>

<p>// exit both
exit_main_loop = exit_nested_loop = 1;</p>

<p>THREAD LOCKING EXAMPLE</p>

<p>Here is a fictitious example of how to run an event loop in a different thread from where callbacks are being invoked and watchers are created/added/removed.</p>

<p>For a real-world example, see the EV::Loop::Async perl module, which uses exactly this technique (which is suited for many high-level languages).</p>

<p>The example uses a pthread mutex to protect the loop data, a condition variable to wait for callback invocations, an async watcher to notify the event loop thread and an unspecified mechanism to wake up the main thread.</p>

<p>First, you need to associate some data with the event loop:</p>

<p>typedef struct {
mutex_t lock; /* global loop lock */
ev_async async_w;
thread_t tid;
cond_t invoke_cv;
} userdata;</p>

<p>void prepare_loop (EV_P)
{
// for simplicity, we use a static userdata struct.
static userdata u;</p>

<p>ev_async_init (&amp;u-&gt;async_w, async_cb);
ev_async_start (EV_A_ &amp;u-&gt;async_w);</p>

<p>pthread_mutex_init (&amp;u-&gt;lock, 0);
pthread_cond_init (&amp;u-&gt;invoke_cv, 0);</p>

<p>// now associate this with the loop
ev_set_userdata (EV_A_ u);
ev_set_invoke_pending_cb (EV_A_ l_invoke);
ev_set_loop_release_cb (EV_A_ l_release, l_acquire);</p>

<p>// then create the thread running ev_run
pthread_create (&amp;u-&gt;tid, 0, l_run, EV_A);
}</p>

<p>The callback for the ev_async watcher does nothing: the watcher is used solely to wake up the event loop so it takes notice of any new watchers that might have been added:</p>

<p>static void
async_cb (EV_P_ ev_async *w, int revents)
{
// just used for the side effects
}</p>

<p>The l_release and l_acquire callbacks simply unlock/lock the mutex protecting the loop data, respectively.</p>

<p>static void
l_release (EV_P)
{
userdata *u = ev_userdata (EV_A);
pthread_mutex_unlock (&amp;u-&gt;lock);
}</p>

<p>static void
l_acquire (EV_P)
{
userdata *u = ev_userdata (EV_A);
pthread_mutex_lock (&amp;u-&gt;lock);
}</p>

<p>The event loop thread first acquires the mutex, and then jumps straight into ev_run:</p>

<p>void *
l_run (void *thr_arg)
{
struct ev_loop *loop = (struct ev_loop *)thr_arg;</p>

<p>l_acquire (EV_A);
pthread_setcanceltype (PTHREAD_CANCEL_ASYNCHRONOUS, 0);
ev_run (EV_A_ 0);
l_release (EV_A);</p>

<p>return 0;
}</p>

<p>Instead of invoking all pending watchers, the l_invoke callback will signal the main thread via some unspecified mechanism (signals? pipe writes? Async::Interrupt?) and then waits until all pending watchers have been called (in a while loop because a) spurious wakeups are possible and b) skipping inter-thread-communication when there are no pending watchers is very beneficial):</p>

<p>static void
l_invoke (EV_P)
{
userdata *u = ev_userdata (EV_A);</p>

<p>while (ev_pending_count (EV_A))
{
wake_up_other_thread_in_some_magic_or_not_so_magic_way ();
pthread_cond_wait (&amp;u-&gt;invoke_cv, &amp;u-&gt;lock);
}
}</p>

<p>Now, whenever the main thread gets told to invoke pending watchers, it will grab the lock, call ev_invoke_pending and then signal the loop thread to continue:</p>

<p>static void
real_invoke_pending (EV_P)
{
userdata *u = ev_userdata (EV_A);</p>

<p>pthread_mutex_lock (&amp;u-&gt;lock);
ev_invoke_pending (EV_A);
pthread_cond_signal (&amp;u-&gt;invoke_cv);
pthread_mutex_unlock (&amp;u-&gt;lock);
}</p>

<p>Whenever you want to start/stop a watcher or do other modifications to an event loop, you will now have to lock:</p>

<p>ev_timer timeout_watcher;
userdata *u = ev_userdata (EV_A);</p>

<p>ev_timer_init (&amp;timeout_watcher, timeout_cb, 5.5, 0.);</p>

<p>pthread_mutex_lock (&amp;u-&gt;lock);
ev_timer_start (EV_A_ &amp;timeout_watcher);
ev_async_send (EV_A_ &amp;u-&gt;async_w);
pthread_mutex_unlock (&amp;u-&gt;lock);</p>

<p>Note that sending the ev_async watcher is required because otherwise an event loop currently blocking in the kernel will have no knowledge about the newly added timer. By waking up the loop it will pick up any new watchers in the next event loop iteration.</p>

<p>THREADS, COROUTINES, CONTINUATIONS, QUEUES… INSTEAD OF CALLBACKS</p>

<p>While the overhead of a callback that e.g. schedules a thread is small, it is still an overhead. If you embed libev, and your main usage is with some kind of threads or coroutines, you might want to customise libev so that doesn’t need callbacks anymore.</p>

<p>Imagine you have coroutines that you can switch to using a function switch_to (coro), that libev runs in a coroutine called libev_coro and that due to some magic, the currently active coroutine is stored in a global called current_coro. Then you can build your own “wait for libev event” primitive by changing EV_CB_DECLARE and EV_CB_INVOKE (note the differing ; conventions):</p>

<p>#define EV_CB_DECLARE(type)   struct my_coro *cb;
#define EV_CB_INVOKE(watcher) switch_to ((watcher)-&gt;cb)</p>

<p>That means instead of having a C callback function, you store the coroutine to switch to in each watcher, and instead of having libev call your callback, you instead have it switch to that coroutine.</p>

<p>A coroutine might now wait for an event with a function called wait_for_event. (the watcher needs to be started, as always, but it doesn’t matter when, or whether the watcher is active or not when this function is called):</p>

<p>void
wait_for_event (ev_watcher *w)
{
ev_set_cb (w, current_coro);
switch_to (libev_coro);
}</p>

<p>That basically suspends the coroutine inside wait_for_event and continues the libev coroutine, which, when appropriate, switches back to this or any other coroutine.</p>

<p>You can do similar tricks if you have, say, threads with an event queue - instead of storing a coroutine, you store the queue object and instead of switching to a coroutine, you push the watcher onto the queue and notify any waiters.</p>

<p>To embed libev, see EMBEDDING, but in short, it’s easiest to create two files, my_ev.h and my_ev.c that include the respective libev files:</p>

<p>// my_ev.h
#define EV_CB_DECLARE(type)   struct my_coro *cb;
#define EV_CB_INVOKE(watcher) switch_to ((watcher)-&gt;cb);
#include “../libev/ev.h”</p>

<p>// my_ev.c
#define EV_H “my_ev.h”
#include “../libev/ev.c”</p>

<p>And then use my_ev.h when you would normally use ev.h, and compile my_ev.c into your project. When properly specifying include paths, you can even use ev.h as header file name directly.</p>

<p>LIBEVENT EMULATION</p>

<p>Libev offers a compatibility emulation layer for libevent. It cannot emulate the internals of libevent, so here are some usage hints:</p>

<ul>
  <li>
    <p>Only the libevent-1.4.1-beta API is being emulated.
  This was the newest libevent version available when libev was implemented, and is still mostly unchanged in 2010.</p>
  </li>
  <li>Use it by including <event.h>, as usual.</event.h></li>
  <li>The following members are fully supported: ev_base, ev_callback, ev_arg, ev_fd, ev_res, ev_events.</li>
  <li>Avoid using ev_flags and the EVLIST_*-macros, while it is maintained by libev, it does not work exactly the same way as in libevent (consider it a private API).</li>
  <li>Priorities are not currently supported. Initialising priorities will fail and all watchers will have the same priority, even though there is an ev_pri field.</li>
  <li>In libevent, the last base created gets the signals, in libev, the base that registered the signal gets the signals.</li>
  <li>Other members are not supported.</li>
  <li>
    <p>The libev emulation is not ABI compatible to libevent, you need to use the libev header file and library.
  C++ SUPPORT</p>

    <p>C API</p>

    <p>The normal C API should work fine when used from C++: both ev.h and the libev sources can be compiled as C++. Therefore, code that uses the C API will work fine.</p>

    <p>Proper exception specifications might have to be added to callbacks passed to libev: exceptions may be thrown only from watcher callbacks, all other callbacks (allocator, syserr, loop acquire/release and periodic reschedule callbacks) must not throw exceptions, and might need a throw () specification. If you have code that needs to be compiled as both C and C++ you can use the EV_THROW macro for this:</p>

    <p>static void
  fatal_error (const char *msg) EV_THROW
  {
  perror (msg);
  abort ();
  }</p>

    <p>…
  ev_set_syserr_cb (fatal_error);</p>

    <p>The only API functions that can currently throw exceptions are ev_run, ev_invoke, ev_invoke_pending and ev_loop_destroy (the latter because it runs cleanup watchers).</p>

    <p>Throwing exceptions in watcher callbacks is only supported if libev itself is compiled with a C++ compiler or your C and C++ environments allow throwing exceptions through C libraries (most do).</p>

    <p>C++ API</p>

    <p>Libev comes with some simplistic wrapper classes for C++ that mainly allow you to use some convenience methods to start/stop watchers and also change the callback model to a model using method callbacks on objects.</p>

    <p>To use it,</p>
  </li>
</ul>

<p>#include &lt;ev++.h&gt;</p>

<p>This automatically includes ev.h and puts all of its definitions (many of them macros) into the global namespace. All C++ specific things are put into the ev namespace. It should support all the same embedding options as ev.h, most notably EV_MULTIPLICITY.</p>

<p>Care has been taken to keep the overhead low. The only data member the C++ classes add (compared to plain C-style watchers) is the event loop pointer that the watcher is associated with (or no additional members at all if you disable EV_MULTIPLICITY when embedding libev).</p>

<p>Currently, functions, static and non-static member functions and classes with operator () can be used as callbacks. Other types should be easy to add as long as they only need one additional pointer for context. If you need support for other types of functors please contact the author (preferably after implementing it).</p>

<p>For all this to work, your C++ compiler either has to use the same calling conventions as your C compiler (for static member functions), or you have to embed libev and compile libev itself as C++.</p>

<p>Here is a list of things available in the ev namespace:</p>

<p>ev::READ, ev::WRITE etc.
These are just enum values with the same values as the EV_READ etc. macros from ev.h.</p>

<p>ev::tstamp, ev::now
Aliases to the same types/functions as with the ev_ prefix.</p>

<p>ev::io, ev::timer, ev::periodic, ev::idle, ev::sig etc.
For each ev_TYPE watcher in ev.h there is a corresponding class of the same name in the ev namespace, with the exception of ev_signal which is called ev::sig to avoid clashes with the signal macro defined by many implementations.</p>

<p>All of those classes have these methods:</p>

<p>ev::TYPE::TYPE ()
ev::TYPE::TYPE (loop)
ev::TYPE::~TYPE
The constructor (optionally) takes an event loop to associate the watcher with. If it is omitted, it will use EV_DEFAULT.</p>

<p>The constructor calls ev_init for you, which means you have to call the set method before starting it.</p>

<p>It will not set a callback, however: You have to call the templated set method to set a callback before you can start the watcher.</p>

<p>(The reason why you have to use a method is a limitation in C++ which does not allow explicit template arguments for constructors).</p>

<p>The destructor automatically stops the watcher if it is active.</p>

<p>w-&gt;set&lt;class, &amp;class::method&gt; (object <em>)
This method sets the callback method to call. The method has to have a signature of void (</em>)(ev_TYPE &amp;, int), it receives the watcher as first argument and the revents as second. The object must be given as parameter and is stored in the data member of the watcher.</p>

<p>This method synthesizes efficient thunking code to call your method from the C callback that libev requires. If your compiler can inline your callback (i.e. it is visible to it at the place of the set call and your compiler is good :), then the method will be fully inlined into the thunking function, making it as fast as a direct C callback.</p>

<p>Example: simple class declaration and watcher initialisation</p>

<p>struct myclass
{
void io_cb (ev::io &amp;w, int revents) { }
}</p>

<p>myclass obj;
ev::io iow;
iow.set &lt;myclass, &amp;myclass::io_cb&gt; (&amp;obj);</p>

<p>w-&gt;set (object *)
This is a variation of a method callback - leaving out the method to call will default the method to operator (), which makes it possible to use functor objects without having to manually specify the operator () all the time. Incidentally, you can then also leave out the template argument list.</p>

<p>The operator () method prototype must be void operator ()(watcher &amp;w, int revents).</p>

<p>See the method-set above for more details.</p>

<p>Example: use a functor object as callback.</p>

<p>struct myfunctor
{
void operator() (ev::io &amp;w, int revents)
{
…
}
}</p>

<p>myfunctor f;</p>

<p>ev::io w;
w.set (&amp;f);</p>

<p>w-&gt;set<function> (void *data = 0)
Also sets a callback, but uses a static method or plain function as callback. The optional data argument will be stored in the watcher's data member and is free for you to use.</function></p>

<p>The prototype of the function must be void (*)(ev::TYPE &amp;w, int).</p>

<p>See the method-set above for more details.</p>

<p>Example: Use a plain function as callback.</p>

<p>static void io_cb (ev::io &amp;w, int revents) { }
iow.set <io_cb> ();</io_cb></p>

<p>w-&gt;set (loop)
Associates a different struct ev_loop with this watcher. You can only do this when the watcher is inactive (and not pending either).</p>

<p>w-&gt;set ([arguments])
Basically the same as ev_TYPE_set (except for ev::embed watchers&gt;), with the same arguments. Either this method or a suitable start method must be called at least once. Unlike the C counterpart, an active watcher gets automatically stopped and restarted when reconfiguring it with this method.</p>

<p>For ev::embed watchers this method is called set_embed, to avoid clashing with the set (loop) method.</p>

<p>w-&gt;start ()
Starts the watcher. Note that there is no loop argument, as the constructor already stores the event loop.</p>

<p>w-&gt;start ([arguments])
Instead of calling set and start methods separately, it is often convenient to wrap them in one call. Uses the same type of arguments as the configure set method of the watcher.</p>

<p>w-&gt;stop ()
Stops the watcher if it is active. Again, no loop argument.</p>

<p>w-&gt;again () (ev::timer, ev::periodic only)
For ev::timer and ev::periodic, this invokes the corresponding ev_TYPE_again function.</p>

<p>w-&gt;sweep () (ev::embed only)
Invokes ev_embed_sweep.</p>

<p>w-&gt;update () (ev::stat only)
Invokes ev_stat_stat.</p>

<p>Example: Define a class with two I/O and idle watchers, start the I/O watchers in the constructor.</p>

<p>class myclass
{
ev::io   io  ; void io_cb   (ev::io   &amp;w, int revents);
ev::io   io2 ; void io2_cb  (ev::io   &amp;w, int revents);
ev::idle idle; void idle_cb (ev::idle &amp;w, int revents);</p>

<p>myclass (int fd)
{
io  .set &lt;myclass, &amp;myclass::io_cb  &gt; (this);
io2 .set &lt;myclass, &amp;myclass::io2_cb &gt; (this);
idle.set &lt;myclass, &amp;myclass::idle_cb&gt; (this);</p>

<p>io.set (fd, ev::WRITE); // configure the watcher
io.start ();            // start it whenever convenient</p>

<p>io2.start (fd, ev::READ); // set + start in one call
}
};</p>

<p>OTHER LANGUAGE BINDINGS</p>

<p>Libev does not offer other language bindings itself, but bindings for a number of languages exist in the form of third-party packages. If you know any interesting language binding in addition to the ones listed here, drop me a note.</p>

<p>Perl
The EV module implements the full libev API and is actually used to test libev. EV is developed together with libev. Apart from the EV core module, there are additional modules that implement libev-compatible interfaces to libadns (EV::ADNS, but AnyEvent::DNS is preferred nowadays), Net::SNMP (Net::SNMP::EV) and the libglib event core (Glib::EV and EV::Glib).</p>

<p>It can be found and installed via CPAN, its homepage is at http://software.schmorp.de/pkg/EV.</p>

<p>Python
Python bindings can be found at http://code.google.com/p/pyev/. It seems to be quite complete and well-documented.</p>

<p>Ruby
Tony Arcieri has written a ruby extension that offers access to a subset of the libev API and adds file handle abstractions, asynchronous DNS and more on top of it. It can be found via gem servers. Its homepage is at http://rev.rubyforge.org/.</p>

<p>Roger Pack reports that using the link order -lws2_32 -lmsvcrt-ruby-190 makes rev work even on mingw.</p>

<p>Haskell
A haskell binding to libev is available at http://hackage.haskell.org/cgi-bin/hackage-scripts/package/hlibev.</p>

<p>D
Leandro Lucarella has written a D language binding (ev.d) for libev, to be found at http://www.llucax.com.ar/proj/ev.d/index.html.</p>

<p>Ocaml
Erkki Seppala has written Ocaml bindings for libev, to be found at http://modeemi.cs.tut.fi/~flux/software/ocaml-ev/.</p>

<p>Lua
Brian Maher has written a partial interface to libev for lua (at the time of this writing, only ev_io and ev_timer), to be found at http://github.com/brimworks/lua-ev.</p>

<p>Javascript
Node.js (http://nodejs.org) uses libev as the underlying event library.</p>

<p>Others
There are others, and I stopped counting.</p>

<p>MACRO MAGIC</p>

<p>Libev can be compiled with a variety of options, the most fundamental of which is EV_MULTIPLICITY. This option determines whether (most) functions and callbacks have an initial struct ev_loop * argument.</p>

<p>To make it easier to write programs that cope with either variant, the following macros are defined:</p>

<p>EV_A, EV_A_
This provides the loop argument for functions, if one is required (“ev loop argument”). The EV_A form is used when this is the sole argument, EV_A_ is used when other arguments are following. Example:</p>

<p>ev_unref (EV_A);
ev_timer_add (EV_A_ watcher);
ev_run (EV_A_ 0);</p>

<p>It assumes the variable loop of type struct ev_loop * is in scope, which is often provided by the following macro.</p>

<p>EV_P, EV_P_
This provides the loop parameter for functions, if one is required (“ev loop parameter”). The EV_P form is used when this is the sole parameter, EV_P_ is used when other parameters are following. Example:</p>

<p>// this is how ev_unref is being declared
static void ev_unref (EV_P);</p>

<p>// this is how you can declare your typical callback
static void cb (EV_P_ ev_timer *w, int revents)</p>

<p>It declares a parameter loop of type struct ev_loop *, quite suitable for use with EV_A.</p>

<p>EV_DEFAULT, EV_DEFAULT_
Similar to the other two macros, this gives you the value of the default loop, if multiple loops are supported (“ev loop default”). The default loop will be initialised if it isn’t already initialised.</p>

<p>For non-multiplicity builds, these macros do nothing, so you always have to initialise the loop somewhere.</p>

<p>EV_DEFAULT_UC, EV_DEFAULT_UC_
Usage identical to EV_DEFAULT and EV_DEFAULT_, but requires that the default loop has been initialised (UC == unchecked). Their behaviour is undefined when the default loop has not been initialised by a previous execution of EV_DEFAULT, EV_DEFAULT_ or ev_default_init (…).</p>

<p>It is often prudent to use EV_DEFAULT when initialising the first watcher in a function but use EV_DEFAULT_UC afterwards.</p>

<p>Example: Declare and initialise a check watcher, utilising the above macros so it will work regardless of whether multiple loops are supported or not.</p>

<p>static void
check_cb (EV_P_ ev_timer *w, int revents)
{
ev_check_stop (EV_A_ w);
}</p>

<p>ev_check check;
ev_check_init (&amp;check, check_cb);
ev_check_start (EV_DEFAULT_ &amp;check);
ev_run (EV_DEFAULT_ 0);</p>

<p>EMBEDDING</p>

<p>Libev can (and often is) directly embedded into host applications. Examples of applications that embed it include the Deliantra Game Server, the EV perl module, the GNU Virtual Private Ethernet (gvpe) and rxvt-unicode.</p>

<p>The goal is to enable you to just copy the necessary files into your source directory without having to change even a single line in them, so you can easily upgrade by simply copying (or having a checked-out copy of libev somewhere in your source tree).</p>

<p>FILESETS</p>

<p>Depending on what features you need you need to include one or more sets of files in your application.</p>

<p>CORE EVENT LOOP</p>

<p>To include only the libev core (all the ev_* functions), with manual configuration (no autoconf):</p>

<p>#define EV_STANDALONE 1
#include “ev.c”</p>

<p>This will automatically include ev.h, too, and should be done in a single C source file only to provide the function implementations. To use it, do the same for ev.h in all files wishing to use this API (best done by writing a wrapper around ev.h that you can include instead and where you can put other configuration options):</p>

<p>#define EV_STANDALONE 1
#include “ev.h”</p>

<p>Both header files and implementation files can be compiled with a C++ compiler (at least, that’s a stated goal, and breakage will be treated as a bug).</p>

<p>You need the following files in your source tree, or in a directory in your include path (e.g. in libev/ when using -Ilibev):</p>

<p>ev.h
ev.c
ev_vars.h
ev_wrap.h</p>

<p>ev_win32.c      required on win32 platforms only</p>

<p>ev_select.c     only when select backend is enabled (which is enabled by default)
ev_poll.c       only when poll backend is enabled (disabled by default)
ev_epoll.c      only when the epoll backend is enabled (disabled by default)
ev_kqueue.c     only when the kqueue backend is enabled (disabled by default)
ev_port.c       only when the solaris port backend is enabled (disabled by default)</p>

<p>ev.c includes the backend files directly when enabled, so you only need to compile this single file.</p>

<p>LIBEVENT COMPATIBILITY API</p>

<p>To include the libevent compatibility API, also include:</p>

<p>#include “event.c”</p>

<p>in the file including ev.c, and:</p>

<p>#include “event.h”</p>

<p>in the files that want to use the libevent API. This also includes ev.h.</p>

<p>You need the following additional files for this:</p>

<p>event.h
event.c</p>

<p>AUTOCONF SUPPORT</p>

<p>Instead of using EV_STANDALONE=1 and providing your configuration in whatever way you want, you can also m4_include([libev.m4]) in your configure.ac and leave EV_STANDALONE undefined. ev.c will then include config.h and configure itself accordingly.</p>

<p>For this of course you need the m4 file:</p>

<p>libev.m4</p>

<p>PREPROCESSOR SYMBOLS/MACROS</p>

<p>Libev can be configured via a variety of preprocessor symbols you have to define before including (or compiling) any of its files. The default in the absence of autoconf is documented for every option.</p>

<p>Symbols marked with “(h)” do not change the ABI, and can have different values when compiling libev vs. including ev.h, so it is permissible to redefine them before including ev.h without breaking compatibility to a compiled library. All other symbols change the ABI, which means all users of libev and the libev code itself must be compiled with compatible settings.</p>

<p>EV_COMPAT3 (h)
Backwards compatibility is a major concern for libev. This is why this release of libev comes with wrappers for the functions and symbols that have been renamed between libev version 3 and 4.</p>

<p>You can disable these wrappers (to test compatibility with future versions) by defining EV_COMPAT3 to 0 when compiling your sources. This has the additional advantage that you can drop the struct from struct ev_loop declarations, as libev will provide an ev_loop typedef in that case.</p>

<p>In some future version, the default for EV_COMPAT3 will become 0, and in some even more future version the compatibility code will be removed completely.</p>

<p>EV_STANDALONE (h)
Must always be 1 if you do not use autoconf configuration, which keeps libev from including config.h, and it also defines dummy implementations for some libevent functions (such as logging, which is not supported). It will also not define any of the structs usually found in event.h that are not directly supported by the libev core alone.</p>

<p>In standalone mode, libev will still try to automatically deduce the configuration, but has to be more conservative.</p>

<p>EV_USE_FLOOR
If defined to be 1, libev will use the floor () function for its periodic reschedule calculations, otherwise libev will fall back on a portable (slower) implementation. If you enable this, you usually have to link against libm or something equivalent. Enabling this when the floor function is not available will fail, so the safe default is to not enable this.</p>

<p>EV_USE_MONOTONIC
If defined to be 1, libev will try to detect the availability of the monotonic clock option at both compile time and runtime. Otherwise no use of the monotonic clock option will be attempted. If you enable this, you usually have to link against librt or something similar. Enabling it when the functionality isn’t available is safe, though, although you have to make sure you link against any libraries where the clock_gettime function is hiding in (often -lrt). See also EV_USE_CLOCK_SYSCALL.</p>

<p>EV_USE_REALTIME
If defined to be 1, libev will try to detect the availability of the real-time clock option at compile time (and assume its availability at runtime if successful). Otherwise no use of the real-time clock option will be attempted. This effectively replaces gettimeofday by clock_get (CLOCK_REALTIME, …) and will not normally affect correctness. See the note about libraries in the description of EV_USE_MONOTONIC, though. Defaults to the opposite value of EV_USE_CLOCK_SYSCALL.</p>

<p>EV_USE_CLOCK_SYSCALL
If defined to be 1, libev will try to use a direct syscall instead of calling the system-provided clock_gettime function. This option exists because on GNU/Linux, clock_gettime is in librt, but librt unconditionally pulls in libpthread, slowing down single-threaded programs needlessly. Using a direct syscall is slightly slower (in theory), because no optimised vdso implementation can be used, but avoids the pthread dependency. Defaults to 1 on GNU/Linux with glibc 2.x or higher, as it simplifies linking (no need for -lrt).</p>

<p>EV_USE_NANOSLEEP
If defined to be 1, libev will assume that nanosleep () is available and will use it for delays. Otherwise it will use select ().</p>

<p>EV_USE_EVENTFD
If defined to be 1, then libev will assume that eventfd () is available and will probe for kernel support at runtime. This will improve ev_signal and ev_async performance and reduce resource consumption. If undefined, it will be enabled if the headers indicate GNU/Linux + Glibc 2.7 or newer, otherwise disabled.</p>

<p>EV_USE_SELECT
If undefined or defined to be 1, libev will compile in support for the select(2) backend. No attempt at auto-detection will be done: if no other method takes over, select will be it. Otherwise the select backend will not be compiled in.</p>

<p>EV_SELECT_USE_FD_SET
If defined to 1, then the select backend will use the system fd_set structure. This is useful if libev doesn’t compile due to a missing NFDBITS or fd_mask definition or it mis-guesses the bitset layout on exotic systems. This usually limits the range of file descriptors to some low limit such as 1024 or might have other limitations (winsocket only allows 64 sockets). The FD_SETSIZE macro, set before compilation, configures the maximum size of the fd_set.</p>

<p>EV_SELECT_IS_WINSOCKET
When defined to 1, the select backend will assume that select/socket/connect etc. don’t understand file descriptors but wants osf handles on win32 (this is the case when the select to be used is the winsock select). This means that it will call _get_osfhandle on the fd to convert it to an OS handle. Otherwise, it is assumed that all these functions actually work on fds, even on win32. Should not be defined on non-win32 platforms.</p>

<p>EV_FD_TO_WIN32_HANDLE(fd)
If EV_SELECT_IS_WINSOCKET is enabled, then libev needs a way to map file descriptors to socket handles. When not defining this symbol (the default), then libev will call _get_osfhandle, which is usually correct. In some cases, programs use their own file descriptor management, in which case they can provide this function to map fds to socket handles.</p>

<p>EV_WIN32_HANDLE_TO_FD(handle)
If EV_SELECT_IS_WINSOCKET then libev maps handles to file descriptors using the standard _open_osfhandle function. For programs implementing their own fd to handle mapping, overwriting this function makes it easier to do so. This can be done by defining this macro to an appropriate value.</p>

<p>EV_WIN32_CLOSE_FD(fd)
If programs implement their own fd to handle mapping on win32, then this macro can be used to override the close function, useful to unregister file descriptors again. Note that the replacement function has to close the underlying OS handle.</p>

<p>EV_USE_WSASOCKET
If defined to be 1, libev will use WSASocket to create its internal communication socket, which works better in some environments. Otherwise, the normal socket function will be used, which works better in other environments.</p>

<p>EV_USE_POLL
If defined to be 1, libev will compile in support for the poll(2) backend. Otherwise it will be enabled on non-win32 platforms. It takes precedence over select.</p>

<p>EV_USE_EPOLL
If defined to be 1, libev will compile in support for the Linux epoll(7) backend. Its availability will be detected at runtime, otherwise another method will be used as fallback. This is the preferred backend for GNU/Linux systems. If undefined, it will be enabled if the headers indicate GNU/Linux + Glibc 2.4 or newer, otherwise disabled.</p>

<p>EV_USE_KQUEUE
If defined to be 1, libev will compile in support for the BSD style kqueue(2) backend. Its actual availability will be detected at runtime, otherwise another method will be used as fallback. This is the preferred backend for BSD and BSD-like systems, although on most BSDs kqueue only supports some types of fds correctly (the only platform we found that supports ptys for example was NetBSD), so kqueue might be compiled in, but not be used unless explicitly requested. The best way to use it is to find out whether kqueue supports your type of fd properly and use an embedded kqueue loop.</p>

<p>EV_USE_PORT
If defined to be 1, libev will compile in support for the Solaris 10 port style backend. Its availability will be detected at runtime, otherwise another method will be used as fallback. This is the preferred backend for Solaris 10 systems.</p>

<p>EV_USE_DEVPOLL
Reserved for future expansion, works like the USE symbols above.</p>

<p>EV_USE_INOTIFY
If defined to be 1, libev will compile in support for the Linux inotify interface to speed up ev_stat watchers. Its actual availability will be detected at runtime. If undefined, it will be enabled if the headers indicate GNU/Linux + Glibc 2.4 or newer, otherwise disabled.</p>

<p>EV_NO_SMP
If defined to be 1, libev will assume that memory is always coherent between threads, that is, threads can be used, but threads never run on different cpus (or different cpu cores). This reduces dependencies and makes libev faster.</p>

<p>EV_NO_THREADS
If defined to be 1, libev will assume that it will never be called from different threads (that includes signal handlers), which is a stronger assumption than EV_NO_SMP, above. This reduces dependencies and makes libev faster.</p>

<p>EV_ATOMIC_T
Libev requires an integer type (suitable for storing 0 or 1) whose access is atomic with respect to other threads or signal contexts. No such type is easily found in the C language, so you can provide your own type that you know is safe for your purposes. It is used both for signal handler “locking” as well as for signal and thread safety in ev_async watchers.</p>

<p>In the absence of this define, libev will use sig_atomic_t volatile (from signal.h), which is usually good enough on most platforms.</p>

<p>EV_H (h)
The name of the ev.h header file used to include it. The default if undefined is “ev.h” in event.h, ev.c and ev++.h. This can be used to virtually rename the ev.h header file in case of conflicts.</p>

<p>EV_CONFIG_H (h)
If EV_STANDALONE isn’t 1, this variable can be used to override ev.c’s idea of where to find the config.h file, similarly to EV_H, above.</p>

<p>EV_EVENT_H (h)
Similarly to EV_H, this macro can be used to override event.c’s idea of how the event.h header can be found, the default is “event.h”.</p>

<p>EV_PROTOTYPES (h)
If defined to be 0, then ev.h will not define any function prototypes, but still define all the structs and other symbols. This is occasionally useful if you want to provide your own wrapper functions around libev functions.</p>

<p>EV_MULTIPLICITY
If undefined or defined to 1, then all event-loop-specific functions will have the struct ev_loop * as first argument, and you can create additional independent event loops. Otherwise there will be no support for multiple event loops and there is no first event loop pointer argument. Instead, all functions act on the single default loop.</p>

<p>Note that EV_DEFAULT and EV_DEFAULT_ will no longer provide a default loop when multiplicity is switched off - you always have to initialise the loop manually in this case.</p>

<p>EV_MINPRI
EV_MAXPRI
The range of allowed priorities. EV_MINPRI must be smaller or equal to EV_MAXPRI, but otherwise there are no non-obvious limitations. You can provide for more priorities by overriding those symbols (usually defined to be -2 and 2, respectively).</p>

<p>When doing priority-based operations, libev usually has to linearly search all the priorities, so having many of them (hundreds) uses a lot of space and time, so using the defaults of five priorities (-2 .. +2) is usually fine.</p>

<p>If your embedding application does not need any priorities, defining these both to 0 will save some memory and CPU.</p>

<p>EV_PERIODIC_ENABLE, EV_IDLE_ENABLE, EV_EMBED_ENABLE, EV_STAT_ENABLE, EV_PREPARE_ENABLE, EV_CHECK_ENABLE, EV_FORK_ENABLE, EV_SIGNAL_ENABLE, EV_ASYNC_ENABLE, EV_CHILD_ENABLE.
If undefined or defined to be 1 (and the platform supports it), then the respective watcher type is supported. If defined to be 0, then it is not. Disabling watcher types mainly saves code size.</p>

<p>EV_FEATURES
If you need to shave off some kilobytes of code at the expense of some speed (but with the full API), you can define this symbol to request certain subsets of functionality. The default is to enable all features that can be enabled on the platform.</p>

<p>A typical way to use this symbol is to define it to 0 (or to a bitset with some broad features you want) and then selectively re-enable additional parts you want, for example if you want everything minimal, but multiple event loop support, async and child watchers and the poll backend, use this:</p>

<p>#define EV_FEATURES 0
#define EV_MULTIPLICITY 1
#define EV_USE_POLL 1
#define EV_CHILD_ENABLE 1
#define EV_ASYNC_ENABLE 1</p>

<p>The actual value is a bitset, it can be a combination of the following values (by default, all of these are enabled):</p>

<p>1 - faster/larger code
Use larger code to speed up some operations.</p>

<p>Currently this is used to override some inlining decisions (enlarging the code size by roughly 30% on amd64).</p>

<p>When optimising for size, use of compiler flags such as -Os with gcc is recommended, as well as -DNDEBUG, as libev contains a number of assertions.</p>

<p>The default is off when <strong>OPTIMIZE_SIZE</strong> is defined by your compiler (e.g. gcc with -Os).</p>

<p>2 - faster/larger data structures
Replaces the small 2-heap for timer management by a faster 4-heap, larger hash table sizes and so on. This will usually further increase code size and can additionally have an effect on the size of data structures at runtime.</p>

<p>The default is off when <strong>OPTIMIZE_SIZE</strong> is defined by your compiler (e.g. gcc with -Os).</p>

<p>4 - full API configuration
This enables priorities (sets EV_MAXPRI=2 and EV_MINPRI=-2), and enables multiplicity (EV_MULTIPLICITY=1).</p>

<p>8 - full API
This enables a lot of the “lesser used” API functions. See ev.h for details on which parts of the API are still available without this feature, and do not complain if this subset changes over time.</p>

<p>16 - enable all optional watcher types
Enables all optional watcher types. If you want to selectively enable only some watcher types other than I/O and timers (e.g. prepare, embed, async, child…) you can enable them manually by defining EV_watchertype_ENABLE to 1 instead.</p>

<p>32 - enable all backends
This enables all backends - without this feature, you need to enable at least one backend manually (EV_USE_SELECT is a good choice).</p>

<p>64 - enable OS-specific “helper” APIs
Enable inotify, eventfd, signalfd and similar OS-specific helper APIs by default.</p>

<p>Compiling with gcc -Os -DEV_STANDALONE -DEV_USE_EPOLL=1 -DEV_FEATURES=0 reduces the compiled size of libev from 24.7Kb code/2.8Kb data to 6.5Kb code/0.3Kb data on my GNU/Linux amd64 system, while still giving you I/O watchers, timers and monotonic clock support.</p>

<p>With an intelligent-enough linker (gcc+binutils are intelligent enough when you use -Wl,–gc-sections -ffunction-sections) functions unused by your program might be left out as well - a binary starting a timer and an I/O watcher then might come out at only 5Kb.</p>

<p>EV_API_STATIC
If this symbol is defined (by default it is not), then all identifiers will have static linkage. This means that libev will not export any identifiers, and you cannot link against libev anymore. This can be useful when you embed libev, only want to use libev functions in a single file, and do not want its identifiers to be visible.</p>

<p>To use this, define EV_API_STATIC and include ev.c in the file that wants to use libev.</p>

<p>This option only works when libev is compiled with a C compiler, as C++ doesn’t support the required declaration syntax.</p>

<p>EV_AVOID_STDIO
If this is set to 1 at compiletime, then libev will avoid using stdio functions (printf, scanf, perror etc.). This will increase the code size somewhat, but if your program doesn’t otherwise depend on stdio and your libc allows it, this avoids linking in the stdio library which is quite big.</p>

<p>Note that error messages might become less precise when this option is enabled.</p>

<p>EV_NSIG
The highest supported signal number, +1 (or, the number of signals): Normally, libev tries to deduce the maximum number of signals automatically, but sometimes this fails, in which case it can be specified. Also, using a lower number than detected (32 should be good for about any system in existence) can save some memory, as libev statically allocates some 12-24 bytes per signal number.</p>

<p>EV_PID_HASHSIZE
ev_child watchers use a small hash table to distribute workload by pid. The default size is 16 (or 1 with EV_FEATURES disabled), usually more than enough. If you need to manage thousands of children you might want to increase this value (must be a power of two).</p>

<p>EV_INOTIFY_HASHSIZE
ev_stat watchers use a small hash table to distribute workload by inotify watch id. The default size is 16 (or 1 with EV_FEATURES disabled), usually more than enough. If you need to manage thousands of ev_stat watchers you might want to increase this value (must be a power of two).</p>

<p>EV_USE_4HEAP
Heaps are not very cache-efficient. To improve the cache-efficiency of the timer and periodics heaps, libev uses a 4-heap when this symbol is defined to 1. The 4-heap uses more complicated (longer) code but has noticeably faster performance with many (thousands) of watchers.</p>

<p>The default is 1, unless EV_FEATURES overrides it, in which case it will be 0.</p>

<p>EV_HEAP_CACHE_AT
Heaps are not very cache-efficient. To improve the cache-efficiency of the timer and periodics heaps, libev can cache the timestamp (at) within the heap structure (selected by defining EV_HEAP_CACHE_AT to 1), which uses 8-12 bytes more per watcher and a few hundred bytes more code, but avoids random read accesses on heap changes. This improves performance noticeably with many (hundreds) of watchers.</p>

<p>The default is 1, unless EV_FEATURES overrides it, in which case it will be 0.</p>

<p>EV_VERIFY
Controls how much internal verification (see ev_verify ()) will be done: If set to 0, no internal verification code will be compiled in. If set to 1, then verification code will be compiled in, but not called. If set to 2, then the internal verification code will be called once per loop, which can slow down libev. If set to 3, then the verification code will be called very frequently, which will slow down libev considerably.</p>

<p>The default is 1, unless EV_FEATURES overrides it, in which case it will be 0.</p>

<p>EV_COMMON
By default, all watchers have a void *data member. By redefining this macro to something else you can include more and other types of members. You have to define it each time you include one of the files, though, and it must be identical each time.</p>

<p>For example, the perl EV module uses something like this:</p>

<p>#define EV_COMMON                       \
SV <em>self; /</em> contains this struct <em>/  \
SV *cb_sv, *fh /</em> note no trailing “;” */</p>

<p>EV_CB_DECLARE (type)
EV_CB_INVOKE (watcher, revents)
ev_set_cb (ev, cb)
Can be used to change the callback member declaration in each watcher, and the way callbacks are invoked and set. Must expand to a struct member definition and a statement, respectively. See the ev.h header file for their default definitions. One possible use for overriding these is to avoid the struct ev_loop * as first argument in all cases, or to use method calls instead of plain function calls in C++.</p>

<p>EXPORTED API SYMBOLS</p>

<p>If you need to re-export the API (e.g. via a DLL) and you need a list of exported symbols, you can use the provided Symbol.* files which list all public symbols, one per line:</p>

<p>Symbols.ev      for libev proper
Symbols.event   for the libevent emulation</p>

<p>This can also be used to rename all public symbols to avoid clashes with multiple versions of libev linked together (which is obviously bad in itself, but sometimes it is inconvenient to avoid this).</p>

<p>A sed command like this will create wrapper #define’s that you need to include before including ev.h:</p>

<p>&lt;Symbols.ev sed -e “s/.*/#define &amp; myprefix_&amp;/” &gt;wrap.h</p>

<p>This would create a file wrap.h which essentially looks like this:</p>

<p>#define ev_backend     myprefix_ev_backend
#define ev_check_start myprefix_ev_check_start
#define ev_check_stop  myprefix_ev_check_stop
…</p>

<p>EXAMPLES</p>

<p>For a real-world example of a program the includes libev verbatim, you can have a look at the EV perl module (http://software.schmorp.de/pkg/EV.html). It has the libev files in the libev/ subdirectory and includes them in the EV/EVAPI.h (public interface) and EV.xs (implementation) files. Only the EV.xs file will be compiled. It is pretty complex because it provides its own header file.</p>

<p>The usage in rxvt-unicode is simpler. It has a ev_cpp.h header file that everybody includes and which overrides some configure choices:</p>

<p>#define EV_FEATURES 8
#define EV_USE_SELECT 1
#define EV_PREPARE_ENABLE 1
#define EV_IDLE_ENABLE 1
#define EV_SIGNAL_ENABLE 1
#define EV_CHILD_ENABLE 1
#define EV_USE_STDEXCEPT 0
#define EV_CONFIG_H <config.h></config.h></p>

<p>#include “ev++.h”</p>

<p>And a ev_cpp.C implementation file that contains libev proper and is compiled:</p>

<p>#include “ev_cpp.h”
#include “ev.c”</p>

<p>INTERACTION WITH OTHER PROGRAMS, LIBRARIES OR THE ENVIRONMENT</p>

<p>THREADS AND COROUTINES</p>

<p>THREADS</p>

<p>All libev functions are reentrant and thread-safe unless explicitly documented otherwise, but libev implements no locking itself. This means that you can use as many loops as you want in parallel, as long as there are no concurrent calls into any libev function with the same loop parameter (ev_default_* calls have an implicit default loop parameter, of course): libev guarantees that different event loops share no data structures that need any locking.</p>

<p>Or to put it differently: calls with different loop parameters can be done concurrently from multiple threads, calls with the same loop parameter must be done serially (but can be done from different threads, as long as only one thread ever is inside a call at any point in time, e.g. by using a mutex per loop).</p>

<p>Specifically to support threads (and signal handlers), libev implements so-called ev_async watchers, which allow some limited form of concurrency on the same event loop, namely waking it up “from the outside”.</p>

<p>If you want to know which design (one loop, locking, or multiple loops without or something else still) is best for your problem, then I cannot help you, but here is some generic advice:</p>

<ul>
  <li>
    <p>most applications have a main thread: use the default libev loop in that thread, or create a separate thread running only the default loop.
  This helps integrating other libraries or software modules that use libev themselves and don’t care/know about threading.</p>
  </li>
  <li>
    <p>one loop per thread is usually a good model.
  Doing this is almost never wrong, sometimes a better-performance model exists, but it is always a good start.</p>
  </li>
  <li>
    <p>other models exist, such as the leader/follower pattern, where one loop is handed through multiple threads in a kind of round-robin fashion.
  Choosing a model is hard - look around, learn, know that usually you can do better than you currently do :-)</p>
  </li>
  <li>
    <p>often you need to talk to some other thread which blocks in the event loop.
  ev_async watchers can be used to wake them up from other threads safely (or from signal contexts…).</p>

    <p>An example use would be to communicate signals or other events that only work in the default loop by registering the signal watcher with the default loop and triggering an ev_async watcher from the default loop watcher callback into the event loop interested in the signal.</p>

    <p>See also THREAD LOCKING EXAMPLE.</p>

    <p>COROUTINES</p>

    <p>Libev is very accommodating to coroutines (“cooperative threads”): libev fully supports nesting calls to its functions from different coroutines (e.g. you can call ev_run on the same loop from two different coroutines, and switch freely between both coroutines running the loop, as long as you don’t confuse yourself). The only exception is that you must not do this from ev_periodic reschedule callbacks.</p>

    <p>Care has been taken to ensure that libev does not keep local state inside ev_run, and other calls do not usually allow for coroutine switches as they do not call any callbacks.</p>

    <p>COMPILER WARNINGS</p>

    <p>Depending on your compiler and compiler settings, you might get no or a lot of warnings when compiling libev code. Some people are apparently scared by this.</p>

    <p>However, these are unavoidable for many reasons. For one, each compiler has different warnings, and each user has different tastes regarding warning options. “Warn-free” code therefore cannot be a goal except when targeting a specific compiler and compiler-version.</p>

    <p>Another reason is that some compiler warnings require elaborate workarounds, or other changes to the code that make it less clear and less maintainable.</p>

    <p>And of course, some compiler warnings are just plain stupid, or simply wrong (because they don’t actually warn about the condition their message seems to warn about). For example, certain older gcc versions had some warnings that resulted in an extreme number of false positives. These have been fixed, but some people still insist on making code warn-free with such buggy versions.</p>

    <p>While libev is written to generate as few warnings as possible, “warn-free” code is not a goal, and it is recommended not to build libev with any compiler warnings enabled unless you are prepared to cope with them (e.g. by ignoring them). Remember that warnings are just that: warnings, not errors, or proof of bugs.</p>

    <p>VALGRIND</p>

    <p>Valgrind has a special section here because it is a popular tool that is highly useful. Unfortunately, valgrind reports are very hard to interpret.</p>

    <p>If you think you found a bug (memory leak, uninitialised data access etc.) in libev, then check twice: If valgrind reports something like:</p>

    <p>==2274==    definitely lost: 0 bytes in 0 blocks.
  ==2274==      possibly lost: 0 bytes in 0 blocks.
  ==2274==    still reachable: 256 bytes in 1 blocks.</p>

    <p>Then there is no memory leak, just as memory accounted to global variables is not a memleak - the memory is still being referenced, and didn’t leak.</p>

    <p>Similarly, under some circumstances, valgrind might report kernel bugs as if it were a bug in libev (e.g. in realloc or in the poll backend, although an acceptable workaround has been found here), or it might be confused.</p>

    <p>Keep in mind that valgrind is a very good tool, but only a tool. Don’t make it into some kind of religion.</p>

    <p>If you are unsure about something, feel free to contact the mailing list with the full valgrind report and an explanation on why you think this is a bug in libev (best check the archives, too :). However, don’t be annoyed when you get a brisk “this is no bug” answer and take the chance of learning how to interpret valgrind properly.</p>

    <p>If you need, for some reason, empty reports from valgrind for your project I suggest using suppression lists.</p>

    <p>PORTABILITY NOTES</p>

    <p>GNU/LINUX 32 BIT LIMITATIONS</p>

    <p>GNU/Linux is the only common platform that supports 64 bit file/large file interfaces but disables them by default.</p>

    <p>That means that libev compiled in the default environment doesn’t support files larger than 2GiB or so, which mainly affects ev_stat watchers.</p>

    <p>Unfortunately, many programs try to work around this GNU/Linux issue by enabling the large file API, which makes them incompatible with the standard libev compiled for their system.</p>

    <p>Likewise, libev cannot enable the large file API itself as this would suddenly make it incompatible to the default compile time environment, i.e. all programs not using special compile switches.</p>

    <p>OS/X AND DARWIN BUGS</p>

    <p>The whole thing is a bug if you ask me - basically any system interface you touch is broken, whether it is locales, poll, kqueue or even the OpenGL drivers.</p>

    <p>kqueue is buggy</p>

    <p>The kqueue syscall is broken in all known versions - most versions support only sockets, many support pipes.</p>

    <p>Libev tries to work around this by not using kqueue by default on this rotten platform, but of course you can still ask for it when creating a loop - embedding a socket-only kqueue loop into a select-based one is probably going to work well.</p>

    <p>poll is buggy</p>

    <p>Instead of fixing kqueue, Apple replaced their (working) poll implementation by something calling kqueue internally around the 10.5.6 release, so now kqueue and poll are broken.</p>

    <p>Libev tries to work around this by not using poll by default on this rotten platform, but of course you can still ask for it when creating a loop.</p>

    <p>select is buggy</p>

    <p>All that’s left is select, and of course Apple found a way to fuck this one up as well: On OS/X, select actively limits the number of file descriptors you can pass in to 1024 - your program suddenly crashes when you use more.</p>

    <p>There is an undocumented “workaround” for this - defining _DARWIN_UNLIMITED_SELECT, which libev tries to use, so select should work on OS/X.</p>

    <p>SOLARIS PROBLEMS AND WORKAROUNDS</p>

    <p>errno reentrancy</p>

    <p>The default compile environment on Solaris is unfortunately so thread-unsafe that you can’t even use components/libraries compiled without -D_REENTRANT in a threaded program, which, of course, isn’t defined by default. A valid, if stupid, implementation choice.</p>

    <p>If you want to use libev in threaded environments you have to make sure it’s compiled with _REENTRANT defined.</p>

    <p>Event port backend</p>

    <p>The scalable event interface for Solaris is called “event ports”. Unfortunately, this mechanism is very buggy in all major releases. If you run into high CPU usage, your program freezes or you get a large number of spurious wakeups, make sure you have all the relevant and latest kernel patches applied. No, I don’t know which ones, but there are multiple ones to apply, and afterwards, event ports actually work great.</p>

    <p>If you can’t get it to work, you can try running the program by setting the environment variable LIBEV_FLAGS=3 to only allow poll and select backends.</p>

    <p>AIX POLL BUG</p>

    <p>AIX unfortunately has a broken poll.h header. Libev works around this by trying to avoid the poll backend altogether (i.e. it’s not even compiled in), which normally isn’t a big problem as select works fine with large bitsets on AIX, and AIX is dead anyway.</p>

    <p>WIN32 PLATFORM LIMITATIONS AND WORKAROUNDS</p>

    <p>General issues</p>

    <p>Win32 doesn’t support any of the standards (e.g. POSIX) that libev requires, and its I/O model is fundamentally incompatible with the POSIX model. Libev still offers limited functionality on this platform in the form of the EVBACKEND_SELECT backend, and only supports socket descriptors. This only applies when using Win32 natively, not when using e.g. cygwin. Actually, it only applies to the microsofts own compilers, as every compiler comes with a slightly differently broken/incompatible environment.</p>

    <p>Lifting these limitations would basically require the full re-implementation of the I/O system. If you are into this kind of thing, then note that glib does exactly that for you in a very portable way (note also that glib is the slowest event library known to man).</p>

    <p>There is no supported compilation method available on windows except embedding it into other applications.</p>

    <p>Sensible signal handling is officially unsupported by Microsoft - libev tries its best, but under most conditions, signals will simply not work.</p>

    <p>Not a libev limitation but worth mentioning: windows apparently doesn’t accept large writes: instead of resulting in a partial write, windows will either accept everything or return ENOBUFS if the buffer is too large, so make sure you only write small amounts into your sockets (less than a megabyte seems safe, but this apparently depends on the amount of memory available).</p>

    <p>Due to the many, low, and arbitrary limits on the win32 platform and the abysmal performance of winsockets, using a large number of sockets is not recommended (and not reasonable). If your program needs to use more than a hundred or so sockets, then likely it needs to use a totally different implementation for windows, as libev offers the POSIX readiness notification model, which cannot be implemented efficiently on windows (due to Microsoft monopoly games).</p>

    <p>A typical way to use libev under windows is to embed it (see the embedding section for details) and use the following evwrap.h header file instead of ev.h:</p>
  </li>
</ul>

<p>#define EV_STANDALONE              /* keeps ev from requiring config.h <em>/
#define EV_SELECT_IS_WINSOCKET 1   /</em> configure libev for windows select */</p>

<p>#include “ev.h”</p>

<p>And compile the following evwrap.c file into your project (make sure you do not compile the ev.c or any other embedded source files!):</p>

<p>#include “evwrap.h”
#include “ev.c”</p>

<p>The winsocket select function</p>

<p>The winsocket select function doesn’t follow POSIX in that it requires socket handles and not socket file descriptors (it is also extremely buggy). This makes select very inefficient, and also requires a mapping from file descriptors to socket handles (the Microsoft C runtime provides the function _open_osfhandle for this). See the discussion of the EV_SELECT_USE_FD_SET, EV_SELECT_IS_WINSOCKET and EV_FD_TO_WIN32_HANDLE preprocessor symbols for more info.</p>

<p>The configuration for a “naked” win32 using the Microsoft runtime libraries and raw winsocket select is:</p>

<p>#define EV_USE_SELECT 1
#define EV_SELECT_IS_WINSOCKET 1   /* forces EV_SELECT_USE_FD_SET, too */</p>

<p>Note that winsockets handling of fd sets is O(n), so you can easily get a complexity in the O(n²) range when using win32.</p>

<p>Limited number of file descriptors</p>

<p>Windows has numerous arbitrary (and low) limits on things.</p>

<p>Early versions of winsocket’s select only supported waiting for a maximum of 64 handles (probably owning to the fact that all windows kernels can only wait for 64 things at the same time internally; Microsoft recommends spawning a chain of threads and wait for 63 handles and the previous thread in each. Sounds great!).</p>

<p>Newer versions support more handles, but you need to define FD_SETSIZE to some high number (e.g. 2048) before compiling the winsocket select call (which might be in libev or elsewhere, for example, perl and many other interpreters do their own select emulation on windows).</p>

<p>Another limit is the number of file descriptors in the Microsoft runtime libraries, which by default is 64 (there must be a hidden 64 fetish or something like this inside Microsoft). You can increase this by calling _setmaxstdio, which can increase this limit to 2048 (another arbitrary limit), but is broken in many versions of the Microsoft runtime libraries. This might get you to about 512 or 2048 sockets (depending on windows version and/or the phase of the moon). To get more, you need to wrap all I/O functions and provide your own fd management, but the cost of calling select (O(n²)) will likely make this unworkable.</p>

<p>PORTABILITY REQUIREMENTS</p>

<p>In addition to a working ISO-C implementation and of course the backend-specific APIs, libev relies on a few additional extensions:</p>

<p>void (*)(ev_watcher_type *, int revents) must have compatible calling conventions regardless of ev_watcher_type *.
Libev assumes not only that all watcher pointers have the same internal structure (guaranteed by POSIX but not by ISO C for example), but it also assumes that the same (machine) code can be used to call any watcher callback: The watcher callbacks have different type signatures, but libev calls them using an ev_watcher * internally.</p>

<p>pointer accesses must be thread-atomic
Accessing a pointer value must be atomic, it must both be readable and writable in one piece - this is the case on all current architectures.</p>

<p>sig_atomic_t volatile must be thread-atomic as well
The type sig_atomic_t volatile (or whatever is defined as EV_ATOMIC_T) must be atomic with respect to accesses from different threads. This is not part of the specification for sig_atomic_t, but is believed to be sufficiently portable.</p>

<p>sigprocmask must work in a threaded environment
Libev uses sigprocmask to temporarily block signals. This is not allowed in a threaded program (pthread_sigmask has to be used). Typical pthread implementations will either allow sigprocmask in the “main thread” or will block signals process-wide, both behaviours would be compatible with libev. Interaction between sigprocmask and pthread_sigmask could complicate things, however.</p>

<p>The most portable way to handle signals is to block signals in all threads except the initial one, and run the signal handling loop in the initial thread as well.</p>

<p>long must be large enough for common memory allocation sizes
To improve portability and simplify its API, libev uses long internally instead of size_t when allocating its data structures. On non-POSIX systems (Microsoft…) this might be unexpectedly low, but is still at least 31 bits everywhere, which is enough for hundreds of millions of watchers.</p>

<p>double must hold a time value in seconds with enough accuracy
The type double is used to represent timestamps. It is required to have at least 51 bits of mantissa (and 9 bits of exponent), which is good enough for at least into the year 4000 with millisecond accuracy (the design goal for libev). This requirement is overfulfilled by implementations using IEEE 754, which is basically all existing ones.</p>

<p>With IEEE 754 doubles, you get microsecond accuracy until at least the year 2255 (and millisecond accuracy till the year 287396 - by then, libev is either obsolete or somebody patched it to use long double or something like that, just kidding).</p>

<p>If you know of other additional requirements drop me a note.</p>

<p>ALGORITHMIC COMPLEXITIES</p>

<p>In this section the complexities of (many of) the algorithms used inside libev will be documented. For complexity discussions about backends see the documentation for ev_default_init.</p>

<p>All of the following are about amortised time: If an array needs to be extended, libev needs to realloc and move the whole array, but this happens asymptotically rarer with higher number of elements, so O(1) might mean that libev does a lengthy realloc operation in rare cases, but on average it is much faster and asymptotically approaches constant time.</p>

<p>Starting and stopping timer/periodic watchers: O(log skipped_other_timers)
This means that, when you have a watcher that triggers in one hour and there are 100 watchers that would trigger before that, then inserting will have to skip roughly seven (ld 100) of these watchers.</p>

<p>Changing timer/periodic watchers (by autorepeat or calling again): O(log skipped_other_timers)
That means that changing a timer costs less than removing/adding them, as only the relative motion in the event queue has to be paid for.</p>

<p>Starting io/check/prepare/idle/signal/child/fork/async watchers: O(1)
These just add the watcher into an array or at the head of a list.</p>

<p>Stopping check/prepare/idle/fork/async watchers: O(1)
Stopping an io/signal/child watcher: O(number_of_watchers_for_this_(fd/signal/pid % EV_PID_HASHSIZE))
These watchers are stored in lists, so they need to be walked to find the correct watcher to remove. The lists are usually short (you don’t usually have many watchers waiting for the same fd or signal: one is typical, two is rare).</p>

<p>Finding the next timer in each loop iteration: O(1)
By virtue of using a binary or 4-heap, the next timer is always found at a fixed position in the storage array.</p>

<p>Each change on a file descriptor per loop iteration: O(number_of_watchers_for_this_fd)
A change means an I/O watcher gets started or stopped, which requires libev to recalculate its status (and possibly tell the kernel, depending on backend and whether ev_io_set was used).</p>

<p>Activating one watcher (putting it into the pending state): O(1)
Priority handling: O(number_of_priorities)
Priorities are implemented by allocating some space for each priority. When doing priority-based operations, libev usually has to linearly search all the priorities, but starting/stopping and activating watchers becomes O(1) with respect to priority handling.</p>

<p>Sending an ev_async: O(1)
Processing ev_async_send: O(number_of_async_watchers)
Processing signals: O(max_signal_number)
Sending involves a system call iff there were no other ev_async_send calls in the current loop iteration and the loop is currently blocked. Checking for async and signal events involves iterating over all running async watchers or all signal numbers.</p>

<p>PORTING FROM LIBEV 3.X TO 4.X</p>

<p>The major version 4 introduced some incompatible changes to the API.</p>

<p>At the moment, the ev.h header file provides compatibility definitions for all changes, so most programs should still compile. The compatibility layer might be removed in later versions of libev, so better update to the new API early than late.</p>

<p>EV_COMPAT3 backwards compatibility mechanism
The backward compatibility mechanism can be controlled by EV_COMPAT3. See “PREPROCESSOR SYMBOLS/MACROS” in the EMBEDDING section.</p>

<p>ev_default_destroy and ev_default_fork have been removed
These calls can be replaced easily by their ev_loop_xxx counterparts:</p>

<p>ev_loop_destroy (EV_DEFAULT_UC);
ev_loop_fork (EV_DEFAULT);</p>

<p>function/symbol renames
A number of functions and symbols have been renamed:</p>

<p>ev_loop         =&gt; ev_run
EVLOOP_NONBLOCK =&gt; EVRUN_NOWAIT
EVLOOP_ONESHOT  =&gt; EVRUN_ONCE</p>

<p>ev_unloop       =&gt; ev_break
EVUNLOOP_CANCEL =&gt; EVBREAK_CANCEL
EVUNLOOP_ONE    =&gt; EVBREAK_ONE
EVUNLOOP_ALL    =&gt; EVBREAK_ALL</p>

<p>EV_TIMEOUT      =&gt; EV_TIMER</p>

<p>ev_loop_count   =&gt; ev_iteration
ev_loop_depth   =&gt; ev_depth
ev_loop_verify  =&gt; ev_verify</p>

<p>Most functions working on struct ev_loop objects don’t have an ev_loop_ prefix, so it was removed; ev_loop, ev_unloop and associated constants have been renamed to not collide with the struct ev_loop anymore and EV_TIMER now follows the same naming scheme as all other watcher types. Note that ev_loop_fork is still called ev_loop_fork because it would otherwise clash with the ev_fork typedef.</p>

<p>EV_MINIMAL mechanism replaced by EV_FEATURES
The preprocessor symbol EV_MINIMAL has been replaced by a different mechanism, EV_FEATURES. Programs using EV_MINIMAL usually compile and work, but the library code will of course be larger.</p>

<p>GLOSSARY</p>

<p>active
A watcher is active as long as it has been started and not yet stopped. See WATCHER STATES for details.</p>

<p>application
In this document, an application is whatever is using libev.</p>

<p>backend
The part of the code dealing with the operating system interfaces.</p>

<p>callback
The address of a function that is called when some event has been detected. Callbacks are being passed the event loop, the watcher that received the event, and the actual event bitset.</p>

<p>callback/watcher invocation
The act of calling the callback associated with a watcher.</p>

<p>event
A change of state of some external event, such as data now being available for reading on a file descriptor, time having passed or simply not having any other events happening anymore.</p>

<p>In libev, events are represented as single bits (such as EV_READ or EV_TIMER).</p>

<p>event library
A software package implementing an event model and loop.</p>

<p>event loop
An entity that handles and processes external events and converts them into callback invocations.</p>

<p>event model
The model used to describe how an event loop handles and processes watchers and events.</p>

<p>pending
A watcher is pending as soon as the corresponding event has been detected. See WATCHER STATES for details.</p>

<p>real time
The physical time that is observed. It is apparently strictly monotonic :)</p>

<p>wall-clock time
The time and date as shown on clocks. Unlike real time, it can actually be wrong and jump forwards and backwards, e.g. when you adjust your clock.</p>

<p>watcher
A data structure that describes interest in certain events. Watchers need to be started (attached to an event loop) before they can receive events.</p>

<p>AUTHOR</p>

<p>Marc Lehmann <a href="mailto:libev@schmorp.de">libev@schmorp.de</a>, with repeated corrections by Mikael Magnusson and Emanuele Giaquinta, and minor corrections by many others.</p>


                    ]]>
                </content:encoded>
                <guid isPermaLink="false">/blog/2017/libev-manual-zh-cn/</guid>
                <description>
                    
                </description>
                <pubDate>Mon, 29 May 2017 00:00:00 +0800</pubDate>
                <author>94geek.com by Seapeak.Xu</author>
            </item>
        
    
        
            <item>
                <title>我认为更好的管理github pages blog</title>
                <link>http://www.94geek.com/blog/2017/mgr-blog/</link>
                <content:encoded>
                    <![CDATA[
                    <p>使用jekyll也有好几年了，说实话其实jekyll + markdown的方式真的没有cnblogs等这种专门的平台来的方便。至少纯粹从写blog的角度出发，在目前的互联网用户体验大环境下，冷静思考这种方式，真的挺差。</p>

<p>以前，在改blog风格之前，因为没有使用jekyll的plugins，所以我还是启用了github pages服务的jekyll服务。但是这次因为图片管理的这个plugin，已经不能再启用github pages的jekyll服务了（因为github禁止第三方的plugins），所以只能启用直接嵌入静态文件的方式来执行。那么问题就来了，整个站点的site是目录和站点的原信息目录，到底怎么解决它们之间的问题？</p>

<hr />

<h3 id="更多的做法">更多的做法</h3>

<p>我也搜了一下，更多的做法是这样的：</p>
<ol>
  <li>在github上开一个project作为pages服务的project；</li>
  <li>在这个project上开启一个分支gh-pages，因为这是github默认的blog服务分支；</li>
  <li>当你写blog的时候，checkout到master分支，然后开始写，写完后build；</li>
  <li>checkout到gh-pages分支，将master中的site目录合并到当前分支；</li>
  <li>commit gh-pages分支，再commit master分支；</li>
  <li>结束</li>
</ol>

<p>这也是一种办法，但是对于我来说受不了的是：一个目录中文件有冲突。一个文件夹存在了多个功能，区分这些功能的办法竟然是我们使用git的分支来达到目的。虽然这样也可以，但并不能有效的去解决一个问题，或者说我一直要check一个问题：就是我当前到底在哪个分支下？显然，对于有神经质的我来说，这种办法明显不切实际。</p>

<hr />

<h3 id="我喜欢的办法">我喜欢的办法</h3>

<ol>
  <li>一个目录就一个用处，多个功能我宁愿开多个目录；</li>
  <li>不要把功能都合并到一起，显然这样在日常维护中很难执行，能分即分开；</li>
  <li>做事的流程要分开，比如我写blog的时候，我就只要照顾到写blog就可以了，当我准备发布的时候，我只要照顾到发布就可以了。两者之间不要切换来切换去；</li>
  <li>自动化，比如发布，最好是一个脚本直接搞定；</li>
</ol>

<p>所以我重新设计了一种办法：</p>
<ol>
  <li>将上面的一个文件夹管理一个blog的方式直接换成2个文件夹，一个只管source的源信息目录，一个管理静态站点，也就是元信息build后生成的site的文件夹；</li>
  <li>因为blog本质上变成了2个文件夹，所以github上也直接申请两个project，一一对应；</li>
  <li>调试blog可以在source中进行，source中完成后，cp其中的site目录到我们的静态站点目录；</li>
  <li>直接commit两个project到github即可；</li>
</ol>

<p>所以有了这样的一个流程脚本：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>cd 94geek #切换到静态站点proejct
git checkout gh-pages #确保目前在gh-pages分支，github只支持这个分支
cd ../source/ #切换到源目录
rm -rf  _site #删除上一次的site目录
jekyll build #编译当前的source
cp -rf _site/* ../94geek/  #cp当前次生成的site到静态project
git add ./ #加入更新的blog
git status #查看一下当前的状态对不对
git commit -am"upload log" #提交，这里信息被写死了，其实你可以使用参数来指定
git push #同步到github
cd ../94geek #切换到静态project
git add ./ #加入新增的blog静态文件
git status #查看当前静态project的状态
git commit -am"update blog" #提交
git push #同步
</code></pre>
</div>

<p>将这个文件放入静态project和source同等级目录下，每次写完blog后只要简单的执行这个脚本即可。</p>

<hr />

<h3 id="总结">总结</h3>

<p>这种方式有几个好处：</p>
<ol>
  <li>清晰：目录和功能各司其职；</li>
  <li>简单：写blog和发布没有任何的确认，其实只要管理好source就可以了，别的都是自动执行；</li>
  <li>统一：写blog和发布blog不混乱，各管各的，不需要分心来处理；</li>
</ol>


                    ]]>
                </content:encoded>
                <guid isPermaLink="false">/blog/2017/mgr-blog/</guid>
                <description>
                    
                </description>
                <pubDate>Sun, 28 May 2017 00:00:00 +0800</pubDate>
                <author>94geek.com by Seapeak.Xu</author>
            </item>
        
    
        
            <item>
                <title>jekyll图片管理插件</title>
                <link>http://www.94geek.com/blog/2017/blog-image/</link>
                <content:encoded>
                    <![CDATA[
                    <p>使用jekyll搭建github的pages服务已经很多年了，虽然写的blog不是特别多，但在使用的过程中难免还是遇到了很多的问题。在所有这些问题中，几乎所有的问题都被解决了。但有且只有一个问题几乎无解：图片管理。使用jekyll的程序员几乎都搭配markdown，但是markdown对于图片的管理，简直就是可以用一坨屎来形容。</p>

<h3 id="以前问题">以前问题</h3>

<hr />

<p>通常在markdown中，引用图片都是使用标记来进行。但是引用的图片路径往往是一个问题。优先了jekyll，那么本地的编辑器可能就无法显示和预览；优先了本地预览，那么markdown上传到jekyll后路径是一个问题。</p>

<p>那么我们最常用的就是这种办法：因为markdown引用图片最常用的就是http形式的地址引用。所以前提就是你必须先有一个稳定的图床，然后上传图片，获取地址，再把地址贴入markdown中。这种方式我受不了的地方在于中间插入图片或者修改图片多次的话，往往需要长时间的停下来先弄图片，再写markdown，整个思路会受到很多的影响。有时候弄完图片已经没心情再写东西了。</p>

<p>那么有没有一种办法来解决这个问题呢？</p>

<p>首先我们想到了一种办法，把图片直接放到某个文件夹里面，上传到github，但是这样的做法还是会在本地编辑器和jekyll中满足一个。另外一个办法，就是把图片和markdown放在同一个文件夹，这样就没有路径问题了，直接用文件名就可以引用图片。但是这种办法满足了编辑器，在jekyll build的时候，jekyll对于_post目录下的文件只处理markdown文件，不会处理别的文件。看上去这条路也不通了。</p>

<p>那么到底有没有别的办法呢？</p>

<h3 id="我的解决方案">我的解决方案</h3>

<hr />

<p>其实能想到的方案上面都已经全部想到了，但是不管怎么去解决，在jekyll和本地编辑器中往往只能满足一个，两个能同时兼顾的就没有。但是对比上面的几种方案，最靠谱的貌似还是最后一种** markdown和图片同目录 ** 但是在同目录jekyll又不管，幸好jekyll提供了插件功能。</p>

<p>jekyll的插件有很多种，具体的请查看 <a href="http://jekyllcn.com/docs/plugins/">jekyll插件科普</a></p>

<p>回到我们的问题，我们的问题其实已经很清楚了，就是在jekyll解析markdown到html的同时，将同目录的静态文件全部cp到生成的html的目录。这样markdown文件生成的html和静态资源文件又在一个目录下了，这样就可以避免目录的问题了。</p>

<p>在这些插件的hooks中，我们选择了 :posts :post_write 这个hooks，因为这个hooks是在markdown已经被解析，并且被写入磁盘以后发生的。这个时间点正好就是我们想要的这个时间点。那么我们现在就是只要实现这个hooks就可以了。所以就有了下面的代码：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>Jekyll::Hooks.register :posts, :post_write do |doc|
# Minify HTML files after site build
#  gulp = File.join(site.source, 'node_modules', '.bin', 'gulp')
#  system "#{gulp} minifyHTML --silent"
#
#Kernel.puts "11111111111111111111"
#Kernel.puts doc.path

pn = Pathname.new(doc.path)
basedir  = pn.dirname 
dest_path =File.join(doc.site.config["destination"] , doc.url)
Dir.foreach(basedir) {|x| 
    if !(x.start_with?("."))
        if !(x.end_with?("md") || x.end_with?("markdown"))
            stmp = File.join(basedir,x)
            dtmp = File.join(dest_path,x)
            Kernel.puts stmp
            Kernel.puts dtmp
            FileUtils.cp(stmp,dtmp)
            Kernel.puts "copy static file from #{stmp} to #{dtmp}"
        end
    end
}

end
</code></pre>
</div>

<p>将这个文件保存到_plugins目录下，随便给一个文件名即可。再次运行jekyll server就可以看到这个hooks被执行了。</p>

<p>具体:</p>
<ol>
  <li>项目源码: <a href="https://github.com/xvhfeng/jekyll-markdown-image">github project</a><br />
2 如何使用：<a href="https://github.com/xvhfeng/blog-source">blog源码</a></li>
</ol>

<h3 id="缺点">缺点</h3>

<hr />

<p>这个解决方案并不是万能的，它也有自己的缺点。目前使用下来，缺点有几个：</p>
<ol>
  <li>只支持markdown和静态文件同目录的情况；</li>
  <li>对于jekyll的permalink的配置一定要正确，千奇百怪的配置不一定可用，我的配置是/blog/:year/:title/，注意，最后那个目录分隔符 “/” 一定要带;</li>
  <li>对于post中的markdown转html的时候，列表页的显示也有问题，如果列表页上会显示摘要或者是文章的一部分内容，而恰巧这部分在列表上显示的内容中有图片的引用，这样这个图片也会有显示问题。因为图片其实是在markdown生成的html目录，而列表页是一个单独的目录，所以图片路径是取不到的。这部分其实是可以完善的，但是对于我来说，这部分几乎很少用到，我也就没管了；</li>
  <li>因为你使用了自定义的plugin，而github为了安全考虑是不支持自定义plugin的，所以对于使用自定义的用户来说，只能在本地build完了站点后，把_site目录下的文件签入github，使用静态文件的方式来提供blog的服务；（PS，好处时自定义的插件可以让你为所欲为，有失必有得）</li>
</ol>

                    ]]>
                </content:encoded>
                <guid isPermaLink="false">/blog/2017/blog-image/</guid>
                <description>
                    
                </description>
                <pubDate>Fri, 26 May 2017 00:00:00 +0800</pubDate>
                <author>94geek.com by Seapeak.Xu</author>
            </item>
        
    
        
            <item>
                <title>关于csdn的采访</title>
                <link>http://www.94geek.com/blog/2016/csdn-staffer/</link>
                <content:encoded>
                    <![CDATA[
                    <p>前几天在csdn的《程序员》杂志上发表了一篇关于我写的<a href="/2015/DFS.html">dfs</a>的文章。借
着这次机会，csdn的编辑钱兄邀请我上4月份的sdcc深圳场做一个演讲。为此，他们还专门
采访了我。刚开始他们准备让我在几个主题里面挑一个，后来我和他们说，这些主题我都可
以，他们可以随便选。钱兄就建议来一个综合的。我觉得这样也可以。然后就有了下文：</p>

<p><b> CSDN：请简单介绍下您和目前的工作，以及关注的领域。</b></p>

<p>徐海峰：大家好，我是阅文集团（由盛大文学和腾讯文学整合而成的集团）的首席架构师徐
海峰，大家可以叫我大嘴。我目前的工作主要在分布式存储、分布式计算、公司内部框架的
架构等工作。今年我还给自己加了一个工作项：推动我们的一些项目在GitHub上开源。</p>

<p>对于我自己来说，我一般比较关注分布式存储和分布式计算、高性能运算等。其实业务系统
的框架架构等工作很久之前就做过了，只是后来更关注分布式计算，所以现在我把它当成了
副业，我的主业主要还是高性能运算。</p>

<p><b> CSDN：您有着10年的互联网开发经验，您是如何走上技术这条路的？</b></p>

<p>徐海峰：为什么看见这个问题，我第一个想到的字就是“熬”？其实确实也只能说是熬吧。
开始的时候是技术不太过关，我就开始熬技术方面的。当时也傻乎乎的，办法也不多，就想
到买几本书看看。然后没想到看书竟然后来发展成了我的一个习惯。这10年来，我一直看书
，我霸占了我家的一个半书架，里面都是我的书。这还不算上被我淘汰掉的很多书。在技术
行业就是这样，等你技术ok了，你的机会就来了。还是那句话，熬着，磨练自己，机会只留
给有准备的人。</p>

<p><b> CSDN：您现任职于由盛大文学和腾讯文学整合而成的阅文集团，也曾在携程、5173工作
过，可否简要回顾下自己的工作历程，有什么心得和体会可分享？</b></p>

<p>徐海峰：先说一下这3家公司的区别吧！现在的公司阅文集团，因为我的自主性大一些，所
以可以干预很多地方，虽然现在属于刚刚开始，但底子算是比较好的；Ctrip，我当时去的
时候就是磨练心智的，Ctrip在当时比较古板，技术也是相对挺low的（所以待了11个月实在
受不了了，必须要走了）；5173的话比较自由，很多事情都可以很简单的完成，而且同事之
间关系很不错，我们到现在都一直在一起玩，我也在里面待的最久。</p>

<p>这么多年，我认为公司对人的关系挺大的，判断一家公司的好坏，不能单一的看付多少报酬
，虽然这是第一选择，但是还要看给你做多少的事情，你想做什么，到你能做什么，再到你
能实现什么是有一个很大的跨度的。如果这家公司能给你想法上的自由，行动上的支持那就
应该待的久一些。</p>

<p><b> CSDN：您目前是阅文集团的首席架构师，此前也是携程和5173的架构师，在每一个阶段
中您对架构是怎样的理解？以及您对于架构师是如何定义的？</b></p>

<p>徐海峰：我个人觉得架构挺简单的。我一直和我下面的人说，做架构要比用架构简单，因为
你是游戏规则设定者。你既是运动员还是裁判，你再干不过人家那就没法原谅了。另外，架
构好比画圆，不管你怎么画，最后总归要圆回来。当然一个架构的好坏还得看业务模式、人
员素质、使用便捷性等因数。</p>

<p>一个好的架构一般不是靠短期内做出来的，都是一步一步改出来，或者是总结前面发生的事
情再写出来的。</p>

<p>我现在说得好像挺简单，不过也有迷茫的时候，记得当时我做一个单点登录都要想很久。在
5173时，我认为技术就是无敌的，那时候刚刚接触分布式计算等技术，一切都是崭新的，充
满着诱惑，几乎每天都干到很晚。后来到了Ctrip发现原来技术差一些也行？其实在Ctrip我
算是闭关，在那里看了很多的书，有技术也有人文类的。一年时间也想通了很多的问题。</p>

<p>架构不仅和技术有关，还和人有关。一个架构除了完成既定系统任务还要兼顾开发者等。现
在我的同事经常说我喜欢在技术上“强奸”别人。其实完全不是这样，只是我想过几乎所有
的方式/方法，而且我选择了我认为最好的那种。既能做到架构的简洁，又能做到对于开发
者快速的接受。像架构这种东西，不是越灵活越好，我恰恰相反的认为，架构这种东西，特
别是需要靠别人编程配合完成的东西，越限制死越好。</p>

<p>架构师的定义，我还是觉得他既是裁判又是运动员吧。当架构师不难，难的是怎么让运动人
忘记你裁判的身份。我一直在公司说的一句话：</p>

<p>我真正的成功在于你们都应该不知道有我这个人存在。特别是在系统上线后，如果在没有我
的情况下，系统能正常运行，那我才算是牛。我也一直朝着这个目标努力。目前来看，在
Ctrip、5173这两个地方都实现了这个目标，我希望在阅文集团也能实现。</p>

<p><b> CSDN：您认为具备哪些素质才能成为是出色的架构师？</b></p>

<p>徐海峰：首先是要忍。一个公司的架构或者是技术线并不是一朝一夕来决定的，它有很多的
历史原因，也有很多的无奈之举。所谓的存在即合理，千万不要上来就去大刀阔斧的砍下去
，对于一些觉得不顺眼、不那么完美的事情要学会去接受，等待时机再干掉它；</p>

<p>其次是要自我进化。作为架构师，一般都是在公司内部技术比较牛的人。现在这个世界是日
新月异的变化着，作为一个公司的技术领航人员，在技术上必须要保持一定的先进性。时刻
需要进化自己，不断的补充新的知识；</p>

<p>再次代码能力不能丢。我一些朋友也是做架构师的，他们对我现在还在写代码觉得很吃惊，
而我对他们现在不写代码但是确是架构师也很吃惊。一个架构师连代码都不写了，难道就做
做Slides？画画图？然后开几个演讲？这就太颓废了一些。不仅对公司不好，对自己也不负
责任啊。</p>

<p>最后要学会忍受寂寞。牛的人都是寂寞的。往往一个挺好的事情，当你满怀信心的和同事们
说的时候，他们一脸的迷茫。几乎是没有人点头的，更不要说受到支持。这时候就要学会忍
受这种“寂寞”，并学会去处理这种“寂寞”。</p>

<p>总的来说，我还是认为架构师和管理者还是不太一样。架构师必须要首先做事情，然后再做
人，当然做事情的时候也要追求合理的方式方法。</p>

<p><b> CSDN：目前，阅文集团的架构是怎样的？可否简单介绍下阅文集团整体架构的一些架构
特点？以及作为架构师，您的工作重点有哪些？</b></p>

<p>徐海峰：说实话，阅文的架构还是比较乱的。毕竟是3家公司合并成的。目前我们的架构硬
性上来说简直可以开展览馆了。数据库有：MySQL、SQL Server、Oracle等；应用层有：
Java、PHP、C#、Python等，而业务系统还分属在不同的机房。这是没办法的事情，毕竟以
前是分属3家公司，现在合并了，这种历史预留问题是我们要面对的也是必须要解决的。</p>

<p>现在我们决定把数据库从Oracle和SQL Server上迁移到MySQL上。应用层基本上以后就只有
Java和PHP了，Java做Service，PHP做页面，各取所长吧。目前我们已经在推进这个事情了
，去年先把内容统一了，今年开始统一应用层和应用层的数据库等。毕竟饭要一口一口吃，
罗马也不是一天建成的。这种“乱”的现象正在一步一步的被改进，我相信用不了多久就能
统一吧。</p>

<p>我在阅文的时间其实刚刚2年，我是2014年4月15日入职的，那时候还叫腾讯文学。这两年来
，我一直在负责分布式存储和分布式计算的工作。第一年我一个人写了一个分布式文件系统
（DFS），后撰写的文章也发表在《程序员》2016年4月期上。然后抽空算是帮忙吧，贡献了
一个编程框架，叫Albianj。Albianj主要做分布式业务系统用，自带了分布式事务、OEM、
数据路由等功能，它可以让你用单机开发部署到线上，更改几个配置文件立刻就变成分布式
系统来运行，目前也在我们公司大规模的使用。上文中说到的业务系统的迁移就是使用
Albianj来完成的。后来配合内容中心的统一，我还写了一个id生成器，这就是我要在SDCC
2016深圳站之架构技术峰会上讲的，中间因为调度的需要，还开发了一个调度系统，比当当
开源的那个功能要多一些（当当的海峰会不会杀了阅文的海峰？）。从去年7月份开始，我
也开始接管团队，我们团队在做几个东西：一个RPC的通讯协议、Nameserver、LogDB等工作
。</p>

<p>我今年的工作重点应该不会放在具体的实现上了，我更多的会去做一些系统整体性的架构设
计等工作。还有就是开源的工作，我也一直在不停的推进这件事情。目前来看，上面提到的
几个东西都会开源。到时候欢迎大家去GitHub，一起讨论这些方案和实现。</p>

<p><b> CSDN：您如今是如何安排自己的新技术学习、研发团队管理、编程、生活等时间的？
</b></p>

<p>徐海峰：对于学习，我恰恰和别人相反。我不太去关注新的技术，我倒是挺喜欢那种老掉牙
的技术的。开始我是写C#的，后来我尽然去写了C。其实就像我喜欢用VIM或者是Emacs而用
不惯Sublime Text一样，我对于新的东西到不是那么的感冒。我一直觉得现在技术不管怎么
变化，都是从那些老掉牙的技术演化而来的，金矿还是在老掉牙的技术中。比如现在分布式
文件系统的存储技术，几乎和操作系统原理中的磁盘管理一模一样，只是加了很多平衡性、
一致性之类的算法，所以我现在在看汇编。对于汇编，我开始非常抗拒，但前几天的一个系
统Down掉让我重新重视了起来。很多时候，在Online环境中，你根本就是无法Debug，就算
用GDB也仅仅是把Dump文件拿下来，但那次我把源文件给弄丢了，不看汇编不行，所以我还
是下定决定好好的看看汇编。汇编也没有想象中的难，除了繁琐一些，别的都还好。也不知
道是不是我学的不精，还是还没深入下去，没到难的地方。</p>

<p>管理团队这个事情其实我已近很久没干了。去年开始又需要扮演这个角色了，我才捡了起来
。要说工作嘛，肯定是一个人的时候舒服，人多了黑管理者带来了比较多的乱七八糟事情。
我一般管理分为2部分：</p>

<p>首先在生活上，我会给与一定的照顾。对于一些可以变通的地方我也不是那么的强求。互联
网公司嘛，本来就是比较自由的，而且我们的工作还不太算是简单的业务实现，而是需要一
定的创造性的，所以在这个上面我一直比较松。另一方面，在技术上，我被我同事称为“魔
鬼”。我同事说我发起火来六亲不认（PS：我已经很少发火了）。我规定对于屡教不改的我
要惩罚。这算是我这里的“私刑”。第一次屡教不改的错误，解决方案抄100遍，第二次200
，依次类推。我觉得犯错误不要紧，谁能无过？关键是你是不是真的用心去记住这个错误。
我对待错误的态度是，第一次叫做不知道，第二次叫做不小心，千万不要有第三次，第三次
在我这里就是故意。既然你故意，那我就用故意的办法治你。我是公司内第一个让下属抄“
100遍”的上司。100遍这种惩罚虽然恶心、下流、卑鄙，但效果却是出奇的好。凡是抄过
100遍的人，至今还没有人抄200遍。编程和生活我还是放在一起说吧。因为我爱人和我说，
在我的生活中，没有生活。我是把爱好玩着玩着最后玩成工作的人。高中的时候就对编程很
感兴趣，后来找工作的时候发现除了编程我啥都不会，所以最后爱好变成了工作。也不知道
这到底算不算是我的优势，我可以花更多的时间在编程上。我觉得时间是一定的，所以你的
时间花在了这里，那么那里就会少一块。我经常性把编程和生活搞乱在一起的。我会在洗澡
的时候想问题，我会在出去玩的时候带着电脑，甚至去年7月份前同事结婚，我们一起去马
尔代夫，早晨起来我还坐在阳台上写代码。完了被朋友笑称：在扔美金写代码。也因为这样
，我觉得我无形中比别人多挤出来了一些时间吧！开始时没有什么效果，但是久而久之，效
果很明显。现在确实感觉知道的比一般的人多一些，贵在坚持啊！</p>

<p>好好准备，安安心心坚持，机会还是留给有准备的人。</p>

<p><b> CSDN：在本次SDCC 2016（深圳站）架构峰会上，您想分享的话题是？</b></p>

<p>徐海峰：这次我分享一个主题：id生成器。说到id生成器，没听过的会很诧异，这也好意思
拿出来说？知道一点的，会和你说Snowflake算法。Twitter的Snowflake算法确实不错，但
是我认为它还能做得更好。我们的id生成器是在统一内容时发现要用。以前我们也是用数据
库的解决方案，但统一内容中心的时候，数据库方案已经不能用了。当然我们也参考了
Snowflake，但是都被否决了。最后我决定自己来开发一个。开始没觉得有多难，其实本身
确实也不是很难，但是需要考虑的相关问题却要很多。一个小小的id，仅仅自是一个uint64
的值，里面却包含了很多的信息和对于取舍的考量。此次分享具体的包括：我们前期怎样使
用数据库生成id、我们为什么放弃Snowflake算法、再到后来我们自己的算法，以及此后我
们特有的排序id算法，来听一下你就知道。</p>

<p><b> CSDN：您最期待在SDCC 2016（深圳站）架构峰会上看到哪些内容？</b></p>

<p>徐海峰：我还是想看到更多的自创的东西，而不是使用的心得什么的。这不是说使用的心得
什么的不重要，也很重要，可以让很多人少走很多的弯路。但是技术的发展毕竟是靠创新的
。使用仅仅只是站在了巨人的肩膀上，我更喜欢看到更多的巨人自己站出来。</p>

<p>对于技术的纵向选择，我这个人并不挑食，只要是好的都可以接受。不管你是运维、DB、架
构，这些都可以相互借鉴。</p>

<hr />
<p>这是我得第二次被采访，上一次被采访是去年的11月份，sacc对我做了演讲之前的采访。
相比上一次采访，这一次显然更加的放松一些，说的话也多了一些。<br />
这些年来，技术圈内也是出现了很多的炒作现象。不是说不能炒作，而是说不能过分的
炒作。虽然我也认为我们现在的年代已经不是“酒香不怕巷子深”了。但是，我们也要在
一定的限制内来运行炒作。而不是泛泛而谈，硬是把死人给炒活了、把原本只是一个
程序员水平给炒成cto。</p>

<p>PS:话说上首页的感觉还是不错的！！！ <br />
<img src="csdn.jpg" alt="csdn" /></p>

                    ]]>
                </content:encoded>
                <guid isPermaLink="false">/blog/2016/csdn-staffer/</guid>
                <description>
                    
                </description>
                <pubDate>Sat, 16 Apr 2016 00:00:00 +0800</pubDate>
                <author>94geek.com by Seapeak.Xu</author>
            </item>
        
    
        
            <item>
                <title>腾讯文学内容中心id生成器的设计与实现</title>
                <link>http://www.94geek.com/blog/2015/idcreator/</link>
                <content:encoded>
                    <![CDATA[
                    <h3 id="名词解释">名词解释</h3>

<ol>
  <li>dfs: 分布式文件系统，具体的实现请参考 [这里] (/2015/DFS.html “分布式文件系统”)</li>
  <li>idc: idcreator的缩写，是指id生成器本身</li>
  <li>albianj: 我们开发的一个分布式业务统一框架 具体实现请查考<a href="/2015/albianj.html" title="分布式统一框架">这里</a></li>
  <li>数据路由: 业务系统中经常会用到的分库分表操作</li>
</ol>

<h3 id="摘要">摘要</h3>

<p>我们设计并实现了一个分布式的id生成器。它是基于linux操作系统的，面向我们几乎所有
的业务操作，为我们所有的业务提供对象的唯一标识，也为我们的错误号提供标示。虽然
id生成器被设计成运行在廉价的linux机器上或者是混搭在别的业务机器上，但是它依然为
我们提供了良好的可访问性和可伸缩性。后期因为业务的需要，我们也让id生成器为我们
提供了良好的完整性和一致性。</p>

<p>虽然id生成器比较简单，但是它确实出自于我们对于搭建一个分布式业务系统的实际需要
和我们对于搭建分布式业务系统的一个理解。它和我们搭建的dfs或者是albianj一样，并
不是出自于某些论文或者是高大上的理论。它更多的是被用来解决我们在系统中碰到的实
际问题，所以对于我们来说，它比某些开源或者是论文的更加的具有适应性、维护性和
可用性。</p>

<p>id生成器已经被部署到我们的内容中心系统中，最初的版本已经稳定的运行了9个月，中间
没有一次的down机事故。现在它也被用来改造我们以前的老系统，改造我们从oracle或者
是mssql迁移到mysql的过程。目前为止，我们的id生成器已经部署了2套，一共6台机器，
它为我们源源不断的输出我们需要使用的业务id。</p>

<p>本文档中我们会最终讨论我们现在id的生成方法和后期我们处理强增长模型id的解决办法,
还有现在的id生成办法和以前id的比较、我们使用id的方法等。当然，我们着重要介绍的
还是我们id生成器在分布式业务系统中的架构和特性。</p>

<h3 id="简介">简介</h3>

<p>我们开发idc的初衷是确实碰到了业务大数据的问题。我们的书、章、章节等动辄百万、千万、
甚至上亿的记录需要被最后存储到数据库中。就目前的数据量，如果使用简单的方案，只
能寻求商业数据库的支持，但对于一个互联网公司来说，商业的数据库会大大的增加成本
。我们继而选择了使用开源的mysql来作为底层的关系型数据的存储。但因为mysql的单表
压力远远无法满足我们现实的压力需求。我们只能对业务数据进行了拆分，继而变相的对
我们提出了数据路由的功能。</p>

<p>虽然数据路由的整体实现由<a href="/2015/albianj.html" title="分布式统一框架">albianj</a>负责并且实现，但
是数据路由的规则必须由我们根据业务设定。而设计数据路由的前提是我们必须要存在一个可以作
为<b>数据路由标识</b>的载体。同样是路由，如果是web的负载均衡路由一般就会使用客
户端ip等作为标识，但是类似的解决方案并不适用于我们的数据存储，因为数据库的路由
除了存储数据之外，还要考虑可以通过标识能定位位置，继而还能读取这些记录。所以我
们必须具有一个明确的、不会改变的、唯一的标识来配合数据路由。这个标识就是我们这
里要介绍的id。</p>

<p>我们为此设计并且实现了整个的idc。考虑到目前我们的现实情况，该idc除了具有高性能
的tcp接口和自定义的api外，我们还为此提供了一个语言无关性的http接口。和tcp的api
不一致之处在于tcp会单纯的返回id，而http的接口将会访问一个json对象，继而通过json
可以获取id或者是判断是否出现了访问错误。</p>

<p>虽然idc是分布式的结构，但是和dfs之类的存储类分布式系统相比还是差别非常大的。对
于dfs中比较强调的数据一致性、数据可恢复等等要求，在id生成器中基本上不需要太多的
考虑。这是因为存储需要保存我们提交的内容，而id它只需要和时间成正相关性即可满足
要求。但idc也需要遵循统一的分布式系统的一些规则。idc同样要满足分布式系统的高可
用性、高稳定性、单点无关性等要求。</p>

<p>在互联网行业，前期的考虑总觉得已经满足了需求。但是变化永远大于计划。在我们的idc
中，后来的需求还需要满足生成带有业务状态的id。这是我们的idc和别的idc有差别的地
方。在章节的顺序上，我们需要一个定步长并且只可递增不可乱序的id来满足我们的排序
要求。就这个要求，打破了我们前期对于idc的设计，我们对于idc增加了状态的管理，并
且设计了新的算法来满足此需求。</p>

<h3 id="设计目标">设计目标</h3>

<p>按照往常一样，我们也对我们的idc提出了一些设计上的原则和目标。遵守这些原则、达到
这些目标可以让我们的idc能更好的为我们所用。和以前的dfs和albianj完全不一样，idc
的目标确实比较多，但是它的目标一般都比较的清晰。因为相比它们两个已经设计完的组
件，idc的功能相对简单而单一，对于idc更多还是在性能和扩展性上存在一些实现上的难
度。</p>

<p>在上面的介绍中，我们重点介绍了我们的idc的背景和大概的用处，以及一些idc必须遵循
的规则。但是我们并没有说明我们的idc的设计构想。所以，下面我就讲一下我们的设计构
想。</p>

<ol>
  <li>
    <p>唯一性。从我们的idc中生成的id必须是具有唯一性的。并且是全站唯一的id。这样的id
可以很方便的得到它的业务信息。不管是对于数据路由还是对于业务排错都会具有一个清
晰的、可维护的id；</p>
  </li>
  <li>
    <p>短。idc生成的id必须要足够的短。最好是一个uint32的值，最长也不能长于uint64.一
来对于长于uint64的值存储将会是一个麻烦，另外运算也是需要借助移位等算法，对于编程语
言还无法使用语言内置的类型系统；</p>
  </li>
  <li>
    <p>生成的速度要足够快。这大家都很好理解。没有一个程序是不追求速度的。而且对于我
们的业务系统来说，id的服务是对应于一个分布式的结构。在可用性、可维护性上相比本
地生成或者是数据库生成会有一次的tcp交互时间。所以我们要确保在业务系统正常运行的
情况下，idc能快速的给业务系统提供服务。尽可能的减少因为生成id所需要花费的时间；</p>
  </li>
  <li>
    <p>id的运算要足够简单。这是吸取以前使用字符串来作为id的时候的一个教训。不管是应
用程序还是数据库，使用字符串作为id是可以“为所欲为”，但是在运算上不管是排序还
是hash都会比int类型的数据慢很多，或者是多步骤。所以我们生成的id要尽可能的满足于
简单，最好就是一个数字，这样计算可以直接进行，而且可以直接使用内置简单类型；</p>
  </li>
  <li>
    <p>id不仅仅是一个无意义的id，而是一个带有业务性质的id。这应该是一条“毁三观”
的目标。因为我们的数据库教科书上有一条明确的规则：实体id最好是不要带业务性质的
，仅仅起标识作用的id。但是这也仅仅只是写在教科书上罢了。其实真的很误人子弟，或
者说是跟不上时代。在现实系统中，一个没有业务意义的id在分布式系统中几乎是寸步难
行。不仅仅是不好维护，而且还很不好扩展，不能自由的做数据路由，也不能给开发者或
者是维护者一个明确的“望文生义”的提示。</p>
  </li>
  <li>
    <p>部分自定义位。idc中生成的id除了具有业务意义外，还必须具有一定的空间提供给业
务系统来进行自定义。业务系统中的业务路由也是强业务性质的，和业务结合的相当的紧密
，可以这么说，几乎每一个业务都会有一个不一样的数据路由的定制化功能。而我们需要
满足这些定制化功能。满足定制化功能的前提就是idc中生成的id并不是一个成品，而是一
个半成品。开发者可以通过这个半成品id进行业务加工，使其变成一个完整的、符合当前
业务需求的id；</p>
  </li>
  <li>
    <p>可识别。可识别，也就是可读性。我们认为这是id作为一个标识最应该具有的一个特性
。一个只可计算机识别不可人类肉眼识别的信息几乎是没有任何用处的。我们的idc中生成
的id必须不是那种只为了计算机而存在的。开发应用程序、维护应用程序的都是我们开发
者或者是维护者，本质上说都是人。我们把开发和维护作为头等大事来对待，而机器运行
程序，这是我们程序的附属品，只是碰巧我们写了一个机器可以运行起来的程序而已。首
要条件还是人类友好。</p>
  </li>
  <li>
    <p>对索引友好。这其实是我们开发idc第二个重要的原因。如果不要求索引，字符串是最
好的解决方式。但是字符串在排序上太差了，而这也会影响到数据库的速度。使用字符串
，插入数据的时候会对数据库的索引进行随即写入，而数据库最快的速度应该是尽量的避
免随机写，把随机写变成顺序写这样来提高速度。所以我们的idc中产生的id必须要满足这
个要求，也就是说，从一定意义上，idc中生成的id必须是有顺序的，是可以把对数据库
的随机写优化成顺序写的；</p>
  </li>
</ol>

<p>上面说了很多我们对于idc生成的id的各种设计目标。这仅仅是我们对于这个idc系统
一部分的思考和实践。但是对于我们idc本身，我们也会有一定的设计目标或者说是设计
规则，用来满足我们的idc对于业务系统的支撑。</p>

<ol>
  <li>
    <p>高可用性。我们的idc必须具备高可用性的特点。因为我们的idc被设计成分布式的方式
，又是被构建在廉价的linux普通服务器上，所以这些服务器具有易损坏的属性。但是我们
的idc集群不能因为服务器的损坏而不能为业务系统提供服务。我们必须设计一种或者多种
规则来规避单机down机的问题，从而达到整个集群的高可用；</p>
  </li>
  <li>
    <p>数据一致性：起初这并不是idc的一个必须的属性。因为idc被设计为无状态，仅仅与时
间相关，所以这部分被忽略。但是因为现实业务的需求，我们需要带有状态的idc，故数据
的一致性便成为了整个idc集群的一个标准特性，也是必须被满足的特性；</p>
  </li>
  <li>
    <p>单机承受能力：根据我们整个的业务系统中的业务压力，
引申出来我们的集群需要能支撑的一个量，这基本上就是我们的整个idc集群的最基础的应
对量。鉴于我们业务的发布量和发布态时间，我们的idc集群在前期基本上需要支持每秒5k
的QPS。在业务大量的导入后，预估计这个量在万的级别，应该不会超过百万。所以划分到
我们的单台机器，基本上在1w／s左右的qps即可扛住整个站点的压力；</p>
  </li>
</ol>

<p>最后，也是最重要的一点是，我们的idc必须能在经受住我们系统的同时，可以方便对idc
自定义规则。这是我们比较关心的，毕竟业务随时在变，数据随时都在增加，而我们的应
对策略也一直都在变更。在整个的idc架构中，我们必须要保证留取一块地方，给我们的生
成算法服务，它可以方便的进行自定义，可以方便的嵌入或者重写算法。</p>

<h3 id="架构">架构</h3>

<p>为了达到我们的设计目标，我们对于我们的idc进行了总体上的架构，并且对其架构进行了
细化切分。细分后的idc基本上等同于一个简单的tcp／http服务器。我们也对idc整体的功
能性上进行了细化。目前来说，我们主要的点有以下几个组成：</p>

<h4 id="高可用架构">高可用架构</h4>

<p>对于一个分布式的集群来说，高可用永远是一个不可回避的话题，也是一个必须达到的话
题。我们的idc也不可避免的需要高可用的架构设计。对于idc来说，相对来说数据比较少
，而且相互之间的关系也没有dfs那么的紧密。起初我们设计的idc压根就是无状态的集群
。所有的id都与也仅仅与时间有关。所以我们的idc被设计成平行的无状态结构。从架构上
来说有点像memcached，服务器没有任何的管理服务器或者是状态服务器来为这些idc集群
提供负载均衡、状态管理和故障转移。</p>

<p><img src="idc.png" alt="idc" /></p>

<p>但是和别的系统一样，业务总归是千变万化的，很多时候计划是赶不上变化的。没有多久
我们就需要一种强一致性的id，我们对于原有的idc集群需要一个重新的考量。为了不影响
现有idc的工作，我们在idc上增加了一个弱化的管理节点，它仅仅只是会管理集群中的idc
，而不会像dfs一样还要做一些负载均衡和故障转移的工作。所以这个增加的节点其实不能
叫做manager，而仅仅只是一个agnet的角色。因为我们这样一个特殊的agnet的架构，所以
对于我们的一致性问题也提出了一定的挑战，因为我们不能使用manager来平衡或者是分配
相同请求的master机器了。因为idc集群还是和以前一样都是平行的架构设计，所以就会带
来一个所有的idc都是master的问题。我们也确实使用一种算法规避了这个问题。具体的请
参考“一致性问题”。</p>

<p><img src="idc2.png" alt="idc2" /></p>

<p>对于一个没有管理节点的集群，我们原定使用的负载均衡的方式很简单，就两种。一种是
轮训，另外一个是一致性hash。但是一致性hash还是比较少使用的，特别是后来我们使用
了一致性算法后，几乎就不需要一致性hash饿的存在了，轮询就已经可以满足我们的要求
了。因为我们已经不需要知道master机器在哪里，或者是让一台idc机器通过选举变成
master了。这对于系统的简单行和idc集群的性能是一个很大的提升。而我们这个负载均衡
是在客户端实现的。所以对于我们的客户端来说，也是省掉了很多的东西，只需要做一个
简单的哨兵来去维护轮询的idc即可。</p>

<h4 id="id的可视化问题">id的可视化问题</h4>

<p>说到id的可视化问题，有过id生成算法使用经验的同学肯定会想到snowflake算法。
snowflake算法其实是一种偏向计算机的算法。它通过将一个数转变成二进制，然后通过计
算机的移位算法来解决问题。这也是大家经常会想到的解决方法。这种方式将计算速度看
的非常重要，而忽略了了一个问题：那就是人的问题。系统是由人写出来的，也是由人来
维护的。一个好的代码不仅仅只是写出来给计算机来执行的。而应该是写出来给人看的，
好巧不巧的偏偏海能给计算机运行。所以我们并没有使用类似于snowflake的算法，而是使
用了十进制来生成ID。</p>

<p>十进制，我们人类经常使用的一种记述算法。相比二进制，它更贴近我们的生活。以至于
到了我们人类一眼或者谁靠着简单的风格位数就可以区分出来数字的意义。这正是我们想
要一种方式，也可以称之为感觉。因为根据我们的经验，一般的id都是在数据路由中使用
，这个时候其实对于系统来说是二进制还是十进制没有什么差别，因为计算机都能处理，
我们人也不会去看；但是当我们维护人员要去看这个id的时候，往往都是在系统出现问题
的时候，这时候时间就会显得异常的宝贵，再加上当时哪种紧张的心理，如果这个id不是
哪种一眼就能看出来意思的id的话，往往会有很大的打击作用，进而会让维护人员产生更
大的焦虑症状。这并不是我们想要的。我们可以看一下以下的例子来感受一下：</p>

<p><b>9223  3720 3257 7650 688</b>这样的一个数字看起来还算相对整齐，但在系统中，它
看起来往往是这样的一个样子<b>9223372032577650688</b>,这就已经有点凌乱的。压根不
知道表示的是什么鬼。然而，按照snowflake算法，其实它的二进制应该是这样的：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>0111 1111 1111 1111 1111 1111 1111 1111
0000 0001 0001 0000 0100 0000 0000 0000
</code></pre>
</div>

<p>但是我们还是看不懂它表示的是什么意思，我们再对它进行移位计算，分别计算出来它的
各个位置上的值，其实它的真正的表示的值是这样的<b>2199023251472-264-0</b>(中间的
－是为了方便区分添加的)。敢问你现在是一种什么样的心情？</p>

<p>但是是不是这种二进制算法就没用？其实也不是。我们也使用了这种算法的变种，我们将
它使用在我们的排错异常号上，具体的可以请参考虾面的使用id章节。</p>

<h4 id="id模型">id模型</h4>

<p>在我们的业务系统中，我们的id最主要的作用还是作为数据路由的一个标识。所以我们的id
其实最终决定了我们的业务系统数据库存储是不是会均衡或者是趋向于均衡。这就决定了我们
必须要采用一种算法来确定我们生成的id是线性的。又因为我们的id需要对数据库索引的
友好，我们放弃了随机数的算法，而是使用了简单轮询的算法来生成id。</p>

<p>首先，放弃随机数算法是因为本质上我们没有办法确定随机数会对数据库索引友好。虽然
随机数可以满足线性这么的一个条件，但是先后生成的随机数的大小是我们没有办法决
定的,也就是说又50%的可能性后生成的那个随机数会比前面那个随机数小。这样的概率
显然太大，并不适合我们的要求。那么我们只能选择轮询这种算法。</p>

<p>其次：我们不会存储轮询的哨兵的值。这个取决于我们的id并不仅仅更我们的轮询数有关，
还和我们的时间有关。我们的id是在时间的基础上增加轮询数来共同决定一个id的主体，
所以对于我们来说，对于轮询数的单调一致性要求并没有想象中的高。所以也会出现下面
的这种情况：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>429497-9998-01-1-00
429498-9999-01-1-00
429498-0000-01-1-00
</code></pre>
</div>

<p>这个id中，第一部分是时间，第二部分就是轮询数。所以我们的id可能会出现这样的一个
情况：正如第二、第三两个id一样，因为递增到了一个临界值，又为了避免位数的溢出，
我们只能选择将id值的轮询数归0.这样的话，我们也可能会出现部分对索引不友好的情况
（后面生成的id小于前面生成的id）。但是这种情况只是小概率时间，因为这种情况只会
出现在1s之内，当跳过1s后，因为时间的真大，数的前半部分会变大，所以整个数也会变
大。这样就又回到了单调递增的条件下了。</p>

<p>这种id适合做分库分表，但是对于单表的排序id并不适合，所以我们还提供了严格递增的
算法。</p>

<p>严格的递增算法其实和轮询递增算法差不多，只是在我们的轮询数上做了一点点的改动。
我们把单调递增改成了秒内递增，溢出不饭号或者是从定向的方法。比如，生成的id号是
这样的：</p>

<div class="highlighter-rouge"><pre class="highlight"><code>429496-0000-01-1-00
429497-0000-01-1-00
429498-0000-01-1-00
</code></pre>
</div>

<p>这样的号，会随着前面的时间或者是中间的轮询数单调递增。永远不会出现变小的问题。
但是这仅仅是单台情况下的表现，如果是分布式的情况下，也会出现问题。所以这个id
同样不适用于严格的递增情况。后面我们会讲到碰到需要严格的递增的时候我们的
解决办法。</p>

<p>这种id明显的看出来不适合按照轮询数来做数据路由。对于这种id，增长的曲线角度永远
是45，而且是每秒都会重新开始，所以就会导致这些id大概率的倾向于值小的路由。</p>

<p>综上所述：我们目前的两种id增长曲线如图：</p>

<p><img src="4.png" alt="idc4" /></p>

<h4 id="简单唯一性算法">简单唯一性算法</h4>

<p>唯一性在单机的系统中还是一个可以容易解决的事情。但是在分布式的系统中，唯一性对
于架构来说往往是一个挑战。终其原因会有很多，但是最大的问题就是：在分布式的系统
中没有一个精确的时钟。没有了精确的时钟，很多的解决方案就会失去作用，而且失去作
用的不仅仅是唯一性，可能的单调性也是一个问题。</p>

<p>一般解决这个问题的方案是在服务器集群中放一台时间服务器，所有的机器都会每隔一个
心跳时间去这台时间服务器上校验和更新时间。但是就算是再频繁的同步，这种精度也就
是在毫秒甚至是秒级别了。不会有比这个更精确的度了。所以严格的来讲，这不能作为很
好的一个解决办法。</p>

<p>我们的idc集群因为是分布式的也同样的存在这个问题。而我们也采取了一定的策略来去避
免这个问题。我们将我们的id设计成和时间、机器相关。这样一个带上机器编号的id，能
保证在整个的系统中唯一了。以此，我们的id方案为：</p>

<center>
<b>时间戳－轮询数－机器id－数据库位</b>  
</center>

<p>这种解决办法确实解决了这个问题。但是也有一个副作用。因为考虑到我们的id要放下很
多的业务性质属性，所以留给我们的机器id位就会变的很少。我们现在的情况下留给机器
id位的长度仅有一位，也就是说：我们的idc集群最多支持10台机器。看上去10台机器很少
，但是我们单机的承压在每秒10k。所以基本上我们集群的id生成量在每秒100k。这仅仅是
一种类型的数量，在我们的idc中，一种支持100种类型的id，所以我们整个集群的量大概
在每秒1kk。</p>

<h4 id="idc保存数据算法">IDC保存数据算法</h4>
<p>该来的还是会来的，只是设计的时候时候未到。我们开始的时候并没有考虑严格的带有递
增id的需求。但是这个需求在后面没多久就出现了。先来看看我们遇到的问题：我们在三
方内容合并的时候，为了迎合原来的各业务系统，不打破他们的使用规则，所以我们的章
节信息在正常的数据路由id使用的基础上，增加了一个排序id，这个id必须是严格递增的
，因为它代表了章节的前后次序。但是在我们的系统结构中，如下图，我们对于mysql使用
了读写分离的策略，那么问题来了，就算我的同步速度非常快，无限快，它也只是趋向于
实时，但并肯定就是实时的。也就是说同步是肯定要时间的，唯一的差别就是时间的长短
。这也就意味着可能会出现下面的情况：我们在master中插入一个正确编号的章节A，这时
候A还没同步到slave数据库，我们又要插入章节B，这时候我们需要一个编号，我们从
slave数据库中读取一个编号，这个编号是当时slave数据库中最大的编号，我们再加上步
长，其实这个编号和刚刚插入的章节A的编号是一样的。然后再插入master数据库，这时候
章节A和章节B的编号就会发生冲突。在我们的系统中，就会出现章节重复的问题。</p>

<p><img src="7.png" alt="idc7" /></p>

<p>这确实是一个架构上的问题。本质就是写入和读取并不是来自于同一个数据库，所以造成
了数据上的误差。这种问题的解决办法业余很多，以前我们使用的一种办法是在修改数据
或者是需要严格数据一致性插入数据的时候，都要在master数据库中先load一下数据，其
实我们设计的albianj确实也有这个功能，这样做的好处是简单明了。坏处是破坏了架构的
一致性，后期也有可能在代码上引起混乱。而且就一个排序号，这个对我们来说是可以避
免去master数据库load数据的，所以我们采取了另外一个方式：让idc支持这样的一个id生
成。</p>

<p>总体上来说，这样的需求也不是很难解决。但是因为章节是挂载到一本书的，所以这个id
只要在一本书内唯一并且按步长自增就可以了。没有必要做到全局唯一自增。这样的需求
其实更增加了我们的难度。如果只是全局内单调自增，那么我们只要记录下来一个id就可
以了；现在是每一本书都需要一个id序列，所以idc要为每一本书都记录下来它的id状态。
记录每一本书的算法采用了skiplist。我们将书的id作为唯一的key，当前编号和一些源信
息作为value。这样我们就构建了我们书数据中心的整个索引。每次更新或者查询都只是一
个skiplist的操作而已。</p>

<p>我们的skiplist通常情况下都是常驻内存的，所以搜索的时候性能并不是问题。而且我们的
item经过测算是一个很小的值，大概只有10b级别。所以256mb的内存就可以存放大概1kw的
item数据，所以不管是内存还是io都不是我们这个skiplist的瓶颈和消耗点所在。</p>

<p>多本书的问题解决后，我们解决状态的问题。我们给idc配备了一个后台的线程，每隔一个
固定的时间就会触发skiplist的IO化。IO线程会判断skiplist中的item的状态，将短期内
update或者是新增的item刷入到磁盘中。这样状态就会被保存下来。保存了状态后，每次
idc重启都会去判断是否有skiplist的持久化文件，如果有文件，就会先加载这些文件到内
存。如果没有文件，那么就去同逻辑组的idc中随便选取一台，同步skiplist的文件。然后
再加载。这种办法简单，有效。并不存在数据不一致的状态。这是因为我们在生成id的算
法上也会规避这个id状态的问题。</p>

<h4 id="有状态id算法">有状态id算法</h4>
<p>对于状态id的基本上情况下面已经介绍清楚了，但是我们到底怎么去生成这个id？这是我
们需要考虑的一个问题。其实仔细的分析这个id，貌似就是一个zookeeper就能解决的问题
。但是我们前面还有欠债，因为我们的idc已经上线，并且我们的idc是平行设计，并没有
master的角色。所以这就给我们提出了新的问题，怎么样在全是master的情况下，能生成
一个唯一id？</p>

<p>提到zookeeper，我们肯定知道它决定谁是master的算法，也就是选举算法。这个算法被我
们采用，但是我们采用这个算法并不是产生一个master的idc，而是产生一个最大的id。如
下图：</p>

<p><img src="3.png" alt="idc3" /></p>

<p>我们将zookeeper的集群启动选举变成一个常态。将每一次的请求都泛化成选举操作。当然
这仅仅出现在这种严格id的情况下，并不影响别的id的生成。所以它也并不会因为特殊的
需求而给整个集群带来性能的颠簸。我们平行的idc设计导致了每一台机器都可能会接收到
请求，所以我们干脆把这些接收到请求的机器全部当成master机器，然后他们会根据客户
端传输来的bookid得到目前当前机器上的id值，先预加上步长，然后会发送请求到集群中
的每一台idc，接到请求的idc也会根据bookid得到当前的id，然后加上步长，直接返回给
发送端机器，发送端机器拿到id后会和自己的做对比，选取最大的id作为当前这次批号的
id，然后把这个id再次通知到集群中的idc，他们会根据这个id和当前的本机id比较，如果
传输来的id更大，更新当前的id；反之不更新，直接返回。发送端接收到整个通知ok的消
息后，返回给客户端当前的id。这个id即是当前最大的id。</p>

<p>有时候会发生一本书同时发章节的情况，这样我们idc集群可能会有2台机器同时接收到同
一id的申请，也就是所谓的并发，这样也不是不能处理。首先，从业务上来说，对于同一
个id的处理是不是可以被接受？如果不可以，那么我们在业务层就需要使用分布式锁的方
式来规避这个问题；如果业务上这种同时发生也是可行的，那么到我们的idc端是有可能碰
到前后不一致的情况，因为我们的idc集群对于同时到达的同一id的请求，采用的是“类彩
票”方式，也就是所谓的“比手速”，谁先进入idc集群谁就是前面的那一个，后进入的就
是后面那一个。这并不是idc的问题，而是idc其实也无法决定谁先到达这个难题。</p>

<h4 id="id长度问题">id长度问题</h4>

<div class="highlighter-rouge"><pre class="highlight"><code>数据路由: 343429497-9998-01-1-00
有状态id：20160423-000-00-000100
</code></pre>
</div>

<p>看一下这两个数字，对于一个uint64类型的值来说，最大的数是1844 6744 0737 0955 1656，
应该是20位，而我们的数字缺只有19位，少了一位这是为什么呢？</p>

<p>这其实是idc的一个坑，很多时候并不会碰到，但是当碰到的时候可能就已经来不及了，而
且现象会非常的奇怪。这个问题就是曾经被老生常谈的：溢出。我们的千几位是被时间占
用的，而时间会随着年代的久远越来越多。就算我们不以1970－01-01作为起始时间点（其
实我们也是这样做的），我们按照站点上线的时间点作为一个起始点，那么一个uint32的
值也是有限的，如果我们取的时间精度再高一些，值会更大。而其实溢出会更快，因为我
们看一下uint64的最大值，最高位是18XXXXXXXX,所以只要最高到19XXXXXX就会溢出。所以
为了避免这个问题，我们只能把整个id的值缩短到不管怎么变化，都不会过它的最高第二
位。这样，就永远也不会溢出了。所以我们想到了直接缩掉一位，也就是将最大值直接取
1/2，这样就不会溢出了。</p>

<p>这里还提到一个问题，这样设计的idc到底可以用多少时间？其实这个时间非常的长，用
int32最大的值来算，基本上我们的idc使用的年限在175年左右。到176年的时候就会溢出。</p>

<h3 id="id生成器的id和传统id的比较">id生成器的id和传统id的比较</h3>

<p>传统上，我们经常会使用数据库的自增int作为对象的唯一标识，稍微符合现在的系统设计
原则的就会使用GUID／UUID等字符串唯一标识，再进步一些就会自定义一个字符串的唯一
标识，这个字符串不仅仅满足唯一性还会增加一些业务的标识。不管使用何种的算法，它
都和我们对于id的需求又较大的差距，那么这些差距到底表现在哪些方面呢？</p>

<h4 id="和数据库生成id相比">和数据库生成ID相比</h4>

<p>数据库生成id的方案现在基本上只有2种方案：一种是直接int自增，步长为1；另外一种也
是int自增，但是步长可以自定义，一般步长定义成数据库表的个数。</p>

<p>int自增、步长为1的方案其实是扩展性最差的方案。首先：它的事务性要求很高，插入数
据和获取id必须在一个事务中操作，否则id就有偏差的可能。第二个步长固定，无法对应
现在互联网大数据的分库分表操作。这个方案一般都会被用在传统企业的数据库设计中，
因为他们的数据库一经设计基本上不太会变更。</p>

<p>那么第二种步长可自定的方案(如下图)是对上一种方案的优化。将步长设置成数据库表的
数量可以解决当前的数据库分库分表的问题，也减小了数据库的压力。当步长严重依赖于
数据库的表数量，在扩展的时候还需要更改表的设置，从运维和dba的角度来说，其实相当
的不方便。而且对于业务来说，因为步长固定，又为了数据的均衡性，只能选择loop的算
法来进行数据路由。</p>

<p><img src="9.png" alt="idc9" /></p>

<h4 id="和字符串id相比">和字符串id相比</h4>

<p>使用字符串的方案一般也是有两种：一种是GUID／UUID，另外一个是自定义字符串。GUID
／UUID一般情况下是不太可能会碰撞的，所以唯一性倒是能保证的。对于数据路由，一般
是将GUID／UUID做一个hash，然后取模，使用GUID／UUID的很少使用loop等数据路由算法
，也不太好做。又因为GUID／UUID没有业务性质，所以也很难按照业务类型做数据路由。
和数据库生成id一样。所以也在GUID／UUID的基础上产生了自定义字符串id的算法。</p>

<p>自定义字符串id一般使用的也是32位长度id。只是可以根据自己的实际情况来给这32位长
度的字符串赋值。这种的字符串的算法一般会使用本地生成，带上机器信息、类型、时间
戳、顺序号。这样的id可以保证唯一性，也可以满足复杂的数据路由功能。但是没有办法
排序，对数据库索引也不友好。</p>

<p>不管是GUID／UUID还是自定义字符串，总体来说都不是很对我们的需求，我们将它们的优
缺点罗列了一个表：如下：</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">序号</th>
      <th style="text-align: center">优点</th>
      <th style="text-align: center">缺点</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">1</td>
      <td style="text-align: center">自定义性强，可以根据实际情况自己定义</td>
      <td style="text-align: center">String有点太长了</td>
    </tr>
    <tr>
      <td style="text-align: center">2</td>
      <td style="text-align: center">可以轻松的实现复杂的数据路由算法</td>
      <td style="text-align: center">String截取部分内容或者是整体的hash运算<br />都会有额外的消耗</td>
    </tr>
    <tr>
      <td style="text-align: center">3</td>
      <td style="text-align: center">自定义算法id有人类识别度，<br />而且后期运维也方便</td>
      <td style="text-align: center">UUID/GUID没有业务性质，人类识别度不高</td>
    </tr>
    <tr>
      <td style="text-align: center">4</td>
      <td style="text-align: center">本地生成，无事务性、也无延时</td>
      <td style="text-align: center">一样无可排序性，对索引和写入都不友好</td>
    </tr>
  </tbody>
</table>

<h3 id="我们使用id的方法">我们使用id的方法</h3>

<p>idc服务器生成的id在我们的系统中已经被广泛的使用。在我们的业务系统中，所有的业
务对象的id都是由idc生成的。我们使用这些id进行了我们的数据路由的设计和实现。目前
的数据路由基本上在单数据库1000张表起。我们的idc和albianj相互配合，完成了我们整
个复杂业务层的数据层。</p>

<p>我们也不单单将id使用在数据路由中，还将id使用在排错中。这也是一种以前几乎很少会
使用的解决方案，目前使用下来，运行良好。还未出现异常情况。</p>

<p>下面我们将讨论我们的id使用方案，这仅仅是我们使用的方法而已，并不是标准。根据idc
的id，可以很方便的根据自己的业务来决定自己的数据路由规则。</p>

<h4 id="数据路由">数据路由</h4>

<p>idc生成的id，不管是自增id还是章节唯一id，至少都保证了3个我们经常会使用的元素：
时间戳、序号、库位。在业务系统中，经常会被使用的数据路由算法有几种：根据时间划
分数据库和表，比如将一个月分成3部分，1-10的放在01表中、11-20放在02表中、21号以
后的放在03表中，这样每个月就产生3张表；使用序号的方式有很多，最常见的是使用取模
或者是最后几位确定，比如我们的分表位是3位长度，那么可以表示0-999的数据，这样可
以把一张表分成1000张分表，获取分表位的数值，根据这个数值推出来这个数据应该放在
那张表中，再插入数据。</p>

<p><img src="5.png" alt="idc5" />
<img src="6.png" alt="idc6" /></p>

<p>至于库位。其实就是数据库的编号。这个编号也是经常会被忽视的地方。原因是很多时候
，我们其实也可以根据分表位的数值来推导出来应该将数据放在那个表里。但是这种方法
的问题在于。如果我们要扩展数据库，那么我们只有导数据，将数据先重现平衡，然后再
提供服务的一种办法。虽然我们也可以使用“类二叉树”的方法将导数据的量减小一半，
但是依然挺烦人的。所以我们抛弃了这种做法，我们在我们的id上留了2个位置，专门来给
我们的数据库指定位置。这样我们的数据库在扩展的时候可以不用动我们的历史数据。这
也是我们特殊的业务决定的。一般的业务可能不适合使用这套方法。因为这样的做法可能
会将热数据全部放到新加上来的db中，而我们没有这个问题。所以我们在设计的时候可以
不用考虑这个问题</p>

<p>还有一种数据路由的方式是根据类型来划分。这也是经常需要使用的一种方法。所以我们
在自增的id上增加了类型的位，已方便数据层使用类型进行数据路由。但是我们在章节唯
一id上却没有相应的类型位，这是因为章节自增id其实是我们id的一个垂直细分，也就意
味着只要使用这种id就一定明确的知道你在使用哪种类型的数据，所以这样的意思就是暗
示使用者可以明确的知道正在使用的id用途。所以并不需要类型id。</p>

<h4 id="异常排错">异常排错</h4>

<p>这应该是我们特有的一种id的使用方法。它主要解决两个问题：</p>

<ol>
  <li>将系统内部的异常或者是错误信息给报给了客户，引起信息外泄，导致数据不安全；</li>
  <li>定义一个全局的类似于linux的errno的机制，后期需要维护这个列表的成本太高，并
不是一个很好的解决方案；</li>
</ol>

<p>我们经过仔细的考虑，我们觉得对于一个系统来说，过滤异常只要知道异常类型就可以了；
对于异常信息，不应该报给客户，或者说少报给用户，但是系统却必须完整的记录下来，以
方便后期的排查。所以其实非常的简单，对于我们来说，我们只要构建一个桥梁，将报给用户
的信息和系统内部的信息连结上，然后提供给用户的只是简洁的信息，系统记录详情即可。
这样我们就设计了一个这样的id，它甚至不需要使用十进制，二进制的snowflake算法都一样
能达到目的。因为它只要唯一性，只要能和系统内部一一对应起来即可。</p>

<p><img src="8.png" alt="idc8" /></p>

<p>我们使用这种策略，当发生问题的时候，我们只需要问客户要一个id号，然后使用这个id
号到我们的系统中去查询，即可确定用户当时到底发生了什么问题。这个id仅仅相当于这
个用户一个系统级的sessionid而已。</p>

<h3 id="总结">总结</h3>
<p>我们重新设计和实现了一个完整的、分布式的id生成器。它设计的过程中，我们也碰到了
各种各样的为题，但是最后我们还是一一解决了。</p>

<p>这个id生成器相对来说还是简单的，但是通过这次的idc设计和实现，我们觉得我们最大的
收获是不迷信“高大上”的算法和“高大上”的公司，踏踏实实的根据自己的业务来自己
实现一个符合我们自己业务的id生成器，即保证了我们的业务系统顺利的完成上线，又锻
炼了我们解决实际问题的能力。</p>

<p>这个id生成器到目前为止已经在公司内部稳定的运行了9个月多，中间没有一次出现问题和
异常，可以说我们很好的完成了任务，也更深层次的解决了分布式系统的问题。</p>

                    ]]>
                </content:encoded>
                <guid isPermaLink="false">/blog/2015/idcreator/</guid>
                <description>
                    
                </description>
                <pubDate>Mon, 23 Nov 2015 00:00:00 +0800</pubDate>
                <author>94geek.com by Seapeak.Xu</author>
            </item>
        
    
        
            <item>
                <title>腾讯文学内容中心分布式统一框架的设计与实现</title>
                <link>http://www.94geek.com/blog/2015/albianj/</link>
                <content:encoded>
                    <![CDATA[
                    <h3 id="摘要">摘要</h3>
<p>我们设计并开发了内容中心统一的分布式开发框架。我们把它取名为albian，
albian是基于java的（故以下简称albianj）。他主要是面向海量数据处理、海
量数据访问、并解决互联网开发中经常会碰到的数据海量增长问题，也一并解决
互联网开发团队中，开发人员的水平参差不齐的问题。albianj还应当具有良好
的伸缩性和可定制性。他设计并且运行在简单的
web容器中，比如tomcat或者是jetty，也可以运行在application类型的应用中，
但是它依然提供了企业级开发应该具备的一切效能。</p>

<p>从业界来说，目前成熟的框架有很多，但是从EJB因为复杂性而被大多数公
司放弃后，spring+Hibernate在业界成为了事实上的标准。总体来说
spring+Hibernate可以解决掉企业开发的很多问题，但是在互联网行业，在快速
开发、海量数据处理和快速迭代引起的统一问题面前，这个组合还是有或多或少
的问题。所以我们最后决定自己开发一个适合我们自己的框架出来，来解决sh组
合不能很好的解决的问题。</p>

<p>虽然albianj和sh有很多的相似性，可能很多的功能都是重复的实现，但是毕竟
albianj实际来自于我们对于掌控业务和掌控代码的现实需求，所以它更面向于
我们的实际情况，而不是来源于开源组织对于系统的理解或者是某篇论文对于系
统概念的理解。这样，也就意味着albianj相比sh会更实用，并且能给我们带来
更好的可用性和可维护性。</p>

<p>albianj的使用满足了我们在业务上对于程序代码控制和功能上对于处理海量实
时数据的需要。目前albianj已经使用在我们的生产环境中，主要为内容中心提
供数据的存储和读取之用。目前它一共被部署在上百台的机器上，来完成对于几
十台数据库的各种不同模式的访问。</p>

<p>在本文章中，我们主要阐述我们设计和开发albianj的一些观点和一些策略选择
的原因，以及我们是怎么设计和实现albianj的，最后我们会列出实际情况下我
们的开发效率和性能数据。</p>

<h3 id="简介">简介</h3>
<p>albianj主要完成的任务就是统一程序员的工作，让程序员在统一的口径
下完成他们的工作，这仅仅是一个长远的战略目标；更现实的目标是alabianj必
须提供一套简单的机制在应对对于拥有复杂部署结构的后端数据库的访问和在数
据量增长的过程中，方便的切合数据的再划分等等功能。在开源的项目中，我们
考察了guzz和hbm shared，但是前者过于复杂，导致我们迷失在了配置文件中，
而且对于他显式的指定数据路由有一定的不可接受；而后者，它仅仅只是一个补
丁，而且这个补丁的质量真的令人堪忧，不支持分布式事务这是完全不能接受的
事实，而且当使用数据路由之后，分布式事务肯定是无法避免的、肯定会有所需
求的重要功能。所以我们综合的考量下来，决定自己来设计并完成整个框架系统。</p>

<p>对于albianj，其实它和市面上提供的各种开发框架功能类似，最最基本的功能
也仅仅只是IoC和ORM，所以从这2个方面可以看出，我们还是在追求对于OO的控
制。但是albianj不仅仅只是完成这些功能，它更多需要强调一致性。不仅仅是
数据的一致性，而是对于程序员写代码的一致性和可控性，兼具对于各种
albianj中主键的一致性和可控性；其二，它还需要解决一个大多数的框架都没
有解决的问题，那就是数据路由的能力。简单而一致的数据路由功能可以快速的
开发大数据量的业务，并且也可以在短时间让自己的系统重新适应并且无缝的连
连接已经重新切分好的数据。相比传统的开发框架，我们在设计和开发albianj的时候就已经
额外的考虑了更多的内容，并在其中进行了有的放矢的选择，引申出了和以往不
同的开发思路，也实现了我们开始对于albianj设计时制定的目标。</p>

<p>首先，albianj和别的框架不一样的核心点是“单维性”，简单来说就是一种需
求只会一种办法来解决，轻易不会出现第二种办法。就算为此牺牲一定的编程便
利性，albianj也需要守住这个底线。所以这个模式就和spring或者诸如此类的
框架有质的不同，一方面我们没有必要为了迎合新的概念或者新的技术频繁的对
albianj进行升级和改造，另一方面，我们也没有必要为了多功能而引入不必要
的复杂税。从程序员写代码的角度来说，他们也仅仅只需要学会一种途径就可以
依葫芦画瓢似的解决类似的问题。这样的结果就是代码会无比的统一，熟悉
albianj过后开发也是无比的迅速。这一点是albianj一直在追求的，也是一直在
遵循的一个必须准则。albianj所有的功能都是建立在这个标准之上的。</p>

<p>其次，和别的框架一样，我们必须也需要使用配置。但是我们和别的框架不一样
的地方是我们没有“约定优于配置原则”。在稍早之前，随着java对于xml的配
置越来越依赖，导致了很多的java程序员40%的时间在写代码，另外的时间都在
写配置或者是copy配置。后来随着各种抱怨的产生，遂订立了一个规则，就是坑
爹的“约定优于配置”。这个出发点其实和hbm的sharing是一样的，它仅仅只是一
个补丁而已。其实我们经过10多年的互联网开发，总结了一下，我们认为，目前
xml的配置一部分是因为功能的复杂而决定了，另外一部分是被滥用了，两点相
加造成了目前的这种境况，然而为了前面的失误，后面加入了一个补丁（约定优
于配置）来解决这个问题。其实并没有真正的解决问题。所以albianj在设计的
过程中就是尽量的对配置做减法，仅仅保留必要的配置，但是在配置和一致性、
可维护性冲突的时候，我们选择了一致性和可维护性，放弃了对于配置精简的需
求。</p>

<p>第三：albianj是所有组件的总称。其实它里面包括了多个不同功能的组件。对
于这些功能性组件，除了基本kernel以外，所有的组件都是被设计成插件式的。
我们采用了一键安装和尽量透明使用的策略。在一些需要使用的地
方只需要配置项加上某些配置，功能会自动启用。这样在保证解决问题一致性的
同时对程序员又不失开发上的便捷。对于我们的整个系统来说，它不仅仅解决了
开发效率的问题，更是解决了年久失修这个困扰我们团队已久的问题。</p>

<p>第四：albianj对于我们团队来说，还解决了团队中开发人员水平参差不齐的问题。因为
albianj恪守一致性的原则，只要对albianj使用得当，写出来的代码几乎是一个
模板刻出来的，不管程序员的水平是应届生还是具有开发经验的程序员，几乎写
的代码大同小异。在关键的数据路由等功能性问题上，albianj提供的解决方案
是提供一些接口来供程序员使用，程序员要做的事情就是实现这些接口而已，中
间并没有除此之外的任何代码需要程序员来完成。</p>

<p>最后：最重要的一点是，albianj的完成是我们整个团队在互联网开发10多年来的
经验结晶。它容易设计并且容易完成，而且因为它是为我们量身定做的，所以在
使用上并不存在任何碍手碍脚的地方。总体上的架构因为全部是我们自己从头开
始搭建，所以解决bug或者易用性问题也是一件非常简单的事情。我们并没有因
为整个albianj的开发而导致业务的延期，相反在业务的开发中，我们不时的发
现albianj改进的点，对此我们加以了改进，生成的效率也有所提升。我们进行
了逐一的更改和优化。这些更改和优化也会一并在这篇文章中体现。</p>

<h3 id="设计概述">设计概述</h3>

<h4 id="目标">目标</h4>

<p>在上面的介绍中，我们简单的介绍了albianj的一些设计的思想和准则。并且我
们声明了albianj在系统存在的地位和它的一些基本功能。在这一节中，我们将
详细的说明albianj设计的目标和对我们的挑战。在设计和实现的过程中，我们
印证了一些我们初定的目标，在项目使用和实施的过程中，我们也根据我们实际
的情况对于初定的目标进行了一定的筛减和优化。</p>

<ol>
  <li>
    <p>首要的目标就是一致性。在开始设计albianj的时候就把albianj的一致
性作为极致的追求来实现。我们认为在一个软件的声明周期内，一致性起到
的作用不仅仅体现在代码的可读性上，而且更有利于后期的软件的可维护性
上。特别当团队的人员开始流动的时候（其实我们一直觉得人员的流动是无
法避免的），拥有一致性和可维护性的软件会拥有更长的生命周期。而且一
致性不仅仅体现在可维护性上，还有更多的是可以节省前期程序员的工作量
和降低bug出现的机率。</p>
  </li>
  <li>
    <p>albianj必须可以应对海量数据的访问。在现在的互联网系统中，海量的数据
和高并发的访问已经变得越来越普遍。对于庞大的系统来说，应对海量数据和
高并发流量的策略就是拆分。所以本质上，albianj其实需要面对上百台甚至
是上千台的后端服务器，他们可能是分布式的存储，也可能是关系型的数据
库，或者是后端的业务接口服务器。albianj可以提供一种简单而有效的方法
来应对那么多的机器。实际的情况其实并不仅仅只是这么简单，因为albianj本
身就在分布式的环境中，它需要部署在成百上千台服务器上，以提供最基本
的框架服务。</p>
  </li>
  <li>
    <p>作为一个开发框架，albianj必须要可以随时来应对机器的增加和损坏。
albianj必须在有限的时间内来应对机器的部署改变，而不需要更改代码或者
仅仅只是更改有限的配置。传统来说，就算机器一切安全而稳固，整个服务
也会因为数据量的增加而需要重新审视架构和机器的部署。更多的时候是需
要拆分数据和移动数据，而albianj需要在面对复杂的架构调整的时候，轻易
的来应对问题。从而让系统重新稳定架构的成本降到最低。</p>
  </li>
  <li>
    <p>作为整个系统的最基本的底层，albianj需要适应更多功能的快速加入。并且
在albianj的规范内快速的形成组件化，做到即插即用的效应。这不仅仅只是
代码级别所考虑的事情，更多的是需要在设计的过程中就注意对于新功能添
加的便捷性。也就是说需要从头就开始考虑以后的可扩展性，做到一致性、
可维护性、可扩展的平衡和兼得。</p>
  </li>
  <li>
    <p>albianj作为这个内容中心的框架，也必须要对程序员做到尽可能的友好，又
必须考虑一些敏感信息对于系统安全的影响，在这两者之间取得相应的平衡，
来达到albianj最好的亲和性和安全性。这个挑战不仅仅在于对于albianj的
使用上，更多的是需要平衡团队内部参差不齐的开发者的编程水平。</p>
  </li>
  <li>
    <p>因为albianj是从头开始搭建的一整套完整的框架，所以难免会出现bug或者
是开发者觉得使用不是那么顺畅的地方。albianj还必须提供一整套的完备机
制来第一时间解决bug或者是易用性的问题。</p>
  </li>
</ol>

<p>在总体的设计思想上，albianj的挑战非常的严峻，特别是对于一致性的特别的追求和
对于安全性、易用性、可扩展性之间平衡的需求不是一点点的难度。然而，不管
怎么样，最后还是需要具体的细化到各个技术点的目标上才可以告别空中楼阁，
才会有落地实现的机会，所以我们又对albianj在技术上定下了一些目标，这些
目标组合起来，可以实现上文提到的一些对于albianj的期望。</p>

<ol>
  <li>
    <p>首先为了解决一致性问题，我们必须使用一致的方法来实现各种功能。albianj
必须设计和实现一套OOP编程机制，其中包括接口、实现、配置之类的相关标准。
albianj还必须设计和实现一套代码的命名标准、代码的相关逻辑组织标准。
必须建立和实施一套我们使用albianj的标准和方法。因为
我们的业务代码最后都会建立在albianj上，所以必须要夯实作为基础的
albianj和相关的规则规章，我们才有可能实现严格的一致性需求。</p>
  </li>
  <li>
    <p>对于albianj来说，它其实是一整套我们经常使用的功能性工具集的集合，所
以务必要做到在不损失alabinaj整体性的同时，使用合理的切分方法
来设计和实现albianj的各个子功能集。所谓合理的方法，其实无非也就是系
统的划分原则，在albianj中，我们使用了”统一依赖、各自管理、各自实现、
减少干涉”的原则，我们给这个原则取了一个名字：边界原则。具体的办法就
是各自实现自己的功能，尽可能的减少子系统间的相互依赖，尽可能的减少
跨系统的生命周期内的依赖。</p>
  </li>
  <li>
    <p>albianj不推荐并且放弃了“惯性原则”，albianj使用显式的声明来完成所有的功能
性配置或者是代码的编写。每个人的受教育程度不同、开发经历也不一样、
对待系统的认知和视角也各不相同，所以基本上是无法真正的做到大家
在同一个认知水平上来处理事务，也就是说“惯性原则”中最重要的“惯性”对
整个团队来说基本上是无法实现的。所以必须要提供一种技术或者
是一种机制来约束这个开发者各自的”惯性“，已达到对于整个系统拥有
一个一致的惯性的理解。</p>
  </li>
  <li>
    <p>albianj作为大家使用的一个功能性集合，必要还要做到albianl自身必须要
保持简单，并且要做到因为albianj的存在，可以隐藏albianj的后端的业务
部署关系。不管是业务集群还是数据库集群。开发者
只要认为使用了albianj就可以简单的把整个系统当成单机系统一样的开发和
测试。</p>
  </li>
</ol>

<h4 id="架构">架构</h4>
<p>在设计albianj之初，其实并没有一个非常明确的对于架构的标准。我们一
致的认为架构的设计实现与架构的层次类别区分并不是由某些理论或者是某篇论
文或者是某个观点来进行的，而是在真正的实现过程中，随着功能点的增加和实
现的代码逐渐的增多，会自然而然的去对整个的系统进行审视和调整，这部分的
工作会一直循序渐进的继续下去，永远不会停止下来。</p>

<p>到目前为止，albianj已经演化成了具有8个子功能集的大架构。它们之间
并无复杂的依赖关系，除了简单的依赖于同一个kernel以外，别的所有的依赖都
是按需而定的。</p>

<p><img src="all.jpg" alt="all" />
&lt;/br&gt;</p>

<p>在框架开发发展了这么多年的今天，对于一个框架来说，寻找一个架构上标新
立异的机会几乎不可能了。而不同在于在使用的便捷性和框架的设计出发点。albianj主要面
向的就是互联网的开发，这是一个基本的立足点。所以，albianj框架首先
不会是大包大揽的功能性集合，对于一些互联网不会用到的功能一律的进行
生删减，但是对于关心的问题，albianj也结合我们自己的实际情况和需求解决
掉了。从而分门别类划分的这几个功能性子集基本上已经代表了albianj所能精简
的极限了。下面会依次的对这些功能性子集做出解释，并且对于没有被albianj
选择的可能的选型做出取舍的原因。</p>

<h4 id="kernel">kernel</h4>
<p>作为整个albianj的核心，它有2部分组成。一部分是albianj基本上都需要
用到的公共功能；另外一部分也是albianj都需要用到的，并且是更加重要的、
满足我们对于管理service需要的ioc功能。</p>

<p>先说公共功能。这部分包括了很多的功能性的封装，包括但是不仅仅局限于hash
算法、输出型参数、日期操作、网络基本接口、反射基本接口、运行时栈信息、
加密解密安全、数据验证接口、xml解析等功能。他们是所有的albianj功能集可
能会使用到的，但是我们又无法给他们分开归类的功能。我们把这些功能统一的
放到kernel下面的公共功能集下面，以供albianj使用。</p>

<p>这部分的功能对于albianj的使用者来说，也可以被直接拿来使用，但是更多的时
候，除了验证机制以外，别的功能基本上都不太用得着。所以对这个功能包不清楚或者不
知道它的存在并不影响合理的使用albianj。</p>

<p>对于ioc功能来说，这是整个albianj的核心。其二，对于使用albianj作为开发
框架的业务系统来说，也是它们的核心。ioc都是提供了一个控制反转的功能。
将我们的接口和实现分开，然后根据自己的需要加载实现。传统的ioc（比如
spring）会有n多种的注入方式，初始化参数、接口、属性等等。但是
albianj仅仅使用一种方式：接口方式。选取这个方式的主要原因有以下几个方
面：</p>

<ol>
  <li>
    <p>albianj认为提供多种的注入方式会引起代码的混乱和配置的文件的复杂度，对
于可维护性来说，过多的解决方案可能会适得其反。当有多个同事同事使用
多种方法时，虽然它们的方法方案被限制在一个框架内，相互之间还是会增加
学习成本，维护成本；</p>
  </li>
  <li>
    <p>选择接口注入的方式是因为albianj需要对于service进行控制。在比较了一些注
入方式后，接口注入是最适合albianj的一种方式。为了更好的管理
各个service和以后的扩展（这会在下一点中有详细说明），albianj必须要干扰
service的初始化和使用过程。albianj需要给每个service标注它的生命周期，
已提供包括惰性加载之类的各种功能；</p>
  </li>
  <li>
    <p>上面讲到以后的扩展。对于albianj来说，目前的service都是在本地运行的，
不会出现remoting的调用，也不会出现微服务的模式。但是互联网的世界瞬
时万变，现在不需要不代表以后不需要，为了让albianj活的更长久，又更强
的生命力，albianj的ioc功能是被设计成可扩展的。以后如果需要加入
remoting的过程调用，对于albianj来说也仅仅是只需要修改service初始化
部分即可，并且当加入remoting调用后，生命周期和惰性加载将会更加的适
用。</p>
  </li>
</ol>

<p>对于albianj的ioc来说，它仅仅只是需要一个配置文件来控制，配置好name，接
口和实现，除了配置以外，albianj还要求所有的service都必须实现
IAlbianService接口，如果是使用默认的albianj的service功能，为了方便，
albianj也提供了FreeAlbianService的基类。这些规则都满足以后，开发者就可以根
据albianj提供的方法从ServiceRouter中根据配置的name获取service就
可以了。剩下的事情都是由albianj内部来完成。</p>

<p>所以albianj的kernel提供了一个解析xml的功能，albainj会把配置在config文
件夹中的配置文件根据实际启用的功能集来加载和解析xml。但是albianj的xml
解析仅仅是提供了最基本的接口功能，因为每个配置文件的格式都是不一样的，
所以具体的解析配置文件的工作被丢给了实际的功能集来完成，这样一来方便了
开发者对于albianj的二次开发，二来也是大大的节省了albianj本身的代码和人
力成本。</p>

<p>那么现实的问题是那些service从哪里来？这些service是在albianj启动的时候
根据你的配置已经进行初始化了。显然albianj使用了单例模式对service进行了
控制。albianj在使用的时候需要使用者在进程启动
的时候显式的调用albianj的启动函数，已启动并且初始化整个albianj环境。这
部分的启动不仅仅初始化albianj的kernel，更是初始化了使用albianj的所有已
配置的service和所有已配置的功能，包括后面会讲到的数据路由、ORM、配置等
等。为了更快的启动albianj和进程，albianj的加载方式还提供另外的一种异步
加载功能。但是使用albianj必须在albianj加载后使用。异步加载仅仅是提供了
进程可以在加载albianj的同时加载它所需要的另外的一些功能。</p>

<p>albianj的kernel除了提供最重要的这两部分之外，在kernel内部还提供了线程
池和异常处理，也定义和实现了log接口（关于log后面会有详细的叙述）。线程
池的作用主要是提供异步的数据操作，这部分会在ORM和缓存部分为使用和提及，
而异常是整个albianj的基础组件。这里所提及的异常是经过完善后的异常，
和程序直接抛出的异常并不是完全相同。这里的异常将会包括比原始异常更丰富
的堆栈信息，它主要面向的是程序员开发和业务处理过程中的日志，让开发者或
者是运维更快速的确定发生异常的地点和原由。</p>

<p>就目前来说，albianj的service已经足够我们使用，当面对的压力变大，系统
需要扩展的事情，只要扩展FreeAlbianService的生命周期实现功能就可以
了。albianj给每个service都定义了一个生命周期，状态依次是：</p>

<ol>
  <li>
    <p>Normal：表示service刚刚构建出来，还不能被albianj初始化，并且不能被
直接使用；</p>
  </li>
  <li>
    <p>Initing：表示service在构建出来后正在执行albianj的初始化功能，在这里
你可以初始化刚刚生成的service，典型的例子是当service作为微服务提供
的时候，在这里可以想nameservice注册service；</p>
  </li>
  <li>
    <p>Running：表示service已经在正常运行状态，使用者可以通过albianj框架调
用这个service；</p>
  </li>
  <li>
    <p>UnLoading：表示service正在被卸载，一般来说，这步除了设置状态和卸载
initing的时候加载的资源就没有什么了，但是如果这个service作为微服务，
那么需要在这里把service从nameservice中注销掉；</p>
  </li>
  <li>
    <p>Unloaded：表示service已经卸载完毕，正在等待GC回收。service到这一状
态后，它将不能被albianj调用，所以这一状态对于开发者来说是透明的；</p>
  </li>
</ol>

<p>albianj的ioc是albianj所有功能的基础，通过简单而可靠的方式实现的ioc为
albianj提供了最大的方便。在扩展性方面，albianj也给了开发者在统一的基础上最大
的自由。下面的所有albianj组件都是建立在albianj ioc的service模型的基础
上。所以搞清楚albianj的ioc，基本上就搞清楚了albianj的一半。</p>

<h4 id="datarouter">DataRouter</h4>

<p>数据路由其实设计和实现albianj的初衷，也是花费那么多的力气，重新找一个
轮子的最基本的动力。上面提到的kernel其实也是因为
数据路由的存在而设计和实现的，kernel的最初功能只是为了管理数据路由中使
用到的service，但是在实践中发现这部分其实也是整个系统所需，才开始认真的重
新设计和重构了原本属于DataRouter的这部分，然后把它单独的作为一个功能开
放给开发者。</p>

<p>我们设计和实现数据路由很大一部分的原因是：目前没有找到一个合适我们实际
情况的路由组件。数据路由：它主要完成的功能是当开发者对数据库进程操作的时
候，数据路由可以根据配置的路由信息把查询或者是数据提交到正确
的目的地。这些目的地包括但是不仅限于数据库，还有可能是一个分布式的存储，
或者是一个nosql的数据存储服务。目前互联网的现状是，几乎每个公司对于数据库的路由功能相对来说迫
切程度比较大，但是找了一下开源，结果还是挺失望的，发现并没有一个简单而
有效的数据路由可以直接拿到使用。连可以拿
来做二次开发的都没有。那么在无路可走的时候，我们开始自己设计和实现数据
路由。</p>

<p>结合我们的实际情况，首先的问题就是数据存储的异构性。目前我们大量使用了mysql作为主力
存储，mysql确实也因为优异的性能表现扛住了压力，但是这不代表我们
仅仅会在mysql上做开发，可能也会引入别的数据库，比如oracle。所以albianj的
数据路由必须要支持异构的数据存储。在支持异构存储的情况下，后面的扩
展才不会大动筋骨。</p>

<p>其次，根据实际情况，albanj的数据路由必须要支持存储的运维部署。比
如支持双写模式、读写分离模式等等。更高的需求是这些运维模式的支持必须是
无缝的，对于开发者来说是透明的。在支持存储部署模式的情况下，albianj还必须
做到简单而有效的支持数据的迁移等等后期的维护问题。这样在目前我们的运维
人手和DBA人手都不是很充足的情况下，可以做到尽量简单的维护我们的系统，
节省我们的人力成本。</p>

<p>再次，albianj的数据路由必须可以随心所欲的进行控制。比如路由的开启和关
闭，或者是路由的重定向等等。只要存储的数据已经到位的情况下，albianj的
路由必须可以在第一时间进行系统的支持。这部分也需要对开发者透明，仅仅需
要运维的改动就可以实现。</p>

<p>然后，albianj的数据路由还必须支持数据的完整性。对于所有的系统来说，数
据的完整性是必须的要求之一，也是最重要的要求之一。因为数据路由的加入，
使得其实对于开发者来说，后端数据库已经被屏蔽了。后端的数据库是不
是采用分布式部署等等信息全部被屏蔽掉，所以albianj必须要替开发者在
albianj的层面上解决这个数据的完整性问题。这个完整性问题在分布式数据库
的时候被扩大，原本的事务被扩大成分布式的事务，也就是说albianj也要必须
能支持分布式的事务。</p>

<p>最后：也是albianj的一直坚持的一点，在支持这么多的功能的时候，必须要做
到统一。必须要做到配置上的统一、代码级别上的统一。</p>

<p>经过前期实际的项目实施，albianj的数据路由被总结成4种情况:</p>

<ol>
  <li>
    <p>最简单的一种是直接把一个对象保存到路由指定的数据库.
<img src="dr1.png" alt="直接保存对象" /></p>
  </li>
  <li>
    <p>稍微复杂一点的是需要同时保存多个对象到各自指定的路由数据库，典型的
操作是在保存一个对象的同时再保存一份日志.
<img src="dr2.png" alt="保存多个对象" /></p>
  </li>
  <li>
    <p>再复杂一点的保存多份，也就是多写.<br />
<img src="dr3.png" alt="多写" /></p>
  </li>
  <li>
    <p>最后是albianj必须还有路由sql语句的能力，而不仅仅是路由数据对象.
<img src="dr4.png" alt="路由Sql" /></p>
  </li>
</ol>

<p>上面的饼已经画的足够的大，现在是实现这个饼的时候了。把空中楼阁落地。
首先确定的一点是这个庞大的数据路由必须在我们的albianj内部实现，
而不是使用类似于mysql proxy这种组件。最简单的原因就是proxy这种组件只能
解决相关的单一类型数据库的问题，它不能解决所有数据库的问题。也就是说不能解决
在扩展中需要的异构数据存储的问题。那么唯一能剩下的就是在JDBC的时
候做手脚了。先来看一段简单代码：</p>

<blockquote>

  <div class="highlighter-rouge"><pre class="highlight"><code>cmdText="INSERT INTO User01 Values....";
connString = "database=db1;user=root...."
Connection c = new Connection(connString);
SqlCommand cmd = new SqlCommand(c,cmdText);
SqlTransaction tran = c.getTransaction();
try {
    tran.begin();
    cmd.Exec();
    tran.commit();
} catch() {
    tran.rollback();
}finally{
    c.close();
}
</code></pre>
  </div>
</blockquote>

<p>这基本上就是实现一个JDBC最简单的模型，我们需要在这段代码中绣出花了，
让这朵花能支持albianj的数据路由功能。仔细看这段代码，其实除了cmdText和
connString这两句以外，别的代码都是已经被公式化的，也就是没办法更改。
而这两句的是仅仅是能定义的两句。其中cmdText中的表名和connString中的
database值是能自定义的，那么现在的问题就是怎么样通过一个规则来
确定我们这里表名和basedata的值。其实这个规则就是确定数据路由。在
albianj中，因为albianj位于底层，albianj只是调用路由规则，并不定义
路由规则，路由规则都是有开发者定的，所以现在的问题又变成了怎么样来
调用规则？</p>

<p>在调用规则之前，还要确定一个事情：在哪里调用规则？或者说为了什么而
调用规则，一个很明显的问题是不可能让程序员自己直接去写JDBC代码，所
以albianj必须要提供一套对象和数据库的映射，那么ORM也就被引进进来了。有了
ORM，又需要更改表名，那么一个地方已经找到了，就是在数据对象转成Sql
语句的时候把表名给拼出来。那么最后一个问题，database的问题，在什么
时候确定database的值？database的使用是在连接数据库的时候，所以必
须要在连接数据库之前确定这个值。而数据库又和路由相关，所以在确定路
由的时候就可以确定database的值。那么最后，albianj演变成路由3部曲：</p>

<p><img src="dr5.png" alt="路由选择" /></p>

<p>对着这3部的路由选择，在albianj中也提供了一个基类来完成实现这个功能。
在albianj中，FreeAlbianObjectDataRouter基类就是这个实现类，在通常的情
况下，开发者只有继承这个类就可以了，对于自己的路由需求，可以通过这个类
里面的不同的方法来实现，这个类一共提供了6个方法，分成2组，一组提供给读
服务，另外一组提供给写服务。但是仅仅是这个基类还无法完成albianj提到的路由
功能，整个的路由功能必须还需要配置文件的配合。其中drouter.xml就是配置
路由的配置文件，drouter根据每个对象来定义它的路由，在发生数据操作的时
候这些路由会被albianj自动调用；还有一个配置文件是storage.xml，这是配置
所有数据库连接的文件，这里的配置信息需要和drouter.xml中的路由配合起来
使用。</p>

<p>albianj在这里并不会牵涉到实际的业务数据路由拆分策略，这是因为具体的拆分策略都
是需要根据自己的实际业务来决定，而albianj只是要实现一个可以实现这种策
略的机制而不是具体的事实策略，所以这部分将不会在本文中出现。</p>

<h4 id="orm">ORM</h4>

<p>在albianj中，因为一些异构数据库的问题，要实现数据路由，必须要依靠ORM来
解决这个问题，那么现在，我们开始说说ORM。</p>

<p>在albianj中，ORM也是被作为一个基本的组件实现。但是albianj中的ORM和很多开源框
架的ORM有很多功能上的取舍。albianj对于ORM进行了精简，已保留albianj最需要
的部分为前提，把所有不相干的功能全部删除掉。所以albianj中的ORM其实仅仅
只是一个对象和关系数据库的实体和表结构映射和相关操作。它并不提供在ORM层面处理复
杂的对象间关系依赖的问题，它也没有涉及到很多的ORM都会存在的多种功能，
比如查询方言等等。这部分的工作有的被albianj转嫁给了程序员来完成，有的
直接就是不在albianj的设计理念之内，所以被删除了。而被转嫁的部分，在
albianj的设计理念中，可以让程序员更好的完成业务开发，也可以更好的处理数据的加载等
问题，虽然在工作量上看似增加了开发者的工作，其实对于系统整体来说，这部
分的工作可以让开发者更好的应对业务问题和系统压力问题。</p>

<p>但是albianj的ORM集成了上文提到的DataRouter，albianj主要是为互联网开发
而设计和实现的。对于albianj来说，解决大并发和海量数据显然要急迫于解决复
杂而吃力不讨好的ORM中的对象问题、全功能问题等等。也因为加入了DataRouter，albianj必
须要重新设计ORM的数据一致性功能。</p>

<p>数据一致性的问题在ORM中可以简单的转换成事务的一致性问题。当数据库只有一台的
时候或者数据都塞在同一个数据库的时候，数据库可以解决掉事务
的一致性问题，但是当需要使用分布式数据库的时候，显然单机的事务已经
无法满足系统对于数据一致性的要求，所以albianj必须引进能在多台数据库服务器
之间可以保证数据一致性要求的技术。在albianj中，这种技术使用了二次提交
来完成。</p>

<p>在albianj中，每一次的数据库访问被成为是一个job，这个job仅仅与现
实业务相关，和albianj需要访问的数据库实例的数量没有关系。或者说albianj
可以在一次job中访问多个数据库实例。所以，job在abianj中其实是一个分布式
事务的控制中心，它对多个数据库实例的事务进行了抽象和统一接管，但是job
不直接管理各个数据库实例的事务和链接，这部分的工作被albianj交给了task
来处理。在一个job中，需要操作的数据库实例一一对应于task。task接管了对
于数据库实例的操作和事务过程。从而可以让albianj支持分布式事务。</p>

<p><img src="dr6.png" alt="分布式事务结构" /></p>

<p>albianj的分布式事务并没有采用并行策略，也没有采用嵌套策略。而是同时采
用了这两者的结合体。因为分布式事务的性质决定了在一些极端的是情况下，数
据库中的数据还是会有可能存在不一致的情况。这是采用分布式事务的时候无法
避免的问题。但是albianj也进行了最大程度的去规避这个严重的问题。albianj直
接使用分布式锁搭配上job-task结构就可以处理规避掉这个问题。</p>

<p>albianj在对操作数据的接口中，置入了通知机制，当albianj的事务发生错
误的时候，首先是自动的去回滚，但是当发生了硬件级别的错误后，比如断电等
等问题，那么这时候自动的回滚无济于事，所以albianj会通过通知机制来通知
到系统的维护人员，维护人员会对于这个数据进行回滚。那么在这个回滚的时间段，
albianj的锁服务（下面会讲到锁服务）一直锁定着资源保存事务发生时的状态，最
后会由维护人员把这个资源释放。这种极端的情况几乎是不太可能发生的。现实
中，因为业务的特殊性问题，albianj目前服务的严重的资源抢占情况比较少，
所以这套流程还没有真正的派上什么用处，但是albianj为分布式事务提供了这
种机制，以满足以后系统扩展所带来的数据一致性问题。</p>

<p>显然，albianj的分布式事务对于使用的环境要求是相对比较苛刻的，而且产生
的效果并不一定能达到100%的事务完整性。但这并不是我们故意为之，而是因为
分布式事务本身的不可控性导致的。分布式的不可控性到目前为止其实都没有一
个非常完善的机制来解决，而是尽量的使用各种策略方法来规避各种问题，以达
到事务的一致性。</p>

<p>那么是不是就没有一种办法来作为替代，来解决这种不可控性？所谓：魔高一尺，
道高一丈。方法总比苦难多。所以前辈们又研究出来另一种方案来替代albianj
所使用的方法，这个方案总结下来就是：拆分-重试-记录。</p>

<p>我们把它称为“记帐”模式。把整个的事务切
分成多个单个事务，最后由job把这些事务的对象发送到一组消息机器。这时处
理方式分成两部，前台直接给用户返回提交成功；服务器开始自己的工作。服务
器端会有一组机器不停的去取消息中的数据，
取到数据后就执行，并且每次都记录下取到的数据和版本号等等信息，这些信息
用来作为判重的依据，这样依次的执行队列中的消息，当执行过程中发现异常的
时候，还是自动的去回滚消息，如果发生硬件级别的问题，也是通过通知机制来
强行的恢复数据。</p>

<p><img src="dr7.png" alt="记账式事务" /></p>

<p>记帐方式相比albianj方式的优点是它可以重试，可以在网络不是那么稳定的环
境中进行安全的事务，而albianj事务的解决方案其实就是一锤子买卖。它无法
实现在网络不稳定的情况下进行不断的重试来
实现分布式事务。但是albianj说使用的方法的成本更低，性价比相对第二套方案更高，对
于开发人员来说，也是相对更加的方便。所以我们最后采用了目前这种直接通过
job和task的抽象，然后管理数据库实例连接和事务的方式。</p>

<p>事务的问题解决后，albianj开始设计和实现数据访问接口。在albianj中，
对于数据的访问一般都是通过JDBC来处理，目前albianj提供的接口有mysql和
sql server的。当然也可以很方便的就实现oracle的。对于一个数据层操作来说，
也就是简单insert、modify、delete和select功能。这些功能都需要albianj
使用反射和配置文件配合解决。这里的配置文件是persisten.xml。它是一
个数据实体结构和数据库表结构一个对应关系的文件，albianj提供了对于字段
各种属性的配置，比如是否主键、长度、数据类型等等。每个albianj使用的实
体必须在这里登记以便albianj引擎可以在启动的时候加载这些实体的信息，然
后供后面的ORM使用。这个配置文件还提供了和缓存的集成，可以通过使用一个
cached的配置节就让实体自动的支持缓存的操作。这样我们在albianj的
persisten层也要提供一个对缓存支持的操作，所以就有了find簇函数和load簇
函数的区分。find簇的函数表示先查找缓存，当数据无法在缓存中找到的时候，
在调用load簇函数从数据库中直接获取。</p>

<p>为了给程序员提供最大的方便，albianj还集成了save方法。简单来说就是当这个
实体的数据数据库中存在的时候就更新，没有的时候就执行插入操作。那么这就
牵涉到两个问题：怎么让albianj知道数据是不是在数据库中存在？还有一个：
如果更新，怎么知道数据库中的数值和目前保存的数值有什么改变？</p>

<p>要解决这些问题，albianj对所使用albianj的对象进行了统一的接管和管理。
albianj提供一个IAlabianObject接口，来完成对象的统一工作。按照惯例，
albianj也提供了一个基类FreeAlbianjObject供开发者使用。在albianj中，更
多的会被推荐使用FreeAlbianObject基类而不是IAlbianjObject。因为使用
IAlbianObject开发者还必须要自己实现albianj制定的规范，而这个规范
FreeAlbianObject已经实现了，所以没必要再实现一次。而且自行实现还有考虑
不周或者是实现失误的风险，还不如直接使用FreeAlbianObject方便。那么这个
接口到底提供了什么功能呢？它包含了一个IsNew属性，这个属性属于albianj的
kernel属性，开发者是无法更改的，这个属性标明了实体对象是否是新创建或者
是从数据库卡中获取获得。另外这个接口还定义了一个私有的map来管理这个实
体原来版本的值（如果有的话），在albianj执行ORM的时候，albianj会通过这个
map中的值和对象中的值进行比较来确定哪些字段需要更新。那么这也说明了从
另外一个角度来说，当有对象需要更新的时候，必须先从数据库中先load一下最
新的数据，然后才能去使用已经发生更改的对象来更新数据库。</p>

<p>另外一种特殊的情况发生在读取的时候，读取数据的时候并不一定都是通过对象
的唯一Id来获取，虽然albianj推荐使用唯一id。所以albianj提供了IFilterCondition来
实现对于数据的筛选，为了更快的满足业务，albianj还提供了
IOrderByCondition接口来提供对于数据的排序。这是albianj为数不多的不OO的
地方，也是albianj认为为了节省劳动力而可以变通的地方。</p>

<p>albianj的ORM重点并不在于实现全部的ORM功能，它删掉了诸如延迟加载等等很
多原本属于ORM的功能，但是却独树一帜的和数据路由功能结合在了一起。
albianj的ORM通过合理的工作分配和调度，使用最小的代价实现了最大的实用价值。</p>

<h4 id="分布式锁服务">分布式锁服务</h4>

<p>在albianj的设计中，分布式锁服务是从开始就被认为是一个极其重要的主键。
但是因为业务实际情况，导致了在整个系统中，发生资源抢占的情况并不突出，
可以说是几乎不存在，这是特殊业务导致的，并不是albianj本身的问题。
但是我们也确实考虑了分布式锁服务的机制，并且认为还是很有必要实现它，以
保证在一些极端的情况下，数据仍然保持绝对的一致性。我们将会在下一篇的文章中详细的
论述我们的分布式锁服务的构建，这块和分布式存储一样，是一个单独的组件，
详细请查看分布式锁服务的文章。</p>

<h4 id="对象唯一id生成器">对象唯一ID生成器</h4>

<p>albianj作为在分布式系统场景下使用的一个基本开发框架，id生成器也是一个
必备的功能。作为一个在分布式系统这个特定条件下的说使用的id，这个id必须
满足几个特点：</p>

<ol>
  <li>
    <p>id必须唯一，这个好像是废话，但是确实是id的最主要的功能；</p>
  </li>
  <li>
    <p>id必须要自带业务功能，必须要做到“望文生义”，必须看见id就能知道这个
id所表示的意思；</p>
  </li>
  <li>
    <p>id必须是可以有一定的规律的，这个规律id生成器能自己实现最好，如果这
个规律有很强的业务性质，id生成器无法实现，那么也要流出空余的槽位；</p>
  </li>
  <li>
    <p>id必须能明确的携带它的生成信息，以方便发生问题时第一时间定位现场；</p>
  </li>
  <li>
    <p>id必须满足业务和数据存储的需要，必须要在合理的范围内生成；</p>
  </li>
</ol>

<p>根据上面的几点，albianj一共设计了3种id生成器，一种生成的id是给log
使用的，这部分会在log部分中详细说明。剩下的2种id生成器一种是albianj自
带的，它所生成的id是一个32位长的字符串；另外一种是一个单独的由c写成的
服务，它所生成的id是一个int64的值。</p>

<p>字符串的id直接由albianj生成，它依赖albianj自带的kernel属性文件，位
于config目录下。这个字符串由4部分组成：</p>

<p>4位长的machineid-7位长的appname-14位长的时间（精确到秒）-4位长的随机数</p>

<p>对于machineid和appname来说，它们如果长度长于规定的值将会被截取，如果长
度长于规定的值，会在左边进行pad操作。这样，albianj就可以保证控制生成的
id一定是32位的长度。这个生成的字符串起初被设计用来作为对象在数据库中的
字段，因为字符串的扩展性和自定义性实在太好了，他的诱惑实在太大，但是当
用字符串作为主键的时候，引起的性能问题也相比int会慢好几倍，所以最后
albianj放弃了用字符串作为对象唯一标识的做法，但是这个id被用在了job上，
他被用来标识job，让job在整个系统中唯一，并且也被用来处理当系统发生异常
的时候，让运维可以快速的通过id定位事发现场，进行进一步的处理。</p>

<p>我们在albianj真正用来做对象唯一标识的是int64的整数型id。整数的id相对于
字符串来说肯定是能快上好几个数量级的，特别是在索引筛选的时候。所以
albianj最后选择了用这个方案来解决对象唯一性问题。</p>

<p>整数型的id也采用了2种方式。一种是二进制按位移动构建的，另外一种是10进
制，采用乘法的方式实现的。二进制的方案是实现简单，保证不会溢出，但是程
序易懂人类难理解。10进制的方法实现也简单，但是如果保证不溢出的话需要精确
的计算，还有一个是逼格不够高，总是觉得有点土，但是好处是人类能看懂，而
且很容易的就能分辨出来。不管是二进制还是十进制，他们的实现思想都是一样
的，就是按照位数进行左移。</p>

<p>一个数由4部分组成：时间戳、生成id的machineid、id的类型、随机数
。二进制的数前32位是时间戳，接着8位是machineid，然后是10位的类型，最
后是10位的随机数。而十进制的组成是按照真实的数据位来划分的，真实的数据
位就是十进制为一位，而十进制为了规避int64的最大值问题，还必须要舍去掉
最高的一位，所以一共就只有19位，而又因为兼容原来的数据类型而不至于更改
所有的数据库表，所以我们的id还是能带符号的，这样就被减少了一位，所以一
共就只有18位可以供使用。所以十进制的id是：32位二进制的时间戳转换成十进
制后左移（这里是直接按照十进制移动，而不是二进制，下同）9位，然后接3位
machineid的值左移6位，再接4位随机数左移2位。最后的2位空出来是为了给程
序自定义数据路由使用。这里没有type对吧？因为在我们的系统中，有明确对象
类型的对象才会使用十进制数的id来区分，id生成器已经最后空出来了2位，就
是给开发者自己标注使用的，所以这里的十进制id是没有显式的加入type信息的，
因为对我们的业务来说，这些type都是已经被定义并且被固定的。而且也不用担
心id会重复的情况，不一样的type会使用不同的id随机数槽进行计算，就算在单
位时间内生成同样的两个id，也因为type的不同，他们不会被保存在同一个数据
库中作为同一个类型对象的主键，所以并不冲突。但是为了后期在使用上有
更大的自由使用幅度，albianj的id生成器也有一种后4位递增的规则id，以保证当业
务需要使用hash或者是取模运算做数据路由的情况，这种情况还在id中加入了
type的值。</p>

<p>为了更好的数据库性能，albianj的id生成器生成的id都是自增的，但是它
并不保证在相对狭小的时间内递增，而是保证在一大段的时间内单调递增，这个
一大段的时间可以确立在1s-2s这个时间段。这也就是说并不能把id生成器生成
的id用来做时间向量。但这并不会极大的影响数据库的性能，
从理论的角度出发，可能会让数据库的索引有分页，断页的操作，但是从实际的
情况来看，基本上对于数据库的影响是没有的，所以可以放心大胆的这样设计和
实现。</p>

<p>在设计的时候，albianj的id生成器是接入nameservice，使用nameservice来保
证id生成器的高可用性，但是在实践的过程中，发现其实id生成器主要依赖的仅
仅是一个时间戳，albianj可以把生成的id看成是一个时间向量，而id生成器服
务是一个无状态的服务，所以最后albianj放弃了原来接入nameservice的计划，
而是使用了平行部署+负债均衡的方式来实现了id生成器的高可用性。</p>

<p>albianj实现id生成器的时候采用了短链接的方式，也提供了长连接的方式，但
是默认和推荐使用短链接。这是和我们现实的环境有关的，albianj面对的服务
器集群有可能是跨机房部署的，在大内网内，长连接相对短链接来说不是那么的
稳定，使用短链接可以有更高的健壮性和可用性的保障。</p>

<p>为了更好的使用id生成器，也为了兼容现实中正在使用的多语言情况，albianj
还给id生成器集成了一个restful服务，通过restful服务，可以满足所有站点对
于唯一id的需求，也大大的方便了隐藏后面的id生成器集群。</p>

<h4 id="log系统">log系统</h4>

<p>作为一个要在分布式系统中运行的框架，日志系统是一个必备的功能。不管是开
发人员还是运维人员，但系统出现问题的时候首先是由监控系统发现，但是监控
系统一般只能是发现问题，并不能诊断问题的原因，这时候就需要日志来帮忙。
日志：它是系统在线上运行时的黑匣子，通过日志往往可以救我们一命。</p>

<p>albianj的日志还结合了异常处理系统。对于抛出问题的异常，albianj会详细的记
录堆栈信息，以便后期的维护和检查使用。albianj也顺带解决了可能的信息泄
漏问题，类似于java中经典的tomcat抛出的带有内存信息的提示信息和c#报出的
“黄页”。albianj解决这个问题的方式是使用2种不同的方言来分别给出信
息.当发生异常或者是发生错误的时候，albianj定义了一个总体的、模糊的、概
述性的信息以提供给用户，而会把详细的堆栈信息记录到我们的日志系统。两者
之间通过使用上文讲到的id生成器生成的id和一些干扰的id作为关联，以方便运
维人员方便的定位到底是哪台服务器出了问题。albianj并没有使用类似于linux中
的errno的机制来逐个的定义错误，这是因为errno实在太难控制和管理，随着时
间的推移，项目需求的增长，团队的各种变迁，最后如果使用使用errno，首先
得有一个相关的冗长的文档来解释，其次是必须再专门派一个人去维护整个文档
和所有的errno的定义。而这里说出现的异常信息或者是错误信息，作为客户并
不需要具体的出错原因，而只是仅仅可以在报告错误的时候能有一个标识，而对
于系统来说，根据这个标识就可以查找到日志，这样就可以获取出错的信息，仅
此而已。而对于如果是相同的异常或者错误，使用类型或者是通过出错的地点就
可以知道是不是同一个异常，所以根本没有必要用类似于errno这样的重型机制
来解决异常和错误的问题。</p>

<p>albianj的log基于log4j实现，这样做的好处是大大的方便和节省了很多代码量
的开发，第二个好处是log4j几乎实现了所有的日志可能发生的记录行为。这两
点满足了albianj对于系统的需要。当albianj启动的时候，就会去建立日志文件，
当日志增大到一点的size后就会被切分到另外一个新建立的日志文件。建立的文
件名上都有新建的时间点，以便查找的时候可以尽可能方便的定位。</p>

<p>目前因为人手的问题，albianj的日志还是散布在各自的服务器上的，这给日常
的运维带来了一些额外的工作，并且也并不是那么的智能化和自动化。后期，我
们将会设计和开发一个logdb。logdb不仅仅会统一而集中的收集和管理各种日志，并且允许
在收集日志的时候加入需要的一些特殊业务。logdb已经在考虑之中，后续会有
logdb的文章被推出来。</p>

<h4 id="缓存系统">缓存系统</h4>

<p>在现在的互联网企业，几乎没有一家敢说自己可以不用缓存，我们当然也不例外。
在设计和构建albiaj的时候，也把对缓存系统的支持作为一个必不可少的组件加
以了考虑，作为albianj一贯要求的标准，在实现albianj对于缓存支持的同时，
尽可能的做到albianj所强调和坚持的一致性原则。经过努力，albianj不但把对于
缓存的支持实现了，而且还做到了对于开发者来说绝对的一致性和未曾强调的一
键使用。</p>

<p>在现今的互联网大环境下，缓存最大的使用场景就是在数据库之前架设，用来把
相同请求的数据暂存在内存中，然后在单位时间内或者是某事件未触发的情况下，
供客户端请求，以减少客户端大量的并发请求被直接发送到数据库，导致数据库
扛不住压力而down机。在albianj中，缓存主要的用处也是在于缓存数据库的数
据，减少对于数据库的请求。但是albianj并不会牵涉到缓存层的物理部署，也
不会直接实现缓存，而是作为一个客户端来使用缓存。</p>

<p>albianj主要支持的是分布式的redis。albianj内置了redis的客户端，并在
redis的客户端上进行了二次开发，以让albianj满足对于缓存的需求。albianj
的缓存依赖于config中的cached.xml配置文件，在这个配置文件中，可以配置
redis的服务器信息，也可以配置redis的部署情况信息，albianj都会对此加以
支持。但是albianj并不支持redis的集群功能。这是albiaj使用缓存的出发点决定
的。albianj只是使用缓存作为一个缓冲，而并不是拿来做存储，虽然redis也有存
储的功能。所以这部分数据的定位应该是易失且可失数据，不存在也不会干扰程
序的正常运行，如果要做高可用，一个多主+各主一个master就可以实现了，如
果需要合理的利用各台机器，那么就必须要重新在客户端层再增加一个负载均衡
层，使用算法执行多写主操作，现在有开源的组件可以使用，但是相对来说代价
有点大，所以albianj只使用最小的功能就可以满足albianj对于缓存的需要。</p>

<p>在albianj中，最大的需求就是在ORM中缓存数据。albianj在persisten.xml中增加
了一个cached的配置节，可以通过这个配置节让albianj接管的对象打开缓存功
能，开发者借助这个配置节就可以让albianj自动的实现缓存功能。ORM在使用缓
存的时候因为是要发生网络连接、发送数据等等步骤，所以ORM中集成的缓存功
能被设计了异步执行。从而可以不用担心对于主流的业务造成影响。</p>

<p>还有一种情况是开发者必须要自定义缓存，可能存储的不是直接从ORM中取出的
数据，而是已经经过业务加工的数据。那么albianj也考虑到了这点，albianj也
暴露了直接操作缓存的接口，以供开发者实现自己的缓存目的。</p>

<p>albianj还支持本地缓存，然后本地缓存一般不推荐使用。本地缓存经常会越用越大，
内存也容易溢出。但是albianj还是设计并且实现了它。使用LRU机制对于本地缓
存进行了瘦身处理，还规定了缓存的最大大小来强制性的约束缓存的使用。
albianj实现本地缓存的主要目的是给albianj本身自己用的。在albianj中，由
于实现的需要，中间存在很多的反射等调用。每次调用反射都是一件很浪费性能
的事情，所以我们需要使用本地缓存把这些信息缓存起来。而这些信息又不大，
远远小于内存溢出的阀值，也远远小于我们定义的缓存的最大大小。所以
albianj可以安全的使用本地缓存来给自己提供性能上的提升。</p>

<p>总的来说，albianj不是真正的去实现一个缓存服务器，而是将目前大家都使用
的缓存服务集成到albianj内部，以供其使用。albianj的缓存集成既可以实现对
于自身功能的需求，又对开发者提供了一致的接口，并且透明化的处理，而且还
未定制化暴露了接口。从albianj的一站式定位来说，缓存的集成再次体现了
albianj所强调的统一化。</p>

<h4 id="配置系统">配置系统</h4>

<p>作为一个IT从业者，当系统发生故障的时候，经常需要我们快速而准确的去排除，
而且一个很重要的前提是不能让现在已经上线的系统停止下来。这就像是一架飞
机正在正常的飞行，突然引擎出现了问题，这时候需要机械师现场排除故障，而
且不能让飞机降落更不能让飞机掉下来。其中的难度当然是可想而知。正是因为
有了这种需求，我们才需要一个可以在系统运行的时候，可以动态改变系统运行
方式的一种方法，而这种方法对于albianj来说，就是内置一个配置系统。</p>

<p>albianj的配置分为两部分，一部分是albianj依赖的xml配置，它主要负责为
albianj的正常运行提供原信息。这部分的配置目前是无法在运行时更改的，如
果要更改必须停止服务。albianj解决xml配置是提供了一个统一的接口：
IAlbianServiceParser。同样，albianj也提供了一个FreeALbianServiceParser
来保证统一性。但是albianj没有提供一个完整的解析xml的算法，而是提供了一
个完整的xml的parser类：AlbianXmlParser。开发者可以自定义自己的xml解析
接口，解析xml的格式。然后通过使用AlbianXmlParser类来完成对于xml的解析。
这部分信息除了本地加载还可以提供远程加载服务，使用远程加载，可以间接的
实现配置重置，但是我们并没有对这个功能加以很多的测试，所以并不推荐使用。</p>

<p>重点要讲述的另一部分：动态配置。albianj使用数据库作为动态配置的持久化
层，使用albianj提供的缓存系统作为抵挡高并发的解决方案。albianj的动态配
置为树形结构，级数最多支持6级。理论上每个节点都可以有任意数量的子节点，
并且子节点还可以继续派生子节点，每级子节点都可以作为叶子节点存在，作为
叶子结点的值可以是除二进制外的任意类型。</p>

<p>albianj为配置系统的使用提供了各种不同的接口，包括简单运维的接口也一并
提供了。albianj将动态配置的管理分为：初始化，运行中两部分。结束之所以
不加以考虑是因为albianj使用的是主动+被动的缓存策略，放弃了更改通知这一
原先流行，现在已经落后的策略。需要使用albianj的动态配置系统，必须在第
一次使用的时候或者是缓存集体失效的时候初始化缓存，这一步经常被称之为”
充缓存。albianj还为了解决缓存的集体失效问题，对于不同类型的缓存或者对
于不同用处的缓存做了不同的过期时间处理，对于不经常变动的缓存直接进行了
不过期处理。albianj会自动的发现和使用缓存，和开发者无关。</p>

<p>然后，当缓存失效的时候，albianj会自动的去再次从数据库中获取值并且加载
到缓存中。当albianj的动态配置项发生变动的时候，albianj也会主动的去更新
缓存中的配置项，如果此次通知失败，albianj提供了一个可以控制到具体缓存
项的接口，以维护者或者运维人员手工的去更新缓存。</p>

<p>主动缓存和被动缓存的使用使albianj放弃了原始而容易引起不一致性的通知机
制更新配置项的方法。目前的很多项目基本上都是基于zk来进行动态配置项的一
致性管理，但是因为网络的问题或者是环境的问题，zk其实是无法保证一定会更
新到缓存的，一旦无法更新到缓存，那么就会引起配置项的不一致性。也有团队
使用自己的消息队列来完成一致性的管理，鉴于我们以前使用的经验，这也不是
万无一失的，以前在5173的时候，我们就会经常因为动态配置项不一致而重启我
们的服务器，因为除了重新加载一遍所有的配置项，基本上没有什么办法来应对
这个麻烦的异常。</p>

<p>albianj的动态缓存在数据库中被分成6个表，每个表存储一级节点的值。对于最
后的5，6节点表来说，数据可能会面临好几个级数的增长。这对于使用albianj
的配置系统来说也不是问题。albianj本身自带路由功能，所以可以方便的将数
据量过于庞大的表进行拆分，只是albianj对于动态缓存的策略是使用父节点进
行拆分，所有同一父节点的子节点必须全部存储在一个表中，以方便albianj加
载数据。</p>

<p>因为动态配置项对于整个系统的重要性，我们对于动态配置项表还增加了一定的
记录处理。每个表都增加了lastmodify，lastmender，createtime，author等信
息，以方便查找最后一个更新的人员来问询更改的目的。也为了方便的对于动态
配置进行控制，albianj还为配置节点信息增加了enable的字段，以方便管理人
员快速的开关该配置项；最后，albianj的动态配置项都不会被删除掉，而是由
albianj进行了“软删除”处理，albianj对于动态配置项增加了isdelete项，以方
便此项控制。</p>

<p>为了更好的识别动态项，albianj特意在id生成器中申请了id为00的id作为动态
配置项的id，以方便维护。</p>

<h4 id="restful服务">Restful服务</h4>

<p>restful是目前为止albianj所支持的最后一个组件。它是我们的内容中心刚刚起
步的时候才被提起，后来慢慢的被使用的越来越多，直到目前，内容中心和我们
内部的一些接口基本上都走了这个内置的restful。</p>

<p>对于restful，albianj开始其实并无多大的需求，腾讯内部有一个微服务的服务器，
使用tcp来完成内部的通讯，同时带有负载均衡等等功能。但是由于这样或者是
那样的原因，使用起来各种的不便，而内容中心的主要职责是提供一致的接
口，所以其实微服务并不太适合网站的开发，而是适合类似于手机或者是内部的
多任务管理的使用场景。而网站，还是restful这种多服务器平行部署比较适合，
一来比较简单，二来维护和扩展也相对方便。</p>

<p>所以albianj设计和实现了restful的服务。restful的内部构建其实很简单，只
要就是一个类似于MVC的模式，而对于restful来说，V只有两种可能的情况：xml
或者是json，所以这部分基本上就相当于省略了。所以对于restful来说，就是
简单的controller和action。albianj基于jetty二次开发了servlet，重新实现
了doget个dopost接口，并且albianj通过kernnel的集成，使用kernnel提供的
service管理功能，将restful的service全部管理了起来。对于每个action，
albianj提供了AlbianRestfulActionAttribute来标识，每个action还提供了一
个verify的接口，以方便对于每个action进行访问的有效性验证。</p>

<p>为了开发者更好的体验，albianj统一了action的函数签名，albianj提供了一个
访问上下文的AlbianRestfulActionContext对象来管理对于action的访问。
action context中包含了当前上下文的resuest、response、sessionid等等信息，
这些信息都是通过jetty或者是客户端提供而得到了。</p>

<p>当restful的接口返回的时候，对于开发者而言也很简单。albianj也对接口的返
回进行了统一。albianj在action context对象中开放了一个result的属性，开
发者只要将返回值正确的设置到这个属性albianj将会自动的进行返回处理，直接
对开发者进行了透明化的隐藏。</p>

<h3 id="成效">成效</h3>
<p>内容中心是第一个真正全面的使用albianj的项目。因为我们的一些业务的特殊性（比如我
们对于资源的面对经常是无抢权更新的），albianj在一些完整性或者是一致性
上都做了相关的一些让步。做出让步并不是指albianj不能做到，而仅仅是为了
系统的简单，我们对于albianj进行了裁剪。但是一些基本的功能和一些基本的
要求，albianj还是一丝不苟去实现的。</p>

<p>使用了albianj后，我们统一了开发者的代码规范，我们也统一了我们维护系统
的一致性。但是在实际的研发过程中，其实并没有给开发者带来更多的在开发时
间上的紧迫感，相反，还可以为开发者赢得相对宝贵的时间。因为albianj在
persisten上做了大量的工作，使得开发者可以完全的不同考虑后端数据库的部
署和数据的拆分对于系统的影响。如果使用标准的三层架构，那么DataAccess层
其实albianj已经帮开发者解决掉了。而对于开发者来说，增加分布式锁，编写
业务性质的数据路由服务，配置albianj的基础配置文件这3项是不管使用什么技
术或者组件，由于系统结构的变迁，这是省不掉的。</p>

<p>因为albianj对于persisten层的精益求精，导致了开发者在开发分布式数据库的
程序的时候几乎是0成本的。而且对于后期的扩展性也有极高的支持。对于分不
分表经常出现的需要重新平衡数据的情况，虽然albianj并不能解决掉这个问题
（因为这个问题主要和业务相关，和albianj并无任何的关系），但是albianj可
以在通过更新几个配置文件不动一行代码的情况下就给予完全的支持。</p>

<p>对于使用albianj的系统，系统的维护也变得相对的简单和快速。因为albianj不
停的强调和强化统一，并且albianj也提供了一站式的开发解决方案，所以对于
开发者来说，他只需要在合适的地方填空合适的代码就基本上可以完成复杂的业
务开发。而对于系统本身来说，因为albianj是为我们量身定做的，而且从设计
上就强调了可维护性，所以整个系统都不会出现复杂税的现象，所有的主键也都
是“一键式”启用的，对于开发者来说，很多的功能都是透明性存在的。</p>

<p>我们对于使用albianj的开发者也进行了实验。参加这个实验的有两个人：一个
是A，刚刚毕业的硕士，没有任何的经验；另外一个是B，起先毫无java经验开发php的开发
者。他们使用的结果如下：</p>

<p>A： 1天上手，2个小时就可以正常使用；
B： 2天上手，2个小可以正常使用；</p>

<p>后来我们分析，A快于B主要是因为A其实在学生时代其实有java的经验，所以上
手比较快，而B其实满脑子的PHP思想，要一下子转变还是比较困难一点的。但是
不管怎么说，这个结果可以说明，使用albianj都可以快速的属性，进而可以快
速的开发系统。</p>

<h3 id="总结">总结</h3>

<p>我们之所以设计和实现albianj并不纯粹是因为好玩，更不是为了重新发明轮子。
但是不得不说，我们设计和实现albianj是更好的发明了互联网圈内的轮子，这
个轮子可能缺了一个幅，有可能采用了真空胎的结构，所以可以说，它只能很舒
服的被适用于互联网开发内，对于企业的开发，其实并不是那么的合适。</p>

<p>从我们设计和开发albianj，其中可以说明几点：</p>

<ol>
  <li>
    <p>现在的开源为了有更好的覆盖面，它们已经被加入了更多的功能使用场景，
但是对于一些特定的场景，特定的一些痛点，往往缺乏有针对性的支持，所以现
在来说，其实使用开发的成本已经越来越高了，使用开源软件，特别是这种开发
框架类的，不但要有使用的能力，甚至还要有阅读代码和二次开发的能力。</p>
  </li>
  <li>
    <p>albianj在实现过程中使用的一些技术，也并不是很难或者是很潮的技术，更
不是那种能拿出来唬人的技术，只是一些平平常常的，就像家常菜一样口味
的技术。这说明其实框架的开发并没有那么难，更没有那么神秘，一般的开
发者完全可以自行的来实现。</p>
  </li>
  <li>
    <p>albianj在设计和实现的过程中，放弃和裁剪了很多的功能，只实现了我们需
要的功能。这说明一个框架的好坏，甚至是好用不好用并不能指望于这个框
架的功能是否完全，而是这个框架是否适合你的使用场景。一个简单、好用、
适用、够用的框架才值得去用。</p>
  </li>
  <li>
    <p>作为开发一个总体上的框架，一致性和可维护性必须从设计开始就要加以考
虑，并且在实现的时候必须加以一丝不苟的执行。这样设计和开发出来的框
架才能让开发者快速的熟悉和使用，让代码的管理者对于后期的业务扩展和
重构更加的自信。所以在前期，就算99%的技术和时间都花在一致性和可维护
性上也不为过。</p>
  </li>
  <li>
    <p>对于开发者怕出现bug的问题，其实有句话叫做：多做多错，少做少错。但是
你不能仅仅因为怕出错就不去做。所以从设计和开发albianj的真实实践中，
我们总结出一个开发伦理：如果不能解决所有的bug，那么就必须提供一个可
快速修复bug的机制。</p>
  </li>
  <li>
    <p>作为一个管理者，有效的控制是必须要追求的。从系统实现的角度来说，要
做到有效的控制，必须要做到统一性和单维性。统一性保证方法的实现和维
护，单维性保证实现的时候能不偏离方向。</p>
  </li>
</ol>

<p>最后：技术是不能解决掉所有问题的，技术最多能解决掉70%的问题，剩下的30%
是需要靠管理来进行制约的。技术可以解决一切问题，但不是一切问题都可以被
技术解决的。</p>


                    ]]>
                </content:encoded>
                <guid isPermaLink="false">/blog/2015/albianj/</guid>
                <description>
                    
                </description>
                <pubDate>Thu, 05 Nov 2015 00:00:00 +0800</pubDate>
                <author>94geek.com by Seapeak.Xu</author>
            </item>
        
    
        
            <item>
                <title>腾讯文学内容中心分布式文件系统的设计和实现</title>
                <link>http://www.94geek.com/blog/2015/DFS/</link>
                <content:encoded>
                    <![CDATA[
                    <h2 id="关键词解释">关键词解释</h2>
<ol>
  <li>逻辑集群：具有相同groupname和syncgroup的storage机器组成的集群。</li>
</ol>

<h3 id="摘要">摘要</h3>
<p>我们设计并实现了一个分布式文件系统(以下简称DFS），它是基于linux的文件系统，并面向大规模数据
存储、海量数据访问、具有良好可伸缩性的文件系统。DFS设计运行在廉价的linux系统中，但是它依然
为数据提供良好的一致性和完整性。</p>

<p>虽然DFS和业界很多的分布式文件系统有很多的相似性，但是它还是更面向我们当前遇到的一些业务的实际
问题。并不是构建在某些论文或者大理论之上，所以它对于我们来说他拥有更好的业务适应性、维护性和可用性。</p>

<p>DFS的出现完全满足了我们对于分布式文件系统的要求。它现在已经部署到我们的线上系统中，来给我们的书库
提供存储和访问的能力。目前为止，我们已经小规模的实验性部署了9个数据节点，存储了600g的数据，但是现在
线上数据还在源源不断的导入进DFS，保守估计前期将会有超过1T的数据用DFS来存储。目前还有一个业务也将会
部署到我们的DFS上，保守估计这个系统会有20T左右的数据。</p>

<p>本文档中，我们主要讨论DFS对于文件在分布式应用中的架构和特性，最后会列出我们的测试数据。</p>

<h3 id="简介">简介</h3>
<p>我们的DFS系统目前的业务主要用于存储文章的章节内容。对于一个阅读性质的网站，其中最大的存储量就是由
作家生成的文章。这些文章量大并不适合使用传统的关系型数据库存储。将文章在系统中抽象，它仅仅是一个对象，
所以我们首先想到了将它存储在某个固定的文件系统中。但是目前很少有文件系统能保证水平扩展的能力，可以增加
机器来解决数据量和访问量的问题。对于数据来说，它还应该具备维护数据的完整性、一致性的能力。
也许开源中，最合适的就是FastDFS了，但是它同组内完全镜像的方式对我们来说无法接受，
它不能实现增加机器就可以平滑的增加我们的性能和吞吐量。</p>

<p>所以我们自己设计并完成了一套DFS，我们的DFS在一些基本的要求上，和别的分布式文件系统都有很多一致的追求目标,比如：数据的完整性、
一致性、数据的恢复能力、可伸缩性、可靠性、可用性、以及成本问题。但是它也有区别于别的分布式文件系统的地方：
比如不需要兼容任何的公共接口，不需要考虑文件的索引问题。所以我们在设计的初期就对DFS采取和别的分布式文件系统
不一样的策略，并进行了折中的一些选择，引伸出了完全不同的设计和实现思路。</p>

<p>首先，我们的DFS不需要保存信息的元数据。在我们的整个系统中，文章的内容只是文章的一个属性，而并不是文章的
全部信息，所以在关系型数据库中保存文章的属性信息是在所难免的。所以这种模式就决定了我们可以将这个分布式文件系统
做成类似于KV的结构模式。也是因为没有元信息，整个系统的架构将会大大的简化。相比于google的GFS或者是apache开源的
HBase，去掉了metedata服务器，整个系统唯一的单点隐患被剔除掉。可用性上也得到了很大的提升,而相对于DFS系统本身，
我们通过key可以精确定位所需要的内容。</p>

<p>其次，和GFS一样，我们认为我们的磁盘是很容易毁坏的，所以数据的完整性和安全性是很重要的一个命题。第一个版本我们
采用实时同步和单盘恢复的两种同步方式来解决。在同步的过程中也有可能出现同步不完整或者同步出错的情况，这个情况将会
在下一个版本中采用出错同步再次同步的方式来解决，相对于同步完的数据，在下一个版本中还会有数据的完整性校验机制来解决
数据可能会引起的完整性问题。</p>

<p>第三，我们的DFS和传统的DFS一个很大的不同就是我们的数据将会面临经常被更改的情况。不仅仅只是尾部增加操作，而是不知
修改位置的增删改操作兼具。又因为没有了元数据信息，所以我们的存储内容必须自带元信息，而且必须给用户给与适当的放大或者缩小
的功能和方便，所以我们合理的将文件稀疏化，合理的放置了文件的空洞来解决频繁的增删改问题。</p>

<p>第四，放弃了系统级别的元信息导致内容自带自解析信息，所以对于我们来说，数据的一致性也是一个需要解决的问题。没有了
元信息服务器，我们没有了可以唯一控制文件被线程安全的写入的机制，我们也无法控制同步中对于同一部分内容先后执行次序的问题，
这一节将会在数据一致性模型中详细讨论。</p>

<p>第五，我们的DFS不需要缓存，因为DFS的内容是稀疏性质存放，而且章节内容也是随机读取的，所以这部分的内容应该是由业务来承担，
而不是DFS自身来承担。DFS仅仅需要做好数据的存储、安全、唯一、备份功能就可以了。</p>

<p>最后，我们不需要兼容任何的标准或者是接口，包括posix的api，这样就对我们的DFS进行很大的简化，并且我们的dfs基于linux的文件系统，
所以我们没有必要要深入到linux的内核进行对于vnode或者是inode是控制。我们只需保证我们的DFS能在linux系统io接口的标准上安全而唯一的
存放、访问就可以了。</p>

<h3 id="设计概述">设计概述</h3>
<h4 id="目标">目标</h4>
<p>在上面的介绍中，我们介绍了一些DFS相当于市面上通常的DFS所存在差异和相同点。在设计满足我们所需要的DFS的过程中，
我们的设计目标既有已经被证明可行的，也有相当一部分是需要自己的摸索的。可谓是机会和挑战并存。之前，我们也提到了
一些我们的设计目标点，这里我们讨论一下我们的设计目标。</p>

<ol>
  <li>
    <p>整个系统必须可以简单而容易的水平扩展，尽量做到增加机器就可以完成系统的存储量和系统的吞吐量的提升，而且这部分工作必须
让系统自动来完成，随着机器的增多，我们的人手将无法从容的应对手动管理机器的行为。</p>
  </li>
  <li>
    <p>系统也必须支持一定界限之内的垂直扩展，类似于增加磁盘挂载点、增加磁盘容量等等操作也必须要在系统给与支持，并且这个支持完全
是自动化的;</p>
  </li>
  <li>
    <p>系统必须是由廉价的机器组成的，所以机器的失效应该是经常发生的一个故障，在整个的系统中，这个故障将被看做是一个正常的系统事件，
系统必须能快速（30s之内）的发现这个异常，并且将访问避开这个发生故障的机器;</p>
  </li>
  <li>
    <p>系统必须充分发挥每一台机器的性能，简单的主从模式并不是我们的首选，我们更需要多主的模式来应对海量的访问；</p>
  </li>
  <li>
    <p>系统必须支持大小文件的存储和访问。我们的业务存储数据量基本都是文章内容，一般在KB级别，但是也会有一些完本的数据等需要存放，
所以我们的存储将会变成MB级别，对于这两者我们必须都进行支持，对于GB级别的大文件，腾讯有TFS来使用，而且效果不错；</p>
  </li>
  <li>
    <p>系统必须保证数据的安全性和数据的一致性。这一点不需要太说明，几乎每个系统都需要保证这2点；</p>
  </li>
  <li>
    <p>系统必须支持数据的频繁更改，对于DFS来说，modify总是最难实现的，它不仅仅会引起文件的空洞问题，更是数据一致性的杀手。很多的DFS
不从根本上支持modify功能，它们把modify认为是一次新的insert，然后通过版本号或者类似的方法来确定先后顺序，最后再通过合并减少文件空洞
并且解决掉数据的一致性问题；但是我们的业务决定了我们必须要面对这个问题，相对于我们都把modify认为是insert，我们的磁盘浪费实在
太大，得不偿失；</p>
  </li>
  <li>
    <p>机器的增加、磁盘的增加或者挂载点的增加，都不会让数据进行再平衡。在分布式系统中，数据的再平衡往往是耗时最长的工作，而且控制度也
不是非常的准确，经常需要多种措施一起才能保证数据的平衡和一致，所以在我们的系统中，除了灾难恢复或者同步以外，不存在任何的数据再
平衡现象；</p>
  </li>
  <li>
    <p>还有一个不得不吐槽的问题，内部的网络总不是那么的好，经常会出现波动的情况，所以我们的系统必须可以承受一定的网络颠簸，这里
不仅仅是对于客户端到存储这个链路来说，而是整个的DFS系统内部，也要对网络的通讯进行一定的考虑，从而可以让系统之间的分布式状态机
能顺利的运行。</p>
  </li>
</ol>

<h4 id="架构">架构</h4>
<p>为了达成目标，我们对DFS进行了最简化的设计。和目前的大家经常和使用的DFS不一样，我们的DFS去掉了元数据功能，但是保留了该服务器节点(
以下我们统称这个节点为tracker）。这点很像FastDFS。简化掉存储元数据的原因我们在上面曾经论述过，简化
后的服务器只剩下了tracker和存储服务器（以下简称storage）。</p>

<p><img src="./2.png" alt="arch" /></p>

<p><br />
tracker的主要用途从存储元信息变成一个状态控制服务器和负载均衡服务器，或者说它成了一个类目录服务器。一方面它主要和系统中的storage配合，对storage进行健康检查和状态维护；
另一方面，tracker还需要对客户端的访问进行路由工作。这样的无元数据的设计不仅仅只是从根本上解决了元数据导致的单点问题，
而且还大大的减轻了数据的完整性在系统中的压力，从实现的角度，也大大减少了代码量，
使tracker节点变成一个可任意水平扩展的节点，从而解决了系统中最不稳定的一环.</p>

<p>相对tracker来说，storage的工作将会复杂很多，它不仅仅要做文件系统本身的“增删改查”工作，还需要肩负一个同步的工作。为了简单，我们把storage
的存储文件只做镜像同步，不做相对复杂的打散再存储工作。也为了尽量合理的利用机器并且可以快速的通过增加机器的方式来达到我们对于存储量和性能的提升，
我们对同组内的storage进行了分片处理，也就是逻辑集群。在同一个组内，分成一定量的syncgroup，每一个syncgroup内部的服务器是镜像的，不同的syncgroup内的storage之间是
平行的，在同步上不存在任何的关系。这一设计在维护的时候增加了一个人工的syncgroup工作，但是它简化了同步打散的算法，最重要的，增加机器不需要移动原先
的数据，使得几乎可以认为增加机器就是在增加DFS的存储量和吞吐能力。</p>

<p>storage的改变不会迁移数据，也会导致性能的热点问题。新加的storage负载可能不够，但是老的数据被频繁的访问。对于我们来说，老的数据基本上都是被用来做读取之用，
业务的服务可以规避掉这个问题。对于写来说，本身就不会有太多的请求，所以这样的设计是我们所能接受的，对于我们这种特殊的需求，这并不是一个问题。</p>

<p>不管是tracker还是storage，它们在linux中都是一个用户层面的进程，并未涉及到系统的内核，它们也都有自己的api，并没有为了兼容poixs等接口带来复杂度。
这样的设计方便了以后的维护和管理，也方便了实现的时候，只要考虑DFS本身的问题即可，无需为一些“杂事”而分心。</p>

<h4 id="进程内部结构模型">进程内部结构模型</h4>
<p>在DFS内部，除了storage的sync模块和storage的心跳模块发起请求的部分之外，余下所有的功能全部依赖于一种线程模型，我们把它称之为module。<br />
module模型主要是把进程分成逻辑上隔离的3个部分，mainsocket module、network module和task module。</p>

<p><img src="4.png" alt="metedata" /></p>

<p><br />
为了socket accept的简单，DFS把mainsocket module设计成单线程module，该module只负责接收main socket的连接，然后获取DFS中的jobcontext对象，
将请求通过负载均衡算法发送到network module。</p>

<p>network module为线程池设计，但是在mainsocket module中，经过负载均衡算法的发送，它保证了一个socket只会被一个network module的线程处理，
所以这里的处理是线程安全的。DFS会根据socket buffer的实际大小和服务器设置来决定读取数据，并且把数据依附在taskcontext对象上，和jobcontext一起
通过负载均衡算法发送到task module。</p>

<p>task module和network module一样也是线程池设计，同样发送到task module后的处理也是线程安全的，task module是整个任务真正被处理的地方。不管任务
是否执行的正确，task module都会装配好回复client使用的response信息，然后按照原路返回给network module，network负责将response信息发送给client。</p>

<h4 id="类目录服务">类目录服务</h4>
<p>上面提到我们节省掉“元数据”信息，然后整个设计都变成了“无中心化”设计，那也就意味着在DFS中不会存在目录服务。但是为了满足DFS容灾的需求，我们设计了一种轻量级的类目录服务。
这种服务不会具体的提供到数据存储的目录或者是文件，而仅仅是提供存储的服务器。又因为我们的逻辑集群内的storage之间是镜像的，所以也不会存在数据迁移的问题，虽然省略掉了元数据
这一块，但是我们还是可以用这种类目录的方式定位到我们的storage。</p>

<p>我们的定位服务有点类似于ceph的CRUSH算法，只是我们的算法没有ceph那么的灵活，一些ceph设置灵活的条件被我们固定了下来，
所以就不会像ceph那样有很多的条件因素来决定。在我们的定位服务中，永远只会有一个满足条件
的storage被返回，以驱动数据的访问。这还是得益于我们的逻辑集群内镜像的设计，它不存在把数据打散或者是重新平衡的问题，只要逻辑集群内的storage都保证会完全镜像，
所以返回一个storage也足以应对我们的需求。</p>

<p>在处理满足条件的storage之中，我们也会根据实际的情况对storage进行筛选。在tracker中，所有的storage都被保存成一种hashtree结构，通过groupname和syncgroup来分组，
然后通过心跳、磁盘大小等等物理条件和设置的平衡策略来选择唯一满足的storage给提供服务。这样的设计简化了算法，并且也保证了系统的事务性。</p>

<h4 id="存储模型">存储模型</h4>
<p>在我们整个系统中，文章只是一个对象。但是在DFS中，文章的内容虽然也是对象，但是它还是被分成了2种：一种是大文件，一种是小文件。
对于文件的区分，我们会通过配置设定一个阀值决定。</p>

<p>大文件将会作为sinalefile单独存储。它不会有带有别的信息，唯一需要使用的信息是lastmodifytime，这部分会在访问和同步中涉及。</p>

<p>对于小文件，DFS会把这些零零散散的内容合并成一个chunkfile，在合并内容的同时，也把零零散散的随机IO变成了顺序IO。这样不仅仅解决了海量小文件
对于系统压力的问题，也解决了随机IO导致的性能低下的问题，一举两得。相对于singlefile，chunkfile内的内容存储就不一样了。DFS无法简单的只存储
内容，所以我们在内容前面给每一个需要存储的内容加了一个metadata。metedata主要存储了文件的存储日期、是否被删除、最后更新时间，总长度，实际使用长度
，等等一序列的数据元信息。但是这些属性里面最重要的是一个类似于MVCC的值，在DFS中是opver，操作版本，它解决了版本问题。</p>

<p><img src="3.png" alt="metedata" /></p>

<p><br />
对于DFS来说，它关心是文件的名字，不管是singlefile还是chunkfile，DFS只会受限于名字不能产生冲突。所以文件名必须带上storage的machineid。machineid是在
group内部唯一的。文件名带上machineid后，首先，它能确保文件的归属问题，可以把唯一范围缩小到单机，但是在单机内部还不能保证文件的唯一性，所以，我们给文件名带上另外的
一些信息，包括但不限于创建时间、顺序数、线程ID号。至少由这4部分组成的文件名才能确保该文件在DFS系统内唯一。</p>

<p>对于storage，我们首选使用的是多而小的磁盘，这样可以让系统的并发达到最大化。而对于整个系统来说，我们又必须要支持磁盘的大容量。所以我们增加了多挂载点的功能，
原则上，每台storage机器最多可支持256个挂载点，这些挂载点会根据一定的规则进行数据的平衡策略。通常采用的是轮询的策略，也支持最大剩余空间等等策略，这部分
可以根据自己的需要自己来决定。对于多挂载点的支持，唯一的要求是同一逻辑集群内，必须做到镜像。</p>

<p>对于磁盘的剩余空间，我们也会做相应的处理，DFS并不会使用全部的磁盘空间来存储数据，具体最后剩余多大的空间也会让系统的使用者根据实际的使用情况来确定，一般
我们的推荐值是大于4G，这个数字并不是信口开河设置的，而是根据storage和tracker时间的心跳时间差和单位时间内最大上传量计算所得。如果想把剩余空间缩小，
那么可能需要先把心跳时间差缩小（现在是30s），这样会导致过于频繁的心跳检查，对tracker会照成一定的影响。</p>

<h4 id="数据一致性问题">数据一致性问题</h4>
<p>在分布式系统中，数据的一致性问题是被比较多的提及和难以解决的点。一般数据一致性出现问题的地方在于数据的版本控制和数据同步上。一旦在数据的版本控制上
出现纰漏，几乎数据的同步是肯定会发生一致性问题的。所以要解决数据一致性的问题，主要的工作还是在数据的版本控制上。</p>

<p>对于DFS，刚刚上面讲到我们使用类似于MVCC的opver来解决这个问题。那么我们到底怎么解决这个问题？和为什么要这样解决这个问题呢？</p>

<p>首先，来看singlefile，对于singlefile来说，它不需要版本控制，它是一个单独的实体，有就有，没有就没有，不会存在对于它的版本。 版本的冲突一般发生在modify的情况下，
只有执行modify，数据才会对同一个文件块进行覆盖。但是对于singlefile来说，它被更改就是先上传一个新的singlefile，然后把原来的siglefile删除掉，所以在这种情况下不存在问题。那么还有
一种情况，如果原来是一个singlefile，然后需要更新的是一个小文件阀值定义的内容，这时候DFS还是先上传一个新的chunkfile内容，然后把老的删除，以后的版本控制就会
按照chunkfile的版本控制来进行，所以singlefile是不需要做版本控制的，只要在同步的时候检测一下该文件是否还存在，然后根据实际的需要进行同步。</p>

<p>那么对于chunkfile来说，opver相对就很重要的。为什么需要opver而不是使用最后更新时间戳呢？这是因为在分布式系统中，时间是不确定的。
每个计算机都有它自己的物理时钟，而且时钟会经常性的发生偏移，又不能完美的同步它们。所以多台storage时间多多少少会有一些时间不同步的问题，如果当A机器的
某一个内容被更新后就down机，然后cleint马上再次对这一块的内容进行修改，因为A已经down机，所以请求会给落到同组内的B机器上，
而B机器接受再一次的更新，但是因为B机器的时间慢于A机器，这时候，其实B的版本更新，需要覆盖A的版本，但是时间戳是A的更晚一些，所以就会出现版本的问题。也有会认为你
更新的时候判断一下你提供的lastmodifytime和chunkfile的元数据中的lastmodifytime是否一样？这种做法不是不可以，但是在没有原子钟的情况下不是那么的稳妥(如果我们在系统
已经运行了几天后才发现时间差别很大，我们调整时间后，我们的数据怎么办？），所以我们最后还是放弃了这个做法。</p>

<p>我们使用了opver，它是一个单调递增的值。其实opver就是一个时钟向量(注意：虽然它名字叫时间向量，其实和时间没啥关系，它只是一个操作单向自增而已)，
相对于lastmodifytime来说，它的优点是在各自的storage之间，不会出现误差，并且可控。同样是上面的A和B机器之间的例子，
对于opver来说，因为它只可能保持单调递增，所以它不会出现时间戳被回拨的问题。我们在更新或者同步的时候，只要简单的对比opver就可以了。在同步的时候，当需要同步的数据opver
大于被同步数据的opver时，我们就认为需要同步的数据是最新版本，我们同步这块数据即可。</p>

<h4 id="线程安全">线程安全</h4>
<p>为了达到多线程性能的最大化，我们设计了一个多线程安全模型。总体上来说，就是对象线程化。</p>

<p>在多线程的环境中，最大的性能消耗就在于处理资源竞争的锁上面，所以怎么样避免这个锁的出现就成为了性能优劣的一个大问题。在这点上可以选择的技术方案也不是那么多，除了CAS
好像就没有什么合适的。但是CAS在这里其实不是那么的适用。所以我们就想到了对象线程化。又为了更好的优化性能，我们又加上了对象池的概念，把对象线程化的范围只缩小到
在该对象被访问使用期间。</p>

<p>对象线程化的具体是每当有访问进来的时候，DFS会根据访问的不同分发到不同的服务器。一般来说，insert操作会被随机的分配，但是删改查的操作就会被通过一个算法分配到一个task module中
的线程进行处理，这样通过task module中的loop进行操作排队，这些操作永远都是被串行化的，所以这些操作之间不会对同一块数据进行并发的操作，以此来达到访问操作串行化。</p>

<p>当然，仅仅使用这个办法还无法彻底解决数据的线程安全和资源的竞争锁问题，它还需要在写入磁盘的时候用磁盘的文件进行配合。使用同样的方法，我们将磁盘的文件也进行线程化，
对于singlefile，它不需要任何的线程化的控制；对于chunkfile文件，它的线程化处理方法就是每个线程对应一个文件，直到将这个文件写满，否则一直写这个文件。这样的做法解决
了在数据落入磁盘时的竞争锁的问题，但是它并不是完美的。对于停机的时候，因为chunkfile就会被关闭，然而它已经申请但是未被写入数据的部分大小将会形成文件空洞，而且这个文件空洞
是无法避免和再次利用的，所以这部分的损失将有我们系统直接忽略。</p>

<p>这里另外还牵扯到一个chunkfile的文件大小问题。相对于DFS来说，chunkfile的大小并无多少影响，我们只是需要从磁盘的使用率和系统调用的性能出发来合理的确定一个值。
目前我们使用的值是64mb，这个数字来源于我们区分singlefile和chunkfile的阀值，我们把小于1mb的数据划分入chunkfile，大于1mb的数据被认为是大文件，使用singlefile存储。
而64mb相当于最少存储64个文章章节，我们认为这种系统调用开销我们还算能接受。当从目前的实际使用情况来看，我们的当章节数据量远远小于1mb，一般就是kb级别，所以下一个版本中，
我们的chunkfile可能会成倍的缩小，应该会在4mb-8mb之间。</p>

<h4 id="文件空洞问题">文件空洞问题</h4>
<p>我们的DFS和一些开源的DFS最大的不同就是对于modify的支持。一些开源的DFS基本上不会考虑modify的支持，比如leveldb等等。它们是通过版本号然后合并的方式来规避掉对于modify的直接支持。
这样对于这些DFS来说，他们就不太会存在一个比较棘手的文件空洞问题。</p>

<p>文件空洞，因为DFS支持更改，删除这些操作的原因，导致文件内容断断续续,不会形成一整块。虽然对正常的使用影响不是那么的大，但是对于性能还是有一定的影响，
文件空洞这个问题只会存在在chunkfile中，对于singlefile，它是单独的文件，整个的都会去交给系统去处理。所以singlefile不需要我们去考虑。对于使用空间的问题，
对于我们这种支持频繁modify功能的DFS，空间的浪费还是一个比较可观的量，所以我们必须要解决这个问题。</p>

<p>在我们的DFS中，解决这个问题的方法分成2步走：</p>

<ol>
  <li>
    <p>对于每次的insert操作，我们都会预留了一部分的空间给modify的支持。这个预留空间的量可以通过相对的业务来决定。目前支持绝对值或者百分比增量。
一般的增量在第一次量的20%左右，我们进过几次业务的观察，发现20%这个量是合适的。对于我们的DFS磁盘来说，也是我们可以接受的一个值。
扩充20%之后，后面的每次modify只要量不超过这个值直接使用这块空间，不需要再次申请空间。从性能角度来说比不上顺序写（其实这时候是随机写），
但这样写的方式还是一个我们可以接受的。</p>
  </li>
  <li>
    <p>对于modify操作增量超过阀值的情况，我们只能重新申请空间，但是以前的那一块空间也不能浪费，浪费的话就会出现文件空洞，所以我们会有一个管理这个废弃空间的skiplist，
当insert的时候，我们会优先使用这些废弃的空间，来达到消除文件空洞，合理利用空间的效果。</p>
  </li>
</ol>

<p>对于顺序写和随机写这个问题，从性能角度来说，顺序写远远好于随机写，但是不管怎么样，就算把所有的随机写全部改成顺序写，也都会出现1bit的随机读写（需要把isdelete置位），所以
性能的开销倒并不是那么的大，如果使用顺序写+版本号，后续使用合并的功能替代掉，</p>

<h4 id="数据完整性">数据完整性</h4>
<p>对于分布式系统来说，数据的完整性一直是一个非常头疼的问题。不仅仅如此，对于系统来说，数据完整性也是一点都不能出差错的地方。</p>

<p>对于单台机器之内的数据完整性，前面已经有过比较详细的叙述，这里不会给与太多的讨论。下面，我们主要讨论一下多机之间的数据完整性问题。</p>

<h5 id="日志">日志</h5>
<p>对于所有的完整性来说，日志都是一个关键时刻救命的一票。我们的DFS也不例外，在我们的DFS中，数据完整性相关的日志分为2类：binlog和synclog。</p>

<p>为什么没有常见的redo？对于我们的DFS来说，它并不存在多数据刷入磁盘的时间间隔问题。因为它完完全全是一个KV的数据库，没有各种RMDB的繁琐的操作，更
没有事务的概念，对于DFS的操作就是直接对某一个值的操作，不存在恢复数据这一说。</p>

<p>binlog主要记录了对于DFS的增删改操作，根据不同的操作，记录的格式和内容不一样。</p>

<p>synclog主要记录了对于DFS同步的时候，已经同步到的记录。synclog的格式和binlog一致。可以认为synclog是binlog在remote machine上的一个备份文件。</p>

<h5 id="同步">同步</h5>
<p>DFS的同步分为2部分组成。一部分是通常意义上的同步，主要的目的是完成运行时同一syncgroup内部的数据镜像问题；另外一部分因为DFS的特点，在设计的时候
我们就认为DFS的机器是易损坏的且不可能完全通过本机磁盘恢复的，所以我们增加了一个单盘恢复功能。它主要用来在磁盘出现问题，或者机器出现问题的时候，
或者增加机器的时候，数据重新自动平衡自用。</p>

<p><b> 实时同步</b></p>

<p>对于实时同步，我们的DFS使用的是gossip算法。通过遍历本机binlog，把数据采用push的方式同步到remote storage。这些remote storage必须拥有同样的groupname
和syncgroup，具体的原因上面已经有过论述。因为我们的DFS总体上就是“去中心化”的设计，所以每台storage在成为master的同时又都扮演slaver的角色，所以在同步
的时候，并没有一个固定的参照来作为标准，这里我们使用了自创的“分布式同步状态机”来完成。</p>

<p>分布式同步状态机，其实就是各storage都会维护一个同步状态，在storage启动的时候或者是重新启动同步的时候做状态机的校验。因为网络、同步延迟和同步方式的关系，
我们统一将remote storage上的状态做为当前同步的起始点，本地storage获取remote storage上的状态后，才会构建同步状态机。</p>

<p>为了简单，同步只是发生在storage之间，实际上并没有tracker任何实际性的事情。tracker在整个同步中不会充当任何的角色，它仅仅是为storage提供了一个获取remote storage
的功能，类似于提供了目录服务。storage会周期性的获取remote storage信息，然后通过获取的remote storage来构建同步。</p>

<p>同步数据会随着binlog的日志一并发送给remote storage，remote storage会在处理完同步后，把日志记录到synclog，以表明已经接受此信息的同步。synclog不仅仅只是
显式的提供信息确认功能，它还在单盘恢复中充当极其重要的角色。</p>

<p>因为实时同步根据binlog文件的增加来完成同步功能，所以可能会在文件属性更改的窗口期发生延迟现象。目前还没有找到更好的方式来解决这个办法，也许使用一个内存内的
变量会是一个比较好的方式，目前这个方案还仅仅在构思阶段，并未进入我们实际的系统。</p>

<p><b>单盘恢复</b><br />
单盘恢复对于DFS来说是一个很好的补充。从系统设计的开始，我们的目标就是把廉价的磁盘组合起来，组合成可以存储大容量的设备。但是这些廉价的磁盘不可避免的会经常发生
损坏或者下线的情况，所以磁盘损坏后数据的修复工作变得极其重要。而且随着机器的增多，手工的完成这部分工作显然是非常不能被接受的，这也就意味着这部分必须自动化的完成。
这就是单盘恢复的由来，它给系统带来了完整性，解放了运维的痛苦。</p>

<p>单盘恢复和实时同步采取的算法大同小异，也是使用gossip的方式。但是单盘恢复并不采用push方式，而是采用了相反的pull方式来执行。究其原因：对于实时同步来说，如果是采用
pull方式，那么我们必须要进过2次的通讯才能完成一条记录的同步，而采用push方式只需要一次合并后的通讯就可以解决问题，显然push方式更合适。而且对于实时同步，salver机器
并不知道需要同步的数据和时间点，所以由master主动发起同步更合适。但是单盘恢复就不同了，我们认为单盘恢复发生的条件是本地的磁盘损坏了，需要重新把这些数据从同一syncgroup
内的机器上同步过来，那么对于发生单盘恢复的机器来说，本地是存在以前的同步记录的，所以这时候我们是知道需要同步的数据具体有那些的，而且不管是pull还是push方式，都是需要
同样的网络通讯次数（同样是1次）才能同步一条数据，所以这里使用pull方式更合适。</p>

<p>当然凡事都有以外，如果DFS的日志文件丢失怎么办？这一点对于我们的DFS来说并不是灾难，我们在执行单盘恢复之前会首先检查我们的synclog和binlog在不在，如果不在先同步synclog
和binlog，把这些文件同步过来之后，再通过这些文件恢复数据。只是唯一不好处理的是，我们必须校验所有的synclog和binlog，以免发生synclog和binlog不一致的情况，导致数据
同步不完整，引起系统数据不完整的情况。</p>

<p>对于单盘恢复来说，并不是完全的“无中心化”设计的。它必要的时候必须要有一个storage充当master，来提供synclog和binlog的同步和数据的同步。这种情况只发生在一个逻辑集群（
同一group，同一syncgroup）内多机发生故障。这种时候当发生故障的机器无法满足同步的需要的时候，必须要一个master机器作为标准来提供一句。虽然DFS的设计对于机器的启动顺序不做
限制，但是这里的情况下，一般都是第一台online的机器作为master机器，这是需要注意的地方。</p>

<p>单盘恢复也支持同步中间停机，不管是在同步日志文件阶段还是在同步数据阶段，如果需要，可以随时将正在同步的机器切下线，系统并不会发生问题，也不会丢失前面已经同步的工作。
在单盘恢复结束后，一般还会接上实时同步，从最新的状态点开始把同步时间差之内的数据同步掉，达到完整的一致性后把系统切换上线。</p>

<p>单盘恢复的时候相比实时同步更为简单，因为它不必存在分布式状态机机制，也不必实时的检查remote storage状况，只是一个简单的多storage之间的通讯而已，这大大的简化了单盘
恢复功能的实现，也减少了同步这一棘手问题发生故障的概率。</p>

<h4 id="运行时状态">运行时状态</h4>
<p>storage在整个集群中并没有任何的状态，都是对等的角色，但是这并不代表它自己本身就没有任何的状态。每一台的storage都是一台有状态的机器，对于一直运行的storage来说，它也是
一个作为状态机存在。开始的设计初衷就有单机可以随便上下线的功能。我们并不限制单机的状态，但是我们必须可以让单机在重启的时候恢复到之前的状态，然后运行。</p>

<p>在这个过程中，为了保持机器的状态，我们设计了几个状态保持文件来保持状态。这些状态文件分为两类，一类是从头到尾一直存在的，属于机器状态的元信息；一类是运行过程中才会存在的
状态，只要这个过程执行完毕，这些文件将自动被删除，典型的应用就是在单盘恢复的时候，这些文件是不会长久留存的。</p>

<h4 id="机器的改变和数据迁移">机器的改变和数据迁移</h4>
<p>在我们的DFS中，机器数量的改变不会发生数据的迁移。这是我们从一开始就完全确定的一个设计方案。我们把我们的DFS设计成一个巨大的集群，但是在这个大集群内部会被分割成几个相互
之间独立的，并无任何关系的逻辑集群。这些逻辑集群只是显式的处于一个大集群中而已，其实他们之间是不会发生任何的相互之间的状态、文件的关系的。数据的迁移只会发生在逻辑集群内部。</p>

<p>这些逻辑集群并不是由系统随意决定的，也不是由像ceph那样的由crush算法来决定这些逻辑集群，而是这些机器被安放到大集群内部时就已经被标明了属于的逻辑集群，是我们显式的给与这些机器
的一个属性。那么也就是说其实这些逻辑集群内部的确定也确定了另外一个重要的事情：一个文件会被备份的份数。因为逻辑集群内部是镜像的，所以这个备份分数就是逻辑集群的机器数-1，也就是说
这个备份数也会因为逻辑集群的人为指定而变成人为确定。</p>

<p>这样的做好的坏处是人为决定因素太多，但是带来的好处是在机器数量发生变化的时候，数据不会发生迁移（注意：这里只是说不会发生迁移，但是相互之间的备份还是会发生的）。这种数据量的备份
已经是最小化的节省了数据平衡的时间，也不会额外的带来数据迁移带来的压力。在我们的设计中，我们认为这是我们所能接受的最低底限了。</p>

                    ]]>
                </content:encoded>
                <guid isPermaLink="false">/blog/2015/DFS/</guid>
                <description>
                    
                </description>
                <pubDate>Thu, 24 Sep 2015 00:00:00 +0800</pubDate>
                <author>94geek.com by Seapeak.Xu</author>
            </item>
        
    
        
            <item>
                <title>使用linux的lsof和pmap解决fd和内存泄漏</title>
                <link>http://www.94geek.com/blog/2015/slove-fd-and-mmap-overfolw/</link>
                <content:encoded>
                    <![CDATA[
                    <p><br />
最近dfs开发到了最后的调试阶段，进过了艰苦卓越的斗争，终于还是解决了几个fd泄漏
和内存泄漏的问题。这里把一些经验记录下来，以备后患。<br />
那么先介绍一下dfs，dfs分为两部分，tracker和storage。
tracker只负责负载均衡和调度。storage负责数据
的存储和同步,基本的信息就是这样。</p>

<p><br /></p>
<h4 id="现象">现象</h4>
<ol>
  <li>dfs的storage在单机运行的时候没有问题，不管是upload，delete还是modify或者find都没有
任何问题，可以一直工作到磁盘塞满；</li>
  <li>当存在多storage的时候，前期可以正常工作，但是进过了一段时间的运行，就会出错，
进程不会产生dump文件，但是日志会抛出errno=24,然后退出。</li>
</ol>

<h4 id="初步诊断">初步诊断</h4>
<p>通过errno得到信息，首先初步判断可能的问题是fd的泄漏，并且结合dump文件没有生成
而且还有log，那么说明我们已经捕获到这个问题。还有一个可能的原因是本身服务器设置
就有问题，比如fd设置的过小。但是基本上80%还是怀疑泄漏。现在的问题是，你知道了
问题的可能原因，但是你不知道问题出现的地方。fd泄漏是open了fd但是没有关闭，log的
信息提示是在你open的时候才提示的，所以log的地方并不是出现问题的事发现场。那么怎么
办？首先想到的是：怎么样去看一下程序运行时有多少个打开的文件？</p>

<h4 id="解决办法">解决办法</h4>
<ol>
  <li>先看一下fd的数量问题，运行ulimit -a命令看一下：</li>
</ol>

<p><img src="ulimit.png" alt="ulimit" /></p>

<p>文件fd的数量是1024，算一下进程正常运行需要的fd数量：module之间的pipe数量+线程
打开的文件数+log+binlog+synclog+marklog+mpstatue 差不多在300左右，远远小于1024
这样，可以排除这个问题应该不在这里；</p>
<ol>
  <li>那么下来就只能用lsof看一下了，用lsof -p pid得到如下：</li>
</ol>

<p><img src="lsof.png" alt="lsof" /></p>

<p>kao,那么多的文件，而且chunkfile和singlefine都存在。肯定是这里泄漏了。整理思绪，
在程序中，我们可能打开这些文件的地方是对文件的增删改查，还有一个就是sync。这里文件名
中带有m001，这个进程的业务id就是m001，这个并不能一次性的能确定是在那里。那么
我们通过lsof可以看到每个被打开文件的fd值，这就好办了，反正程序中打开文件的地方也不多，
索性在每个open的时候把fd给记录下来，结合lsof的fd，如果两个fd的值相同，比且出现在lsof
的命令输出里面，那么就是这个fd泄漏了。</p>

<p><br /></p>
<h4 id="现象-1">现象</h4>
<ol>
  <li>在fd的泄漏解决后，程序能长时间跑了，但是随着跑的时间越来越长，系统也变得越来越慢。
开始以为是不是磁盘被塞满了而导致的，那就把磁盘的空间释放出来。释放磁盘后，再次运行
程序，现象依旧。</li>
</ol>

<h4 id="初步诊断-1">初步诊断</h4>
<p>目前我们只有一个很浅显的系统越来越慢的现象，这个现象的形成99%的罪魁祸首是内存泄漏。
随着我们把磁盘的问题排除掉，那么剩下的选择真的不多了，不得不去面对让人头疼又无比痛苦的
内存泄漏问题。看一下程序，整个过程中内存的alloc和free都很多，不知道哪里可能会出现问题.
还是一个办法，需要查看程序runtime状态下的内存结构。</p>

<h4 id="解决办法-1">解决办法</h4>
<ol>
  <li>首先想到gdb，人工的去dump一个文件，然后对这个文件进行调试，可是理想是丰满的，
现实是骨感的。gdb好像并不能很好的去监控heap信息。看来此路不通，遂放弃。</li>
  <li>也想过用一些静态内存检查工具，但是我们的程序有大量的pool机制，对于这些静态内存
检查工具，干扰太多了，也并不是太适合，关键是一直没怎么用过，不熟悉。</li>
  <li>那就只能寻求于系统了。翻一下linux的工具箱，有一个叫pmap的工具可以查看进程的内存
情况，那就用pmap试试。结果不试不知道，一试吓一跳：</li>
</ol>

<p><img src="pmap.png" alt="pmap" /></p>

<p>好多的打开文件没有关闭，而且还有大小，挺详细。算了一下，一共泄漏了12g+的内存，幸好
哥的机器是16g内存。那么现在知道是什么原因了，但是和fd泄露一样，事发地点在那儿？</p>
<ol>
  <li>结合storage单机的时候可以稳定的运行，那八九不离十就是在sync部分了，那sync也分为
两部分，一部分是传给remote storage的，另一部分是从remote storage传过来的。看一下
pmap的出来的文件名，都是m001的文件，而这个进程的业务就是m001，那就是在发送的时候
发生了问题。现在范围又缩小了，但是通过工具也就只能缩小到这儿了，剩下的就只能看硬
看代码了。</li>
  <li>还好函数不长，经过仔细的查看代码，每个文件都会被一个yssc对象管理着，每次sync后
都会通过yssc的fd。mptr和len进行fd的关闭和mmap的释放。应该不存在问题。那么为什么还会
有内存在进程中呢？再看一下这些值，启动gdb，attach到运行的进程，监听到yssc被free的
哪个地方，看一下它的值：</li>
</ol>

<p><img src="gdb.png" alt="gdb" /></p>

<p>len=0？问题找到了，在mmap的时候，没有给yssc的len赋值，导致在free的时候，mmap的内存
一点都没释放，怪不得pmap的结果上的内存大小正好和upload的大小吻合呢。</p>

<h4 id="经验">经验</h4>
<ol>
  <li>像fd泄漏，内存泄漏这种bug必须要去查看现场，经验可以增加判断的准确度，但是不能作为
唯一的标准。</li>
  <li>必须要查看到runtime的信息，必须。</li>
  <li>合理的利用linux的工具，可以加快bug的确定。</li>
</ol>


                    ]]>
                </content:encoded>
                <guid isPermaLink="false">/blog/2015/slove-fd-and-mmap-overfolw/</guid>
                <description>
                    
                </description>
                <pubDate>Wed, 23 Sep 2015 00:00:00 +0800</pubDate>
                <author>94geek.com by Seapeak.Xu</author>
            </item>
        
    
        
            <item>
                <title>使用bit解决跳位问题</title>
                <link>http://www.94geek.com/blog/2014/bit-alg/</link>
                <content:encoded>
                    <![CDATA[
                    <h4 id="背景">背景</h4>
<p>近期一直在做DFS的开发工作，在开发工作中碰到一个”跳目录”的问题。其实就是递增目录
的情况.</p>

<p>具体是这样的，
首先我们的DFS（名字叫ydb，一下就称ydb吧。）也就是ydb会对每个配置的挂载点进行格
式化。这个格式化其实就是建立文件夹。文件夹的数量(一下简称storerooms）是可配置的，比如你可以配置成64
也可以配置成128或者任何一个你想要的数，但是最大不能超过256(其实是255，0-FF）.那么ydb就会对每个挂
载点进行一次storeromes*storerooms的文件夹建立，最后文件夹的呈现这样一个情况：<br />
<img src="dirs.png" alt="dirs-style" /><br />
在ydb中，每个文件夹保存的文件数也是可以配置的（配置项为storecount），只要文件
夹内的文件存储量达到storecount，那么下一个文件将会存入下一个文件夹，比如当前存
储在00/03文件夹，那么下一次就会存储到00/04，如果storerooms为256，那么如果当前
文件夹为00/FF，那么下一次将会01/00（其实就是会跳母文件夹）。<br />
其实就是这个跳文件夹的功能，怎么样才能解决问题？</p>

<h4 id="解决方案">解决方案</h4>
<p>为了方便里面，我们把前面的p1设成母文件夹，p2设成子文件夹，就是这样p1/p2。</p>
<h5 id="人类的代码">人类的代码</h5>
<p>人类能理解的代码呢，基本上就是按部就班的解决这个问题，思路是这样的：</p>
<ol>
  <li>判断p2+1 是不是等于storerooms，如果没有，那就+1；</li>
  <li>如果等于storerooms，那么p2归零，p1+1；</li>
  <li>判断p1+1后是不是等于storerooms，如果不是，那么正常执行，如果是，那么p1，p2.<br />
全部归零，从头开始；或者根据mp的负载均衡配置，决定存储的mp。<br />
代码大概就是这样的；</li>
</ol>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12</pre></td><td class="code"><pre><span class="k">if</span><span class="p">(</span><span class="n">storerooms</span> <span class="o">==</span> <span class="n">p2</span> <span class="o">+</span> <span class="mi">1</span><span class="p">){</span>
    <span class="n">p2</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="k">if</span><span class="p">(</span><span class="n">storerooms</span> <span class="o">==</span> <span class="n">p1</span> <span class="o">+</span> <span class="mi">1</span><span class="p">){</span>
        <span class="n">p1</span> <span class="o">=</span> <span class="mi">0</span> <span class="p">;</span>
        <span class="c1">//insert get mp by storemode
</span>    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
        <span class="n">p1</span> <span class="o">+=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="p">}</span>
<span class="p">}</span><span class="k">else</span><span class="p">{</span>
    <span class="n">p2</span> <span class="o">+=</span> <span class="mi">1</span><span class="p">;</span>
<span class="p">}</span>
    <span class="w">
</span></pre></td></tr></tbody></table></code></pre></figure>

<p>这样勉强还算能看的下去，是吧？但是总归让人感觉不是很舒服，层级太多，判断太多了
，那么我们来一种计算机喜欢的方式。</p>
<h5 id="计算机喜欢的代码">计算机喜欢的代码</h5>
<p>这里我们使用了一个技巧，就是char和int之间的关系。<br />
<img src="int.jpg" alt="int" /><br />
如上图，一个int在内存中是4个byte，一个byte的最大值正好是255.完全符合我们的
storerooms的最大值。那么也就是说p1,p2是一个int的2个byte(分别为
        p2-&gt;byte0,p1-&gt;byte1,flag-&gt;byte2)，而且如果我们的最大值
正好设定为255，那么我们连跳级都不用了，直接就已经内置了（因为p2达到255，再加1
，正好向p1加1，p2归0）。所以我们就有如下的算法：</p>

<figure class="highlight"><pre><code class="language-c" data-lang="c"><table style="border-spacing: 0"><tbody><tr><td class="gutter gl" style="text-align: right"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16</pre></td><td class="code"><pre><span class="n">u32_t</span> <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
<span class="n">u8_t</span> <span class="n">flag</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
<span class="n">total</span> <span class="o">=</span> <span class="n">p1</span> <span class="o">&lt;&lt;</span> <span class="mi">8</span> <span class="o">|</span> <span class="n">p2</span><span class="p">;</span>
<span class="n">total</span><span class="o">++</span><span class="p">;</span>
<span class="n">flag</span> <span class="o">=</span> <span class="n">total</span> <span class="o">&gt;&gt;</span> <span class="mi">16</span> <span class="o">&amp;</span> <span class="mh">0xFF</span><span class="p">;</span>
<span class="n">p1</span> <span class="o">=</span> <span class="n">total</span> <span class="o">&gt;&gt;</span> <span class="mi">8</span> <span class="o">&amp;</span> <span class="mh">0xFF</span><span class="p">;</span>
<span class="n">p2</span> <span class="o">=</span> <span class="n">total</span> <span class="o">&amp;</span> <span class="mh">0xFF</span><span class="p">;</span>
<span class="k">if</span><span class="p">(</span><span class="n">c</span><span class="o">-&gt;</span><span class="n">storerooms</span> <span class="o">==</span> <span class="n">p2</span><span class="p">){</span>
    <span class="n">p1</span><span class="o">++</span><span class="p">;</span>
    <span class="n">p2</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
<span class="k">if</span><span class="p">(</span><span class="n">c</span><span class="o">-&gt;</span><span class="n">storerooms</span> <span class="o">==</span> <span class="n">p1</span><span class="p">){</span>
    <span class="n">flag</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="n">p1</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
    <span class="w">
</span></pre></td></tr></tbody></table></code></pre></figure>

<p>解释一下：</p>
<ol>
  <li>首先，我们需要一个u32的临时变量，所有的数据都是在它内部变的；</li>
  <li>flag就是是不是需要重新获取mp或者说该mp下所有的目录都放满的标志；</li>
  <li>把p1和p2根据位置压入u32的临时变量，然后直接对这个变量+1；</li>
  <li>再把u32的变量分解成flag，p1和p2；</li>
  <li>然后判断母子目录要不要跳；</li>
  <li>最后根据flag，决定是否需要重新确定存储mp。</li>
</ol>


                    ]]>
                </content:encoded>
                <guid isPermaLink="false">/blog/2014/bit-alg/</guid>
                <description>
                    
                </description>
                <pubDate>Thu, 04 Sep 2014 00:00:00 +0800</pubDate>
                <author>94geek.com by Seapeak.Xu</author>
            </item>
        
    
        
            <item>
                <title>vim配置</title>
                <link>http://www.94geek.com/blog/2014/vim/</link>
                <content:encoded>
                    <![CDATA[
                    <h4 id="摘要">摘要</h4>
<p>这次主要讲讲VIM对于一些”古怪”安静绑定的前因后果。这有助于我们更加了解VIM的历史
。然后再讲一下，在现在的键盘上，我们怎么通过”经济”的办法来达到使用VIM时，能保
证小手指尽量的舒适，一些按键能尽量的控制在键盘的大区内；然后，我会讲一下我的
VIM配置文件的组成，以及为什么我要用这种方法来配置我的VIM。最后当然是重头的VIM
配置文件。</p>

<h4 id="解放你的小手指">解放你的小手指</h4>
<p>讲VIM的小手指问题，我们得先讲讲VIM的出生年代。在Bill Joy开发VI的时候，其实他使
用的机器是ADM-3A。这款机器的键盘和现在机器的键盘是不一样的，详细看图：</p>

<p><img src="vim-kb.jpg" alt="ADM-3A的键盘" /></p>

<p>这是理解了吧。这不是Joy有意，实在是他使用的键盘CTRL的按键确实很方便，所以快捷
键很多都是CTRL。后来计算机键盘的发展把CTRL放到了下角，才导致了现在使用VIM的时
候，只要时间一长，小手指就像不是你的一样。<br />
再看一下键盘的上下左右按键，分别对应的是HJKL，所以VIM也就使用这几个键来作为基
本的移动按键。我觉得如果但是的键盘上有单独的上下左右按键，Joy应该也会随大流吧
。PS：其实后来有一款游戏CS（一款对战游戏）还重新定义了一种叫做WASD的移动风格。<br />
还有一个就是ESC，对于ESC按键，当初在键盘上的位置就在CTRL上边，就是现在我们TAB
键的位置，你按按TAB键试试，是不是很上手？<br />
那么面对这种情况，我们不是没有改变的办法，我们改变的办法就是重新绑定我们这几个
功能键，把它绑定到我们自己认为舒服的位置就可以。<br />
具体的方法就是，在你的HOME下新建一个.Xmodmap文件就可以，然后输入以下内容：</p>

<pre><code>
keycode 66 = Control_L
keycode 108 = Escape
clear Lock
add Control = Control_L
keycode 135 = Caps_Lock
add Lock = Caps_Lock
</code></pre>

<p>有的时候，你具体的键值可能是不一样的，这个时候你必须要使用软件来检测一下你的键
盘上CAPS、CTRP，ALT（right）和ESC的键值各是多少，然后根据你的实际情况换进去就
可以。<br />
如果你的米足够，并且是一个键盘党，那么这里推荐一款键盘，HHKB。其貌不扬的外观下
面是一颗静电容的芯。目前我使用的就是这款，它的键盘布局就非常适合Linux的CUI操作
用户，特别是VIMer。但是不适合Emacer（因为按键太少了，也没带脚踏板功能！)</p>

<p><img src="hhkb.jpg" alt="HHKB" /></p>

<h4 id="vim配置的进化">VIM配置的进化</h4>
<p>在很久之前，好像是3年吧。那个时候VIM的插件管理还没有什么好的办法。一般的做法都
是从vim.org上下载一个插件，然后解压，在cp到你的.vim目录下。如果有需要，再在
vimrc中配置一下插件，个性化一下或者重新绑定几个快捷键什么的。但是这种插件的管
理方法看似很简单，实则非常落后。主要是</p>
<ol>
  <li>乱，你的.vim文件夹的子文件夹内到处充满了不知道是什么插件的问题；</li>
  <li>不要禁用插件。当你想试用一下某个插件，等你安装完后觉得不爽，想删除的时候，
因为它是散落在多个文件夹的，所以你根本无法去删除或者是删除干净；</li>
  <li>版本不好控制。这种方式一般都是自己管理版本。把vimrc和.vim下面的文件全部签到
你自己的github或者googlecode上，这样就可以了，但是如果插件本身升级了，你还得手
动的去下载一个插件，覆盖掉你本地的插件，然后在签入自己的。或者你fork一个子项目
，然后定期更新什么的。反正比较麻烦。<br />
后来，估计是有几个VIMer对于这种方式实在恼火了，vundle这类”全家旅游，杀人越货”
级别的必备良药出现了。大家很快就使用了这种方式来管理。瞬间”这个世界变的清静了
“.</li>
</ol>

<h4 id="vim配置文件">VIM配置文件</h4>
<p>首先，我的配置文件由4个分文件构成。原因就是全部写在一个vimrc中的话，这个文件实
在太长了，也无法很好的定位和管理。所以我就把这个总的vimrc文件分成了4个文件。具
体如下:</p>
<ol>
  <li>main.vimrc 这个是主vimrc文件，里面加载另外的3个文件，并且一些基本的vim配置
都是在这个文件中完成；</li>
  <li>bundle.vimrc 这个vimrc文件主要配置了你需要使用的第三方插件；要使用这个文件
，必须先安装vundle插件；</li>
  <li>keymmaping.vimrc 这个文件是快捷键绑定文件，主要就是一些vim内置功能（不包括第
三方插件，第三方插件的快捷键在bundle.vimrc中配置）的快捷键；</li>
  <li>function.vimrc 这个文件主要管理一些自定义的功能函数。一般都是使用vim script
写的简单功能。</li>
</ol>
<pre><code>
"==========================================
" Base Settings  基本设置 main.vimrc
"==========================================
&lt;/br&gt;
:set nocompatible
&lt;/br&gt;
"""""""""""""""""""""""""""""""""""""""""""
" Include vimrc 读取子vimrc
"""""""""""""""""""""""""""""""""""""""""""
" install Vundle bundles
if filereadable(expand("~/.vim/myvim/bundle.vimrc"))
  source ~/.vim/myvim/bundle.vimrc
endif
&lt;/br&gt;
" ensure ftdetect et al work by including this after the Vundle stuff
filetype plugin indent on
&lt;/br&gt;
"loading key-mapping
if filereadable(expand("~/.vim/myvim/keymapping.vimrc"))
  source ~/.vim/myvim/keymapping.vimrc
endif
&lt;/br&gt;
"loading function
if filereadable(expand("~/.vim/myvim/function.vimrc"))
  source ~/.vim/myvim/function.vimrc
endif
&lt;/br&gt;
"自动启用vimrc配置
autocmd! bufwritepost .vimrc source ~/.vimrc
:set switchbuf=useopen
"设置光标可以到最后一个字面后
set virtualedit=onemore
"设置快捷键等待时间
 " set timeout timeoutlen=300
 set timeout ttimeoutlen=-1
"设置退格键为删除键
set backspace=indent,eol,start
"设置移动命令在行首或者行尾时依然有效
set whichwrap+=b,s,&lt;,&gt;,[,]
set whichwrap+=&lt;,&gt;,h,l
"设置历史命令保存数
set history=1000
"关闭智能补全预览窗口
set completeopt=longest,menu
"设置鼠标可以选择文本
set selectmode+=mouse
"设置自动读取外面对于文件的变更
set autoread
"设置命令行高度为2
set cmdheight=1
set nobackup
set nowb
set noswapfile
"与windows共享剪贴板
set clipboard+=unnamed
"set clipboard+=unamedplus
"增强模式中的命令行自动完成操作
set wildmenu
"开启鼠标
set mouse=a
" 启动的时候不显示那个援助索马里儿童的提示
set shortmess=atI
" 不让vim发出讨厌的滴滴声
set novisualbell         " don't beep
set noerrorbells
"自动切换当前目录为当前文件所在目录
set autochdir
"打开时忽略文件名后缀
set wildignore+=\*.o,\*.obj,\*.pyc,\*.db,\*.swp,\*.bak,\*.class
"默认就是全buffer搜索
set gdefault
"切换到当前tab打开文件的路径下
autocmd BufEnter * cd %:p:h
"检测文件类型
filetype on
"针对不同的文件类型采用不同的缩进格式
filetype indent on
"允许插件
filetype plugin on
"启动自动补全
filetype plugin indent on
"create undo file
set undolevels=1000         " How many undos
set undoreload=10000        " number of lines to save for undo
if v:version &gt;= 730
    set undofile                " keep a persistent backup file
    set undodir=/tmp/vimundo/
endif
" 修复ctrl+m 多光标操作选择的bug，但是改变了ctrl+v进行字符选中时将包含光标下的字符
"set selection=exclusive
" set selection=inclusive
" set selectmode=mouse,key
" No annoying sound on errors
set title                " change the terminal's title
set t_vb=
set tm=500
" Remember info about open buffers on close"
set viminfo^=%
" For regular expressions turn magic on
set magic
&lt;/br&gt;
"==========================================
" Display Settings 展示/排版等界面格式设置
"==========================================
"设置一行字数
set tw=78
"折行
set lbr
"中文折行不断字
set fo+=mB
:set formatoptions+=mM "format for chinese
" 高亮显示匹配的括号
set showmatch
"带有如下符号的单词不要被换行分割
set iskeyword+=$,@,%,#,-,__
set ambiwidth=double
"开启行号显示
:set number
"显示当前的行号列号：
set ruler
""在状态栏显示正在输入的命令
set showcmd
" Show current mode
set showmode
" Set 7 lines to the cursor - when moving vertically using j/k 上下滚动,始终在中间
set scrolloff=7
" 命令行（在状态行下）的高度，默认为1，这里是2
 set statusline=%&lt;%f\ %h%m%r%=%k[%{(&amp;fenc==\"\")?&amp;enc:&amp;fenc}%{(&amp;bomb?\",BOM\":\"\")}]\ %-14.(%l,%c%V%)\ %P
" Always show the status line
set laststatus=2
" 取消换行。
" set nowrap
" How many tenths of a second to blink when matching brackets
set mat=2
" 突出显示当前行等
" set cursorcolumn
set cursorline          " 突出显示当前行
&lt;/br&gt;
"设置文内智能搜索提示
" 高亮search命中的文本。
set hlsearch
" 搜索时忽略大小写
set ignorecase
" 在搜索时，输入的词句的逐字符高亮（类似firefox的搜索）
set incsearch
" 有一个或以上大写字母时仍大小写敏感
set smartcase     " ignore case if search pattern is all lowercase, case-sensitive otherwise
&lt;/br&gt;
" 代码折叠
set foldenable
" 折叠方法
" manual    手工折叠
" indent    使用缩进表示折叠
" expr      使用表达式定义折叠
" syntax    使用语法定义折叠
" diff      对没有更改的文本进行折叠
" marker    使用标记进行折叠, 默认标记是 }
set foldmethod=marker
set foldlevel=1
&lt;/br&gt;
" 缩进配置
set smartindent   " Smart indent
set autoindent    " always set autoindenting on
set copyindent
" never add copyindent, case error   " copy the previous indentation on autoindenting
"c程序可以在v模式中按=格式化
set cin
set cursorline
&lt;/br&gt;
" tab相关变更
set tabstop=4     " 设置Tab键的宽度        [等同的空格个数]
set shiftwidth=4  " number of spaces to use for autoindenting
set softtabstop=4 " 按退格键时可以一次删掉 4 个空格
set smarttab      " insert tabs on the start of a line according to shiftwidth, not tabstop 按退格键时可以一次删掉 4 个空格
set expandtab     " 将Tab自动转化成空格    [需要输入真正的Tab键时，使用 Ctrl+V + Tab]
set shiftround    " use multiple of shiftwidth when indenting with '&lt;' and '&gt;'
set cindent shiftwidth=4
set autoindent shiftwidth=4
&lt;/br&gt;
" A buffer becomes hidden when it is abandoned
" 允许在有未保存的修改时切换缓冲区，此时的修改由 vim 负责保存
set hidden
set autowrite
set wildmode=list:longest
set ttyfast
&lt;/br&gt;
"设置 退出vim后，内容显示在终端屏幕, 可以用于查看和复制
"好处：误删什么的，如果以前屏幕打开，可以找回
set t_ti= t_te=
&lt;/br&gt;
"==========================================
" FileEncode Settings 文件编码,格式
"==========================================
" 设置新文件的编码为 UTF-8
set encoding=utf-8
" 自动判断编码时，依次尝试以下编码：
set fileencodings=ucs-bom,utf-8,cp936,gb18030,big5,euc-jp,euc-kr,latin1
&lt;/br&gt;
"如果帮助无法显示中文,增加这句试试:
set helplang=cn
&lt;/br&gt;
" 下面这句只影响普通模式 (非图形界面) 下的 Vim。
set termencoding=utf-8
&lt;/br&gt;
" Use Unix as the standard file type
set ffs=unix,dos,mac
&lt;/br&gt;
" 如遇Unicode值大于255的文本，不必等到空格再折行。
set formatoptions+=m
&lt;/br&gt;
" 合并两行中文时，不在中间加空格：
set formatoptions+=B
&lt;/br&gt;
if has("win32") || has("win64")
	set fileencoding=chinese
else
	set fileencodings=utf-8,chinese,latin-1
endif
&lt;/br&gt;
if !has("gui_running")
	:set tenc=utf-8,gb2312,chinese
endif
&lt;/br&gt;
"解决consle输出乱码
language messages zh_CN.utf-8
&lt;/br&gt;
"==========================================
" Theme Settings  主题设置
"==========================================
&lt;/br&gt;
" Set extra options when running in GUI mode
if has("gui_running")
    set guifont=Monaco:h14
    set guioptions-=T
    set guioptions+=e
    set guioptions-=r
    set guioptions-=L
    set guitablabel=%M\ %t
    set showtabline=1
    set linespace=2
    set noimd
    " set t_Co=256
    "定义givm的颜色和去掉gvim的工具栏
	set guioptions-=T
&lt;/br&gt;
    "高亮显示
    if &amp;t_Co &gt; 2
        syntax on
        set hlsearch
    endif
endif
&lt;/br&gt;
"当终端支持颜色显示时打开彩色显示
if &amp;t_Co &gt; 1
	syntax enable
endif
&lt;/br&gt;
" theme主题
"背景变暗dark，亮设置为light
set background=dark
"colorscheme solarized
" colorscheme elise
set t_Co=256
&lt;/br&gt;
hi cursorline guibg=#333333 	" highlight bg color of current line
hi CursorColumn guibg=#333333   " highlight cursor
&lt;/br&gt;
"设置标记一列的背景颜色和数字一行颜色一致
hi! link SignColumn   LineNr
hi! link ShowMarksHLl DiffAdd
hi! link ShowMarksHLu DiffChange
&lt;/br&gt;
"" for error highlight，防止错误整行标红导致看不清
highlight clear SpellBad
highlight SpellBad term=standout ctermfg=1 term=underline cterm=underline
highlight clear SpellCap
highlight SpellCap term=underline cterm=underline
highlight clear SpellRare
highlight SpellRare term=underline cterm=underline
highlight clear SpellLocal
highlight SpellLocal term=underline cterm=underline
&lt;/br&gt;
"==========================================
" others 其它设置
"==========================================
autocmd! bufwritepost _vimrc source % " vimrc文件修改之后自动加载。 windows。
autocmd! bufwritepost .vimrc source % " vimrc文件修改之后自动加载。 linux。
&lt;/br&gt;
" 自动补全配置
"让Vim的补全菜单行为与一般IDE一致(参考VimTip1228)
set completeopt=longest,menu
&lt;/br&gt;
"离开插入模式后自动关闭预览窗口
autocmd InsertLeave * if pumvisible() == 0|pclose|endif
&lt;/br&gt;
" if this not work ,make sure .viminfo is writable for you
if has("autocmd")
  au BufReadPost * if line("'\"") &gt; 1 &amp;&amp; line("'\"") &lt;= line("$") | exe "normal! g'\"" | endif
endif
</code></pre>
<p>&lt;/br&gt;</p>
<pre><code>  
"==========================================
    "配置插件管理 bundle.vimrc
"==========================================
filetype off
&lt;/br&gt;
set rtp+=~/.vim/bundle/vundle/
call vundle#rc()
&lt;/br&gt;
Bundle "vundle"
&lt;/br&gt;
" 多语言语法检查
Bundle 'scrooloose/syntastic'
let g:syntastic_error_symbol='&gt;&gt;'
let g:syntastic_warning_symbol='&gt;'
let g:syntastic_check_on_open=1
let g:syntastic_enable_highlighting = 0
let g:syntastic_python_checkers=['pyflakes'] " 使用pyflakes,速度比pylint快
highlight SyntasticErrorSign guifg=white guibg=black
&lt;/br&gt;
Bundle 'genutils'
&lt;/br&gt;
Bundle 'xvhfeng/c.vim'
map &lt;c-x&gt;c \cc
map &lt;c-x&gt;u \co
&lt;/br&gt;
" Bundle 'The-NERD-Commenter'
Bundle 'ShowTrailingWhitespace'
&lt;/br&gt;
Bundle 'EasyMotion'
let g:EasyMotion_leader_key = 'f'
&lt;/br&gt;
Bundle 'FencView.vim'
&lt;/br&gt;
Bundle 'The-NERD-tree'
let NERDTreeWinPos = "left" "where NERD tree window is placed on the screen
let NERDTreeWinSize = 30 "size of the NERD tree
nmap &lt;F7&gt; &lt;ESC&gt;:NERDTreeToggle&lt;RETURN&gt;" Open and close the NERD_tree.vim separately
&lt;/br&gt;
Bundle 'auto_mkdir'
&lt;/br&gt;
Bundle 'bufexplorer.zip'
:vmap &lt;c-x&gt;b &lt;esc&gt;:w!&lt;esc&gt;,be
:nmap &lt;c-x&gt;b &lt;esc&gt;:w!&lt;esc&gt;,be
&lt;/br&gt;
Bundle 'CRefVim'
if !hasmapto('&lt;Plug&gt;CRV_CRefVimInvoke')
    map &lt;silent&gt; &lt;unique&gt; &lt;Leader&gt;ci &lt;Plug&gt;CRV_CRefVimInvoke
endif
&lt;/br&gt;
Bundle 'DoxygenToolkit.vim'
let g:DoxygenToolkit_briefTag_pre="@Remark:"
let g:DoxygenToolkit_paramTag_pre="@Param:"
let g:DoxygenToolkit_returnTag="@Returns:"
map &lt;c-x&gt;f &lt;ESC&gt;:Dox&lt;cr&gt;
&lt;/br&gt;
Bundle 'grep.vim'
:nmap &lt;c-g&gt; &lt;ESC&gt;:Grep&lt;CR&gt;
&lt;/br&gt;
Bundle 'lookupfile'
" lookup file with ignore case
        function! LookupFile_IgnoreCaseFunc(pattern)
        let _tags = &amp;tags
        try
            let &amp;tags = eval(g:LookupFile_TagExpr)
            let newpattern = '\c' . a:pattern
            let tags = taglist(newpattern)
        catch
            echohl ErrorMsg | echo "Exception: " . v:exception | echohl NONE
            return ""
        finally
            let &amp;tags = _tags
        endtry
    " Show the matches for what is typed so far.
        let files = map(tags, 'v:val["filename"]')
        return files
    endfunction
&lt;/br&gt;
let g:LookupFile_LookupFunc = 'LookupFile_IgnoreCaseFunc'
let g:LookupFile_MinPatLength = 2
let g:LookupFile_PreserveLastPattern = 0
let g:LookupFile_PreservePatternHistory = 1
let g:LookupFile_AlwaysAcceptFirst = 1
let g:LookupFile_AllowNewFiles = 0
"if filereadable("./filenametags")
"let g:LookupFile_TagExpr = '"./filenametags"'
"endif
nmap &lt;silent&gt; &lt;leader&gt;lf :LookupFile&lt;cr&gt;
nmap &lt;silent&gt; &lt;leader&gt;lb :LUBufs&lt;cr&gt;
nmap &lt;silent&gt; &lt;leader&gt;lw :LUWalk&lt;cr&gt;
&lt;/br&gt;
Bundle 'ShowMarks'
&lt;/br&gt;
Bundle 'statusline.vim'
&lt;/br&gt;
Bundle 'taglist.vim'
let Tlist_Exit_OnlyWindow = 1
"taglist窗口是否出现在右边，默认是左边
let Tlist_Use_Right_Window = 1
"是否在选择了taglist后自动关闭taglist窗口
let Tlist_Close_On_Select = 0
"是否在打开了taglist的同时把焦点设置到taglist窗口
let Tlist_GainFocus_On_ToggleOpen = 1
"当多个文件在taglist从显示的时候，只打开当前文件，折叠别的文件
let Tlist_File_Fold_Auto_Close = 0
let Tlist_Auto_Update = 1
"map &lt;silent&gt; &lt;leader&gt;tl :TlistToggle&lt;cr&gt;
map &lt;F8&gt; &lt;ESC&gt;:TlistToggle&lt;cr&gt;
&lt;/br&gt;
Bundle 'vmark.vim--Visual-Bookmarking'
&lt;/br&gt;
Bundle 'terryma/vim-multiple-cursors'
let g:multi_cursor_use_default_mapping=1
let g:multi_cursor_next_key='&lt;C-n&gt;'
let g:multi_cursor_prev_key='&lt;C-p&gt;'
let g:multi_cursor_skip_key='&lt;C-k&gt;'
let g:multi_cursor_quit_key='&lt;Esc&gt;'
&lt;/br&gt;
Bundle 'Yggdroot/indentLine'
"config for indentLine
let g:indentLine_indentLevel = 5
let g:indentLine_enabled = 1
"hi Conceal ctermfg=red ctermbg=red
"let g:indentLine_char = '|'
&lt;/br&gt;
Bundle 'a.vim'
"设置c语言的header和c文件转换
:nmap &lt;C-x&gt;h &lt;ESC&gt;:w!&lt;ESC&gt;:A!&lt;CR&gt;
&lt;/br&gt;
Bundle 'Valloric/YouCompleteMe'
let g:ycm_global_ycm_extra_conf = '~/.ycm_extra_conf.py'
let g:ycm_error_symbol = '&gt;&gt;'
let g:ycm_warning_symbol = '&gt;*'
let g:ycm_min_num_of_chars_for_completion = 2
let g:ycm_min_num_identifier_candidate_chars = 0
" 直接触发自动补全
let g:ycm_key_invoke_completion = '&lt;c-x&gt;&lt;c-o&gt;'
let g:ycm_cache_omnifunc = 1
let g:ycm_auto_trigger = 0
let g:ycm_enable_diagnostic_signs = 0
let g:ycm_enable_diagnostic_highlighting = 1
let g:ycm_echo_current_diagnostic = 1
"youcompleteme  默认tab  s-tab 和自动补全冲突
let g:ycm_key_list_select_completion=['&lt;c-n&gt;']
" let g:ycm_key_list_select_completion = ['&lt;Down&gt;']
let g:ycm_key_list_previous_completion=['&lt;c-p&gt;']
" let g:ycm_key_list_previous_completion = ['&lt;Up&gt;']
let g:ycm_complete_in_comments = 1  "在注释输入中也能补全
let g:ycm_complete_in_strings = 1   "在字符串输入中也能补全
let g:ycm_collect_identifiers_from_comments_and_strings = 1   "注释和字符串中的文字也会被收入补全
let g:ycm_seed_identifiers_with_syntax=1   "语言关键字补全, 不过python关键字都很短，所以，需要的自己打开
let g:ycm_collect_identifiers_from_tags_files = 1
nnoremap &lt;leader&gt;gd :YcmCompleter GoToDeclaration&lt;CR&gt;
nnoremap &lt;leader&gt;gi :YcmCompleter GoToDefinition&lt;CR&gt;
nnoremap &lt;leader&gt;gb :YcmCompleter GoToDefinitionElseDeclaration&lt;CR&gt;
nmap &lt;leader&gt;yd :YcmDiags&lt;CR&gt;
nmap &lt;F11&gt; :YcmRestartServer&lt;CR&gt;
&lt;/br&gt;
Bundle 'terryma/vim-expand-region'
map + &lt;Plug&gt;(expand_region_expand)
map _ &lt;Plug&gt;(expand_region_shrink)
&lt;/br&gt;
Bundle 'tpope/vim-commentary'
&lt;/br&gt;
" 代码片段快速插入
"Bundle 'SirVer/ultisnips'
" Snippets are separated from the engine. Add this if you want them:
&lt;/br&gt;
"Bundle 'snipMate'
&lt;/br&gt;
Bundle 'honza/vim-snippets'
let g:UltiSnipsExpandTrigger = "&lt;tab&gt;"
let g:UltiSnipsJumpForwardTrigger = "&lt;tab&gt;"
" 定义存放代码片段的文件夹 .vim/additional_snippets下，使用自定义和默认的，将会的到全局，有冲突的会提示
let g:UltiSnipsSnippetDirectories=["additional_snippets", 'UltiSnips']
&lt;/br&gt;
" 自动补全html/xml标签
Bundle 'docunext/closetag.vim'
let g:closetag_html_style=1
&lt;/br&gt;
" 快速加入修改环绕字符
Bundle 'tpope/vim-surround'
&lt;/br&gt;
" for repeat -&gt; enhance surround.vim, . to repeat command
Bundle 'tpope/vim-repeat'
&lt;/br&gt;
" 快速去行尾空格 [, + &lt;Space&gt;]
Bundle 'bronson/vim-trailing-whitespace'
map &lt;leader&gt;es :FixWhitespace<cr>
&lt;/br&gt;
" 文件搜索
Bundle 'kien/ctrlp.vim'
let g:ctrlp_map = '&lt;leader&gt;p'
let g:ctrlp_cmd = 'CtrlP'
map &lt;leader&gt;f :CtrlPMRU&lt;CR&gt;
"set wildignore+=*/tmp/*,*.so,*.swp,*.zip     " MacOSX/Linux"
let g:ctrlp_custom_ignore = {
    \ 'dir':  '\v[\/]\.(git|hg|svn|rvm)$',
    \ 'file': '\v\.(exe|so|dll|zip|tar|tar.gz)$',
    \ }
"\ 'link': 'SOME_BAD_SYMBOLIC_LINKS',
let g:ctrlp_working_path_mode=0
let g:ctrlp_match_window_bottom=1
let g:ctrlp_max_height=15
let g:ctrlp_match_window_reversed=0
let g:ctrlp_mruf_max=500
let g:ctrlp_follow_symlinks=1
&lt;/br&gt;
"状态栏增强展示
" Bundle 'Lokaltog/vim-powerline'
"if want to use fancy,need to add font patch -&gt; git clone git://gist.github.com/1630581.git ~/.fonts/ttf-dejavu-powerline
"let g:Powerline_symbols = 'fancy'
" let g:Powerline_symbols = 'unicode'
&lt;/br&gt;
"括号显示增强
Bundle 'kien/rainbow_parentheses.vim'
let g:rbpt_colorpairs = [
    \ ['brown',       'RoyalBlue3'],
    \ ['Darkblue',    'SeaGreen3'],
    \ ['darkgray',    'DarkOrchid3'],
    \ ['darkgreen',   'firebrick3'],
    \ ['darkcyan',    'RoyalBlue3'],
    \ ['darkred',     'SeaGreen3'],
    \ ['darkmagenta', 'DarkOrchid3'],
    \ ['brown',       'firebrick3'],
    \ ['gray',        'RoyalBlue3'],
    \ ['black',       'SeaGreen3'],
    \ ['darkmagenta', 'DarkOrchid3'],
    \ ['Darkblue',    'firebrick3'],
    \ ['darkgreen',   'RoyalBlue3'],
    \ ['darkcyan',    'SeaGreen3'],
    \ ['darkred',     'DarkOrchid3'],
    \ ['red',         'firebrick3'],
    \ ]
let g:rbpt_max = 40
let g:rbpt_loadcmd_toggle = 0
au VimEnter * RainbowParenthesesToggle
au Syntax * RainbowParenthesesLoadRound
au Syntax * RainbowParenthesesLoadSquare
au Syntax * RainbowParenthesesLoadBraces
&lt;/br&gt;
"################### 显示增强-主题 ###################"
&lt;/br&gt;
"主题 solarized
Bundle 'altercation/vim-colors-solarized'
"let g:solarized_termcolors=256
let g:solarized_termtrans=1
let g:solarized_contrast="normal"
let g:solarized_visibility="normal"
&lt;/br&gt;
"主题 molokai
Bundle 'tomasr/molokai'
"let g:molokai_original = 1
&lt;/br&gt;
"###### Python #########
" python fly check, 弥补syntastic只能打开和保存才检查语法的不足
Bundle 'kevinw/pyflakes-vim'
let g:pyflakes_use_quickfix = 0
&lt;/br&gt;
" for python.vim syntax highlight
Bundle 'hdima/python-syntax'
let python_highlight_all = 1
&lt;/br&gt;
"###### Markdown #########
Bundle 'plasticboy/vim-markdown'
let g:vim_markdown_folding_disabled=1
&lt;/br&gt;
"###### HTML/JS/JQUERY/CSS #########
&lt;/br&gt;
" for javascript
Bundle "pangloss/vim-javascript"
let g:html_indent_inctags = "html,body,head,tbody"
let g:html_indent_script1 = "inc"
let g:html_indent_style1 = "inc"
&lt;/br&gt;
"for jquery
Bundle 'nono/jquery.vim'
&lt;/br&gt;
"###### Jinja2 #########
Bundle 'Glench/Vim-Jinja2-Syntax'
&lt;/br&gt;
"###### nginx #########
Bundle 'evanmiller/nginx-vim-syntax'
&lt;/br&gt;
Bundle 'SQLComplete.vim'
let g:sql_type_default = 'mysql'
"SQLSetType mysql
&lt;/br&gt;
"the markdown editer
Bundle 'plasticboy/vim-markdown'
&lt;/br&gt;
"the properties file editor
Bundle 'kamichidu/vim-edit-properties'
&lt;/br&gt;
"auto input the right ) ] or }
"Bundle 'jiangmiao/auto-pairs'
&lt;/br&gt;
"undo tree
Bundle 'mbbill/undotree'
nnoremap &lt;F12&gt; :UndotreeToggle&lt;cr&gt;
if has("persistent_undo")
    set undodir='~/.vim/undodir/'
    set undofile
endif
"
" golang
" " Go
" We are using cespare's modification,
" which uses bradfitz's goimports instead of gofmt.
" With goimports, you can add missing imports automatically.
" To install goimport:
"   go get github.com/bradfitz/goimports
" Bundle 'cespare/vim-golang'
" To install godef:
"   go get code.google.com/p/rog-go/exp/cmd/godef
" Bundle 'dgryski/vim-godef'
" To install gocode:
"   go get github.com/nsf/gocode
" Bundle 'Blackrush/vim-gocode'
" Bundle 'bradfitz/goimports'
" Bundle 'UltiSnips'
"Bundle 'AutoClose' -- this plug change the timeout and ttimeout fuck.
" 代码缩进
" https://github.com/nathanaelkane/vim-indent-guides
"Bundle 'nathanaelkane/vim-indent-guides'
"let g:indent_guides_auto_colors = 0
"autocmd VimEnter,Colorscheme * :hi IndentGuidesOdd  guibg=red   ctermbg=3
"autocmd VimEnter,Colorscheme * :hi IndentGuidesEven guibg=green ctermbg=4
"hi IndentGuidesOdd  guibg=red   ctermbg=3
"hi IndentGuidesEven guibg=green ctermbg=4
"hi IndentGuidesOdd  ctermbg=black
"hi IndentGuidesEven ctermbg=darkgrey
&lt;/br&gt;
filetype on
&lt;/code&gt;&lt;/pre&gt;
&lt;/br&gt;
<pre><code>
"==========================================
" HotKey Settings  自定义快捷键设置 keymmaping.vimrc
"==========================================
let mapleader = ","
nnoremap ; :
&lt;/br&gt;
" F1 - F6 设置
" F1 废弃这个键,防止调出系统帮助
" F2 行号开关，用于鼠标复制代码用
" F3 显示可打印字符开关
" F4 换行开关
" F5 粘贴模式paste_mode开关,用于有格式的代码粘贴
" F6 语法开关，关闭语法可以加快大文件的展示
&lt;/br&gt;
" I can type :help on my own, thanks.  Protect your fat fingers from the evils of &lt;F1&gt;
noremap &lt;F1&gt; &lt;Esc&gt;
""为方便复制，用&lt;F2&gt;开启/关闭行号显示:
function! HideNumber()
  if(&amp;relativenumber == &amp;number)
    set relativenumber! number!
  elseif(&amp;number)
    set number!
  else
    set relativenumber!
  endif
  set number?
endfunc
nnoremap &lt;F2&gt; :call HideNumber()&lt;CR&gt;
nnoremap &lt;F3&gt; :set list! list?&lt;CR&gt;
nnoremap &lt;F4&gt; :set wrap! wrap?&lt;CR&gt;
"set paste
"when in insert mode, press &lt;F5&gt; to go to
"paste mode, where you can paste mass data
"that won't be autoindented
set pastetoggle=&lt;F5&gt;
&lt;/br&gt;
" disbale paste mode when leaving insert mode
au InsertLeave * set nopaste
nnoremap &lt;F6&gt; :exec exists('syntax_on') ? 'syn off' : 'syn on'&lt;CR&gt;
&lt;/br&gt;
" 关闭方向键, 强迫自己用 hjkl
map &lt;Left&gt; &lt;Nop&gt;
map &lt;Right&gt; &lt;Nop&gt;
map &lt;Up&gt; &lt;Nop&gt;
map &lt;Down&gt; &lt;Nop&gt;
&lt;/br&gt;
"空格即选中当前项
inoremap &lt;expr&gt; &lt;Space&gt;       pumvisible() ? "\&lt;C-y&gt;\&lt;Space&gt;" : "\&lt;Space&gt;"
&lt;/br&gt;
"上下左右键的行为 会显示其他信息
inoremap &lt;expr&gt; &lt;Down&gt;     pumvisible() ? "\&lt;C-n&gt;" : "\&lt;Down&gt;"
inoremap &lt;expr&gt; &lt;Up&gt;       pumvisible() ? "\&lt;C-p&gt;" : "\&lt;Up&gt;"
inoremap &lt;expr&gt; &lt;PageDown&gt; pumvisible() ? "\&lt;PageDown&gt;\&lt;C-p&gt;\&lt;C-n&gt;" : "\&lt;PageDown&gt;"
inoremap &lt;expr&gt; &lt;PageUp&gt;   pumvisible() ? "\&lt;PageUp&gt;\&lt;C-p&gt;\&lt;C-n&gt;" : "\&lt;PageUp&gt;"
&lt;/br&gt;
"tab 缩进
:nmap &lt;tab&gt;  v&gt;&lt;esc&gt;
:nmap &lt;s-tab&gt; v&lt;&lt;esc&gt;
:vmap &lt;tab&gt; &gt;gv
:vmap &lt;s-tab&gt; &lt;gv
"Reselect visual block after indent/outdent.调整缩进后自动选中，方便再次操作
" 在visual模式下缩进 (无限可重复)
:vnoremap &lt; &lt;gv
" 译释：:vnoremap 重定义了visual模式下 &lt; 符号的含义
" 把它定义成 &lt;gv
" 即：先&lt;向外缩进，然后gv重新选择上一次选择了的区域
" 这样在visual模式下就可以实现连续按<而连续缩进了 :vnoremap=""> &gt;gv
" 同里，内缩
":vmap &lt;tab&gt; &gt;gv
":imap &lt;s-tab&gt; &lt;Left&gt;
&lt;/br&gt;
"粘贴后剪切版不变
xnoremap p pgvy
noremap vp viwpgvy
noremap vy yiw
noremap Y y$
&lt;/br&gt;
"设置复制使用window粘贴板
:nmap &lt;C-p&gt; "+p
:vmap &lt;C-y&gt; "+y
:nmap Y y$
:vmap Y y$
" y$ -&gt; Y Make Y behave like other capitals
map Y y$
&lt;/br&gt;
"emacs style
":set winaltkeys=no
:imap &lt;C-e&gt; &lt;END&gt;
:imap &lt;C-a&gt; &lt;HOME&gt;
:imap &lt;C-b&gt; &lt;Left&gt;
:imap &lt;C-n&gt; &lt;Down&gt;
:imap &lt;C-p&gt; &lt;Up&gt;
:imap &lt;C-f&gt; &lt;Right&gt;
:imap &lt;C-v&gt; &lt;PageDown&gt;
:imap &lt;C-u&gt; &lt;PageUp&gt;
:imap &lt;C-d&gt; &lt;Delete&gt;
:imap &lt;C-r&gt; &lt;BackSpace&gt;
:imap &lt;c-w&gt;&lt;c-b&gt; &lt;s-left&gt;
:imap &lt;c-w&gt; &lt;s-right&gt;
:imap &lt;c-e&gt;&lt;c-b&gt; &lt;END&gt;&lt;Left&gt;
&lt;/br&gt;
nmap &lt;leader&gt;w :w!&lt;cr&gt;
nmap &lt;leader&gt;e :e&lt;SPACE&gt;
nmap &lt;leader&gt;s i&lt;space&gt;&lt;esc&gt;
nmap K i&lt;cr&gt;&lt;esc&gt;
&lt;/br&gt;
"格式化c语言块
:map &lt;leader&gt;fmt &lt;ESC&gt;=a{
&lt;/br&gt;
nmap &lt;c-e&gt;i &lt;esc&gt;guiw
nmap &lt;c-e&gt;u &lt;esc&gt;gUiw
&lt;/br&gt;
nmap wv     &lt;C-w&gt;v     " 垂直分割当前窗口
nmap wc     &lt;C-w&gt;c     " 关闭当前窗口
nmap ws     &lt;C-w&gt;s     " 水平分割当前窗口
&lt;/br&gt;
"set listchars=tab:./ ,trail:.   " 将制表符显示为'.   '
&lt;/br&gt;
"范围折叠
noremap &lt;c-x&gt;z &lt;esc&gt;zf%
&lt;/br&gt;
" 用空格键来开关折叠
nmap &lt;space&gt; za
&lt;/br&gt;
"清除c-x对于数字的按键，为组合键让步
map &lt;c-x&gt; &lt;ESC&gt;
&lt;/br&gt;
"the mapping for the cmd-line
" start of line
:cnoremap &lt;C-A&gt; &lt;Home&gt;
" back one character
:cnoremap &lt;C-B&gt; &lt;Left&gt;
" delete character under cursor
:cnoremap &lt;C-D&gt; &lt;Del&gt;
" end of line
:cnoremap &lt;C-E&gt; &lt;End&gt;
" forward one character
:cnoremap &lt;C-F&gt; &lt;Right&gt;
" recall newer command-line
:cnoremap &lt;C-N&gt; &lt;Down&gt;
" recall previous (older) command-line
:cnoremap &lt;C-P&gt; &lt;Up&gt;
" back one word
:cnoremap &lt;Esc&gt;&lt;C-B&gt; &lt;S-Left&gt;
" forward one word
:cnoremap &lt;Esc&gt;&lt;C-F&gt; &lt;S-Right&gt;
cnoremap &lt;C-j&gt; &lt;t_kd&gt;
cnoremap &lt;C-k&gt; &lt;t_ku&gt;
&lt;/br&gt;
"Treat long lines as break lines (useful when moving around in them)
"se swap之后，同物理行上线直接跳
map j gj
map k gk
&lt;/br&gt;
" Go to home and end using capitalized directions
noremap H ^
noremap L $l
&lt;/br&gt;
" select all
map &lt;Leader&gt;sa ggVG"
&lt;/br&gt;
" select block
nnoremap &lt;leader&gt;v V`}
&lt;/br&gt;
" w!! to sudo &amp; write a file
cmap w!! w !sudo tee &gt;/dev/null %
&lt;/br&gt;
" kj 替换 Esc
inoremap kj &lt;Esc&gt;
&lt;/br&gt;
" 滚动Speed up scrolling of the viewport slightly
nnoremap &lt;C-e&gt; 2&lt;C-e&gt;
nnoremap &lt;C-y&gt; 2&lt;C-y&gt;
&lt;/br&gt;
"Jump to start and end of line using the home row keys
nmap t o&lt;ESC&gt;k
nmap T O&lt;ESC&gt;j
&lt;/br&gt;
" Swap implementations of ` and ' jump to markers
" By default, ' jumps to the marked line, ` jumps to the marked line and
" column, so swap them
nnoremap ' `
nnoremap ` '
&lt;/br&gt;
" remap U to &lt;C-r&gt; for easier redo
nnoremap U &lt;C-r&gt;
&lt;/br&gt;
" Quickly edit/reload the vimrc file
nmap &lt;silent&gt; &lt;leader&gt;ev :e $MYVIMRC&lt;CR&gt;
nmap &lt;silent&gt; &lt;leader&gt;sv :so $MYVIMRC&lt;CR&gt;
&lt;/br&gt;
" 搜索相关
" 进入搜索Use sane regexes"
nnoremap / /\v
vnoremap / /\v
&lt;/br&gt;
" 去掉搜索高亮
noremap &lt;silent&gt;&lt;leader&gt;/ :nohls&lt;CR&gt;
"Keep search pattern at the center of the screen."
nnoremap &lt;silent&gt; n nzz
nnoremap &lt;silent&gt; N Nzz
nnoremap &lt;silent&gt; * *zz
nnoremap &lt;silent&gt; # #zz
nnoremap &lt;silent&gt; g* g*zz
&lt;/code&gt;&lt;/pre&gt;

&lt;/br&gt;
<pre><code>
"==========================================
" Function Settings  自定义函数功能 function.vimrc
"==========================================
function! RunShell(Msg, Shell)
	echo a:Msg . '...'
	call system(a:Shell)
	echon 'done'
endfunction
&lt;/br&gt;
function! ReName()
    let old_name = expand("&lt;cword&gt;")
    let old_name = input("old name:",old_name)
	let new_name = input("new name:",old_name)
    let exec = input("are sure to refactor(y/n|Y/N):")
    if 'y' == exec || 'Y' == exec
        let cmd = printf("/opt/sys/settings/bin/vim/shell/ref.sh %s %s",old_name,new_name)
        echo cmd
        :call RunShell("refactoring",cmd)
    endif
endfunction
&lt;/br&gt;
let g:spx_begin = 0
&lt;/br&gt;
function! GetCurrentCursor()
    let g:spx_begin = line('.')
    let g:spx_begin = g:spx_begin + 0
    echo "get current line idx:".g:spx_begin
endfunction
&lt;/br&gt;
function! ClearCurrentCursor()
    let g:spx_begin = 0
    echo "clear current cursor is success"
endfunction
&lt;/br&gt;
function! CopyLinesToSystem()
    let begin_idx = 0
    if 0 != g:spx_begin
        let begin_idx = g:spx_begin
        let g:spx_cpy_begin = 0
    else
        let begin_idx = line(".")
        let begin_idx = input("begin line idx:",begin_idx)
    endif
    let end_idx = line(".")
    let end_idx = input("end line idx:",end_idx)
    let begin_idx = begin_idx + 0
    let end_idx = end_idx + 0
    if begin_idx &gt; end_idx
        let tmp = begin_idx
        let begin_idx = end_idx
        let end_idx = tmp
    endif
    let list = getline(begin_idx,end_idx)
    let lines = join(list,"\n")
    call setreg("+",lines)
    echo "copy lines to system begin:" . begin_idx . " end:" . end_idx
endfunction
&lt;/br&gt;
function! DeleteLines()
    let begin_idx = 0
    if 0 != g:spx_begin
        let begin_idx = g:spx_begin
        let g:spx_cpy_begin = 0
    else
        let begin_idx = line('.')
        let begin_idx = input("begin line idx:",begin_idx)
    endif
    let end_idx = line('.')
    let end_idx = input("end line idx:",end_idx)
    let begin_idx = begin_idx + 0
    let end_idx = end_idx + 0
    if begin_idx &gt; end_idx
        let tmp = begin_idx
        let begin_idx = end_idx
        let end_idx = tmp
    endif
    let cur = getpos('.')
    let cur[1] = begin_idx + 0
    let result = setpos('.',cur)
    if(0 != result)
        echo "delete lines begin:" . begin_idx . " end:" . end_idx ." is fail"
        return
    endif
    let lines = abs(begin_idx - end_idx) + 1 "add the line self
    "for fold
    execute ":". begin_idx . "," . end_idx . "de"
    echo "delete lines begin:" . begin_idx . " end:" . end_idx
endfunction
&lt;/br&gt;
noremap &lt;leader&gt;xg :call GetCurrentCursor()&lt;cr&gt;
noremap &lt;leader&gt;xc :cal ClearCurrentCursor()&lt;cr&gt;
noremap &lt;leader&gt;xy :call CopyLinesToSystem()&lt;cr&gt;
noremap &lt;leader&gt;xd :call DeleteLines()&lt;cr&gt;
noremap &lt;leader&gt;xr :call ReName()&lt;cr&gt;
&lt;/br&gt;
nmap &lt;M-g&gt; :call GetCurrentCursor()&lt;cr&gt;
nmap &lt;M-c&gt; :call ClearCurrentCursor()&lt;cr&gt;
nmap &lt;M-y&gt; :call CopyLinesToSystem()&lt;cr&gt;
nmap &lt;M-d&gt; :call DeleteLines()&lt;cr&gt;
nmap &lt;M-r&gt; :call ReName()&lt;cr&gt;
&lt;/br&gt;
"设定当前列高亮
function! SetColorColumn()
    let col_num = virtcol(".")
    let cc_list = split(&amp;cc, ',')
    if count(cc_list, string(col_num)) &lt;= 0
        execute "set cc+=".col_num
    else
        execute "set cc-=".col_num
    endif
endfunction
map &lt;leader&gt;ch :call SetColorColumn()&lt;CR&gt;
&lt;/br&gt;
" 定义函数AutoSetFileHead，自动插入文件头
autocmd BufNewFile *.sh,*.py,*.md exec ":call AutoSetFileHead()"
function! AutoSetFileHead()
    "如果文件类型为.sh文件
    if &amp;filetype == 'sh'
        call setline(1, "\#!/bin/bash")
    endif

    "如果文件类型为python
    if &amp;filetype == 'python'
        call setline(1, "\#!/usr/bin/env python")
        call append(1, "\# encoding: utf-8")
    endif
    if &amp;filetype == 'mkd' || &amp;filetype == 'md'
        call setline('.',"---")
        normal ==o
        call setline('.',"layout: post")
        normal ==o
        call setline('.',"categories: []")
        normal ==o
        call setline('.',"title: \" \"")
        normal ==o
        call setline('.',"tags: []")
        normal ==o
        call setline('.',"---")
        normal ==o
    endif

    normal G
    normal o
    normal o
endfunc
&lt;/br&gt;
" 保存文件时删除多余空格
" Delete trailing white space on save, useful for Python and CoffeeScript ;)
func! DeleteTrailingWS()
  exe "normal mz"
  %s/\s\+$//ge
  exe "normal `z"
endfunc
autocmd BufWrite *.py :call DeleteTrailingWS()
autocmd BufWrite *.c :call DeleteTrailingWS()
autocmd BufWrite *.h :call DeleteTrailingWS()
autocmd BufWrite *.vimrc :call DeleteTrailingWS()
&lt;/br&gt;
" 相对行号      行号变成相对，可以用 nj  nk   进行跳转 5j   5k 上下跳5行
set relativenumber number
au FocusLost * :set norelativenumber number
au FocusGained * :set relativenumber
" 插入模式下用绝对行号, 普通模式下用相对
autocmd InsertEnter * :set norelativenumber number
autocmd InsertLeave * :set relativenumber
function! NumberToggle()
  if(&amp;relativenumber == 1)
    set norelativenumber number
  else
    set relativenumber
  endif
endfunc
nnoremap &lt;C-t&gt; :call NumberToggle()&lt;cr&gt;
&lt;/br&gt;
function InsertHeadDef(firstLine, lastLine)
    if a:firstLine &lt;1 || a:lastLine&gt; line('$')
        echoerr 'InsertHeadDef : Range overflow !(FirstLine:'.a:firstLine.';LastLine:'.a:lastLine.';ValidRange:1~'.line('$').')'
        return ''
    endif
    let sourcefilename=expand("%:t")
    let definename=substitute(sourcefilename,' ','','g')
    let definename=substitute(definename,'\.','_','g')
    let definename = toupper(definename)
    exe 'normal '.a:firstLine.'GO'
    call setline('.', '#ifndef _'.definename."_")
    normal ==o
    call setline('.', '#define _'.definename."_")
    normal ==o
    call setline('.', '#ifdef __cplusplus')
    normal ==o
    call setline('.', 'extern "C" {')
    normal ==o
    call setline('.', '#endif')
    normal ==o
    exe 'normal =='.(a:lastLine-a:firstLine+1).'jo'
    call setline('.', '#ifdef __cplusplus')
    normal ==o
    call setline('.', '}')
    normal ==o
    call setline('.', '#endif')
    normal ==o
    call setline('.', '#endif')
    let goLn = a:firstLine+2
    exe 'normal =='.goLn.'G'
endfunction
function InsertHeadDefN()
    let firstLine = 1
    let lastLine = line('$')
    let n=1
    while n &lt; 20
        let line = getline(n)
        if n==1
            if line =~ '^\/\*.*$'
                let n = n + 1
                continue
            else
                break
            endif
        endif
        if line =~ '^.*\*\/$'
            let firstLine = n+1
            break
        endif
        let n = n + 1
    endwhile
    call InsertHeadDef(firstLine, lastLine)
endfunction
nmap ha :call InsertHeadDefN()&lt;CR&gt;
</code></pre>
</而连续缩进了></code></pre></cr></code></pre>

                    ]]>
                </content:encoded>
                <guid isPermaLink="false">/blog/2014/vim/</guid>
                <description>
                    
                </description>
                <pubDate>Sat, 30 Aug 2014 00:00:00 +0800</pubDate>
                <author>94geek.com by Seapeak.Xu</author>
            </item>
        
    
        
            <item>
                <title>系统配置</title>
                <link>http://www.94geek.com/blog/2014/system/</link>
                <content:encoded>
                    <![CDATA[
                    <h4 id="摘要">摘要</h4>
<p>多年来，具体来说5年了，我一直使用ub+awesome的工作环境。在过程中，被公司的同事
笑成为”生活在CUI”中的另类。我选中ub是因为方便，apt-get实在让我无法自拔，并且ub
对于desktop的支持也是很多别的linux发行版无法比拟的。cos等等都比较适合部署在
server环境上。选中awesome，是因为喜欢它简洁的界面，瓦片式的管理也让屏幕的任何
一部分都不会被浪费。再加上我本身就喜欢CUI，所以awesome就成了首选。这些年来，积
累了一些配置文件，个人觉得还算用着顺手，这里就拿出来分享一下。</p>

<p><img src="awesome.jpg" alt="awesome" /></p>

<ol>
  <li>声音。<br />
ub的root默认是不开的，我又不喜欢使用sudo，就是不喜欢那种隔一层纱的感觉，所以虽
然自知linux不推荐开启root，但是我还是喜欢使用root的直接。所以一般我第一件事情
就是把root开启。开启的root的命令是：
    <div class="highlighter-rouge"><pre class="highlight"><code>sudo pwsswd root
</code></pre>
    </div>
    <p>然后输入你的root密码，这样就算是打开了，但是还不能登陆。还需要更改登陆配置。找
到/etc/gdm/gdm.conf，然后把AllowRoot改为true。<br />
如果你的root账户还不能登陆，你还需要去”系统-&gt;系统管理-&gt;登陆窗口”中的安全页中把
“允许本地系统管理员登陆”选项打开。</p>
  </li>
  <li>声音。<br />
root登陆后，你会发现声音没了。对我这种上班就带上耳机的人来说这是相当不能接受的
。所以你也要把声音打开。找到pulseaudio文件，然后把文件内的两个选项改成以下这样：
    <div class="highlighter-rouge"><pre class="highlight"><code>PULSEAUDIO_SYSTEM_START=1
DISALLOW_MODULE_LOADING=0
</code></pre>
    </div>
    <p>重启，就会有声音了。但是还有一个问题就是不知道为什么，有的时候启动的时候也是没
有声音，但是重启一下就正常了，分析了一下日志也没发现有什么问题，如果你知道，请
你告诉我。</p>
  </li>
  <li>chrome在root下无法启动。<br />
ub的root环境下，chrome无法启动，所以必须得给它加一个脚本，自定义user-data-dir
参数，就可以了。
    <div class="highlighter-rouge"><pre class="highlight"><code># /bin/bash
google-chrome \-\-user-data-dir=/root/.config/google-chrome &amp;
</code></pre>
    </div>
  </li>
  <li>awesome<br />
安装awesome
    <div class="highlighter-rouge"><pre class="highlight"><code>apt-get install awesome
</code></pre>
    </div>
    <p>awesome在/etc/下有一个文件夹是有它的配置文件的，awesome的配置文件使用lua写的，
个人的配置文件如下：</p>
  </li>
</ol>

<figure class="highlight"><pre><code class="language-lua" data-lang="lua">    <span class="c1">-- Standard awesome library</span>
    <span class="nb">require</span><span class="p">(</span><span class="s2">"awful"</span><span class="p">)</span>
    <span class="nb">require</span><span class="p">(</span><span class="s2">"awful.autofocus"</span><span class="p">)</span>
    <span class="nb">require</span><span class="p">(</span><span class="s2">"awful.rules"</span><span class="p">)</span>
    <span class="c1">-- Theme handling library</span>
    <span class="nb">require</span><span class="p">(</span><span class="s2">"beautiful"</span><span class="p">)</span>
    <span class="c1">-- Notification library</span>
    <span class="nb">require</span><span class="p">(</span><span class="s2">"naughty"</span><span class="p">)</span>
    <span class="c1">-- Load Debian menu entries</span>
    <span class="nb">require</span><span class="p">(</span><span class="s2">"debian.menu"</span><span class="p">)</span>

    <span class="c1">-- Themes define colours, icons, and wallpapers</span>
    <span class="n">beautiful</span><span class="p">.</span><span class="n">init</span><span class="p">(</span><span class="s2">"/usr/share/awesome/themes/default/theme.lua"</span><span class="p">)</span>

    <span class="c1">-- This is used later as the default terminal and editor to run.</span>
    <span class="n">terminal</span> <span class="o">=</span> <span class="s2">"x-terminal-emulator"</span>
    <span class="n">editor</span> <span class="o">=</span> <span class="nb">os.getenv</span><span class="p">(</span><span class="s2">"EDITOR"</span><span class="p">)</span> <span class="ow">or</span> <span class="s2">"editor"</span>
    <span class="n">editor_cmd</span> <span class="o">=</span> <span class="n">terminal</span> <span class="o">..</span> <span class="s2">" -e "</span> <span class="o">..</span> <span class="n">editor</span>

    <span class="c1">-- Default modkey.</span>
    <span class="c1">-- Usually, Mod4 is the key with a logo between Control and Alt.</span>
    <span class="c1">-- If you do not like this or do not have such a key,</span>
    <span class="c1">-- I suggest you to remap Mod4 to another key using xmodmap or other tools.</span>
    <span class="c1">-- However, you can use another modifier like Mod1, but it may interact with others.</span>

    <span class="n">modkey</span> <span class="o">=</span> <span class="s2">"Mod4"</span>
    <span class="c1">--modkey = "alt"</span>

    <span class="c1">-- Table of layouts to cover with awful.layout.inc, order matters.</span>
    <span class="n">layouts</span> <span class="o">=</span>
    <span class="p">{</span>
        <span class="n">awful</span><span class="p">.</span><span class="n">layout</span><span class="p">.</span><span class="n">suit</span><span class="p">.</span><span class="n">floating</span><span class="p">,</span>
        <span class="n">awful</span><span class="p">.</span><span class="n">layout</span><span class="p">.</span><span class="n">suit</span><span class="p">.</span><span class="n">tile</span><span class="p">,</span>
        <span class="n">awful</span><span class="p">.</span><span class="n">layout</span><span class="p">.</span><span class="n">suit</span><span class="p">.</span><span class="n">tile</span><span class="p">.</span><span class="n">left</span><span class="p">,</span>
        <span class="n">awful</span><span class="p">.</span><span class="n">layout</span><span class="p">.</span><span class="n">suit</span><span class="p">.</span><span class="n">tile</span><span class="p">.</span><span class="n">bottom</span><span class="p">,</span>
        <span class="n">awful</span><span class="p">.</span><span class="n">layout</span><span class="p">.</span><span class="n">suit</span><span class="p">.</span><span class="n">tile</span><span class="p">.</span><span class="n">top</span><span class="p">,</span>
        <span class="n">awful</span><span class="p">.</span><span class="n">layout</span><span class="p">.</span><span class="n">suit</span><span class="p">.</span><span class="n">fair</span><span class="p">,</span>
        <span class="n">awful</span><span class="p">.</span><span class="n">layout</span><span class="p">.</span><span class="n">suit</span><span class="p">.</span><span class="n">fair</span><span class="p">.</span><span class="n">horizontal</span><span class="p">,</span>
        <span class="n">awful</span><span class="p">.</span><span class="n">layout</span><span class="p">.</span><span class="n">suit</span><span class="p">.</span><span class="n">spiral</span><span class="p">,</span>
        <span class="n">awful</span><span class="p">.</span><span class="n">layout</span><span class="p">.</span><span class="n">suit</span><span class="p">.</span><span class="n">spiral</span><span class="p">.</span><span class="n">dwindle</span><span class="p">,</span>
        <span class="n">awful</span><span class="p">.</span><span class="n">layout</span><span class="p">.</span><span class="n">suit</span><span class="p">.</span><span class="n">max</span><span class="p">,</span>
        <span class="n">awful</span><span class="p">.</span><span class="n">layout</span><span class="p">.</span><span class="n">suit</span><span class="p">.</span><span class="n">max</span><span class="p">.</span><span class="n">fullscreen</span><span class="p">,</span>
        <span class="n">awful</span><span class="p">.</span><span class="n">layout</span><span class="p">.</span><span class="n">suit</span><span class="p">.</span><span class="n">magnifier</span>
    <span class="p">}</span>

    <span class="c1">-- Define a tag table which hold all screen tags.</span>
    <span class="n">tags</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">screen</span><span class="p">.</span><span class="n">count</span><span class="p">()</span> <span class="k">do</span>
        <span class="c1">-- Each screen has its own tag table.</span>
        <span class="n">tags</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">awful</span><span class="p">.</span><span class="n">tag</span><span class="p">({</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span> <span class="p">},</span> <span class="n">s</span><span class="p">,</span> <span class="n">layouts</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
    <span class="k">end</span>

    <span class="c1">-- Create a laucher widget and a main menu</span>
    <span class="n">myawesomemenu</span> <span class="o">=</span> <span class="p">{</span>
        <span class="p">{</span> <span class="s2">"manual"</span><span class="p">,</span> <span class="n">terminal</span> <span class="o">..</span> <span class="s2">" -e man awesome"</span> <span class="p">},</span>
        <span class="p">{</span> <span class="s2">"edit config"</span><span class="p">,</span> <span class="n">editor_cmd</span> <span class="o">..</span> <span class="s2">" "</span> <span class="o">..</span> <span class="n">awful</span><span class="p">.</span><span class="n">util</span><span class="p">.</span><span class="n">getdir</span><span class="p">(</span><span class="s2">"config"</span><span class="p">)</span> <span class="o">..</span> <span class="s2">"/rc.lua"</span> <span class="p">},</span>
        <span class="p">{</span> <span class="s2">"restart"</span><span class="p">,</span> <span class="n">awesome</span><span class="p">.</span><span class="n">restart</span> <span class="p">},</span>
        <span class="p">{</span> <span class="s2">"quit"</span><span class="p">,</span> <span class="n">awesome</span><span class="p">.</span><span class="n">quit</span> <span class="p">}</span>
    <span class="p">}</span>

    <span class="n">mymainmenu</span> <span class="o">=</span> <span class="n">awful</span><span class="p">.</span><span class="n">menu</span><span class="p">({</span> <span class="n">items</span> <span class="o">=</span> <span class="p">{</span> <span class="p">{</span> <span class="s2">"awesome"</span><span class="p">,</span> <span class="n">myawesomemenu</span><span class="p">,</span> <span class="n">beautiful</span><span class="p">.</span><span class="n">awesome_icon</span> <span class="p">},</span>
    <span class="p">{</span> <span class="s2">"Linux"</span><span class="p">,</span> <span class="n">debian</span><span class="p">.</span><span class="n">menu</span><span class="p">.</span><span class="n">Debian_menu</span><span class="p">.</span><span class="n">Debian</span> <span class="p">},</span>
    <span class="p">{</span> <span class="s2">"shell"</span><span class="p">,</span> <span class="n">terminal</span> <span class="p">},</span>
                    <span class="p">}</span>
                <span class="p">})</span>
    <span class="n">mylauncher</span> <span class="o">=</span> <span class="n">awful</span><span class="p">.</span><span class="n">widget</span><span class="p">.</span><span class="n">launcher</span><span class="p">({</span> <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="p">(</span><span class="n">beautiful</span><span class="p">.</span><span class="n">awesome_icon</span><span class="p">),</span>
    <span class="n">menu</span> <span class="o">=</span> <span class="n">mymainmenu</span> <span class="p">})</span>

    <span class="c1">-- Create a textclock widget</span>
    <span class="n">mytextclock</span> <span class="o">=</span> <span class="n">awful</span><span class="p">.</span><span class="n">widget</span><span class="p">.</span><span class="n">textclock</span><span class="p">({</span> <span class="n">align</span> <span class="o">=</span> <span class="s2">"right"</span> <span class="p">})</span>
    <span class="c1">-- Create a systray</span>
    <span class="n">mysystray</span> <span class="o">=</span> <span class="n">widget</span><span class="p">({</span> <span class="nb">type</span> <span class="o">=</span> <span class="s2">"systray"</span> <span class="p">})</span>
    <span class="c1">-- Create a wibox for each screen and add it</span>
    <span class="n">mywibox</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">mypromptbox</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">mylayoutbox</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">mytaglist</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">mytaglist</span><span class="p">.</span><span class="n">buttons</span> <span class="o">=</span> <span class="n">awful</span><span class="p">.</span><span class="n">util</span><span class="p">.</span><span class="n">table</span><span class="p">.</span><span class="n">join</span><span class="p">(</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">button</span><span class="p">({</span> <span class="p">},</span> <span class="mi">1</span><span class="p">,</span> <span class="n">awful</span><span class="p">.</span><span class="n">tag</span><span class="p">.</span><span class="n">viewonly</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">button</span><span class="p">({</span> <span class="n">modkey</span> <span class="p">},</span> <span class="mi">1</span><span class="p">,</span> <span class="n">awful</span><span class="p">.</span><span class="n">client</span><span class="p">.</span><span class="n">movetotag</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">button</span><span class="p">({</span> <span class="p">},</span> <span class="mi">3</span><span class="p">,</span> <span class="n">awful</span><span class="p">.</span><span class="n">tag</span><span class="p">.</span><span class="n">viewtoggle</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">button</span><span class="p">({</span> <span class="n">modkey</span> <span class="p">},</span> <span class="mi">3</span><span class="p">,</span> <span class="n">awful</span><span class="p">.</span><span class="n">client</span><span class="p">.</span><span class="n">toggletag</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">button</span><span class="p">({</span> <span class="p">},</span> <span class="mi">4</span><span class="p">,</span> <span class="n">awful</span><span class="p">.</span><span class="n">tag</span><span class="p">.</span><span class="n">viewnext</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">button</span><span class="p">({</span> <span class="p">},</span> <span class="mi">5</span><span class="p">,</span> <span class="n">awful</span><span class="p">.</span><span class="n">tag</span><span class="p">.</span><span class="n">viewprev</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">mytasklist</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">mytasklist</span><span class="p">.</span><span class="n">buttons</span> <span class="o">=</span> <span class="n">awful</span><span class="p">.</span><span class="n">util</span><span class="p">.</span><span class="n">table</span><span class="p">.</span><span class="n">join</span><span class="p">(</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">button</span><span class="p">({</span> <span class="p">},</span> <span class="mi">1</span><span class="p">,</span> <span class="k">function</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">c</span><span class="p">:</span><span class="n">isvisible</span><span class="p">()</span> <span class="k">then</span>
            <span class="n">awful</span><span class="p">.</span><span class="n">tag</span><span class="p">.</span><span class="n">viewonly</span><span class="p">(</span><span class="n">c</span><span class="p">:</span><span class="n">tags</span><span class="p">()[</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">end</span>
        <span class="n">client</span><span class="p">.</span><span class="n">focus</span> <span class="o">=</span> <span class="n">c</span>
        <span class="n">c</span><span class="p">:</span><span class="n">raise</span><span class="p">()</span>
    <span class="k">end</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">button</span><span class="p">({</span> <span class="p">},</span> <span class="mi">3</span><span class="p">,</span> <span class="k">function</span> <span class="p">()</span>
        <span class="k">if</span> <span class="n">instance</span> <span class="k">then</span>
            <span class="n">instance</span><span class="p">:</span><span class="n">hide</span><span class="p">()</span>
            <span class="n">instance</span> <span class="o">=</span> <span class="kc">nil</span>
        <span class="k">else</span>
            <span class="n">instance</span> <span class="o">=</span> <span class="n">awful</span><span class="p">.</span><span class="n">menu</span><span class="p">.</span><span class="n">clients</span><span class="p">({</span> <span class="n">width</span><span class="o">=</span><span class="mi">250</span> <span class="p">})</span>
        <span class="k">end</span>
    <span class="k">end</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">button</span><span class="p">({</span> <span class="p">},</span> <span class="mi">4</span><span class="p">,</span> <span class="k">function</span> <span class="p">()</span>
        <span class="n">awful</span><span class="p">.</span><span class="n">client</span><span class="p">.</span><span class="n">focus</span><span class="p">.</span><span class="n">byidx</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">client</span><span class="p">.</span><span class="n">focus</span> <span class="k">then</span> <span class="n">client</span><span class="p">.</span><span class="n">focus</span><span class="p">:</span><span class="n">raise</span><span class="p">()</span> <span class="k">end</span>
    <span class="k">end</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">button</span><span class="p">({</span> <span class="p">},</span> <span class="mi">5</span><span class="p">,</span> <span class="k">function</span> <span class="p">()</span>
        <span class="n">awful</span><span class="p">.</span><span class="n">client</span><span class="p">.</span><span class="n">focus</span><span class="p">.</span><span class="n">byidx</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">client</span><span class="p">.</span><span class="n">focus</span> <span class="k">then</span> <span class="n">client</span><span class="p">.</span><span class="n">focus</span><span class="p">:</span><span class="n">raise</span><span class="p">()</span> <span class="k">end</span>
    <span class="k">end</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">screen</span><span class="p">.</span><span class="n">count</span><span class="p">()</span> <span class="k">do</span>
        <span class="c1">-- Create a promptbox for each screen</span>
        <span class="n">mypromptbox</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">awful</span><span class="p">.</span><span class="n">widget</span><span class="p">.</span><span class="n">prompt</span><span class="p">({</span> <span class="n">layout</span> <span class="o">=</span> <span class="n">awful</span><span class="p">.</span><span class="n">widget</span><span class="p">.</span><span class="n">layout</span><span class="p">.</span><span class="n">horizontal</span><span class="p">.</span><span class="n">leftright</span> <span class="p">})</span>
        <span class="c1">-- Create an imagebox widget which will contains an icon indicating which layout we're using.</span>
        <span class="c1">-- We need one layoutbox per screen.</span>
        <span class="n">mylayoutbox</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">awful</span><span class="p">.</span><span class="n">widget</span><span class="p">.</span><span class="n">layoutbox</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
        <span class="n">mylayoutbox</span><span class="p">[</span><span class="n">s</span><span class="p">]:</span><span class="n">buttons</span><span class="p">(</span><span class="n">awful</span><span class="p">.</span><span class="n">util</span><span class="p">.</span><span class="n">table</span><span class="p">.</span><span class="n">join</span><span class="p">(</span>
        <span class="n">awful</span><span class="p">.</span><span class="n">button</span><span class="p">({</span> <span class="p">},</span> <span class="mi">1</span><span class="p">,</span> <span class="k">function</span> <span class="p">()</span> <span class="n">awful</span><span class="p">.</span><span class="n">layout</span><span class="p">.</span><span class="n">inc</span><span class="p">(</span><span class="n">layouts</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">end</span><span class="p">),</span>
        <span class="n">awful</span><span class="p">.</span><span class="n">button</span><span class="p">({</span> <span class="p">},</span> <span class="mi">3</span><span class="p">,</span> <span class="k">function</span> <span class="p">()</span> <span class="n">awful</span><span class="p">.</span><span class="n">layout</span><span class="p">.</span><span class="n">inc</span><span class="p">(</span><span class="n">layouts</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">end</span><span class="p">),</span>
        <span class="n">awful</span><span class="p">.</span><span class="n">button</span><span class="p">({</span> <span class="p">},</span> <span class="mi">4</span><span class="p">,</span> <span class="k">function</span> <span class="p">()</span> <span class="n">awful</span><span class="p">.</span><span class="n">layout</span><span class="p">.</span><span class="n">inc</span><span class="p">(</span><span class="n">layouts</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="k">end</span><span class="p">),</span>
        <span class="n">awful</span><span class="p">.</span><span class="n">button</span><span class="p">({</span> <span class="p">},</span> <span class="mi">5</span><span class="p">,</span> <span class="k">function</span> <span class="p">()</span> <span class="n">awful</span><span class="p">.</span><span class="n">layout</span><span class="p">.</span><span class="n">inc</span><span class="p">(</span><span class="n">layouts</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">end</span><span class="p">)))</span>
        <span class="c1">-- Create a taglist widget</span>
        <span class="n">mytaglist</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">awful</span><span class="p">.</span><span class="n">widget</span><span class="p">.</span><span class="n">taglist</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">awful</span><span class="p">.</span><span class="n">widget</span><span class="p">.</span><span class="n">taglist</span><span class="p">.</span><span class="n">label</span><span class="p">.</span><span class="n">all</span><span class="p">,</span> <span class="n">mytaglist</span><span class="p">.</span><span class="n">buttons</span><span class="p">)</span>
        <span class="c1">-- Create a tasklist widget</span>
        <span class="n">mytasklist</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">awful</span><span class="p">.</span><span class="n">widget</span><span class="p">.</span><span class="n">tasklist</span><span class="p">(</span><span class="k">function</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">awful</span><span class="p">.</span><span class="n">widget</span><span class="p">.</span><span class="n">tasklist</span><span class="p">.</span><span class="n">label</span><span class="p">.</span><span class="n">currenttags</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
        <span class="k">end</span><span class="p">,</span> <span class="n">mytasklist</span><span class="p">.</span><span class="n">buttons</span><span class="p">)</span>
        <span class="c1">-- Create the wibox</span>
        <span class="n">mywibox</span><span class="p">[</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">awful</span><span class="p">.</span><span class="n">wibox</span><span class="p">({</span> <span class="n">position</span> <span class="o">=</span> <span class="s2">"top"</span><span class="p">,</span> <span class="n">screen</span> <span class="o">=</span> <span class="n">s</span> <span class="p">})</span>
        <span class="c1">-- Add widgets to the wibox - order matters</span>
        <span class="n">mywibox</span><span class="p">[</span><span class="n">s</span><span class="p">].</span><span class="n">widgets</span> <span class="o">=</span> <span class="p">{</span>
            <span class="p">{</span>
                <span class="n">mylauncher</span><span class="p">,</span>
                <span class="n">mytaglist</span><span class="p">[</span><span class="n">s</span><span class="p">],</span>
                <span class="n">mypromptbox</span><span class="p">[</span><span class="n">s</span><span class="p">],</span>
                <span class="n">layout</span> <span class="o">=</span> <span class="n">awful</span><span class="p">.</span><span class="n">widget</span><span class="p">.</span><span class="n">layout</span><span class="p">.</span><span class="n">horizontal</span><span class="p">.</span><span class="n">leftright</span>
            <span class="p">},</span>
            <span class="n">mylayoutbox</span><span class="p">[</span><span class="n">s</span><span class="p">],</span>
            <span class="n">mytextclock</span><span class="p">,</span>
            <span class="n">s</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">mysystray</span> <span class="ow">or</span> <span class="kc">nil</span><span class="p">,</span>
            <span class="n">mytasklist</span><span class="p">[</span><span class="n">s</span><span class="p">],</span>
            <span class="n">layout</span> <span class="o">=</span> <span class="n">awful</span><span class="p">.</span><span class="n">widget</span><span class="p">.</span><span class="n">layout</span><span class="p">.</span><span class="n">horizontal</span><span class="p">.</span><span class="n">rightleft</span>
        <span class="p">}</span>
    <span class="k">end</span>

    <span class="n">root</span><span class="p">.</span><span class="n">buttons</span><span class="p">(</span><span class="n">awful</span><span class="p">.</span><span class="n">util</span><span class="p">.</span><span class="n">table</span><span class="p">.</span><span class="n">join</span><span class="p">(</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">button</span><span class="p">({</span> <span class="p">},</span> <span class="mi">3</span><span class="p">,</span> <span class="k">function</span> <span class="p">()</span> <span class="n">mymainmenu</span><span class="p">:</span><span class="n">toggle</span><span class="p">()</span> <span class="k">end</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">button</span><span class="p">({</span> <span class="p">},</span> <span class="mi">4</span><span class="p">,</span> <span class="n">awful</span><span class="p">.</span><span class="n">tag</span><span class="p">.</span><span class="n">viewnext</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">button</span><span class="p">({</span> <span class="p">},</span> <span class="mi">5</span><span class="p">,</span> <span class="n">awful</span><span class="p">.</span><span class="n">tag</span><span class="p">.</span><span class="n">viewprev</span><span class="p">)</span>
    <span class="p">))</span>

    <span class="n">globalkeys</span> <span class="o">=</span> <span class="n">awful</span><span class="p">.</span><span class="n">util</span><span class="p">.</span><span class="n">table</span><span class="p">.</span><span class="n">join</span><span class="p">(</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span>           <span class="p">},</span> <span class="s2">"Left"</span><span class="p">,</span>   <span class="n">awful</span><span class="p">.</span><span class="n">tag</span><span class="p">.</span><span class="n">viewprev</span>       <span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span>           <span class="p">},</span> <span class="s2">"Right"</span><span class="p">,</span>  <span class="n">awful</span><span class="p">.</span><span class="n">tag</span><span class="p">.</span><span class="n">viewnext</span>       <span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span>           <span class="p">},</span> <span class="s2">"Escape"</span><span class="p">,</span> <span class="n">awful</span><span class="p">.</span><span class="n">tag</span><span class="p">.</span><span class="n">history</span><span class="p">.</span><span class="n">restore</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span>           <span class="p">},</span> <span class="s2">"j"</span><span class="p">,</span>
    <span class="k">function</span> <span class="p">()</span>
        <span class="n">awful</span><span class="p">.</span><span class="n">client</span><span class="p">.</span><span class="n">focus</span><span class="p">.</span><span class="n">byidx</span><span class="p">(</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">client</span><span class="p">.</span><span class="n">focus</span> <span class="k">then</span> <span class="n">client</span><span class="p">.</span><span class="n">focus</span><span class="p">:</span><span class="n">raise</span><span class="p">()</span> <span class="k">end</span>
    <span class="k">end</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span>           <span class="p">},</span> <span class="s2">"k"</span><span class="p">,</span>
    <span class="k">function</span> <span class="p">()</span>
        <span class="n">awful</span><span class="p">.</span><span class="n">client</span><span class="p">.</span><span class="n">focus</span><span class="p">.</span><span class="n">byidx</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">client</span><span class="p">.</span><span class="n">focus</span> <span class="k">then</span> <span class="n">client</span><span class="p">.</span><span class="n">focus</span><span class="p">:</span><span class="n">raise</span><span class="p">()</span> <span class="k">end</span>
    <span class="k">end</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span>           <span class="p">},</span> <span class="s2">"w"</span><span class="p">,</span> <span class="k">function</span> <span class="p">()</span> <span class="n">mymainmenu</span><span class="p">:</span><span class="n">show</span><span class="p">(</span><span class="kc">true</span><span class="p">)</span>        <span class="k">end</span><span class="p">),</span>
    <span class="c1">-- Layout manipulation</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span> <span class="s2">"Shift"</span>   <span class="p">},</span> <span class="s2">"j"</span><span class="p">,</span> <span class="k">function</span> <span class="p">()</span> <span class="n">awful</span><span class="p">.</span><span class="n">client</span><span class="p">.</span><span class="n">swap</span><span class="p">.</span><span class="n">byidx</span><span class="p">(</span>  <span class="mi">1</span><span class="p">)</span>    <span class="k">end</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span> <span class="s2">"Shift"</span>   <span class="p">},</span> <span class="s2">"k"</span><span class="p">,</span> <span class="k">function</span> <span class="p">()</span> <span class="n">awful</span><span class="p">.</span><span class="n">client</span><span class="p">.</span><span class="n">swap</span><span class="p">.</span><span class="n">byidx</span><span class="p">(</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>    <span class="k">end</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span>           <span class="p">},</span> <span class="s2">","</span><span class="p">,</span> <span class="k">function</span> <span class="p">()</span> <span class="n">awful</span><span class="p">.</span><span class="n">screen</span><span class="p">.</span><span class="n">focus_relative</span><span class="p">(</span> <span class="mi">1</span><span class="p">)</span> <span class="k">end</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span>           <span class="p">},</span> <span class="s2">"."</span><span class="p">,</span> <span class="k">function</span> <span class="p">()</span> <span class="n">awful</span><span class="p">.</span><span class="n">screen</span><span class="p">.</span><span class="n">focus_relative</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">end</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span>           <span class="p">},</span> <span class="s2">"u"</span><span class="p">,</span> <span class="n">awful</span><span class="p">.</span><span class="n">client</span><span class="p">.</span><span class="n">urgent</span><span class="p">.</span><span class="n">jumpto</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span>           <span class="p">},</span> <span class="s2">"Tab"</span><span class="p">,</span>
    <span class="k">function</span> <span class="p">()</span>
        <span class="n">awful</span><span class="p">.</span><span class="n">client</span><span class="p">.</span><span class="n">focus</span><span class="p">.</span><span class="n">history</span><span class="p">.</span><span class="n">previous</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">client</span><span class="p">.</span><span class="n">focus</span> <span class="k">then</span>
            <span class="n">client</span><span class="p">.</span><span class="n">focus</span><span class="p">:</span><span class="n">raise</span><span class="p">()</span>
        <span class="k">end</span>
    <span class="k">end</span><span class="p">),</span>
    <span class="c1">-- Standard program</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span>           <span class="p">},</span> <span class="s2">"Return"</span><span class="p">,</span> <span class="k">function</span> <span class="p">()</span> <span class="n">awful</span><span class="p">.</span><span class="n">util</span><span class="p">.</span><span class="n">spawn</span><span class="p">(</span><span class="n">terminal</span><span class="p">)</span> <span class="k">end</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="p">},</span> <span class="s2">"XF86AudioRaiseVolume"</span><span class="p">,</span>    <span class="k">function</span> <span class="p">()</span> <span class="n">awful</span><span class="p">.</span><span class="n">util</span><span class="p">.</span><span class="n">spawn</span><span class="p">(</span><span class="s2">"amixer set Master 3+"</span><span class="p">)</span> <span class="k">end</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="p">},</span> <span class="s2">"XF86AudioLowerVolume"</span><span class="p">,</span>    <span class="k">function</span> <span class="p">()</span> <span class="n">awful</span><span class="p">.</span><span class="n">util</span><span class="p">.</span><span class="n">spawn</span><span class="p">(</span><span class="s2">"amixer set Master 3-"</span><span class="p">)</span> <span class="k">end</span><span class="p">),</span>
    <span class="c1">--define by myself</span>
    <span class="c1">--              awful.key({ modkey,           }, "F11", function () awful.util.spawn("dmenu_run") end),</span>
    <span class="c1">--awful.key({ modkey,           }, "v", function () awful.util.spawn("gnome-volume-control-applet") end),</span>
    <span class="c1">--awful.key({ modkey,"Control"  }, "n", function () awful.util.spawn("nm-applet") end),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span>		    <span class="p">},</span> <span class="s2">"x"</span><span class="p">,</span> <span class="k">function</span> <span class="p">()</span> <span class="n">awful</span><span class="p">.</span><span class="n">util</span><span class="p">.</span><span class="n">spawn</span><span class="p">(</span><span class="s2">"xlock"</span><span class="p">)</span> <span class="k">end</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span> <span class="s2">"Control"</span> <span class="p">},</span> <span class="s2">"r"</span><span class="p">,</span> <span class="n">awesome</span><span class="p">.</span><span class="n">restart</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span> <span class="s2">"Shift"</span>	  <span class="p">},</span> <span class="s2">"q"</span><span class="p">,</span> <span class="n">awesome</span><span class="p">.</span><span class="n">quit</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span>           <span class="p">},</span> <span class="s2">"l"</span><span class="p">,</span>     <span class="k">function</span> <span class="p">()</span> <span class="n">awful</span><span class="p">.</span><span class="n">tag</span><span class="p">.</span><span class="n">incmwfact</span><span class="p">(</span> <span class="mi">0</span><span class="p">.</span><span class="mi">05</span><span class="p">)</span>    <span class="k">end</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span>           <span class="p">},</span> <span class="s2">"h"</span><span class="p">,</span>     <span class="k">function</span> <span class="p">()</span> <span class="n">awful</span><span class="p">.</span><span class="n">tag</span><span class="p">.</span><span class="n">incmwfact</span><span class="p">(</span><span class="o">-</span><span class="mi">0</span><span class="p">.</span><span class="mi">05</span><span class="p">)</span>    <span class="k">end</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span> <span class="s2">"Shift"</span>   <span class="p">},</span> <span class="s2">"h"</span><span class="p">,</span>     <span class="k">function</span> <span class="p">()</span> <span class="n">awful</span><span class="p">.</span><span class="n">tag</span><span class="p">.</span><span class="n">incnmaster</span><span class="p">(</span> <span class="mi">1</span><span class="p">)</span>      <span class="k">end</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span> <span class="s2">"Shift"</span>   <span class="p">},</span> <span class="s2">"l"</span><span class="p">,</span>     <span class="k">function</span> <span class="p">()</span> <span class="n">awful</span><span class="p">.</span><span class="n">tag</span><span class="p">.</span><span class="n">incnmaster</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>      <span class="k">end</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span> <span class="s2">"Control"</span> <span class="p">},</span> <span class="s2">"h"</span><span class="p">,</span>     <span class="k">function</span> <span class="p">()</span> <span class="n">awful</span><span class="p">.</span><span class="n">tag</span><span class="p">.</span><span class="n">incncol</span><span class="p">(</span> <span class="mi">1</span><span class="p">)</span>         <span class="k">end</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span> <span class="s2">"Control"</span> <span class="p">},</span> <span class="s2">"l"</span><span class="p">,</span>     <span class="k">function</span> <span class="p">()</span> <span class="n">awful</span><span class="p">.</span><span class="n">tag</span><span class="p">.</span><span class="n">incncol</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>         <span class="k">end</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span>           <span class="p">},</span> <span class="s2">"space"</span><span class="p">,</span> <span class="k">function</span> <span class="p">()</span> <span class="n">awful</span><span class="p">.</span><span class="n">layout</span><span class="p">.</span><span class="n">inc</span><span class="p">(</span><span class="n">layouts</span><span class="p">,</span>  <span class="mi">1</span><span class="p">)</span> <span class="k">end</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span> <span class="s2">"Shift"</span>   <span class="p">},</span> <span class="s2">"space"</span><span class="p">,</span> <span class="k">function</span> <span class="p">()</span> <span class="n">awful</span><span class="p">.</span><span class="n">layout</span><span class="p">.</span><span class="n">inc</span><span class="p">(</span><span class="n">layouts</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">end</span><span class="p">),</span>
    <span class="c1">-- Prompt</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span> <span class="p">},</span>            <span class="s2">"r"</span><span class="p">,</span>     <span class="k">function</span> <span class="p">()</span> <span class="n">awful</span><span class="p">.</span><span class="n">util</span><span class="p">.</span><span class="n">spawn</span><span class="p">(</span><span class="s2">"dmenu_run"</span><span class="p">)</span> <span class="k">end</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="n">clientkeys</span> <span class="o">=</span> <span class="n">awful</span><span class="p">.</span><span class="n">util</span><span class="p">.</span><span class="n">table</span><span class="p">.</span><span class="n">join</span><span class="p">(</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span>           <span class="p">},</span> <span class="s2">"f"</span><span class="p">,</span>      <span class="k">function</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">c</span><span class="p">.</span><span class="n">fullscreen</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">c</span><span class="p">.</span><span class="n">fullscreen</span>  <span class="k">end</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span>		  <span class="p">},</span> <span class="s2">"c"</span><span class="p">,</span>      <span class="k">function</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">c</span><span class="p">:</span><span class="n">kill</span><span class="p">()</span>                         <span class="k">end</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span> <span class="s2">"Control"</span> <span class="p">},</span> <span class="s2">"space"</span><span class="p">,</span>  <span class="n">awful</span><span class="p">.</span><span class="n">client</span><span class="p">.</span><span class="n">floating</span><span class="p">.</span><span class="n">toggle</span>                     <span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span> <span class="s2">"Control"</span> <span class="p">},</span> <span class="s2">"Return"</span><span class="p">,</span> <span class="k">function</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">c</span><span class="p">:</span><span class="n">swap</span><span class="p">(</span><span class="n">awful</span><span class="p">.</span><span class="n">client</span><span class="p">.</span><span class="n">getmaster</span><span class="p">())</span> <span class="k">end</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span>           <span class="p">},</span> <span class="s2">"o"</span><span class="p">,</span>      <span class="n">awful</span><span class="p">.</span><span class="n">client</span><span class="p">.</span><span class="n">movetoscreen</span>                        <span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span> <span class="s2">"Shift"</span>   <span class="p">},</span> <span class="s2">"r"</span><span class="p">,</span>      <span class="k">function</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">c</span><span class="p">:</span><span class="n">redraw</span><span class="p">()</span>                       <span class="k">end</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span>           <span class="p">},</span> <span class="s2">"n"</span><span class="p">,</span>      <span class="k">function</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">c</span><span class="p">.</span><span class="n">minimized</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">c</span><span class="p">.</span><span class="n">minimized</span>    <span class="k">end</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span>           <span class="p">},</span> <span class="s2">"m"</span><span class="p">,</span>
    <span class="k">function</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span>
        <span class="n">c</span><span class="p">.</span><span class="n">maximized_horizontal</span> <span class="o">=</span> <span class="ow">not</span> <span class="n">c</span><span class="p">.</span><span class="n">maximized_horizontal</span>
        <span class="n">c</span><span class="p">.</span><span class="n">maximized_vertical</span>   <span class="o">=</span> <span class="ow">not</span> <span class="n">c</span><span class="p">.</span><span class="n">maximized_vertical</span>
    <span class="k">end</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="c1">-- Compute the maximum number of digit we need, limited to 9</span>
    <span class="n">keynumber</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">screen</span><span class="p">.</span><span class="n">count</span><span class="p">()</span> <span class="k">do</span>
        <span class="n">keynumber</span> <span class="o">=</span> <span class="nb">math.min</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="nb">math.max</span><span class="p">(</span><span class="o">#</span><span class="n">tags</span><span class="p">[</span><span class="n">s</span><span class="p">],</span> <span class="n">keynumber</span><span class="p">));</span>
    <span class="k">end</span>
    <span class="c1">-- Bind all key numbers to tags.</span>
    <span class="c1">-- Be careful: we use keycodes to make it works on any keyboard layout.</span>
    <span class="c1">-- This should map on the top row of your keyboard, usually 1 to 9.</span>
    <span class="k">for</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">keynumber</span> <span class="k">do</span>
        <span class="n">globalkeys</span> <span class="o">=</span> <span class="n">awful</span><span class="p">.</span><span class="n">util</span><span class="p">.</span><span class="n">table</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">globalkeys</span><span class="p">,</span>
        <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span> <span class="p">},</span> <span class="s2">"#"</span> <span class="o">..</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">9</span><span class="p">,</span>
        <span class="k">function</span> <span class="p">()</span>
            <span class="kd">local</span> <span class="n">screen</span> <span class="o">=</span> <span class="n">mouse</span><span class="p">.</span><span class="n">screen</span>
            <span class="k">if</span> <span class="n">tags</span><span class="p">[</span><span class="n">screen</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="k">then</span>
                <span class="n">awful</span><span class="p">.</span><span class="n">tag</span><span class="p">.</span><span class="n">viewonly</span><span class="p">(</span><span class="n">tags</span><span class="p">[</span><span class="n">screen</span><span class="p">][</span><span class="n">i</span><span class="p">])</span>
            <span class="k">end</span>
        <span class="k">end</span><span class="p">),</span>
        <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span> <span class="s2">"Control"</span> <span class="p">},</span> <span class="s2">"#"</span> <span class="o">..</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">9</span><span class="p">,</span>
        <span class="k">function</span> <span class="p">()</span>
            <span class="kd">local</span> <span class="n">screen</span> <span class="o">=</span> <span class="n">mouse</span><span class="p">.</span><span class="n">screen</span>
            <span class="k">if</span> <span class="n">tags</span><span class="p">[</span><span class="n">screen</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="k">then</span>
                <span class="n">awful</span><span class="p">.</span><span class="n">tag</span><span class="p">.</span><span class="n">viewtoggle</span><span class="p">(</span><span class="n">tags</span><span class="p">[</span><span class="n">screen</span><span class="p">][</span><span class="n">i</span><span class="p">])</span>
            <span class="k">end</span>
        <span class="k">end</span><span class="p">),</span>
        <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span><span class="s2">"Control"</span><span class="p">,</span>     	<span class="p">},</span> <span class="s2">"#"</span> <span class="o">..</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">9</span><span class="p">,</span>
        <span class="k">function</span> <span class="p">()</span>
            <span class="k">if</span> <span class="n">client</span><span class="p">.</span><span class="n">focus</span> <span class="ow">and</span> <span class="n">tags</span><span class="p">[</span><span class="n">client</span><span class="p">.</span><span class="n">focus</span><span class="p">.</span><span class="n">screen</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="k">then</span>
                <span class="n">awful</span><span class="p">.</span><span class="n">client</span><span class="p">.</span><span class="n">movetotag</span><span class="p">(</span><span class="n">tags</span><span class="p">[</span><span class="n">client</span><span class="p">.</span><span class="n">focus</span><span class="p">.</span><span class="n">screen</span><span class="p">][</span><span class="n">i</span><span class="p">])</span>
            <span class="k">end</span>
        <span class="k">end</span><span class="p">),</span>
        <span class="n">awful</span><span class="p">.</span><span class="n">key</span><span class="p">({</span> <span class="n">modkey</span><span class="p">,</span> <span class="s2">"Control"</span><span class="p">,</span> <span class="s2">"Shift"</span> <span class="p">},</span> <span class="s2">"#"</span> <span class="o">..</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">9</span><span class="p">,</span>
        <span class="k">function</span> <span class="p">()</span>
            <span class="k">if</span> <span class="n">client</span><span class="p">.</span><span class="n">focus</span> <span class="ow">and</span> <span class="n">tags</span><span class="p">[</span><span class="n">client</span><span class="p">.</span><span class="n">focus</span><span class="p">.</span><span class="n">screen</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="k">then</span>
                <span class="n">awful</span><span class="p">.</span><span class="n">client</span><span class="p">.</span><span class="n">toggletag</span><span class="p">(</span><span class="n">tags</span><span class="p">[</span><span class="n">client</span><span class="p">.</span><span class="n">focus</span><span class="p">.</span><span class="n">screen</span><span class="p">][</span><span class="n">i</span><span class="p">])</span>
            <span class="k">end</span>
        <span class="k">end</span><span class="p">))</span>
    <span class="k">end</span>
    <span class="n">clientbuttons</span> <span class="o">=</span> <span class="n">awful</span><span class="p">.</span><span class="n">util</span><span class="p">.</span><span class="n">table</span><span class="p">.</span><span class="n">join</span><span class="p">(</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">button</span><span class="p">({</span> <span class="p">},</span> <span class="mi">1</span><span class="p">,</span> <span class="k">function</span> <span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">client</span><span class="p">.</span><span class="n">focus</span> <span class="o">=</span> <span class="n">c</span><span class="p">;</span> <span class="n">c</span><span class="p">:</span><span class="n">raise</span><span class="p">()</span> <span class="k">end</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">button</span><span class="p">({</span> <span class="n">modkey</span> <span class="p">},</span> <span class="mi">1</span><span class="p">,</span> <span class="n">awful</span><span class="p">.</span><span class="n">mouse</span><span class="p">.</span><span class="n">client</span><span class="p">.</span><span class="n">move</span><span class="p">),</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">button</span><span class="p">({</span> <span class="n">modkey</span> <span class="p">},</span> <span class="mi">3</span><span class="p">,</span> <span class="n">awful</span><span class="p">.</span><span class="n">mouse</span><span class="p">.</span><span class="n">client</span><span class="p">.</span><span class="n">resize</span><span class="p">))</span>
    <span class="c1">-- Set keys</span>
    <span class="n">root</span><span class="p">.</span><span class="n">keys</span><span class="p">(</span><span class="n">globalkeys</span><span class="p">)</span>

    <span class="n">awful</span><span class="p">.</span><span class="n">rules</span><span class="p">.</span><span class="n">rules</span> <span class="o">=</span> <span class="p">{</span>
        <span class="c1">-- All clients will match this rule.</span>
        <span class="p">{</span> <span class="n">rule</span> <span class="o">=</span> <span class="p">{</span> <span class="p">},</span>
        <span class="n">properties</span> <span class="o">=</span> <span class="p">{</span> <span class="n">border_width</span> <span class="o">=</span> <span class="n">beautiful</span><span class="p">.</span><span class="n">border_width</span><span class="p">,</span>
        <span class="n">border_color</span> <span class="o">=</span> <span class="n">beautiful</span><span class="p">.</span><span class="n">border_normal</span><span class="p">,</span>
        <span class="n">focus</span> <span class="o">=</span> <span class="kc">true</span><span class="p">,</span>
        <span class="n">keys</span> <span class="o">=</span> <span class="n">clientkeys</span><span class="p">,</span>
        <span class="n">buttons</span> <span class="o">=</span> <span class="n">clientbuttons</span> <span class="p">}</span> <span class="p">},</span>
        <span class="p">{</span> <span class="n">rule</span> <span class="o">=</span> <span class="p">{</span> <span class="n">class</span> <span class="o">=</span> <span class="s2">"MPlayer"</span> <span class="p">},</span>
        <span class="n">properties</span> <span class="o">=</span> <span class="p">{</span> <span class="n">floating</span> <span class="o">=</span> <span class="kc">true</span> <span class="p">}</span> <span class="p">},</span>
        <span class="p">{</span> <span class="n">rule</span> <span class="o">=</span> <span class="p">{</span> <span class="n">class</span> <span class="o">=</span> <span class="s2">"pinentry"</span> <span class="p">},</span>
        <span class="n">properties</span> <span class="o">=</span> <span class="p">{</span> <span class="n">floating</span> <span class="o">=</span> <span class="kc">true</span> <span class="p">}</span> <span class="p">},</span>
        <span class="p">{</span> <span class="n">rule</span> <span class="o">=</span> <span class="p">{</span> <span class="n">class</span> <span class="o">=</span> <span class="s2">"gimp"</span> <span class="p">},</span>
        <span class="n">properties</span> <span class="o">=</span> <span class="p">{</span> <span class="n">floating</span> <span class="o">=</span> <span class="kc">true</span> <span class="p">}</span> <span class="p">},</span>
        <span class="c1">-- Set Firefox to always map on tags number 2 of screen 1.</span>
        <span class="c1">-- { rule = { class = "Firefox" },</span>
        <span class="c1">--   properties = { tag = tags[1][2] } },</span>
    <span class="p">}</span>

    <span class="c1">-- Signal function to execute when a new client appears.</span>
    <span class="n">client</span><span class="p">.</span><span class="n">add_signal</span><span class="p">(</span><span class="s2">"manage"</span><span class="p">,</span> <span class="k">function</span> <span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">startup</span><span class="p">)</span>
        <span class="c1">-- Add a titlebar</span>
        <span class="c1">-- awful.titlebar.add(c, { modkey = modkey })</span>
        <span class="c1">-- Enable sloppy focus</span>
        <span class="n">c</span><span class="p">:</span><span class="n">add_signal</span><span class="p">(</span><span class="s2">"mouse::enter"</span><span class="p">,</span> <span class="k">function</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">awful</span><span class="p">.</span><span class="n">layout</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="n">c</span><span class="p">.</span><span class="n">screen</span><span class="p">)</span> <span class="o">~=</span> <span class="n">awful</span><span class="p">.</span><span class="n">layout</span><span class="p">.</span><span class="n">suit</span><span class="p">.</span><span class="n">magnifier</span>
                <span class="ow">and</span> <span class="n">awful</span><span class="p">.</span><span class="n">client</span><span class="p">.</span><span class="n">focus</span><span class="p">.</span><span class="n">filter</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="k">then</span>
                <span class="n">client</span><span class="p">.</span><span class="n">focus</span> <span class="o">=</span> <span class="n">c</span>
            <span class="k">end</span>
        <span class="k">end</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">startup</span> <span class="k">then</span>
            <span class="c1">-- Set the windows at the slave,</span>
            <span class="c1">-- i.e. put it at the end of others instead of setting it master.</span>
            <span class="c1">-- awful.client.setslave(c)</span>
            <span class="c1">-- Put windows in a smart way, only if they does not set an initial position.</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">c</span><span class="p">.</span><span class="n">size_hints</span><span class="p">.</span><span class="n">user_position</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">c</span><span class="p">.</span><span class="n">size_hints</span><span class="p">.</span><span class="n">program_position</span> <span class="k">then</span>
                <span class="n">awful</span><span class="p">.</span><span class="n">placement</span><span class="p">.</span><span class="n">no_overlap</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
                <span class="n">awful</span><span class="p">.</span><span class="n">placement</span><span class="p">.</span><span class="n">no_offscreen</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
            <span class="k">end</span>
        <span class="k">end</span>
    <span class="k">end</span><span class="p">)</span>

    <span class="n">client</span><span class="p">.</span><span class="n">add_signal</span><span class="p">(</span><span class="s2">"focus"</span><span class="p">,</span> <span class="k">function</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">c</span><span class="p">.</span><span class="n">border_color</span> <span class="o">=</span> <span class="n">beautiful</span><span class="p">.</span><span class="n">border_focus</span> <span class="k">end</span><span class="p">)</span>
    <span class="n">client</span><span class="p">.</span><span class="n">add_signal</span><span class="p">(</span><span class="s2">"unfocus"</span><span class="p">,</span> <span class="k">function</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="n">c</span><span class="p">.</span><span class="n">border_color</span> <span class="o">=</span> <span class="n">beautiful</span><span class="p">.</span><span class="n">border_normal</span> <span class="k">end</span><span class="p">)</span>

    <span class="n">awful</span><span class="p">.</span><span class="n">util</span><span class="p">.</span><span class="n">spawn_with_shell</span><span class="p">(</span><span class="s2">"nm-applet"</span><span class="p">)</span>
    <span class="n">awful</span><span class="p">.</span><span class="n">util</span><span class="p">.</span><span class="n">spawn_with_shell</span><span class="p">(</span><span class="s2">"gnome-sound-applet"</span><span class="p">)</span> <span class="c1">--sine ubuntu 12.04.02</span>
    <span class="c1">--awful.util.spawn_with_shell("gnome-volume-control-applet")</span>
    <span class="c1">--            awful.util.spawn_with_shell("xautolock -time 10 -locker 'xlock -lockdelay 10'")</span>
    <span class="c1">--                awful.util.run_once("xautolock -time 1 -locker 'xlock -lockdelay 1'")</span>
    <span class="k">function</span> <span class="nf">run_once</span><span class="p">(</span><span class="n">cmd</span><span class="p">)</span>
        <span class="n">findme</span> <span class="o">=</span> <span class="n">cmd</span>
        <span class="n">firstspace</span> <span class="o">=</span> <span class="n">cmd</span><span class="p">:</span><span class="n">find</span><span class="p">(</span><span class="s2">" "</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">firstspace</span> <span class="k">then</span>
            <span class="n">findme</span> <span class="o">=</span> <span class="n">cmd</span><span class="p">:</span><span class="n">sub</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">firstspace</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">end</span>
        <span class="n">awful</span><span class="p">.</span><span class="n">util</span><span class="p">.</span><span class="n">spawn_with_shell</span><span class="p">(</span><span class="s2">"pgrep -u $USER -x "</span> <span class="o">..</span> <span class="n">findme</span> <span class="o">..</span> <span class="s2">" &gt; /dev/null || ("</span> <span class="o">..</span> <span class="n">cmd</span> <span class="o">..</span> <span class="s2">")"</span><span class="p">)</span>
    <span class="k">end</span>
    <span class="n">run_once</span><span class="p">(</span><span class="s2">"xautolock -time 30 -locker 'xlock -lockdelay 30'"</span><span class="p">);</span></code></pre></figure>

<p>&lt;/br&gt;
在使用awesome的过程中，需要dmenu加以配合，这样你的CUI才能真正的用起来，算起来
。</p>
<ol>
  <li>关机<br />
关机需要xlockmore和xautolock两个软件进行配合，使用apt-get就可以。<br />
xlockmore是锁屏和关机的，xautolock是自动启动屏保啥的。<br />
然后在增加一个shutdown的bash文件，你就可以使用这个文件来关机或者休眠了。</li>
</ol>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c">#! /bin/sh</span>

<span class="nv">ACTION</span><span class="o">=</span><span class="sb">`</span>zenity --width<span class="o">=</span>90 --height<span class="o">=</span>200 --list --radiolist --text<span class="o">=</span><span class="s2">"Select logout action"</span> --title<span class="o">=</span><span class="s2">"Logout"</span> --column <span class="s2">"Choice"</span> --column <span class="s2">"Action"</span> TRUE Shutdown FALSE Reboot FALSE LockScreen FALSE Suspend<span class="sb">`</span>

<span class="k">if</span> <span class="o">[</span> -n <span class="s2">"</span><span class="k">${</span><span class="nv">ACTION</span><span class="k">}</span><span class="s2">"</span> <span class="o">]</span>;<span class="k">then
  case</span> <span class="nv">$ACTION</span> <span class="k">in
  </span>Shutdown<span class="p">)</span>
    shutdown -h now
    <span class="c">## or via ConsoleKit</span>
    <span class="c"># dbus-send --system --dest=org.freedesktop.ConsoleKit.Manager </span>
    <span class="c"># /org/freedesktop/ConsoleKit/Manager org.freedesktop.ConsoleKit.Manager.Stop</span>
    <span class="p">;;</span>
  Reboot<span class="p">)</span>
    reboot
    <span class="c">## Or via ConsoleKit</span>
    <span class="c"># dbus-send --system --dest=org.freedesktop.ConsoleKit.Manager </span>
    <span class="c"># /org/freedesktop/ConsoleKit/Manager org.freedesktop.ConsoleKit.Manager.Restart</span>
    <span class="p">;;</span>
  Suspend<span class="p">)</span>
    <span class="c">#gksudo pm-suspend</span>
    dbus-send --system --print-reply --dest<span class="o">=</span>org.freedesktop.Hal 
    /org/freedesktop/Hal/devices/computer 
    org.freedesktop.Hal.Device.SystemPowerManagement.Suspend int32:0
    <span class="c"># HAL is deprecated in newer systems in favor of UPower etc.</span>
    <span class="c"># dbus-send --system --dest=org.freedesktop.UPower /org/freedesktop/UPower org.freedesktop.UPower.Suspend</span>
    <span class="p">;;</span>
  LockScreen<span class="p">)</span>
    slock
    <span class="c"># Or gnome-screensaver-command -l</span>
    <span class="p">;;</span>
  <span class="k">esac</span>
<span class="k">fi</span></code></pre></figure>

<ol>
  <li>小红点<br />
因为一直使用Thinkpad的笔记本，但是ub对于小红点的支持貌似不是太好，刚刚开始的几
个ub的版本好像还不支持小红点，所以就使用一个第三方的软件来加以支持，这个软件叫
gpointing-device-settings,安装以后还是相当好用的，但是你还需要加一个配置文件。
当然，后来的ub好像已经开始支持小红点了，具体忘了，很久没用Thinkpad了。</li>
</ol>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="c">#! /bin/sh</span>
<span class="c">#close touch</span>
synclient <span class="nv">TouchpadOff</span><span class="o">=</span>1
&lt;/br&gt;
<span class="c">#开启小红帽+中键</span>
xinput <span class="nb">set</span>-int-prop <span class="s2">"TPPS/2 IBM TrackPoint"</span> <span class="s2">"Evdev Wheel Emulation"</span> 8 1
xinput <span class="nb">set</span>-int-prop <span class="s2">"TPPS/2 IBM TrackPoint"</span> <span class="s2">"Evdev Wheel Emulation Button"</span> 8 2
xinput <span class="nb">set</span>-int-prop <span class="s2">"TPPS/2 IBM TrackPoint"</span> <span class="s2">"Evdev Wheel Emulation Y Axis"</span> 8 4 5
xinput <span class="nb">set</span>-int-prop <span class="s2">"TPPS/2 IBM TrackPoint"</span> <span class="s2">"Evdev Wheel Emulation X Axis"</span> 8 6 7</code></pre></figure>

<ol>
  <li>CUI中文件夹的颜色<br />
当你使用CUI的时候，使用ls列出来的文件和文件夹都是一样的颜色，你也不能很好的辨
认出来，所以，你增加一个dircolors文件，并且做一个软连接到这个文件就可以：</li>
</ol>

<figure class="highlight"><pre><code class="language-properties" data-lang="properties"><span class="err">\</span><span class="c"># Configuration file for dircolors, a utility to help you set the
</span><span class="err">\</span><span class="c"># LS_COLORS environment variable used by GNU ls with the --color option.
</span><span class="err">\</span><span class="c"># Copyright (C) 1996, 1999-2011 Free Software Foundation, Inc.
</span><span class="err">\</span><span class="c"># Copying and distribution of this file, with or without modification,
</span><span class="err">\</span><span class="c"># are permitted provided the copyright notice and this notice are preserved.
</span><span class="err">\</span><span class="c"># The keywords COLOR, OPTIONS, and EIGHTBIT (honored by the
</span><span class="err">\</span><span class="c"># slackware version of dircolors) are recognized but ignored.
</span><span class="err">\</span><span class="c"># Below, there should be one TERM entry for each termtype that is colorizable
</span><span class="err">TERM</span> <span class="err">Eterm</span>
<span class="err">TERM</span> <span class="err">ansi</span>
<span class="err">TERM</span> <span class="err">color-xterm</span>
<span class="err">TERM</span> <span class="err">con132x25</span>
<span class="err">TERM</span> <span class="err">con132x30</span>
<span class="err">TERM</span> <span class="err">con132x43</span>
<span class="err">TERM</span> <span class="err">con132x60</span>
<span class="err">TERM</span> <span class="err">con80x25</span>
<span class="err">TERM</span> <span class="err">con80x28</span>
<span class="err">TERM</span> <span class="err">con80x30</span>
<span class="err">TERM</span> <span class="err">con80x43</span>
<span class="err">TERM</span> <span class="err">con80x50</span>
<span class="err">TERM</span> <span class="err">con80x60</span>
<span class="err">TERM</span> <span class="err">cons25</span>
<span class="err">TERM</span> <span class="err">console</span>
<span class="err">TERM</span> <span class="err">cygwin</span>
<span class="err">TERM</span> <span class="err">dtterm</span>
<span class="err">TERM</span> <span class="err">eterm-color</span>
<span class="err">TERM</span> <span class="err">gnome</span>
<span class="err">TERM</span> <span class="err">gnome-256color</span>
<span class="err">TERM</span> <span class="err">jfbterm</span>
<span class="err">TERM</span> <span class="err">konsole</span>
<span class="err">TERM</span> <span class="err">kterm</span>
<span class="err">TERM</span> <span class="err">linux</span>
<span class="err">TERM</span> <span class="err">linux-c</span>
<span class="err">TERM</span> <span class="err">mach-color</span>
<span class="err">TERM</span> <span class="err">mlterm</span>
<span class="err">TERM</span> <span class="err">putty</span>
<span class="err">TERM</span> <span class="err">rxvt</span>
<span class="err">TERM</span> <span class="err">rxvt-256color</span>
<span class="err">TERM</span> <span class="err">rxvt-cygwin</span>
<span class="err">TERM</span> <span class="err">rxvt-cygwin-native</span>
<span class="err">TERM</span> <span class="err">rxvt-unicode</span>
<span class="err">TERM</span> <span class="err">rxvt-unicode-256color</span>
<span class="err">TERM</span> <span class="err">rxvt-unicode256</span>
<span class="err">TERM</span> <span class="err">screen</span>
<span class="err">TERM</span> <span class="err">screen-256color</span>
<span class="err">TERM</span> <span class="err">screen-256color-bce</span>
<span class="err">TERM</span> <span class="err">screen-bce</span>
<span class="err">TERM</span> <span class="err">screen-w</span>
<span class="err">TERM</span> <span class="err">screen.Eterm</span>
<span class="err">TERM</span> <span class="err">screen.rxvt</span>
<span class="err">TERM</span> <span class="err">screen.linux</span>
<span class="err">TERM</span> <span class="err">terminator</span>
<span class="err">TERM</span> <span class="err">vt100</span>
<span class="err">TERM</span> <span class="err">xterm</span>
<span class="err">TERM</span> <span class="err">xterm-16color</span>
<span class="err">TERM</span> <span class="err">xterm-256color</span>
<span class="err">TERM</span> <span class="err">xterm-88color</span>
<span class="err">TERM</span> <span class="err">xterm-color</span>
<span class="err">TERM</span> <span class="err">xterm-debian</span>
<span class="err">\</span><span class="c"># Below are the color init strings for the basic file types. A color init
</span><span class="err">\</span><span class="c"># string consists of one or more of the following numeric codes:
</span><span class="err">\</span><span class="c"># Attribute codes:
</span><span class="err">\</span><span class="c"># 00=none 01=bold 04=underscore 05=blink 07=reverse 08=concealed
</span><span class="err">\</span><span class="c"># Text color codes:
</span><span class="err">\</span><span class="c"># 30=black 31=red 32=green 33=yellow 34=blue 35=magenta 36=cyan 37=white
</span><span class="err">\</span><span class="c"># Background color codes:
</span><span class="err">\</span><span class="c"># 40=black 41=red 42=green 43=yellow 44=blue 45=magenta 46=cyan 47=white
</span><span class="err">\</span><span class="c">#NORMAL 00 # no color code at all
</span><span class="err">\</span><span class="c">#FILE 00 # regular file: use no color at all
</span><span class="err">RESET</span> <span class="err">0</span> <span class="c"># reset to "normal" color
</span><span class="err">DIR</span> <span class="err">01;34</span> <span class="c"># directory
</span><span class="err">LINK</span> <span class="err">01;36</span> <span class="c"># symbolic link. (If you set this to 'target' instead of a
</span><span class="err">\</span><span class="c"># numerical value, the color is as for the file pointed to.)
</span><span class="err">MULTIHARDLINK</span> <span class="err">00</span> <span class="c"># regular file with more than one link
</span><span class="err">FIFO</span> <span class="err">40;33</span> <span class="c"># pipe
</span><span class="err">SOCK</span> <span class="err">01;35</span> <span class="c"># socket
</span><span class="err">DOOR</span> <span class="err">01;35</span> <span class="c"># door
</span><span class="err">BLK</span> <span class="err">40;33;01</span> <span class="c"># block device driver
</span><span class="err">CHR</span> <span class="err">40;33;01</span> <span class="c"># character device driver
</span><span class="err">ORPHAN</span> <span class="err">40;31;01</span> <span class="c"># symlink to nonexistent file, or non-stat'able file
</span><span class="err">SETUID</span> <span class="err">37;41</span> <span class="c"># file that is setuid (u+s)
</span><span class="err">SETGID</span> <span class="err">30;43</span> <span class="c"># file that is setgid (g+s)
</span><span class="err">CAPABILITY</span> <span class="err">30;41</span> <span class="c"># file with capability
</span><span class="err">STICKY_OTHER_WRITABLE</span> <span class="err">01;34</span> <span class="c"># dir that is sticky and other-writable (+t,o+w)
</span><span class="err">OTHER_WRITABLE</span> <span class="err">01;34</span> <span class="c"># dir that is other-writable (o+w) and not sticky
</span><span class="err">STICKY</span> <span class="err">01;34</span> <span class="c"># dir with the sticky bit set (+t) and not other-writable
</span><span class="err">\</span><span class="c"># This is for files with execute permission:
</span><span class="err">EXEC</span> <span class="err">01;32</span>
<span class="err">\</span><span class="c"># List any file extensions like '.gz' or '.tar' that you would like ls
</span><span class="err">\</span><span class="c"># to colorize below. Put the extension, a space, and the color init string.
</span><span class="err">\</span><span class="c"># (and any comments you want to add after a '#')
</span><span class="err">\</span><span class="c"># If you use DOS-style suffixes, you may want to uncomment the following:
</span><span class="err">\</span><span class="c">#.cmd 01;32 # executables (bright green)
</span><span class="err">\</span><span class="c">#.exe 01;32
</span><span class="err">\</span><span class="c">#.com 01;32
</span><span class="err">\</span><span class="c">#.btm 01;32
</span><span class="err">\</span><span class="c">#.bat 01;32
</span><span class="err">\</span><span class="c"># Or if you want to colorize scripts even if they do not have the
</span><span class="err">\</span><span class="c"># executable bit actually set.
</span><span class="err">\</span><span class="c">#.sh 01;32
</span><span class="err">\</span><span class="c">#.csh 01;32
</span><span class="err">\</span><span class="c"># archives or compressed (bright red)
</span><span class="err">.tar</span> <span class="err">01;31</span>
<span class="err">.tgz</span> <span class="err">01;31</span>
<span class="err">.arj</span> <span class="err">01;31</span>
<span class="err">.taz</span> <span class="err">01;31</span>
<span class="err">.lzh</span> <span class="err">01;31</span>
<span class="err">.lzma</span> <span class="err">01;31</span>
<span class="err">.tlz</span> <span class="err">01;31</span>
<span class="err">.txz</span> <span class="err">01;31</span>
<span class="err">.zip</span> <span class="err">01;31</span>
<span class="err">.z</span> <span class="err">01;31</span>
<span class="err">.Z</span> <span class="err">01;31</span>
<span class="err">.dz</span> <span class="err">01;31</span>
<span class="err">.gz</span> <span class="err">01;31</span>
<span class="err">.lz</span> <span class="err">01;31</span>
<span class="err">.xz</span> <span class="err">01;31</span>
<span class="err">.bz2</span> <span class="err">01;31</span>
<span class="err">.bz</span> <span class="err">01;31</span>
<span class="err">.tbz</span> <span class="err">01;31</span>
<span class="err">.tbz2</span> <span class="err">01;31</span>
<span class="err">.tz</span> <span class="err">01;31</span>
<span class="err">.deb</span> <span class="err">01;31</span>
<span class="err">.rpm</span> <span class="err">01;31</span>
<span class="err">.jar</span> <span class="err">01;31</span>
<span class="err">.war</span> <span class="err">01;31</span>
<span class="err">.ear</span> <span class="err">01;31</span>
<span class="err">.sar</span> <span class="err">01;31</span>
<span class="err">.rar</span> <span class="err">01;31</span>
<span class="err">.ace</span> <span class="err">01;31</span>
<span class="err">.zoo</span> <span class="err">01;31</span>
<span class="err">.cpio</span> <span class="err">01;31</span>
<span class="err">.7z</span> <span class="err">01;31</span>
<span class="err">.rz</span> <span class="err">01;31</span>
<span class="err">\</span><span class="c"># image formats
</span><span class="err">.jpg</span> <span class="err">01;35</span>
<span class="err">.jpeg</span> <span class="err">01;35</span>
<span class="err">.gif</span> <span class="err">01;35</span>
<span class="err">.bmp</span> <span class="err">01;35</span>
<span class="err">.pbm</span> <span class="err">01;35</span>
<span class="err">.pgm</span> <span class="err">01;35</span>
<span class="err">.ppm</span> <span class="err">01;35</span>
<span class="err">.tga</span> <span class="err">01;35</span>
<span class="err">.xbm</span> <span class="err">01;35</span>
<span class="err">.xpm</span> <span class="err">01;35</span>
<span class="err">.tif</span> <span class="err">01;35</span>
<span class="err">.tiff</span> <span class="err">01;35</span>
<span class="err">.png</span> <span class="err">01;35</span>
<span class="err">.svg</span> <span class="err">01;35</span>
<span class="err">.svgz</span> <span class="err">01;35</span>
<span class="err">.mng</span> <span class="err">01;35</span>
<span class="err">.pcx</span> <span class="err">01;35</span>
<span class="err">.mov</span> <span class="err">01;35</span>
<span class="err">.mpg</span> <span class="err">01;35</span>
<span class="err">.mpeg</span> <span class="err">01;35</span>
<span class="err">.m2v</span> <span class="err">01;35</span>
<span class="err">.mkv</span> <span class="err">01;35</span>
<span class="err">.webm</span> <span class="err">01;35</span>
<span class="err">.ogm</span> <span class="err">01;35</span>
<span class="err">.mp4</span> <span class="err">01;35</span>
<span class="err">.m4v</span> <span class="err">01;35</span>
<span class="err">.mp4v</span> <span class="err">01;35</span>
<span class="err">.vob</span> <span class="err">01;35</span>
<span class="err">.qt</span> <span class="err">01;35</span>
<span class="err">.nuv</span> <span class="err">01;35</span>
<span class="err">.wmv</span> <span class="err">01;35</span>
<span class="err">.asf</span> <span class="err">01;35</span>
<span class="err">.rm</span> <span class="err">01;35</span>
<span class="err">.rmvb</span> <span class="err">01;35</span>
<span class="err">.flc</span> <span class="err">01;35</span>
<span class="err">.avi</span> <span class="err">01;35</span>
<span class="err">.fli</span> <span class="err">01;35</span>
<span class="err">.flv</span> <span class="err">01;35</span>
<span class="err">.gl</span> <span class="err">01;35</span>
<span class="err">.dl</span> <span class="err">01;35</span>
<span class="err">.xcf</span> <span class="err">01;35</span>
<span class="err">.xwd</span> <span class="err">01;35</span>
<span class="err">.yuv</span> <span class="err">01;35</span>
<span class="err">.cgm</span> <span class="err">01;35</span>
<span class="err">.emf</span> <span class="err">01;35</span>
<span class="err">\</span><span class="c"># http://wiki.xiph.org/index.php/MIME_Types_and_File_Extensions
</span><span class="err">.axv</span> <span class="err">01;35</span>
<span class="err">.anx</span> <span class="err">01;35</span>
<span class="err">.ogv</span> <span class="err">01;35</span>
<span class="err">.ogx</span> <span class="err">01;35</span>
<span class="err">\</span><span class="c"># audio formats
</span><span class="err">.aac</span> <span class="err">00;36</span>
<span class="err">.au</span> <span class="err">00;36</span>
<span class="err">.flac</span> <span class="err">00;36</span>
<span class="err">.mid</span> <span class="err">00;36</span>
<span class="err">.midi</span> <span class="err">00;36</span>
<span class="err">.mka</span> <span class="err">00;36</span>
<span class="err">.mp3</span> <span class="err">00;36</span>
<span class="err">.mpc</span> <span class="err">00;36</span>
<span class="err">.ogg</span> <span class="err">00;36</span>
<span class="err">.ra</span> <span class="err">00;36</span>
<span class="err">.wav</span> <span class="err">00;36</span>
<span class="err">\</span><span class="c"># http://wiki.xiph.org/index.php/MIME_Types_and_File_Extensions
</span><span class="err">.axa</span> <span class="err">00;36</span>
<span class="err">.oga</span> <span class="err">00;36</span>
<span class="err">.spx</span> <span class="err">00;36</span>
<span class="err">.xspf</span> <span class="err">00;36</span></code></pre></figure>

<ol>
  <li>外接投影仪或者显示器
外接显示器或者投影器，你必须使用xrand来支持。开机的时候awesome好像默认会检测你
的屏幕数量然后加以显示。如果没有自动，那么你只需要运行一下一下的代码就可以了。</li>
</ol>

<figure class="highlight"><pre><code class="language-bash" data-lang="bash"><span class="se">\#</span>/usr/bin/env bash
<span class="k">case</span> <span class="nv">$1</span> <span class="k">in</span>
	<span class="s2">"-c"</span><span class="p">)</span>
		<span class="c"># 打开外接显示器(--auto:最高分辨率)，与笔记本液晶屏幕显示同样内容（克隆）</span>
		xrandr --output VGA1 --same-as LVDS1 --auto
		<span class="p">;;</span>
	<span class="s2">"-cs"</span><span class="p">)</span>
		<span class="c"># 打开外接显示器(分辨率为1280x1024)，与笔记本液晶屏幕显示同样内容（克隆）</span>
		xrandr --output VGA1 --same-as LVDS1 --mode 1280x1024
		<span class="p">;;</span>
	<span class="s2">"-el"</span><span class="p">)</span>
		<span class="c"># 打开外接显示器(--auto:最高分辨率)，设置为右侧扩展屏幕</span>
		xrandr --output VGA1 --left-of LVDS1 --auto 
		<span class="p">;;</span>
	<span class="s2">"-er"</span><span class="p">)</span>
		<span class="c"># 打开外接显示器(--auto:最高分辨率)，设置为右侧扩展屏幕</span>
		xrandr --output VGA1 --right-of LVDS1 --auto
		<span class="p">;;</span>
	<span class="s2">"-f"</span><span class="p">)</span>
		<span class="c"># 关闭外接显示器</span>
		xrandr --output VGA1 --off
		<span class="p">;;</span>
	<span class="s2">"-oe"</span><span class="p">)</span>
		<span class="c"># 打开外接显示器，同时关闭笔记本液晶屏幕（只用外接显示器工作）</span>
		xrandr --output VGA1 --auto --output LVDS1 --off
		<span class="p">;;</span>
	<span class="s2">"-oo"</span><span class="p">)</span>
		<span class="c"># 关闭外接显示器，同时打开笔记本液晶屏幕 （只用笔记本液晶屏）</span>
		xrandr --output VGA1 --off --output LVDS1 --auto
		<span class="p">;;</span>
	<span class="s2">""</span><span class="p">)</span>
		<span class="nb">echo</span> <span class="s2">"-c: 打开外接显示器(--auto:最高分辨率)，与笔记本液晶屏幕显示同样内容（克隆）"</span>
		<span class="nb">echo</span> <span class="s2">"-cs: 打开外接显示器(分辨率为1280x1024)，与笔记本液晶屏幕显示同样内容（克隆）"</span>
		<span class="nb">echo</span> <span class="s2">"-er: 打开外接显示器(--auto:最高分辨率)，设置为右侧扩展屏幕"</span>
		<span class="nb">echo</span> <span class="s2">"-el: 打开外接显示器(--auto:最高分辨率)，设置为left侧扩展屏幕"</span>
		<span class="nb">echo</span> <span class="s2">"-f: 关闭外接显示器"</span>
		<span class="nb">echo</span> <span class="s2">"-oe: 打开外接显示器，同时关闭笔记本液晶屏幕（只用外接显示器工作）"</span>
		<span class="nb">echo</span> <span class="s2">"-oo: 关闭外接显示器，同时打开笔记本液晶屏幕 （只用笔记本液晶屏）"</span>
		<span class="nb">echo</span> <span class="s2">"如果使用awesome，modkey+ctrl+j,modkey+ctrl+k,切换不同的screen"</span>
		<span class="p">;;</span>

	<span class="s2">"-h"</span><span class="p">)</span>
		<span class="nb">echo</span> <span class="s2">"-c: 打开外接显示器(--auto:最高分辨率)，与笔记本液晶屏幕显示同样内容（克隆）"</span>
		<span class="nb">echo</span> <span class="s2">"-cs: 打开外接显示器(分辨率为1280x1024)，与笔记本液晶屏幕显示同样内容（克隆）"</span>
		<span class="nb">echo</span> <span class="s2">"-e: 打开外接显示器(--auto:最高分辨率)，设置为右侧扩展屏幕"</span>
		<span class="nb">echo</span> <span class="s2">"-f: 关闭外接显示器"</span>
		<span class="nb">echo</span> <span class="s2">"-oe: 打开外接显示器，同时关闭笔记本液晶屏幕（只用外接显示器工作）"</span>
		<span class="nb">echo</span> <span class="s2">"-oo: 关闭外接显示器，同时打开笔记本液晶屏幕 （只用笔记本液晶屏）"</span>
		<span class="nb">echo</span> <span class="s2">"如果使用awesome，modkey+ctrl+j,modkey+ctrl+k,切换不同的screen"</span>
		<span class="p">;;</span>
<span class="k">esac</span></code></pre></figure>

<p><br /></p>
<h4 id="结束语">结束语</h4>
<p>这些配置文件都是可以直接拿来用的，我已经经过了测试。保证可以使用。<br />
因为现在也不太用ub+awesome了，改用了mac，但是说实话，mac没有ub+awesome好用和自
如。如果还能选择，我想还是ub+awesome来的更适合我一些。</p>

                    ]]>
                </content:encoded>
                <guid isPermaLink="false">/blog/2014/system/</guid>
                <description>
                    
                </description>
                <pubDate>Fri, 29 Aug 2014 00:00:00 +0800</pubDate>
                <author>94geek.com by Seapeak.Xu</author>
            </item>
        
    
  </channel>
</rss>
