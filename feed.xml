<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>94geek.com</title>
    <description>属于大嘴的个人blog</description>
    <link>http://www.94geek.com/</link>
    <atom:link href="http://www.94geek.com/feed.xml" rel="self" type="application/rss+xml" />
    
      <item>
        <title>情怀初体验--二周写书记</title>
        <description>&lt;p&gt;从下定决心要开始写书到今天，已经二周有余。在这段时间里，除了工作，剩下的时间基本上全部都是和这本书有关：写书、看书、查资料、思考……,几乎每天都是挑灯夜战到半夜1点。谁让我这么矫情，非要为了那份情怀和感情呢？&lt;/p&gt;

&lt;p&gt;拟定目录和大纲的时候一共拟定了4个部分，大概有9-10章。开始我着手的并不是前言、也不是第一章、更不是最后一章或者后记，而是中间的章节：C语言特殊性与解决方案。这一章主要讲解C语言中比较特殊的、具有和别的语言不一样的特性语法、使用注意事项和解决方案，更有很多从坑中爬出来的经验分享。之所以要首先写这一章，主要还是因为以下几点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;我对C语言比较熟悉，其中几个经常用的特性都比较的清楚，经常会掉进坑里的陷阱也比较熟悉，我想用最快的速度看看在最短的时间内能写多少；&lt;/li&gt;
  &lt;li&gt;计算机语言写成的程序之所以能运行，和操作系统、编译器、连接器等基础设施密切相关，我也想粗略的估计一下经常使用的特性中，需要注意的特性有多少是和基础设施相关的，以好用最短的篇幅来写第一章关于基础知识的内容；&lt;/li&gt;
  &lt;li&gt;这一章在整本书的位置上比较重要，也是基础的章节，后面所有的内容都建立在这一章的基础上。虽然不是C语言的基础知识介绍，但这一章不过关，后面的章节也很难过关；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;从申请内存开始，到释放内存，然后写stack溢出，再到c语言中的字符串。目前已经花了2周有余，但这一章还没写完。时间已经大大的超出了我的预估。按照我的预计，速度应该在一天写一节。这样，整章基本上也只需要一个星期，最多10天就能搞定。这完全是一种非常乐观的，没有写技术书经验的预估方法导致的（PS：以前写过口水书，类小说。）。和实际差的太远了。虽然一章还没写完，但是写到现在，总结如下：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;难。虽然我对写技术书的难度在思想上有所准备，但真的开始写了，还是觉得有很多的准备不足。写技术书最大的难点在于：你怎么把你所知道的知识和信息有条理的、清清楚楚的、由易到难的晨晨展现给大家，并且可以让大家相对简单和容易的在短时间接受并且消化，如果知识点有相关的重点，如何向读者表述你所要表述的重点也是一个很重要的技巧，也是相当有难度；&lt;/li&gt;
  &lt;li&gt;多。技术书的工作量明显多于非技术书。IT技术书的工作量多就主要多在了有很多的示例上。示例的工作量简直就是要了人命了。特别是当示例有好几种可能性结果时，需要把这些可能性通过代码和环境的联合作用运行出不同的结果，n份代码和n个环境设置，想想这个工作量……,简直就是让人抓狂；&lt;/li&gt;
  &lt;li&gt;烦。一图胜千言，这句话在代码界中绝对是一顶一的真理。但是因为载体的限制，静态的载体并不能很好的表达出程序运行的整个过程，特别是一些细微的变化，比如指针的指向改变等等。只能把整个过程通过步骤化的方式，将步骤一步一步的静态化处理成图，然后尽可能完整的画出来变化额蛛丝马迹。整个静态化的过程和画图的过程相当的繁琐不说，静态化后很容易丢失一些关键信息。很多时候画了擦，擦了画，画了再擦……周而复始；&lt;/li&gt;
  &lt;li&gt;累。写书真的很累。没有自己的业余时间、没有休息时间、没有双休日，甚至连自己洗澡的时候都会去想下面的知识点要怎么写？这本书是不是还缺些什么特性或者功能没有？我这样写是不是能表达我的意思？是不是有更好的表达方式？然而当你的实际工作量大大超过你的预估的时候，你又想精益求精而准备返工的时候，你就会觉得更累了；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;情怀和感情，人生中最大的乐趣。所以坚持，坚持下去……&lt;/p&gt;

</description>
        <pubDate>Mon, 11 Sep 2017 00:00:00 +0800</pubDate>
        <link>http://www.94geek.com/blog/2017/c-book-think/</link>
        <guid isPermaLink="true">http://www.94geek.com/blog/2017/c-book-think/</guid>
      </item>
    
      <item>
        <title>为了情怀，我又想写书了</title>
        <description>&lt;p&gt;对于一个写过书，知道写书辛苦、发誓不想再写书的人来说，这几天一直有一个想法在我心里挥之不去：我想写一本书，不是为了钱，也不想为了名，只是想作为一个礼物送给我的那份情怀。&lt;/p&gt;

&lt;p&gt;这本书的主要内容是关于C语言高性能编程的。但是首先，不希望这本书写的有多么的厚；也不希望写一本大而全但全是“Hello world”式的介绍无深度书。我只想把我这7-8年时间对于C语言的项目实践能毫无保留的输出出来。包括C语言的一些基础知识、项目实践、经验总结等等，希望能给更多的人带来便利。&lt;/p&gt;

&lt;p&gt;之所以想出一本这样的书，有几个原因：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;目前市面上关于C语言开发的书，除了讲语法的，就是讲数据结构和算法的。真正用来讲项目实践的，输出项目经验的书少之又少，可以说没有；&lt;/li&gt;
  &lt;li&gt;还有是为了各位我们的小伙伴。我试图让小伙伴们去看书，我还给开了一个详细的C语言项目“打怪升级”书单，但实际收效甚微。总结原因：对于他们来说，看书是很容易，但因为项目经验的欠缺，导致他们无法分辨书中哪些是重点，项目中肯定会用的；哪些是需要知道就行了，项目中很少使用；哪些是压根不需要看的；像这样的情况很多次的出现，几乎每个人都会在这个上卡了很长时间，导致时间花了，但收获很小；&lt;/li&gt;
  &lt;li&gt;这不仅仅是为了大家，也是为了我自己。我们在项目的实施中，新人不断的加入，但是对于C语言的知识、技巧、经验却要重复的对他们进行培训。有时候一个问题要说好几遍，费时费力、投入和产出还不成正比；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;所以注定了，这本书是一本小众的书。这本书面向的是有一定开发经验的程序员，至少你是一个熟悉C语言的人，曾经用C语言的语法写过程序。如果你还是用过别的语言比如java或者c#那就更好了。因为C语言的坑比较多，掌握曲线比较陡峭，所以一直没有自信心在正式的环境中使用并且部署过C语言程序的人也是这本书的潜在对象。&lt;/p&gt;

&lt;p&gt;干脆，我把这本书暂时就取名为《C语言高性能编程》，我打算整本书分为几个部分：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;操作系统原理与程序结构，主要讲解C语言编程中需要使用到的操作系统的原理，内存的映射，进程的原理等等；&lt;/li&gt;
  &lt;li&gt;C语言。但是不会讲解C语言的语法，使用方法等等。这些应该去看K&amp;amp;R，而是会介绍C语言的几个在项目中特别的注意点，比如内存的申请与释放、野指针问题、stack溢出等等实际的问题和解决方案；&lt;/li&gt;
  &lt;li&gt;实际的项目经验。包括在实际项目中内存的管理，客户端-服务器模式的实现，事件机制，服务器端编程技巧等等。这是整本书的重中之重；&lt;/li&gt;
  &lt;li&gt;程序调试。分为3个部分。首先是gdb的普通调试，然后是valgrand的内存泄露检测，最后是线上环境的bug调试与解决方案；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;写书是一件苦差事，肯定会影响到公众号的文章。所以为了弥补，我会设定一些样章，我会把这些写好的样章公布在公众号中。希望大家能喜欢。&lt;/p&gt;

</description>
        <pubDate>Mon, 04 Sep 2017 00:00:00 +0800</pubDate>
        <link>http://www.94geek.com/blog/2017/c-book/</link>
        <guid isPermaLink="true">http://www.94geek.com/blog/2017/c-book/</guid>
      </item>
    
      <item>
        <title>mysql连接池不能回避的wait timeout问题</title>
        <description>&lt;p&gt;感谢我们的木木同学给了我写这篇文章的灵感和机会。&lt;/p&gt;

&lt;h2 id=&quot;起因&quot;&gt;起因&lt;/h2&gt;
&lt;p&gt;我们的项目组一直在使用albianj作为开发框架在开发应用。使用至今倒也是没有出现很大的问题，但最近加过监控的接口基本上都会在使用一段时间后，突然之间执行数据库操作变得很慢。虽然会变慢，但持续的时间比较短，一般1分钟左右，然后会自动恢复正常。但是过了一段时间，这个现象又会出现，周而复始。从监控看，发生的时间点并无规律，有的时候一天发生3次，有的也会有4-5次。虽然从规律上并无法去查找，那就只能从别的地方想办法：增加一些详细的日志，从日志上看一下问题所在。&lt;br /&gt;
详细日志版本刚刚上去，立刻就发生问题了。如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;3.png&quot; alt=&quot;problem&quot; /&gt;&lt;/p&gt;

&lt;p&gt;看一下左下角的曲线图，突然飙高，然后在1500ms的高位不下来。经过查找日志（PS：sorry。写文章的时候日志已经被自动清除，没法截图了），发现程序卡在了getConnection这个方法上，并且卡住的时间从60s开始越来越长。&lt;/p&gt;

&lt;h2 id=&quot;分析&quot;&gt;分析&lt;/h2&gt;
&lt;p&gt;getConnection是一个synchronized方法，主要是从连接池中获取数据连接！卡住时间越来越长这个现象倒是很简单就可以解释：因为getConnection是synchronized的，所以所有的线程到getConnection的时候全部等待，等待的时间越长当然时间越长了。关键在于为啥卡住呢？&lt;br /&gt;
当时有两种可能的想法：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;连接池设置的太小，连接在使用的时候来不及被返还，导致了积压；&lt;/li&gt;
  &lt;li&gt;连接池的设置有问题，返回的连接有问题。如果是这个问题，那可能会比较难查；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;第一种情况显然不会存在，查看albianj的数据库配置，所有的配置对于连接池的设置MinSize为5，MaxSize为20.对于我们的应用来说肯定是够用的。那么就是第二个问题了。&lt;/p&gt;

&lt;p&gt;首先检查连接复用问题，对于数据库的连接字符串，我已经增加了重连的设置：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;autoReconnect=true&amp;amp;failOverReadOnly=false&amp;amp;zeroDateTimeBehavior=convertToNull&amp;amp;maxReconnect=3&amp;amp;autoReconnectForPools=true
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;显然autoReconnect没有起作用。查了一下mysql的客户端说明，后背发凉。基本上的大意翻译过来是这样的&lt;strong&gt;“即使在创建Mysql时url中加入了autoReconnect=true参数,一但这个连接两次访问数据库的时间超出了服务器端wait_timeout的时间限制,还是会CommunicationsException: The last packet successfully received from the server was xxx milliseconds ago. ”&lt;/strong&gt;。赶快去查一下日志，发现并没有报这个错误。那应该不是这个问题。&lt;/p&gt;

&lt;p&gt;既然不能重连接，那么最大的可能就是&lt;strong&gt;“返回的连接本来可能就是有问题的，但是程序确认为没有问题”&lt;/strong&gt;。发生这种问题的最大可能应该就是：&lt;strong&gt;数据库连接池的连接过期时间大于mysql的wait_timeut设置&lt;/strong&gt;。查了一下代码，发现我们默认的数据库连接池连接过期时间是300-30=270s。再去问一下DBA木木，让他查一下线上的数据库wait_timeout设置，被告知是180.瞬间懵逼：连接池的生命周期时间远远参与真实的连接生命周期时间。&lt;/p&gt;

&lt;p&gt;原因是找到了，但是这个问题其实前一段时间已经发现并且已经改过了。因为去年我记得很清楚：又一次我们的probactor（job调度系统）报了上文提到的CommunicationsException异常，后来找到了问题就是因为程序对于连接池中连接的alivetime长于数据库的wait timeout设置，随后我千叮咛万嘱咐这个设置必须要小心小心再小心，但这次还是中招了。因为连接池和网络的问题，我们有同事直接放弃连接池，改用每次连接数据库。放弃连接池确实能解决连接不会出现问题，但是侧面也导致了wait_timeout被设置的过小了。但其实只要把连接池中连接的过期时间设置的比wait_timeout小一些就完全可以了。&lt;/p&gt;

&lt;p&gt;经过更改后的程序终于恢复了正常，看一下更改后的效果：&lt;br /&gt;
&lt;img src=&quot;2.png&quot; alt=&quot;ok&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;科普&quot;&gt;科普&lt;/h2&gt;
&lt;p&gt;何为wait_timeout？&lt;br /&gt;
wait_timeout是mysql的一个设置，主要是用来断开不使用的数据库连接。当连接空闲的时间达到wait_timeout设置的最大值时，mysql会主动切断这个连接，以供别的客户端连接数据库。这个值一般是28800，也就是8小时。在mysql中可以通过：
&lt;code class=&quot;highlighter-rouge&quot;&gt;show variables like “%timeout%”;&lt;/code&gt;
获取。&lt;br /&gt;
另外，当数据库主动切断连接的时候，java的mysql客户端并不知道这个连接已经被切断，所以程序并不知道其已经无效了，然后加上mysql的客户端不支持ReConnect，双重的问题叠加在一起就导致了连接池返回无效连接的可能。这是一个比较扯淡也是一个比较难以发现的问题，但是它确确实实的存在了。大家一定要多加注意。&lt;/p&gt;

&lt;p&gt;这个值可以根据自己网络的环境和业务的并发性来调整。&lt;/p&gt;
</description>
        <pubDate>Tue, 22 Aug 2017 00:00:00 +0800</pubDate>
        <link>http://www.94geek.com/blog/2017/mysql-wait-timeout/</link>
        <guid isPermaLink="true">http://www.94geek.com/blog/2017/mysql-wait-timeout/</guid>
      </item>
    
      <item>
        <title>台湾技术交流见闻与感想</title>
        <description>&lt;h2 id=&quot;前言&quot;&gt;前言&lt;/h2&gt;

&lt;p&gt;这几天有幸因为台湾主办方和国内著名出品人史海峰的邀请前去台湾进行了技术交流。这次技术交流一方面让台湾那边了解目前国内互联网行业的一些技术和状态，另外一方面也让我们可以更加了解台湾互联网技术方面的情况。&lt;/p&gt;

&lt;p&gt;毕竟是来交流技术的，所以先说一下我们这次两岸技术交流的情况和我对于这次交流的一些心得和体会。&lt;/p&gt;

&lt;h2 id=&quot;技术交流&quot;&gt;技术交流&lt;/h2&gt;

&lt;p&gt;从技术交流的现场来说，台湾的技术交流场面很火爆。基本上座无虚席，还有没有抢到主会场的只能看直播。但架构场相对就没有那么理想了，原因后面会讲到。火爆的会场如图：
&lt;img src=&quot;7.jpeg&quot; alt=&quot;交流现场&quot; /&gt;
台湾目前的互联网技术水平和国内相比，说句实话：相差的有点远。在台湾，大多数的工程师都是FullStack类型，并不像是国内的互联网行业：不想当架构师的程序员不是好程序员。而且台湾的技术工作分工也没有国内细分的详细。在台湾最受欢迎的是前端，并不是架构师等后端职位。我们在架构场开讲的时候做过几个调查：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;在座的有多少个是写后端的？举手的只有3个左右，当然我们说的是纯后端。&lt;/li&gt;
  &lt;li&gt;这里有多少个title或者日常工作是架构师？ 举手的只有1个。追问：用什么语言？答：python。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;而我在交流的时候也问了几个问题，有技术也有业务：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;看网络小说的有多少？大概有20个人左右，人还是挺多的；&lt;/li&gt;
  &lt;li&gt;知道阅文集团/起点/腾讯文学任何一家的？前面举手的大概都知道。这里有个情况，其实我们的一些作品有在台湾播放电视剧，我注意一下台湾的电视台，我至少看见有3部：花千骨，芈月传，甄嬛传在播出。后来打听了一下，甄嬛传几乎被当成了“当时内地的还珠格格那种热度”在台湾播出。对我们来说，这个市场还是很大的；&lt;/li&gt;
  &lt;li&gt;技术上就又不一样了，比如讲分库分表和数据路由的时候，基本上下面是一片懵逼。在讲到后面调度系统的时候，quartz这个东西只有3个人听过，cron表达式也只有5个人听过；我调查了一下，写过定时任务的一个都没有。我就有点纳闷：他们的网站难道没有定时任务需要处理吗？&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;我们几个讲师其实也挺费劲，会前讨论应该怎么样让他们听的懂我们在讲什么？会后我们还是在讨论为什么出现这个情况，后来我们总结了一下，主要归结如下：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;用户。台湾一共2200w人，内地15亿。没有用户量爆发式增长，所以很多问题都碰不到，他们也就不用解决，像我们陈老师演讲的时候说，我们一开始规划下来需要26个数据库，马上下面的留言板上说，26个数据库，太庞大了，囧；&lt;/li&gt;
  &lt;li&gt;必要性。按照目前的机器硬件配置，在没有爆发式增长的情况下，没有架构也好，不要后端也罢，只要会写代码，拉几个开源的就可以上了。可能缓存都用不了，不要说什么读写分离、分库分表这些东西了；&lt;/li&gt;
  &lt;li&gt;国外的冲击。米国的互联网台湾都可以用，想fb，google这些都可以，畅通无阻，那么社交他们也主要用line，所以台湾根本没有自主的互联网企业和软件。在“5分钟演讲”环节，有个台湾本地哥们提出来一个问题：台湾有名的软件公司有哪个？只回答了一个“趋势科技”就没了，互联网技术公司一个都没有；&lt;/li&gt;
  &lt;li&gt;重视前端。因为碰不到用户量和数据量的关系，又因为大部分东西都是用国外的，所以剩下的能做的就没几样了。你不做前端做什么呢？&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;台湾的互联网技术除了这些之外，还有几个特点：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;脚本语言占大多数。我们在场内看到的最多的开发者是用nodejs，再下面就是go之类的新兴语言，也有python之类的脚本。但是国内很多互联网公司喜欢用的java，c/cxx这些语言在这里已经绝迹；&lt;/li&gt;
  &lt;li&gt;拼凑。几乎所有的开发都是用了开源的组件拼拼凑凑起来的。印象比较深的是一个哥们讲微服务，然而他并没有去讲微服务怎么怎么实现，而是讲了用了什么什么框架，什么什么组件，在什么什么上，搭起来了。就是那种纯粹的堆积木。我不知道如果这要是放在内地，会不会出去了要挨揍；&lt;/li&gt;
  &lt;li&gt;追新。什么新用什么，不会管这个新的东西到底怎么样，是不是适合，这些好像他们不太会去考虑。上面说到的开源使用，有一些就是觉得为了使用而使用，为了体现我们这个东西是多么的新潮，使用了多么cool的新技术就去使用了，而不会去规划和思考底层的问题；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这次的技术交流，对于我们内地来的讲师来说，最感同身受的是：&lt;strong&gt;我们的互联网技术确实已经起来了。说句大话，对手可能只有一个了，剩下的都是渣渣！&lt;/strong&gt;&lt;br /&gt;
对于台湾技术来说，要想真的提高，必须也要从商业模式和底层技术开始寻找出路，有了良好的商业模式，有用户开始喜欢使用你们的产品了，自然而然的对一些后端的技术会有更高的要求。技术自然就会跟着起来了。但就从现阶段来看，目前的台湾就像我们在10年前、20年前看硅谷一样：一切都是那么的新奇、牛逼闪闪而高高在上。&lt;/p&gt;

&lt;h2 id=&quot;台大&quot;&gt;台大&lt;/h2&gt;

&lt;p&gt;说完演讲正事，再说一下这次的举办场地。主办发选择了台湾大学的社科院作为举办场地让我受宠若惊。第一次站在学术氛围浓厚的大学进行演讲，难免还是有点紧张。演讲之余我们几个大陆来台的讲师也在台大转了一下，我有几个体会：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;台大的校门很低调，低调到如果是在路上走，你可能会根本没在意它的存在。
&lt;img src=&quot;2.jpeg&quot; alt=&quot;台大校门&quot; /&gt;
只有走进了看，才能看清楚上面的字。
&lt;img src=&quot;1.jpeg&quot; alt=&quot;台大校门详细&quot; /&gt;
怎么说台大也是出了很多名人的地方，不管是政治届、娱乐圈、工商界、科技界还是学术界，名人都是大把大把的不缺。但是这个校门真的太低调；&lt;/li&gt;
  &lt;li&gt;台大内部给我的感觉就像是一个缩小版的东京大学，不管是建筑风格、院系设置还是人文情怀，几乎都是照搬东大而来（PS：后来认识了一个导游哥们，他说台大以前叫帝国大学，是在日本占据台湾的时候兴建的，后来国军入台后才改名台大。回去一查，果然前几任校长都是日本人）。
&lt;img src=&quot;3.jpeg&quot; alt=&quot;图书馆&quot; /&gt;
&lt;img src=&quot;4.jpeg&quot; alt=&quot;台大校门详细&quot; /&gt;
这是国内的电子信息工程系，这里的名字叫什么来着，忘记了，反正挺长而且挺繁琐。
&lt;img src=&quot;5.jpeg&quot; alt=&quot;电子信息工程系&quot; /&gt;
没记错的话应该是日本留学生或者是日本留学生留下的一个雕塑作品（PS：这里可能记不太清了。这个雕塑还有一个是草地上的建筑模型，这两个不知道哪个的作者是日本人了。有点健忘，不好意思）
&lt;img src=&quot;6.jpeg&quot; alt=&quot;地标：阅读的小女孩&quot; /&gt;
这个是台大的图腾。一个钟。上面写着：一天其实只有21个小时，另外3个小时是用来……
&lt;img src=&quot;8.jpeg&quot; alt=&quot;台大的图腾&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;彩蛋&quot;&gt;彩蛋&lt;/h2&gt;
&lt;p&gt;程序员就是程序员，会后主办方安排我们去领略了一下台湾当地的风俗人情。其中有个放天灯的环节，一般人在天灯上无非都留下些什么“身体健康”，“全家幸福”，“xxx爱你一辈子”这种的话。只有我们程序员的天灯是那么的与众不同：&lt;/p&gt;

&lt;p&gt;hello world。其实这个不是我写的，虽然拍的是我。我写的是 root#:rm -rf /
&lt;img src=&quot;9.jpeg&quot; alt=&quot;hello world&quot; /&gt;&lt;/p&gt;

&lt;p&gt;来自前端兄弟的javascript是世界上最好的语言。其实我是想用c反驳的，但是家伙狡猾狡猾的，全写满了，不给机会！
&lt;img src=&quot;10.jpeg&quot; alt=&quot;javascript是世界上最好的语言&quot; /&gt;&lt;/p&gt;

&lt;p&gt;58沈大师的“当场面试”–快排算法。可惜最后“一致不怀好意的”判定有两个问题：第一个，函数没写全，编译不通过；第二个，递归漏写了退出条件，CPU100%。
&lt;img src=&quot;11.jpeg&quot; alt=&quot;快排&quot; /&gt;&lt;/p&gt;

&lt;p&gt;主办方和我们架构场的讲师们
&lt;img src=&quot;12.jpeg&quot; alt=&quot;我们架构场的讲师&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这是我们大陆的所有讲师在101大楼，101大楼发生了很多故事，但是只能发这一张了。大陆讲师就缺钟恒了，家伙跑出去单独行动了，目的比较可疑。
&lt;img src=&quot;13.jpeg&quot; alt=&quot;我们讲师&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Sun, 13 Aug 2017 00:00:00 +0800</pubDate>
        <link>http://www.94geek.com/blog/2017/taiwan-ithome/</link>
        <guid isPermaLink="true">http://www.94geek.com/blog/2017/taiwan-ithome/</guid>
      </item>
    
      <item>
        <title>网络read函数未判返回0导致CPU 100%</title>
        <description>&lt;p&gt;我们的“运维小帅哥”又来烦我们了！没事就在群里给我们post了一张图，如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;1.png&quot; alt=&quot;show&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;新上线的lest系统的CPU使用率很高！&lt;/strong&gt;。一看才17%，不是正常吗？小帅哥爆发了，不对。这是多核，被平均的消耗！实际上两个核已经被吃满了！&lt;/p&gt;
&lt;h2 id=&quot;检查服务器&quot;&gt;检查服务器&lt;/h2&gt;

&lt;p&gt;使用top命令看了一下，如下图：&lt;br /&gt;
&lt;img src=&quot;2.png&quot; alt=&quot;top&quot; /&gt;&lt;/p&gt;

&lt;p&gt;从上图可以看到，cpu的load负载一直在2左右，也就是说其中的2个核已经被占满。再看下面，是被2个cpu沾满的！看一下CPU的情况，其中系统负载和用户负载几乎是一样的，一个是9.1%，另外一个是7.4%。这就是说可能的问题出在用户态，用户态因为需要调用系统调用，把系统的负载带起来了！那么造成这种疯狂消耗CPU的原因基本上99%都是在循环中干了什么傻事，导致循环出不来，疯狂的消耗CPU！&lt;/p&gt;

&lt;p&gt;因为是CPU负载比较高，不是什么内存泄露之类的问题，所以没办法通过core来精确的debug。我们只能靠gcore通过人工的方式强行抓取进程的runtimes碰碰运气，看看是不是能看出来一点蛛丝马迹。&lt;/p&gt;

&lt;h2 id=&quot;debug看runtimes&quot;&gt;debug，看runtimes&lt;/h2&gt;

&lt;p&gt;首先，加入core后得到的结果如下图：&lt;br /&gt;
&lt;img src=&quot;3.png&quot; alt=&quot;gdb core&quot; /&gt;&lt;/p&gt;

&lt;p&gt;和上面top对应的是两个线程：25128和24130。因为问题就是出在它们身上，我们进入这2个线程看一下它们到底在做什么，首先看一下线程的编号，如下图：&lt;br /&gt;
&lt;img src=&quot;4.png&quot; alt=&quot;th1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当前线程就是28这个，那就直接来吧，运行bt，如下图：&lt;br /&gt;
&lt;img src=&quot;7.png&quot; alt=&quot;bt&quot; /&gt;
和前面的几次一样都是啥都没有的？，还是使用%rbp来看一下吧，如下图：&lt;br /&gt;
&lt;img src=&quot;5.png&quot; alt=&quot;rbp&quot; /&gt;
这是在读取数据，这个也是正常的调用，但是它是一个“可能的循环”。看上去没发现什么有价值的东西。那么进入到30这个线程看看，如下图：&lt;br /&gt;
&lt;img src=&quot;6.png&quot; alt=&quot;th30&quot; /&gt;
这个线程还是在stack的顶端，没在运行。也就是说可能在我们抓取core的一瞬间，此线程正好因为cpu的时间片被让出，啥都没在干。&lt;/p&gt;

&lt;p&gt;到目前为止，通过gdb我们没有发现很多有价值的东西，除了那个疑似的可能性循环，但是就这点信息不能确定就是它的问题。也就是说从用户态入手，我们看不太到我们想要的信息，那我们看看系统调用的。&lt;/p&gt;

&lt;h2 id=&quot;再次求证&quot;&gt;再次求证&lt;/h2&gt;

&lt;p&gt;使用strace将所有线程的系统调用全部抓取出来，因为线程太多了，容易形成干扰，所以我们使用grep将怀疑有问题的25128线程给抓取出来，如下图：&lt;br /&gt;
&lt;img src=&quot;8.png&quot; alt=&quot;strace&quot; /&gt;&lt;/p&gt;

&lt;p&gt;为了明确问题，我已经用红色的标记给标出来了！我们发现在整个的系统调用中，一直在循环的调用read，epoll_ctl，这样的函数。再仔细看一下，每次read都欲获取29长度的值（29是header的buffer长度），但是实际得到的长度是0，表示没有数据。也就是说，我们试图每次都获取数据，但每次都没有获取到数据，事件机制又把这个fd给重新加到了epoll中监听了。回忆上面core在gdb中的表现，28线程一直在read数据。那么问题就在这里了。因为没有给read进行合理的返回值过滤，导致错误的返回值也被按照正确对待，重新加入epoll监听，有因为epoll是一个无线循环，而每次又都触发read，所以轻轻松松的就干掉了CPU。&lt;/p&gt;

&lt;h2 id=&quot;检查代码&quot;&gt;检查代码&lt;/h2&gt;

&lt;p&gt;回过头来检查代码，read的网络事件都是被组织在spx（是我们的一个c开发组件）中的，查看nio，如下图：
&lt;img src=&quot;9.png&quot; alt=&quot;code&quot; /&gt;
确实没有对read的真实获取长度（就是代码中的&amp;amp;len）为0的情况进行判断，所以发生了这个问题。解决办法也简单，将这个判断加上就可以了。，如下图：&lt;br /&gt;
&lt;img src=&quot;10.png&quot; alt=&quot;code&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;连带问题及其解决&quot;&gt;连带问题及其解决&lt;/h2&gt;

&lt;p&gt;解决问题，心里美滋滋的。上uat，观察一会儿！突然，我同事和我说，为什么fixed后的版本上传数据失败率有点高啊？多高？50%以上！我x。马上拿一个日志下来看看，如图：
&lt;img src=&quot;11.png&quot; alt=&quot;log&quot; /&gt;&lt;/p&gt;

&lt;p&gt;哎呀，很多重试的链接都被强行关闭了。仔细看一下上面的代码，也就是说当spx_read_to_msg_once的err为EAGIN的时候，len也是0，但是代码却先判断了0==len，所以就“变向”过滤掉了err == EAGIN的情况。但是err == EAGIN的情况是正常的，应该被再次加入epoll重试，所以调整一下代码，将0 == len的判断移到判断err的后面，先判断err，就不会出现这种情况下了，代码更改如下：&lt;br /&gt;
&lt;img src=&quot;12.png&quot; alt=&quot;code&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这样世界终于清静了！上uat，果然畅通，稳定后再上到online，看一下这个cpu的曲线：
&lt;img src=&quot;13.png&quot; alt=&quot;cpu&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在这个40°c的天气终于透心凉了！&lt;/p&gt;

&lt;h2 id=&quot;问题引申&quot;&gt;问题引申&lt;/h2&gt;

&lt;p&gt;那么还有问题来了，为什么write数据的时候，如果返回值为0不需要判断呢？&lt;br /&gt;
其实这个和tcpip的api有关。当read的时候，如果返回值是0，就表示对端已经关闭，所以后续没有数据读取了。write的时候，write的是本地的网络缓冲区，也就是滑动窗口，如果你的额client是一个慢client，读取你滑动窗口的数据特别慢，就会导致你write的时候数据写不进去，但是数据写不进去并不是一个错误，只是要你等client读取过后再试一次而已。所以write返回0加入epoll来使用事件触发是正确的。&lt;/p&gt;
</description>
        <pubDate>Tue, 08 Aug 2017 00:00:00 +0800</pubDate>
        <link>http://www.94geek.com/blog/2017/read-rc-0/</link>
        <guid isPermaLink="true">http://www.94geek.com/blog/2017/read-rc-0/</guid>
      </item>
    
      <item>
        <title>解决锁抢占问题--随机式获取抢占锁</title>
        <description>&lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;
&lt;p&gt;我们原本的调度系统是由quartz为基准DIY的系统，但因为quartz的很多问题，特别是可扩展设计是在太差、自定义功能太麻烦，我们不得不自行设计了一个调度系统，内部称为：probactr。probactr分为下面几个节点：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;monitor：监视器，主要负责监视Executor的状态和Executor执行的job状态，如发现Executor出现down机或者job出现问题，会对其进行清理。此节点为可平行扩展集群；&lt;/li&gt;
  &lt;li&gt;Executor：运行器，主要负责从数据库中获取欲执行的job，然后执行job。此节点为可平行扩展集群；&lt;/li&gt;
  &lt;li&gt;LockerServer：分布式锁服务器，为probactr提供一致性功能。目前使用redis替代，有计划将其替换成我们自主研发的lax605；&lt;/li&gt;
  &lt;li&gt;ManagerSite：后台管理系统，可以在这里对job进行添加、删除、暂停等等的管理，也可以查看job的执行状态；&lt;/li&gt;
  &lt;li&gt;database：数据库，所有的job数据全部存入数据库；&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;系统结构图如下：
&lt;img src=&quot;1.png&quot; alt=&quot;probactr&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;问题表现&quot;&gt;问题表现&lt;/h2&gt;
&lt;p&gt;probactr在开发环境中没有任何的问题，运行一切正常。上到test环境运行一段时间后发现有几个问题：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;可并行job（job分为可并行和不可并行2种）的统计状态不对；&lt;/li&gt;
  &lt;li&gt;打开邮箱发现报警邮箱已经被塞爆，据报警信息可知：更新job的状态和统计信息失败，并且基本上1s内可以产生3-4封同样的mail；&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;分析问题&quot;&gt;分析问题&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;首先，分析一下报警的mail，除了知道是更新状态和统计信息失败以外，还发现一个问题：所有报警的job都是可并行的job，且同一个trigger触发了很多个job；&lt;/li&gt;
  &lt;li&gt;接着，看一下job的Executor机器监控，发现CPU很高，有一些核能飙到100%；&lt;/li&gt;
  &lt;li&gt;然后，再查看一下数据库，发现被报警的trigger同时运行的job数特别大（我们当时没有对同一个trigger可以触发的job数进行限制）；&lt;/li&gt;
  &lt;li&gt;再查看一下别的job，发现一些不可并行的trigger并没有被触发，都被积压了；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;到这里问题已经很清楚了，出问题的应该是可并行job导致的。首先想到的是可能是&lt;strong&gt;我们没有限制可并行的job数&lt;/strong&gt;，导致了可并行job并发特别厉害，我们设置阀值，应该就没有问题了。&lt;/p&gt;

&lt;p&gt;我们增加了这个功能，并且上test。发现确实问题减轻了很多，但是并不能完全杜绝。还是会有同样的报警mail出现，只是数量上少了很多。这可以证明问题只是得到了缓解，而并没有彻底解决。所以我们再去找原因。更新job状态的代码只有2处：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;job在启动的时候：trigger被scher扫描到，并且scher认为trigger满足被触发的条件。probactr会执行以下路径的代码：获取job的locker-&amp;gt;启动job-&amp;gt;更新job的状态-&amp;gt;释放locker；&lt;/li&gt;
  &lt;li&gt;job执行完毕的时候：job执行完毕后，也会执行上面同样的逻辑；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;但是问题出现的位置应该不会是在job启动时，因为我们对于job的启动进行了weak化，job起不来没关系，下次scher扫描到再起来即可。但是在job结束时却是要强制性的，因为这一步job已经执行完成，必须要更新job的状态和信息，所以必须要成功，否则整个probactr的状态就会出问题。&lt;/p&gt;

&lt;p&gt;找到问题就好办了。&lt;/p&gt;

&lt;p&gt;再排查下去，更新数据库应该没有问题，因为就一条特别简单的sql语句，唯一能出现问题的地方应该是获取锁了。在job执行完成后，我们需要同时更新job和trigger的状态，所以必须要先获取locker。那么如果可并行job在同一时间结束，而且在同一时间去获取locker，确实可能会出现获取不到锁，然后相当于一直阻塞的状态。我们把并发job的数量改小，相当于同一时间获取的locker的请求量变小了，但是不保证一定没有，所以看起来问题减轻了。但这一步获取locker必须成功，所以保不齐肯定会磕到门牙，问题还是存在。那么为什么有时候CPU会飙升呢？因为我们必须要获取锁，所以一直在loop这个获取锁的功能，CPU当然撑不住。&lt;/p&gt;

&lt;h2 id=&quot;解决办法&quot;&gt;解决办法&lt;/h2&gt;
&lt;p&gt;首先想到的解决办法是：能不能放弃最后一步获取locker。但是很遗憾，经过一遍代码回溯发现行不通。不要locker的话还是存在数据不一致问题，job的属性状态和job的统计信息会不对；  &lt;br /&gt;
第二：调整获取锁的算法，使用sleep的方式来进行，比如sleep(100ms),这个方法在一定程度上是可以的，但还是会有问题，如果两个job同时抢占locker，如果sleep的时间一样，除了cpu的切换以外，还有一定的概率会第二次，第三次同时被唤醒；  &lt;br /&gt;
最后：我们使用了随机值的算法，在一定的范围内，根据我们的算法生成一个值，然后sleep这个随机值。这样可以巧妙的规避掉同时获取locker失败的问题。&lt;/p&gt;
</description>
        <pubDate>Tue, 18 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://www.94geek.com/blog/2017/staircase-locker/</link>
        <guid isPermaLink="true">http://www.94geek.com/blog/2017/staircase-locker/</guid>
      </item>
    
      <item>
        <title>PHP&quot;伪司机&quot;调试PHP CORE</title>
        <description>&lt;p&gt;这次不是装逼，是真的帮忙找问题。对于php，一脸懵逼啊！因为就从来没写过，根本不懂php！&lt;/p&gt;

&lt;h2 id=&quot;发车&quot;&gt;发车&lt;/h2&gt;
&lt;p&gt;正常发布日，因为dfs的php客户端需要增加api而更新，就是在更新的过程中发生了问题，具体的表象为：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;程序无响应，访问web网页没有显示，直接报无响应；&lt;/li&gt;
  &lt;li&gt;CPU100%，服务器的CPU一直100%，非常“稳定”；&lt;/li&gt;
  &lt;li&gt;磁盘100%，磁盘监控显示也是100%，但是我们没有任何的磁盘操作啊，除了读php的文件，懵逼ing；&lt;/li&gt;
  &lt;li&gt;机器非常慢，执行命令非常慢，慢到无法忍受，甚至打命令都很一个字母一个字母的延迟；&lt;br /&gt;
更加诡异的是虽然我们确实更新了php插件，但是这个插件属于提前更新，业务代码并没有使用到这个插件新的api，所以首先排除是因为新插件新增功能的bug导致的，而老的api我们已经用了一年多了，也不会出现问题。那么只有更新的方式不对了？但是这个更新的方式也用了2年多了，以前一直没问题，怎么就今天出现问题了呢？幸好我们打开了core，php进程在crash的时候生成了core，我们可以用gdb调试一下。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;开车&quot;&gt;开车&lt;/h2&gt;
&lt;p&gt;还是老路子，首先压入core文件，如下图：
&lt;img src=&quot;1.png&quot; alt=&quot;php core&quot; /&gt;  &lt;br /&gt;
从这个图中我们可以得到2个信息，红色的已经标注：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;首先core是由php-fpm引起的，问过同事才知道这个是一个php提供web的组件；&lt;/li&gt;
  &lt;li&gt;生成core是因为信号11，也就是段错误。引起这个问题一般的问题就是内存错误，比如内存没有释放，使用了野指针，或者是溢出等等；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;导入php的可执行文件，执行bt查看一下当前的stack情况，如下图：&lt;br /&gt;
&lt;img src=&quot;2.png&quot; alt=&quot;php bt&quot; /&gt;  &lt;br /&gt;
和上次一样，又是stack info全是？？。但是这次有所不同的，上次的dfs中stack问题是因为stack乱掉，虽然编译的时候加了-g参数，可执行文件保存了调试信息，但还是乱掉了，全是？。而这次的php是因为编译的时候没有加-g参数，所以调试信息压根就没有保存下来，所以在这里看不见到stack info是很正常的；&lt;/p&gt;

&lt;p&gt;还是借助寄存器吧，上次就是通过寄存器最后解决了问题，获取一下寄存器的值，如下图：  &lt;br /&gt;
&lt;img src=&quot;3.png&quot; alt=&quot;php regedits&quot; /&gt;&lt;/p&gt;

&lt;p&gt;再通过x命令看一下rbp之前的stack，如下图：  &lt;br /&gt;
&lt;img src=&quot;4.png&quot; alt=&quot;php stack&quot; /&gt;  &lt;br /&gt;
通过这个命令可以看到有3个标识出现了，分别是：zend_check_magic_method_implementation，ip_maskr和zif_sha1_file。因为对php很不熟悉，所以只能g一下php的源码，知道一下这3个到底是啥玩意。如下：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;zend_check_magic_method_implementation：这个是php的一个函数，主要用来做调用php函数之前的校验之类的用的，这个应该关系不大；&lt;/li&gt;
  &lt;li&gt;ip_maskr：这个是一个staic struct,在php的内核crypt_freesec.c文件中182行，大小为8*256，有2048b=2k啊，好大，有重点嫌疑；&lt;/li&gt;
  &lt;li&gt;zif_sha1_file： 这个是用来计算每个申请访问文件的hash值的，在这个函数中需要用到ip_maskr的值，这个也是有重大嫌疑；&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;分析&quot;&gt;分析&lt;/h2&gt;
&lt;p&gt;综上所述，好像发现了一点什么。看最后一张图，上面显示的是ip_maskr+4144，也就是说在ip_maskr的偏移4144处。ip_maskr一共就2k啊，指针的指向不对了，越界了，所以导致了程序crash。那么为什么会指针有问题呢？再要查一下。&lt;/p&gt;

&lt;p&gt;这里就和我们更新php的方式有关了。我们使用reload模式更新，难道是因为reload模式的问题？接触这个疑惑的办法就是我们去看一下php在执行reload的时候执行了哪些代码。所有的bug都是由代码导致的，所以看代码还是根本。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;首先，查看了一下php-pfm的代码，reload使用了SIGUSR2的信号，这个没有问题，大家都是这么玩的；&lt;/li&gt;
  &lt;li&gt;然后，查看SIGUSR2的信号回调函数，如下：&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    static void sig_soft_quit(int signo)
    {
        int saved_errno = errno;
        /* closing fastcgi listening socket will force fcgi_accept() exit immediately */
        close(0);
        if (0 &amp;gt; socket(AF_UNIX, SOCK_STREAM, 0)) {
            zlog(ZLOG_WARNING, &quot;failed to create a new socket&quot;);
       }
       fpm_php_soft_quit();
       errno = saved_errno;
    }
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;问题基本上就是这里了，php确实关掉了监听的socket，但是已经连接了的socket呢，怎么处理了？应该就是因为没有关闭的连接继续执行而静态区的数据已经被破坏，内存映射出现了偏差导致的。g一下，发现php社区其实已经发现了这个问题，bug号：60961。有兴趣大家可以关注一下。可悲的是，我们不小心踩了雷。&lt;/p&gt;

&lt;p&gt;问题最后是找到了，但是上面cpu和磁盘都100%的问题又是什么原因呢？   &lt;br /&gt;
这个其实是牵连问题，也和php有关系。因为php使用fastcgi来处理web请求，执行之间使用父子进程模式，父进程监控子进程的健康状况和重启子进程；而子进程是多子进程，是真正执行处理的地方，我们的服务器上开了有300个子进程，php的客户端访问会被分配到每个执行的子进程上。然而悲剧的也就是子进程多的时候，当子进程crash的时候，我们又给系统开了core文件生成，所以这300个进程又同时写core文件，所以CPU和磁盘肯定都是100%的负载。&lt;/p&gt;

&lt;h2 id=&quot;解决办法&quot;&gt;解决办法&lt;/h2&gt;
&lt;p&gt;处理办法也很简单，堵住问题的引起点就行了。不要使用reload模式，而是先把服务器下线，然后确保没有连接后，使用restart方式重启php，再将更新完成的php上线就没有问题了。&lt;/p&gt;

</description>
        <pubDate>Tue, 11 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://www.94geek.com/blog/2017/debug-php/</link>
        <guid isPermaLink="true">http://www.94geek.com/blog/2017/debug-php/</guid>
      </item>
    
      <item>
        <title>为什么这样设计Chaos</title>
        <description>&lt;p&gt;随着上一篇介绍Chaos的文章推送，最近有好几家公司或者项目负责人联系我，准备在生产环境中使用Chaos，所以也会经常被问到一些问题。这里我总结了一下经常会被问到的几个问题，给大家做一个统一的回答吧！&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;怎么样搭建Chaos的集群环境？&lt;br /&gt;
这个问题分为2步：
    &lt;ul&gt;
      &lt;li&gt;首先是配置mid：chaos的配置文件中有一个配置项是mid，这个mid就是每台chaos服务器的唯一标识，目前支持配置值是0-9的数字。只要在一个集群中保证每台chaos的mid不一样即可。&lt;/li&gt;
      &lt;li&gt;在chaos的前端放一个ngx或者是HA这种的带有“负载均衡”功能的反向代理服务器，将各自单台的chaos组合起来即可，我们用的是ngx；&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;chaos进程起来都是“回话模式”，退出term就没了，怎么设置“后台运行”，难道要自己加&amp;amp;？&lt;br /&gt;
chaos当然不会傻到让使用方自己加&amp;amp;来daemon化，chaos的配置文件中有一个配置项daemon，把这一项设置成true即可。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;chaos起不来，出现libev.so can not found的错误，这是怎么回事？&lt;br /&gt;
这是因为你虽然安装了libev，但是有的系统（比如centos）不会自动去更新系统的so缓存，所以你需要更新一下系统的so缓存。
    &lt;ul&gt;
      &lt;li&gt;执行命令：echo “/usr/local/lib” » /etc/ld.so.conf.d/x86_x64_linux_libev.conf ；&lt;/li&gt;
      &lt;li&gt;ldconfig -v
搞定。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;为什么chaos起来后本地可以访问，换台机器就不能访问了？&lt;br /&gt;
首先你要排除一下你的防火墙，iptables之类的配置是不是都已经开启chaos所使用的端口了。如果已经支持了，那么请看一下chaos配置文件中的配置项bind_ip这个项的值是多少，默认是127.0.0.1，请将这个配置项改成chaos服务器所在的外网可以访问的ip，重启chaos，你就可以在另外一台机器上获取id了。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;chaos在集群的情况下（特别是不同机器之间）生成的id是保证单调自增的吗？&lt;br /&gt;
不是，chaos生成的id在集群的情况下不保证严格的单调递增，特别是1s内生成的id，但chaos肯定保证2s内生成的id具有严格单调递增性，也就是说后一秒生成的id值肯定大于前一秒生成的id值。造成这个原因主要是因为几点：
    &lt;ul&gt;
      &lt;li&gt;严格单调递增不是不能做到，而是消耗的资源太多了。现在chaos在集群情况下是没有主从之分的，也没有相互之间的任何通讯，从而保证了我们获取一个id的快速性，也保证了chaos整个的简单性；&lt;/li&gt;
      &lt;li&gt;获取id后，我们经常做的一个动作就是分库分表操作，所以id会被根据业务规则散落到各个“段表”中，在这过程中，时间应该会在ms或者是s级别，所以chaos严格递增性其实没有那么大的实际需求，我们就可以不优先实现这个功能；&lt;/li&gt;
      &lt;li&gt;系统的健壮性。平行的chaos功能设计有利于chaos的部署简单化和提高chaos的系统鲁棒性，不管chaos的机器发生什么问题，就算机器down掉或者直接换掉，chaos都可以快速的通过使用新机器、新节点来提供新的功能，不需要恢复数据、操作日志（因为根本就没有，每次的id都是纯计算生成的）等等； &lt;br /&gt;
PS：我们有支持严格单调递增的id生成器，是另外一个系统：lax605。lax605在我们的系统中更多的被用来作为分布式协调器的角色使用，类似于zookeeper。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;chaos生成的id是否存在浪费？怎么处理？  &lt;br /&gt;
有浪费现象，比如现在每台机器每秒都可以支持最大2560000个id的生成，但是因为99.9999%的时候你根本就用不到那么多的id，真实的业务量大概每秒也就几百或者几千的id生成，从而因为id中存在序列号，所以没有被轮询到的id就直接被扔掉了，这确实有浪费现象。怎么处理？chaos就没有去处理，因为我们觉得这个没啥必要，反正每秒id那么多，而且对于业务来说如果分库分表规则是按照时间等作为路由是要严格保证时间上的正确性的，综上我们就不去过多的去做额外的处理了。但如果有业务方确实觉得id是一个虚缺资源，需要每一个都不放过，那么可以通过中继器来过渡一下，自己做一个每个id的存储和分发。但是在这么做之前，我觉得要冷静下来思考一个问题：这种做法真的有必要吗？&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;chaos生成的id最大值是多少？多长？长度固定吗？       &lt;br /&gt;
chaos生成的是一个uint64的数，最大的长度是64位，一共最长是18个数字的长度。但是因为id和时间相关，所以开始的时候id的个数长度会比较短，大概在15位左右。所以id的长度是不固定的。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;chaos的客户端有没有java的？&lt;br /&gt;
首先，chaos目前支持两种方式访问：tcp和http。java的客户端也确实有，并且也有开源（在albianj项目中），java的客户端就是通过tcp方式访问的。但就我们自己使用的实际情况和实际效果来看，我们不推荐使用java客户端的tcp方式，我们推荐大家更多的使用http来访问chaos，主要有几点：
    &lt;ul&gt;
      &lt;li&gt;http相比tcp更容易调试，curl或者是浏览器就可以直接调试；&lt;/li&gt;
      &lt;li&gt;http相比tcp，http没有语言的相关性需求，当一个公司或者项目大了以后不保证所有的功能都是java来实现的，所以客户端模式会很蛋疼的需要很多的客户端；&lt;/li&gt;
      &lt;li&gt;对于tcp的通讯相比http性能高的问题，chaos这种访问都是在内网，用http和tcp能差多少？&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;id生成器目前在公司内部使用的怎么样？  &lt;br /&gt;
目前公司内部的内容中心、起点改造等站点正在使用id生成器，每天的请求量总体加起来过亿，一共花费了4台普通的pc服务器。id生成器从上线的那天开始一直到今天有2年多了，中间除了因为功能增加以外从来没有down机，也没有重启记录。稳定性达到惊人的100%。可以算是公司内最稳定的线上运行项目，没有之一。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;目前有几家公司正在使用？  &lt;br /&gt;
到今天为止，一共有10+家公司已经在线上使用id生成器，目前来咨询有使用意向的也有7-8家。我们是最大的一家：阅文集团，该集团是腾讯文学、盛大文学合并而成的。请求量和数据量在网络文学届也是数一数二的。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;评价一下别的id生成器，和chaos有什么差别？ &lt;br /&gt;
这nm怎么评价，谁都是看自己家的孩子更好看，更可爱啊！不要搞事啊！我严重怀疑问我这个问题的人的居心，但一看问这个问题的还挺多。nm，果然都是来搞事的。不过话说回来，虽然我确实看了很多友商的id生成器设计或者是成品，各有千秋，各有优势吧！我觉得我们的chaos主要有几个优势：
    &lt;ul&gt;
      &lt;li&gt;在架构上更加的简单，平行化的设计，没有单点或者主从的问题，也没有机器的浪费问题，都是主；&lt;/li&gt;
      &lt;li&gt;依赖少，除了依赖网络库libev，没有什么mysql数据库或者redis这种依赖（PS：其实我也觉得很奇怪，为嘛一个id生成器需要依赖数据库或者是redis这种玩意，这种东西到底在id生成器中有啥用？除了复杂化设计外，没看到什么必要）；&lt;/li&gt;
      &lt;li&gt;性能上更牛X一些吧，c语言，事件机制，相比java之类的，那是相当妥妥的；&lt;/li&gt;
      &lt;li&gt;可读性上更人性化一些，十进制的数字，基本上都能看的懂；&lt;/li&gt;
      &lt;li&gt;协议更简单一些，支持http，无语言相关性；&lt;/li&gt;
      &lt;li&gt;更适合作为数据库的主键来使用，特别是需要做分布式数据库的情况，有分库分表等等数据路由的情况特别适合；&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Wed, 05 Jul 2017 00:00:00 +0800</pubDate>
        <link>http://www.94geek.com/blog/2017/chaos-qa/</link>
        <guid isPermaLink="true">http://www.94geek.com/blog/2017/chaos-qa/</guid>
      </item>
    
      <item>
        <title>gdb线上crash调试-记一次装逼失败的教训</title>
        <description>&lt;p&gt;可惜这是一次完完全全的装逼不成反被X的典型例子。&lt;/p&gt;

&lt;h2 id=&quot;背景&quot;&gt;背景&lt;/h2&gt;
&lt;p&gt;有一天早晨刚到公司，运维小帅哥突然通知我，我们的dfs在平稳运行了一年时间后，在没有任何异常波动、没有任何资源报警、没有任何升级，也没有任何违规操作的情况下，毫无征兆的crash了。&lt;br /&gt;
小帅哥一头雾水，我一脸懵逼。&lt;br /&gt;
dfs是我们的核心服务，绝对不能down机的，所以就先紧急把它拉了起来。命好的是，起来后程序又平稳运行了，既不crash也不拒绝服务，服务和性能又都是杠杠的。这就让我更懵逼了。&lt;/p&gt;

&lt;h2 id=&quot;怀疑&quot;&gt;怀疑&lt;/h2&gt;
&lt;p&gt;首先怀疑的是内存泄漏一类的资源泄漏问题。毕竟dfs是c写的，内存、fd、locker等等的资源处理太多太杂了。特别是内存，几乎每个函数内都会出现。所以重点对象就是它。&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;找运维查看一下报警系统是不是有没有发出来的报警？查了一下没有。&lt;/li&gt;
  &lt;li&gt;自己还是不放心，直接看了一下线上产生的core文件，大小也只有mb级别，确定确实没有溢出。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;接下来，怀疑是fd或者locker。&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;先说locker。dfs是我们自己设计的无锁处理算法，根本不存在locker的资源操作，所以这个也被排除了。&lt;/li&gt;
  &lt;li&gt;fd，文件描述符。如果fd有溢出，我们也对fd加了报警，报警系统是不会不报的。就算漏了，fd溢出的现象也不应该是进程直接crash，而是会无响应才对。而且去查看了一下log，并没有发现执行close有错误的迹象。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;到目前为止，所有所能想到的原因全部不成立，线索全部中断。那么如果非要弄清楚这次crash到底为了什么，唯一的办法就是去看程序的runtimes。&lt;/p&gt;

&lt;h2 id=&quot;碰碰运气&quot;&gt;碰碰运气&lt;/h2&gt;
&lt;p&gt;反正线上的core文件都已经生成了，不玩白不玩。通知运维把core给拿下来，我非得去看看到底为啥就crash了？不看不要紧，一看就自己打了自己的脸啊！&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;加载core文件，发现程序是因为收到信号6的原因进程被退出的。如下图：
&lt;img src=&quot;1.png&quot; alt=&quot;single 6&quot; /&gt;
信号6，也就是SIGABRT，Linux的man解释：由调用abort函数生成的信号。引起这个信号的可能性有很多，所以这一点没啥用。&lt;/li&gt;
  &lt;li&gt;加载可执行文件，然后看看crash的一瞬间的堆栈是一个什么情况，好做一个大概的判断：哪一行代码可能出现了问题。
&lt;img src=&quot;2.png&quot; alt=&quot;load file&quot; /&gt;
执行bt命令后，显示出来的stack信息全是？？，出现这种情况的可能性有2个：
    &lt;ul&gt;
      &lt;li&gt;可执行被重新编译了，导致了新的可执行文件的元数据和core文件中的元数据对不上，这个首先被排除，我们的可执行文件都是从线上直接拖下来的，所以不可能出现这种情况（这里也要告诫大家，千万要保留运行时程序的可执行文件版本，包括.o文件等）；&lt;/li&gt;
      &lt;li&gt;stack已经被破坏了。这种情况很容易就会发生。程序在运行的过程中因为stack，array等溢出的问题没有第一时间被crash，接着在执行命令的时候，产生的core文件stack可能就会被破坏；&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;目前来看，我们所能拿到的信息都已经指向了线索中断。操作系统给出的信号不能定位问题，使用gdb调试core因为stack被破坏无法再进一步。那么还有没有别的办法呢？&lt;/p&gt;

&lt;h2 id=&quot;再进一步&quot;&gt;再进一步&lt;/h2&gt;
&lt;p&gt;竟然stack已经被破坏，gdb也无法认出，按照正常的路子是解决不了这个问题了。所以这时候“野路子”（其实是更合理更深层次的解决方案）就上场了。既然被破坏，那就恢复它或者是想办法绕过它。&lt;br /&gt;
恢复stack的难度有点大，你首先得知道core文件所有的元数据信息，然后和可执行文件的元数据信息一一合并，还要考虑程序在runtime状态下的内存状态，难度确实是相当的大。所以这一步首先被排除了。&lt;br /&gt;
那就绕过它。考验计算机操作系统原理和计算机运行原理的时刻来了（所以要多读书）。&lt;br /&gt;
首先我们知道所有的程序都是由cpu来执行机器指令的，和cpu执行指令相互配合的是寄存器，其中有几个寄存器记录了当前程序runtime状态下的地址，比如esp/rsp，ebp/rbp等寄存器。也就是说我如果知道程序crash的时候寄存器的值，可能就有希望能复原当时的stack。
方针已经制定，就看执行了。&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;首先看一下各个寄存器的值，如下图:
&lt;img src=&quot;3.png&quot; alt=&quot;regediter&quot; /&gt;
别的都不用看，只要看一下rbp和rsp的值就可以了。
    &lt;ul&gt;
      &lt;li&gt;rsp表示是当时程序runtime的时候栈顶的地址值；&lt;/li&gt;
      &lt;li&gt;rbp表示当时程序执行到的指令的地址值；&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;再看一下执行到rbp的指令的时候，程序前面都执行了什么指令，如下图：
&lt;img src=&quot;4.png&quot; alt=&quot;rbp&quot; /&gt;
哈哈，终于看到函数了。spx_socket_connect_nb和ydb_storage_heartbeat_send。按照stack的FILO的原理，是执行到spx_socket_connect_nb的时候程序发生了问题。具体的地址在函数的地址+611处。先看一下汇编，查一下地址看看能不能看出来一点什么？如图：
&lt;img src=&quot;5.png&quot; alt=&quot;code&quot; /&gt;
好像没啥，前面就是给connect构造结构体，后面就是调用connect。但是问题确实是在connect之前就crash了啊。查看一下代码:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; err_t spx_socket_connect_nb(int fd,string_t ip,int port,u32_t timeout){
     struct sockaddr_in addr;
     bzero(&amp;amp;addr,sizeof(addr));
     addr.sin_family = AF_INET;
     addr.sin_port=htons(port);
     addr.sin_addr.s_addr = inet_addr(ip);
     err_t err = 0;
     err_t rc = 0;
     if(0 &amp;gt; connect(fd,(struct sockaddr *) &amp;amp;addr,sizeof(addr))){
         //filter this errno,
         //socket is not connect to server and return at once
         if (EINPROGRESS == errno) {
             struct timeval tv;
             SpxZero(tv);
             tv.tv_sec = timeout;
             tv.tv_usec = 0;
             fd_set frd;
             FD_ZERO(&amp;amp;frd);
             FD_SET(fd,&amp;amp;frd);
             socklen_t len = sizeof(err);
             if (0 &amp;lt; (rc = select (fd+1 , NULL,&amp;amp;frd,NULL,&amp;amp;tv))) {
                 if(0 &amp;gt; getsockopt(fd,SOL_SOCKET,SO_ERROR,(void*)(&amp;amp;err),&amp;amp;len)) {
                     err = errno;
                     return err;
                 }
                 if (0 != err) {
                     return err;
                 }
             } else if(0 == rc) {
                 err = ETIMEDOUT;
                 return err;
             } else {
                 err = EXDEV;
                 return err;
             }
             SpxErrReset;
             return 0;
         } else {
             return errno;
         }
     }
     return 0;
 }
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;确实前面我们就构建了一个struct sockaddr_in的结构体，然后我们就直接connect了。貌似不会出问题，而且代码也已经运行了很久很久了。但是突然间，有种预感冥冥中就出来了。nm可能就这里出问题了。去看一下配置文件，其中的配置项：
&lt;code class=&quot;highlighter-rouge&quot;&gt;stacksize = 64kb&lt;/code&gt;
直刺眼睛啊！火辣辣的。&lt;br /&gt;
这个配置项用来做什么的？其实这个配置项是用来限制系统的stack大小的。也许很多同学都没有听过东东，但是如果你在linux上运行一下命令：
&lt;code class=&quot;highlighter-rouge&quot;&gt;ulimit -a&lt;/code&gt;
&lt;img src=&quot;6.png&quot; alt=&quot;ulimit -a&quot; /&gt;
会出来如上图的一排设置，其中红色框框圈出来的就是这个stacksize的值。在这台机器上默认的是8mb。stacksize的设置在每种linux发行版上的值可能都是不同的。当初就是为了“装逼”，显示自己的编程水平，将stacksize设置成了64kb，这样程序中每个线程最大的stack可用大小就是64kb，你看看我控制系统资源控制的多好？！结果，当碰上一不小心不注意的时候，stack的size马上就超出了64kb，这样stack就溢出了。当然程序就会crash，stack也当然的被破坏了。&lt;br /&gt;
那么为什么我们的会出现这个问题呢？&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;sockaddr_in的结构体其实并不是很大，但是它申请的是stack的内存，原来使用的内存大小+sockaddr_in的大小应该正好碰上临界点；所以sockaddr_in的申请应该是最后一根稻草；&lt;/li&gt;
  &lt;li&gt;ydb_storage_heartbeat_send这个函数是在heartbeat线程中运行的，heartbeat线程是一个常驻线程，由timer事件来触发，每次都会向tracker发送心跳数据，所以可能会存在stack因为某些原因，导致了再一次运行中申请的内存比较多，比如log记日志的时候；&lt;/li&gt;
  &lt;li&gt;那么为什么不起来就出现这个问题呢，而是要在运行了一段时间后呢？这个问题其实没办法确定申请stack的时间点，比如因为网络的问题我需要记录日志，然而又不是时时刻刻网络不行的，正好在某个瞬间网络不行，申请stack内存记录日志，这样没有释放正好被抓到；&lt;/li&gt;
  &lt;li&gt;又因为heartbeat是常驻线程，所以stack基本上不太会被第一时间回收，肯定要在事件处理的最后被回收，所以在一次事件处理内一定要确保有适当的大小来满足程序对于stack的需求；&lt;br /&gt;
原因也找到了，怎么解决这个问题呢？有几种办法：&lt;/li&gt;
  &lt;li&gt;不要装逼了，直接这个项不用设置。我们的程序使用的是事件模型，并不是像java一样的每个connection一个处理线程，dfs是一个线程对应着多个connection，所以线程数并不多，就算是每个线程最大的stacksize是8mb，也用不了多少的内存；&lt;/li&gt;
  &lt;li&gt;把配置文件中的stacksize改大一点，比如1024kb什么的就可以了。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;经验教训&quot;&gt;经验教训&lt;/h2&gt;
&lt;p&gt;因为stacksize这个项的设置导致了出问题的人我不是第一个，也不会是最后一个，仅仅在dfs出了这个问题的时候，我就知道还有别人因为同样的问题导致程序被crash，只是当时程序跑的好好的我就没有多加注意。所以在这里诚恳的告诫大家：&lt;br /&gt;
莫装逼，装逼遭雷劈;&lt;br /&gt;
莫装帅，装帅遭人踹;&lt;br /&gt;
莫装吊，装吊遭狗咬…&lt;/p&gt;
</description>
        <pubDate>Tue, 27 Jun 2017 00:00:00 +0800</pubDate>
        <link>http://www.94geek.com/blog/2017/gdb-stacksize/</link>
        <guid isPermaLink="true">http://www.94geek.com/blog/2017/gdb-stacksize/</guid>
      </item>
    
      <item>
        <title>如何更好的做一堂技术topic分享的套路</title>
        <description>&lt;p&gt;很荣幸的被csdn选中担任sdcc2017深圳架构场的出品人。更荣幸的是，我推荐团队一个小伙伴的技术topic也被选中，将在sdcc20017深圳场和大家分享。但这位小伙伴是第一次作为讲师参加技术topic这样的活动，所以培训小伙伴的事情就成了当务之急。作为一个经常出入技术topic、已经无所谓脸皮不脸皮的过来人，对做一堂还算相对“和谐与靠谱”的技术topic到底有多少的套路呢？&lt;/p&gt;

&lt;p&gt;总的来说， 一堂技术topic的套路分为几个部分：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;PPT&lt;/li&gt;
  &lt;li&gt;前期准备&lt;/li&gt;
  &lt;li&gt;分享中&lt;/li&gt;
  &lt;li&gt;结束&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;ppt&quot;&gt;PPT&lt;/h2&gt;
&lt;p&gt;PPT永远是一马当先的部分！ppt在整个的topic中占的比重应该是最大的。原因有几个：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;前期主办方唯一需要并且讲师唯一能证明自己的东西；&lt;/li&gt;
  &lt;li&gt;你所要表达的思想和内容都在这张PPT中；&lt;/li&gt;
  &lt;li&gt;在分享中，PPT也是你主要依赖的对象，是你控制整个topic的主线轴；&lt;/li&gt;
  &lt;li&gt;ppt会被主办方以各种形式下发，以确保影响力；&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;所以我们需要更加重视的对待ppt。按照我目前参加技术topic的讲师经验和这次的出品人经验，总结讲师在做PPT时候注意点有以下几个：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;字体。ppt中的字体要尽量的大。有的同学会问我：具体要多大？能不能给一个明确的号数？答案是然后并没有。但如果可以的话，把字体设置成所能设置的最大号。大到你觉得这页PPT不好看了，就像“老人手机屏幕”一样了，基本上就可以了。也有很多同学不理解，为什么好好的一页PPT字体要那么大呢？作为讲师你必须要考虑现场，ppt的字体小了，topic现场后面的同学看不见。而讲师在做PPT的时候通常是没察觉的，因为讲师做完PPT预览的时候都是在自己的电脑屏幕上进行的，所以并没有现实的距离感。&lt;/li&gt;
  &lt;li&gt;色彩。这里推荐的色彩是“暗色系的底、亮色系的字”。这样的设定可以最大程度的提高对比度，以帮助现场的同学尽可能清楚的看清楚ppt上的内容。在制作ppt的过程中，尽量不要使用中色系的颜色，也不要使用晃眼的亮色系，比如黄色等等颜色，使用晃眼的亮色系颜色在现场再加上投影或者是LED的光源，不仅仅是看不清的问题，而是眼睛会很疼。&lt;/li&gt;
  &lt;li&gt;背景。一般主办方会给你一个他们设定的母版页来作为你整个ppt的基调。但是请大家注意，如果对方给的母版页的背景是很花里胡哨的、或者是背景图画部分特别多（占到整张PPT的25%以上的），这样的就需要讲师自己权衡一下了。要么你自己做母版页自己设定背景，要么就不要背景，直接白色。其实依照我的经验，你拿到的母版页不和你口味的比率占到99%以上。所以在可能得情况下，尽量的自己做背景，而对于技术的topic，强烈推荐纯白色背景。&lt;/li&gt;
  &lt;li&gt;分辨率。目前国内的投影器或者是led屏幕，大部分都是4:3的分辨率，而我们的电脑基本上都是16:9，所以请各位在制作ppt的时候一定要事先和主办方或者是出品人沟通好，现场的ppt屏幕比例到底是多少，然后再开始你的ppt。特别是对于有特效的同学，当你的显示比例不对的时候，动画的效果会很差很差。&lt;/li&gt;
  &lt;li&gt;内容。内容主要分以下几块：
    &lt;ul&gt;
      &lt;li&gt;个人介绍. 个人介绍一般都是必不可少的。毕竟你又不是什么人尽皆知的大人物，在开场的时候做个个人介绍还是很有必要的，一来可以让大家先认识一下你，知道你在哪里做什么工作；二来如果你可以在这个阶段加入一些你公司的产品介绍就更好了，在增加人家对你印象的同时顺便给公司做了一个“软广”。&lt;/li&gt;
      &lt;li&gt;目录。这部分很简单，一般也是必不可少的。&lt;/li&gt;
      &lt;li&gt;正文。正文需要说几个注意点：
        &lt;ul&gt;
          &lt;li&gt;字。在ppt中尽量避免一大段一大段文字的情况。这种大段大段的文字基本上没人看。如果要出现这种文字，首先考虑是不是可以图形化，其次考虑是不是可以用list或者table的方式来表达；&lt;/li&gt;
          &lt;li&gt;图。图除了色彩搭配和上面提到的一样需要注意外还需要注意2个问题。图尽量的大，并且尽量的不要失真。第二，尽量不要使用截图，特别是网页截图。这种截图往往很难拉伸，ppt的展示效果比较差；&lt;/li&gt;
          &lt;li&gt;动态效果。在技术ppt中，动态效果不宜过多（PS：我指的是一页中），一般除非需要表示数据流等动态流程图，否则应该尽量少的使用动态效果。动态效果用的好是画龙点睛，用的不好就是画蛇添足。而对于技术性的讲师来说，往往是后者。所以宁愿不用也不要错用；&lt;/li&gt;
          &lt;li&gt;广告。这是一个非常严肃又非常值得讨论的问题。大多数的讲师都会在ppt中加入广告，99%的讲师会加入招聘广告，虽然大家都知道通过这种方式成功的概率微乎其微，但还是在做。正是印证了一句广告界的名言：99%的广告打下去都是没结果的。但是为什么大家都在打呢？因为不知道那1%是在哪里！这里要提醒各位的是，做广告可以，但是吃相不要太难看。比如在topic上写上别人家的活动报名方式什么的，这种就有点夸张了。至少也要尊重一下本次的主办方吗；第二，广告尽量使用“软广”的方式，那种硬性植入就能免则免，太欠缺水平了，也没有情怀和b格；第三，大家可以把Q&amp;amp;A页利用起来，上面放一个公司或者你自己的开源github二维码、公众号二维码之类的图片，让大家觉得你不是在做广告，而是在增加联系。归根结底一句话：广告要做的有水平，不要让人家一眼就看出来你这是在做广告，要有b格和情怀，要有b格和情怀，要有b格和情怀！重要的事情说3遍。&lt;/li&gt;
          &lt;li&gt;页数。 一场topic大概用时一般在45分钟，很少有1个小时的，也很少有低于45分钟的。所以对于讲师来说，你真正拥有的时间大概在30-40分钟之间。那也就是意味着你的ppt页数不能太多，也不能太少。基本上控制在有效页数在15-18页，最多不超过20页、不要少于12页就可以了。虽然我也见过50页ppt半小时讲完的，或者是3页ppt讲2个小时的，但是这种人毕竟是少数。我自认为你不是这种人。有效ppt，是指你真正讲内容的ppt。中间有一些穿插的标题、不展开的结论、ppt转换等这些都属于一带而过的，所以它们并不是有效ppt。那么除了这些，剩下的的ppt，包括了topic大部分真正内容的页，这些都是有效ppt。&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;pdf。一般做完ppt后也要同时提供一份pdf给主办方，作为主办方现场或者是会后发放的内容。这份pdf大家一定要注意，一定要脱敏，特别是公司的一些数据，个人的信息等等。一定要进行脱敏处理后再发送给主办方。&lt;/li&gt;
  &lt;li&gt;交稿时间。一般都是认为越早越好，但我觉得不是。最好的时间应该是开始前2个星期开始做ppt，花几天构思，然后花1天完成。这样可以安排在最后期限的前一个星期这个时间点上提交你的ppt。这个时间点的好处是，首先你至少不会到了现场忘记了ppt，也不会因为你要参加topic影响你的工作；第二，你也需要给出品人一点时间来审核你ppt；第三，你还给了你自己一点时间来修改和完善你的ppt。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;前期准备&quot;&gt;前期准备&lt;/h2&gt;
&lt;p&gt;等交稿一个星期后，基本上你的技术topic分享也要开始了，在分享的过程中，也需要几个注意点：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;到达时间。建议大家尽量提前达到topic举办的城市。一般也不用提前太多，前一天晚上到，第二天分享就可以了。通常主办发会在topic举办的酒店或者就近酒店给你开房间，所以你去了以后尽可能的先去现场转转，特别是你要分享的分会场现场，去看看大体的布局、投影的效果、讲台的位置等等。这样至少能做到前期心中有数。&lt;/li&gt;
  &lt;li&gt;设备问题。建议大家最好能自己带上笔记本，如果有条件的话可以自己带好演讲笔。这个不是必要条件，但以防万一。特别是技术同学，现在很多技术同学使用的都是mac，经常提交的是keynote，而国内目前windows还是非常的通用，所以现场可能会出现ppt放不出来或者ppt有问题等等。不过就算你用的windowns+ppt，有的时候也会因为系统或者ppt的版本不同而发生问题，所以最好还是带好自己的笔记本，出现问题的时候可以立即就解决。&lt;/li&gt;
  &lt;li&gt;最后一眼。在分享的前一天晚上，或者你的topic安排在下午的话就是当天上午，尽量抽时间最后看几眼ppt，查漏补缺一下。这是在分享前最后更新ppt和分享知识的机会，也可以再一次熟悉一下自己要讲的ppt和要讲的内容。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;分享中&quot;&gt;分享中&lt;/h2&gt;
&lt;p&gt;就要来到分享现场了，大家是不是有点紧张？这里就来讲讲分享现场需要注意的问题。&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;紧张。首当其冲的就是紧张问题。不管你是新手还是“老司机”，其实都会紧张的。特别是马上要轮到你了，还没轮到的时候，心理都会有一些波动。这种紧张或者叫担心是很正常的。老司机可能在开始的时候就变的正常了，而新手还是会紧张。这里想和大家说的是，不要太担心，经过上面的准备后，这个环节应该不会有什么大问题。你站在讲台上，相比下面的听众，你有更多的天然优势。你分享的内容你是最熟悉的，下面的听众都没有你熟悉，所以你只要按照你前期的准备按部就班的下去就可以了。&lt;/li&gt;
  &lt;li&gt;怎么讲。这里也需要分几个部分来讲：
    &lt;ul&gt;
      &lt;li&gt;脱稿。首先是要尽量的把ppt串起来，并且在分享的过程中除了需要使用演讲笔现场指出来ppt上的部分内容外，总体上需要脱稿。这也是为什么我在上面强调的：不要太早的做完ppt的原因之一。在整个分享过程中要注意节与节之间的衔接部分，这里特别容易“卡壳”。&lt;/li&gt;
      &lt;li&gt;单页讲解。单页讲解的时候最怕的就是口语。比如很多同学喜欢用“然后”，“嗯”，“下面”，“接下来”……这种的口语化的表达方式，而且是重叠的出现这种，比如一页ppt中不停的“然后”…“然后”…“然后”…。这是很不可取的。一般一页ppt总归有个前后关系，所以最好的方式是多使用层次性的词语来表达，比如“首先”…“然后”…“其次”…“接着”…“最后”…,或者是“第一”…“第二”…“第三”…。&lt;/li&gt;
      &lt;li&gt;肢体语言。在分享的时候，一般一手拿着麦克风，一手拿着演讲笔，幸好人类没有第三只手，否则更乱了。所以很多同学都是拿着麦克风的那只手举着（没办法，至少要说话），而拿着演讲笔的那只手不知道在干嘛。有的垂的，有的乱晃，还有的直接插兜里（PS：虽然我也觉得插兜里挺帅挺个性）……，这些希望大家都不要出现。拿着演讲笔的那只手可以适当的做一些动作，不要太夸张也不要一动不动。适当的做一些动作可以让大家觉得你更融入此次的分享中，也可以让大家更加接受你分享的内容。至于这个度，需要自己把握，确实挺难。&lt;/li&gt;
      &lt;li&gt;掌控讲台。大家千万不要在讲台上一动不动的站着，从上去到下来都在一个地方；或者是直接站在演讲台那边，看着ppt在那里好像在做政府工作报告。你可以适当的在讲台上走走，你要清楚你是讲师，这个讲台在这个45分钟内是属于你一个人的，何必那么拘束呢？一般技术topic的讲台都是一个高于听众的地方，长方形，也不是特别的大。但是绝对在中间。你在讲台上适当的活动一下相比站在一个地方不动，可以照顾到下面更多的同学。可以让大家更好的融入到自己的分享中。&lt;/li&gt;
      &lt;li&gt;提问互动。关于这点公说公有理婆说婆有理的问题确实不好办。但依据我的经验，在分享的过程中尽量避免和下面的听众进行沟通和对他们提问。尽量的少问“这个问题大家知道吗？”，“这个有谁知道吗？”这种问题。首先，你对下面听众的情况不熟悉，你这么“唐突”的提问很少能拿到你想要的答案；其次，这种提问几乎都会冷场，很多最后都是讲师自己尴尬的打圆场过去，很少有人会举手回答，就算有也是你要多次的确认“有人知道吗？”；第三，这是技术分享，不是培训。这点要分开。公司内部的培训可以经常使用这种提问方式，但是演讲不太适合，培训的人数一般只有十几个甚至最多也就几十个，如果人数多了就会分批，规模上好控制，而演讲这种的一般至少100-200人吧，会场也很难控制。&lt;/li&gt;
      &lt;li&gt;段子。不要笑，这是一个很严肃的问题。特别是对于在中间分享的讲师，一定要准备3-4个段子。一般大家在长时间的集中精神后，中间有段时间特别累。其实我们自己也有感觉，你坐在下面听一下试试看，一个上午就受不了了，比上班还累。所以在分享的过程中需要穿插适当的段子来把听众的小差给开回来。当然了也不排除很多同学就是为了听你的段子来的。老罗曾经说过：我讲的题你们都没记住，我讲的段子你们倒是记得清清楚楚，过后还久久回味、栩栩如生。&lt;/li&gt;
      &lt;li&gt;时间控制。这个主持人一般都会帮你。有做的比较好的，比如csdn，会给你一个大大的ipad，给你看从开始到结束的剩余时间倒计时；没有这种ipad，也会有一个最后5分钟，最后3分钟，最后一分钟这样的倒计时提醒牌。有倒计时和没倒计时是一把双刃剑。有吧，总感觉有人在催你；没有吧，总会超时。所以归根结底这还是需要大家多加练习自己的ppt，学会控制时间。这里要说的是尽管很多时候最后肯定会拖时间，但是大家要注意，千万不要拖太多就可以了，拖一个2-3分钟没人会说你，因为主持人会灵活掌握下面同学提问的时间，但有一次我也是讲师，我前面的一个哥们拖了15分钟之久，这就太夸张了。而且TMD拖时间是因为他要做广告，这就让我很无语了。所以我对这个哥们印象很不好，大家都在这个圈子混，名字我就不说了。&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;出现意外。这很正常，比如下面突然有人叫起来：这玩意那里听过，或者是这个ppt我看不清楚。出现这种情况首先是千万不要紧张，也不要不知所措。你可以先安抚一下听众，第二，赶快和主持人沟通怎么解决问题，是不是能把ppt的pdf文档下发下去之类的。这里要说一下，如果你的ppt因为公司保密原因不能下发，那么请各位讲师要和主办方、主持人事先沟通好，商量好万一出现问题的时候怎么解决。这种事情不是没有发生过，我就见过因为这个事情现场闹得不可收拾的。这样对大家都不好，特别是对讲师所在的公司名声影响很差，还不如不要出来做这次分享呢！&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;结束&quot;&gt;结束&lt;/h2&gt;
&lt;p&gt;一般分享结束后，剩下的就是听众提问和讲师解答的阶段了。到这里其实才是最考验各位讲师内功的，因为提问环节基本上你不太可能能全部掌握。就算你前面准备的再好，这部分可能最多你也就只能覆盖到70%。那么这部分会经常出现哪些问题呢？&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;问题超纲。这里的超纲是指超出了讲师的知识所掌握的范围。对于初次作为讲师的同学可能是非常容易碰到的。其实这个并不可怕。解决这个问题的本质还是要奉劝大家平时多加注意积累，多加注意同类型开源软件或者是同类型开源论文等东西，只是临时抱佛脚是解决不了这个问题的。但如果你已经站到讲台上了，碰上这种问题你再告诉是靠积累，你这确定你不是在开玩笑？所以一种办法是你确实回答不上来，那么就大方的承认这个你没考虑过，后面再看看；另外一种可能的情况是你其实知道一些，但是知道的知识并不是特别的清楚，没有十足的把握也没有那么的全。这种情况下你就找几个你有把握的，可以回答这个问题中的几个点就可以了。一般主持人看见这种情况也会帮你解围的。&lt;/li&gt;
  &lt;li&gt;一直追问。 这个是对于下面的听众来说的。如果某个哥们一直霸占着话筒怎么办？这个任务一般是主持人的。他会解决这个问题。我的经验是一般一个人提问一次后我就收走话筒了，一来可以给另外的同学更多的提问机会；二来，还可以兼得保护讲师。但是如果主持人也无动于衷，那你就可能需要自己解决这个问题。在回答完他的问题后，你可以带一句“这位同学，下去了我们微信交流，希望现场能有更多的同学提问”这样的话来结束这个同学的提问。&lt;/li&gt;
  &lt;li&gt;一人多问。这个也很正常。一般一个人的记忆力是有限的，所以你可以一个一个的来回答他的问题。但是一般首先强调一下一次提问最好不要超过2个，最多不要超过3个，因为实在是记不住。如果问完了还是有问题那就私底下微信交流。&lt;/li&gt;
  &lt;li&gt;现场群。多看一下群，万一有同学问到你，如果你不回答的话就显得不太好，所以还是要照顾一下群里的反应。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;p&gt;套路，都是套路。写书有写书的套路，程序有程序的套路，分享也有分享的套路。大家都是按照套路在办事情。目前根据我的经验，基本上作为一个讲师，所能想到的套路就那么多。但是套路归套路，归根结底，还是希望大家如果有志想挑战一下自己，有一天也想站上讲台的话，在套路的同时也一定要对于分享这件事情多加练习。其实每个讲师虽然会使用套路，但是私底下还是很努力练习的。这次我们上sdcc的小朋友在事前被练了一个多星期，用他的话说被练的自己都不知道怎么了。ppt在公司内部走了有4-5遍。先是我们几个内部听，提出问题、整改；然后是部门内部听，提出问题、整改；然后再是我们内部听，提出问题、再整改，以此反复。所有的好分享除了套路更多的还是建立在多加练习、熟能生巧、以勤补挫的基础上的。大家千万不要以为会了套路就会打拳了，这仅仅只是招式，内功还是要靠自己一点一点，日积月累而成的。&lt;/p&gt;

</description>
        <pubDate>Thu, 15 Jun 2017 00:00:00 +0800</pubDate>
        <link>http://www.94geek.com/blog/2017/how-do-topic/</link>
        <guid isPermaLink="true">http://www.94geek.com/blog/2017/how-do-topic/</guid>
      </item>
    
  </channel>
</rss>
